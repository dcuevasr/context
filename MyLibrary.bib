
@misc{_APA_,
  title = {{{APA PsycNet}}},
  howpublished = {https://doi.apa.org/doiLanding?doi=10.1037\%2Fa0017808}
}

@misc{_APA_a,
  title = {{{APA PsycNet}}},
  howpublished = {https://doi.apa.org/doiLanding?doi=10.1037\%2Fxlm0000463}
}

@misc{_APA_b,
  title = {{{APA PsycNet}}},
  howpublished = {https://doi.apa.org/doiLanding?doi=10.1037\%2F0022-3514.52.3.500}
}

@misc{_Automatic_,
  title = {Automatic {{LQR}} Tuning Based on {{Gaussian}} Process Global Optimization - {{IEEE Conference Publication}}},
  howpublished = {https://ieeexplore.ieee.org/document/7487144}
}

@misc{_Bayesian_,
  title = {Bayesian Model Reduction and Empirical {{Bayes}} for Group ({{DCM}}) Studies},
  howpublished = {http://www.sciencedirect.com/science/article/pii/S105381191501037X}
}

@misc{_PLOS_,
  title = {{{PLOS Computational Biology}}: {{Intrinsic Valuation}} of {{Information}} in {{Decision Making}} under {{Uncertainty}}},
  howpublished = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005020}
}

@misc{_Quantifying_,
  title = {Quantifying {{Generalization}} from {{Trial}}-by-{{Trial Behavior}} of {{Adaptive Systems}} That {{Learn}} with {{Basis Functions}}: {{Theory}} and {{Experiments}} in {{Human Motor Control}} | {{Journal}} of {{Neuroscience}}},
  howpublished = {https://www.jneurosci.org/content/23/27/9032.long}
}

@misc{_Temporal_,
  title = {Temporal Discounting in Choice between Delayed Rewards: The Role of Age and Income - {{PubMed}}},
  howpublished = {https://pubmed.ncbi.nlm.nih.gov/8726373/}
}

@misc{_Temporal_a,
  title = {Temporal Discounting in Choice between Delayed Rewards: {{The}} Role of Age and Income. - {{PsycNET}}},
  howpublished = {https://content.apa.org/record/1996-03617-009}
}

@misc{_Temporal_b,
  title = {Temporal Discounting in Choice between Delayed Rewards: {{The}} Role of Age and Income. - {{PsycNET}}},
  shorttitle = {Temporal Discounting in Choice between Delayed Rewards},
  abstract = {APA PsycNet DoiLanding page},
  howpublished = {/doiLanding?doi=10.1037\%2F0882-7974.11.1.79},
  language = {en}
}

@misc{_Web_,
  title = {Web of {{Science}} [v.5.34] - {{Web}} of {{Science Core Collection Full Record}}},
  howpublished = {http://apps.webofknowledge.com/full\_record.do?product=WOS\&search\_mode=GeneralSearch\&qid=2\&SID=D3FeaxA1qKJSUsGAcqZ\&page=1\&doc=5},
  keywords = {theory of mind}
}

@misc{_Zotero_,
  title = {Zotero | {{Downloads}}},
  howpublished = {https://www.zotero.org/download/}
}

@article{Abraham_Maintaining_2004,
  title = {Maintaining {{Accuracy}} at the {{Expense}} of {{Speed}}: {{Stimulus Similarity Defines Odor Discrimination Time}} in {{Mice}}},
  shorttitle = {Maintaining {{Accuracy}} at the {{Expense}} of {{Speed}}},
  author = {Abraham, Nixon M. and Spors, Hartwig and Carleton, Alan and Margrie, Troy W. and Kuner, Thomas and Schaefer, Andreas T.},
  year = {2004},
  month = dec,
  volume = {44},
  pages = {865--876},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2004.11.017},
  abstract = {Odor discrimination times and their dependence on stimulus similarity were evaluated to test temporal and spatial models of odor representation in mice. In a go/no-go operant conditioning paradigm, discrimination accuracy and time were determined for simple monomolecular odors and binary mixtures of odors. Mice discriminated simple odors with an accuracy exceeding 95\%. Binary mixtures evoking highly overlapping spatiotemporal patterns of activity in the olfactory bulb were discriminated equally well. However, while discriminating simple odors in less than 200 ms, mice required 70\textendash 100 ms more time to discriminate highly similar binary mixtures. We conclude that odor discrimination in mice is fast and stimulus dependent. Thus, the underlying neuronal mechanisms act on a fast timescale, requiring only a brief epoch of odor-specific spatiotemporal representations to achieve rapid discrimination of dissimilar odors. The fine discrimination of highly similar stimuli, however, requires temporal integration of activity, suggesting a tradeoff between accuracy and speed.},
  journal = {Neuron},
  number = {5}
}

@article{Acuna_Structure_2010,
  title = {Structure {{Learning}} in {{Human Sequential Decision}}-{{Making}}},
  author = {Acu{\~n}a, Daniel E. and Schrater, Paul},
  year = {2010},
  month = feb,
  volume = {6},
  pages = {e1001003},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1001003},
  abstract = {Author Summary Every decision-making experiment has a structure that specifies how rewards are obtained, which is usually explained to the subject at the beginning of the experiment. Participants frequently fail to act as if they understand the experimental structure, even in tasks as simple as determining which of two biased coins they should choose to maximize the number of trials that produce ``heads''. We hypothesize that participants' behavior is not driven by top-down instructions\textemdash rather, participants must learn through experience how the rewards are generated. We formalize this hypothesis using a fully rational optimal Bayesian reinforcement learning approach that models optimal structure learning in sequential decision making. In an experimental test of structure learning in humans, we show that humans learn reward structure from experience in a near optimal manner. Our results demonstrate that behavior purported to show that humans are error-prone and suboptimal decision makers can result from an optimal learning approach. Our findings provide a compelling new family of rational hypotheses for behavior previously deemed irrational, including under- and over-exploration.},
  journal = {PLOS Comput Biol},
  keywords = {Agent-based modeling,Behavior,Decision Making,Human learning,Learning,machine learning,Machine learning algorithms,Probability distribution},
  number = {12}
}

@article{Adams_Bayesian_2007,
  title = {Bayesian Online Changepoint Detection},
  author = {Adams, Ryan P. and MacKay, David J.C.},
  year = {2007},
  journal = {Cambridge, UK}
}

@article{Adams_Predictions_2013,
  title = {Predictions Not Commands: Active Inference in the Motor System},
  shorttitle = {Predictions Not Commands},
  author = {Adams, Rick A. and Shipp, Stewart and Friston, Karl J.},
  year = {2013},
  month = may,
  volume = {218},
  pages = {611--643},
  issn = {1863-2653},
  doi = {10.1007/s00429-012-0475-5},
  abstract = {The descending projections from motor cortex share many features with top-down or backward connections in visual cortex; for example, corticospinal projections originate in infragranular layers, are highly divergent and (along with descending cortico-cortical projections) target cells expressing NMDA receptors. This is somewhat paradoxical because backward modulatory characteristics would not be expected of driving motor command signals. We resolve this apparent paradox using a functional characterisation of the motor system based on Helmholtz's ideas about perception; namely, that perception is inference on the causes of visual sensations. We explain behaviour in terms of inference on the causes of proprioceptive sensations. This explanation appeals to active inference, in which higher cortical levels send descending proprioceptive predictions, rather than motor commands. This process mirrors perceptual inference in sensory cortex, where descending connections convey predictions, while ascending connections convey prediction errors. The anatomical substrate of this recurrent message passing is a hierarchical system consisting of functionally asymmetric driving (ascending) and modulatory (descending) connections: an arrangement that we show is almost exactly recapitulated in the motor system, in terms of its laminar, topographic and physiological characteristics. This perspective casts classical motor reflexes as minimising prediction errors and may provide a principled explanation for why motor cortex is agranular.},
  journal = {Brain Structure \& Function},
  number = {3},
  pmcid = {PMC3637647},
  pmid = {23129312}
}

@article{Afraimovich_origin_2004,
  title = {On the Origin of Reproducible Sequential Activity in Neural Circuits},
  author = {Afraimovich, V S and Zhigulin, V P and Rabinovich, M I},
  year = {2004},
  month = dec,
  volume = {14},
  pages = {1123--1129},
  issn = {1054-1500},
  doi = {10.1063/1.1819625},
  abstract = {Robustness and reproducibility of sequential spatio-temporal responses is an essential feature of many neural circuits in sensory and motor systems of animals. The most common mathematical images of dynamical regimes in neural systems are fixed points, limit cycles, chaotic attractors, and continuous attractors (attractive manifolds of neutrally stable fixed points). These are not suitable for the description of reproducible transient sequential neural dynamics. In this paper we present the concept of a stable heteroclinic sequence (SHS), which is not an attractor. SHS opens the way for understanding and modeling of transient sequential activity in neural circuits. We show that this new mathematical object can be used to describe robust and reproducible sequential neural dynamics. Using the framework of a generalized high-dimensional Lotka-Volterra model, that describes the dynamics of firing rates in an inhibitory network, we present analytical results on the existence of the SHS in the phase space of the network. With the help of numerical simulations we confirm its robustness in presence of noise in spite of the transient nature of the corresponding trajectories. Finally, by referring to several recent neurobiological experiments, we discuss possible applications of this new concept to several problems in neuroscience.},
  journal = {Chaos (Woodbury, N.Y.)},
  keywords = {Action Potentials,Animals,Biological Clocks,Computer Simulation,Humans,Membrane Potentials,Models; Neurological,Nerve Net,Neural Inhibition,Neurons,Nonlinear Dynamics,Synaptic Transmission},
  language = {eng},
  number = {4},
  pmid = {15568926}
}

@article{al-Nowaihi_note_2008,
  title = {A Note on the Utility Function under Prospect Theory},
  author = {{al-Nowaihi}, Ali and Bradley, Ian and Dhami, Sanjit},
  year = {2008},
  month = may,
  volume = {99},
  pages = {337--339},
  issn = {0165-1765},
  doi = {10.1016/j.econlet.2007.08.004},
  abstract = {We show that preference-homogeneity and loss-aversion are necessary and sufficient for the value function to have the power form with identical powers for gains and losses and for the probability weighting functions for gains and losses to be identical.},
  journal = {Economics Letters},
  keywords = {Functional equations,Preference homogeneity,Prospect theory},
  number = {2}
}

@article{Alexander_Hierarchical_2015,
  title = {Hierarchical {{Error Representation}}: {{A Computational Model}} of {{Anterior Cingulate}} and {{Dorsolateral Prefrontal Cortex}}},
  shorttitle = {Hierarchical {{Error Representation}}},
  author = {Alexander, William H. and Brown, Joshua W.},
  year = {2015},
  month = sep,
  volume = {27},
  pages = {2354--2410},
  issn = {0899-7667},
  doi = {10.1162/NECO_a_00779},
  abstract = {Anterior cingulate and dorsolateral prefrontal cortex (ACC and dlPFC, respectively) are core components of the cognitive control network. Activation of these regions is routinely observed in tasks that involve monitoring the external environment and maintaining information in order to generate appropriate responses. Despite the ubiquity of studies reporting coactivation of these two regions, a consensus on how they interact to support cognitive control has yet to emerge. In this letter, we present a new hypothesis and computational model of ACC and dlPFC. The error representation hypothesis states that multidimensional error signals generated by ACC in response to surprising outcomes are used to train representations of expected error in dlPFC, which are then associated with relevant task stimuli. Error representations maintained in dlPFC are in turn used to modulate predictive activity in ACC in order to generate better estimates of the likely outcomes of actions. We formalize the error representation hypothesis in a new computational model based on our previous model of ACC. The hierarchical error representation (HER) model of ACC/dlPFC suggests a mechanism by which hierarchically organized layers within ACC and dlPFC interact in order to solve sophisticated cognitive tasks. In a series of simulations, we demonstrate the ability of the HER model to autonomously learn to perform structured tasks in a manner comparable to human performance, and we show that the HER model outperforms current deep learning networks by an order of magnitude.},
  journal = {Neural Computation},
  keywords = {unread},
  number = {11}
}

@article{Alexander_Medial_2011,
  title = {Medial Prefrontal Cortex as an Action-Outcome Predictor},
  author = {Alexander, William H. and Brown, Joshua W.},
  year = {2011},
  month = oct,
  volume = {14},
  pages = {1338--1344},
  issn = {1097-6256},
  doi = {10.1038/nn.2921},
  abstract = {The medial prefrontal cortex (mPFC) and especially anterior cingulate cortex is central to higher cognitive function and many clinical disorders, yet its basic function remains in dispute. Various competing theories of mPFC have treated effects of errors, conflict, error likelihood, volatility and reward, using findings from neuroimaging and neurophysiology in humans and monkeys. No single theory has been able to reconcile and account for the variety of findings. Here we show that a simple model based on standard learning rules can simulate and unify an unprecedented range of known effects in mPFC. The model reinterprets many known effects and suggests a new view of mPFC, as a region concerned with learning and predicting the likely outcomes of actions, whether good or bad. Cognitive control at the neural level is then seen as a result of evaluating the probable and actual outcomes of one's actions.},
  copyright = {\textcopyright{} 2011 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  journal = {Nature Neuroscience},
  language = {en},
  number = {10}
}

@book{Anderson_Learning_2000,
  title = {Learning and Memory: {{An}} Integrated Approach, 2nd Ed},
  shorttitle = {Learning and Memory},
  author = {Anderson, John Robert},
  year = {2000},
  pages = {xviii, 487},
  publisher = {{John Wiley \& Sons Inc}},
  address = {{Hoboken, NJ, US}},
  abstract = {Examines the current state of the traditional learning and cognitive fields. Chapter 1 reviews the history of learning and memory research. It explains ideas and paradigms that have dominated the field and why they became prominent. Chapters 2\textendash 4 describe the modern understanding of learning and memory through animal learning, classical conditioning, instrumental conditioning, and reinforcement. Chapters 5\textendash 8 focus on human learning and memory. Chapter 5 examines how information is processed and stored in temporary memories when it is initially received while Chapter 6 investigates how a permanent record of this information is built up in long-term memory. Chapter 7 explores how information is maintained over potentially long periods of time and what underlies forgetting. Chapter 8 looks at the different ways in which information can be retrieved when it is needed. Chapter 9 reviews the learning phenomena that arise when potentially complex skills are acquired. Chapter 10 focuses on issues of inductive learning, how people discover things about the structure of their environment. The final chapter is concerned with the major application of research on learning and memory to education. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  isbn = {978-0-471-24925-2},
  keywords = {Cognitive Processes,Forgetting,Human Information Storage,Learning,Memory},
  series = {Learning and Memory: {{An}} Integrated Approach, 2nd Ed}
}

@article{Anderson_Role_2016,
  title = {The {{Role}} of {{Dopamine}} in {{Value}}-{{Based Attentional Orienting}}},
  author = {Anderson, Brian A. and Kuwabara, Hiroto and Wong, Dean F. and Gean, Emily G. and Rahmim, Arman and Bra{\v s}i{\'c}, James R. and George, Noble and Frolov, Boris and Courtney, Susan M. and Yantis, Steven},
  year = {2016},
  month = feb,
  volume = {26},
  pages = {550--555},
  issn = {0960-9822},
  doi = {10.1016/j.cub.2015.12.062},
  journal = {Current Biology},
  keywords = {unread},
  language = {English},
  number = {4},
  pmid = {26877079}
}

@book{Anton_Insect_1999,
  title = {Insect {{Olfaction}}: {{Antennal Lobe}}},
  author = {Anton, S},
  year = {1999}
}

@article{Apps_role_2015,
  title = {The Role of Cognitive Effort in Subjective Reward Devaluation and Risky Decision-Making},
  author = {Apps, Matthew A. J. and Grima, Laura L. and Manohar, Sanjay and Husain, Masud},
  year = {2015},
  month = nov,
  volume = {5},
  pages = {16880},
  doi = {10.1038/srep16880},
  abstract = {Motivation is underpinned by cost-benefit valuations where costs\textemdash such as physical effort or outcome risk\textemdash are subjectively weighed against available rewards. However, in many environments risks pertain not to the variance of outcomes, but to variance in the possible levels of effort required to obtain rewards (effort risks). Moreover, motivation is often guided by the extent to which cognitive\textemdash not physical\textemdash effort devalues rewards (effort discounting). Yet, very little is known about the mechanisms that underpin the influence of cognitive effort risks or discounting on motivation. We used two cost-benefit decision-making tasks to probe subjective sensitivity to cognitive effort (number of shifts of spatial attention) and to effort risks. Our results show that shifts of spatial attention when monitoring rapidly presented visual stimuli are perceived as effortful and devalue rewards. Additionally, most people are risk-averse, preferring safe, known amounts of effort over risky offers. However, there was no correlation between their effort and risk sensitivity. We show for the first time that people are averse to variance in the possible amount of cognitive effort to be exerted. These results suggest that cognitive effort sensitivity and risk sensitivity are underpinned by distinct psychological and neurobiological mechanisms.},
  copyright = {2015 Nature Publishing Group},
  journal = {Scientific Reports},
  keywords = {saccades},
  language = {en}
}

@article{Arani_VariableMemory_1984,
  title = {A {{Variable}}-{{Memory Model}} of {{Visual Search}}},
  author = {Arani, T. and Karwan, M. H. and Drury, C. G.},
  year = {1984},
  month = dec,
  volume = {26},
  pages = {631--639},
  issn = {0018-7208, 1547-8181},
  doi = {10.1177/001872088402600602},
  journal = {Human Factors: The Journal of the Human Factors and Ergonomics Society},
  language = {en},
  number = {6},
  pmid = {6532941}
}

@article{Arber_Ego_2017,
  title = {Ego {{Depletion}} in {{Real}}-{{Time}}: {{An Examination}} of the {{Sequential}}-{{Task Paradigm}}},
  shorttitle = {Ego {{Depletion}} in {{Real}}-{{Time}}},
  author = {Arber, Madeleine M. and Ireland, Michael J. and Feger, Roy and Marrington, Jessica and Tehan, Joshua and Tehan, Gerald},
  year = {2017},
  volume = {8},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2017.01672},
  abstract = {Current research into self-control that is based on the sequential task methodology is currently at an impasse. The sequential task methodology involves completing a task that is designed to tax self-control resources which in turn has carry-over effects on a second, unrelated task. The current impasse is in large part due to the lack of empirical research that tests explicit assumptions regarding the initial task. Five studies test one key, untested assumption underpinning strength (finite resource) models of self-regulation: Performance will decline over time on a task that depletes self-regulatory resources. In the aftermath of high profile replication failures using a popular letter-crossing task and subsequent criticisms of that task, the current studies examined whether depletion effects would occur in real time using letter-crossing tasks that did not invoke habit-forming and breaking, and whether these effects were moderated by administration type (paper and pencil versus computer administration). Sample makeup and sizes as well as response formats were also varied across the studies. The five studies yielded a clear and consistent pattern of increasing performance deficits (errors) as a function of time spent on task with generally large effects and in the fifth study the strength of negative transfer effects to a working memory task were related to individual differences in depletion. These results demonstrate that some form of depletion is occurring on letter-crossing tasks though whether an internal regulatory resource reservoir or some other factor is changing across time remains an important question for future research.},
  journal = {Frontiers in Psychology},
  keywords = {Ego Depletion,letter-crossing task,Self-regulation,Sequential task,strength model},
  language = {English}
}

@article{Aron_Neural_2007,
  title = {The {{Neural Basis}} of {{Inhibition}} in {{Cognitive Control}}},
  author = {Aron, Adam R.},
  year = {2007},
  month = jun,
  volume = {13},
  pages = {214--228},
  issn = {1073-8584, 1089-4098},
  doi = {10.1177/1073858407299288},
  abstract = {The concept of ``inhibition'' is widely used in synaptic, circuit, and systems neuroscience, where it has a clear meaning because it is clearly observable. The concept is also ubiquitous in psychology. One common use is to connote an active/willed process underlying cognitive control. Many authors claim that subjects execute cognitive control over unwanted stimuli, task sets, responses, memories, and emotions by inhibiting them, and that frontal lobe damage induces distractibility, impulsivity, and perseveration because of damage to an inhibitory mechanism. However, with the exception of the motor domain, the notion of an active inhibitory process underlying cognitive control has been heavily challenged. Alternative explanations have been provided that explain cognitive control without recourse to inhibition as concept, mechanism, or theory. This article examines the role that neuroscience can play when examining whether the psychological concept of active inhibition can be meaningfully applied in cognitive control research. NEUROSCIENTIST 13(3):214\textemdash 228, 2007.},
  journal = {The Neuroscientist},
  keywords = {Executive function,Inhibitory mechanisms,Suppression},
  language = {en},
  number = {3},
  pmid = {17519365}
}

@article{Ashby_Dangers_1994,
  title = {On the {{Dangers}} of {{Averaging Across Subjects When Using Multidimensional Scaling}} or the {{Similarity}}-{{Choice Model}}},
  author = {Ashby, F. Gregory and Maddox, W. Todd and Lee, W. William},
  year = {1994},
  month = may,
  volume = {5},
  pages = {144--151},
  issn = {0956-7976},
  doi = {10.1111/j.1467-9280.1994.tb00651.x},
  abstract = {When ratings of judged similarity or frequencies of stimulus identification are averaged across subjects, the psychological structure of the data is fundamentally changed. Regardless of the structure of the individual-subject data, the averaged similarity data will likely be well fit by a standard multidimensional scaling model, and the averaged identification data will likely be well fit by the similarity-choice model. In fact, both models often provide excellent fits to averaged data, even if they fail to fit the data of each individual subject. Thus, a good fit of either model to averaged data cannot be taken as evidence that the model describes the psychological structure that characterizes individual subjects. We hypothesize that these effects are due to the increased symmetry that is a mathematical consequence of the averaging operation.},
  journal = {Psychological Science},
  language = {en},
  number = {3}
}

@article{Assisi_Synaptic_2012,
  title = {Synaptic Inhibition Controls Transient Oscillatory Synchronization in a Model of the Insect Olfactory System},
  author = {Assisi, Collins and Bazhenov, Maxim},
  year = {2012},
  volume = {5},
  pages = {7},
  issn = {1662-6443},
  doi = {10.3389/fneng.2012.00007},
  abstract = {In a variety of neuronal systems it has been hypothesized that inhibitory interneurons corral principal neurons into synchronously firing groups that encode sensory information and sub-serve behavior (Buzs\'aki and Chrobak, 1995; Buzs\'aki, 2008). This mechanism is particularly relevant to the olfactory system where spatiotemporal patterns of projection neuron (PN) activity act as robust markers of odor attributes (Laurent et al., 1996; Wehr and Laurent, 1996). In the insect antennal lobe (AL), a network of local inhibitory interneurons arborizes extensively throughout the AL (Leitch and Laurent, 1996) providing inhibitory input to the cholinergic PNs. Our theoretical work has attempted to elaborate the exact role of inhibition in the generation of odor specific PN responses (Bazhenov et al., 2001a,b; Assisi et al., 2011). In large-scale AL network models we characterized the inhibitory sub-network by its coloring (Assisi et al., 2011) and showed that it can entrain excitatory PNs to the odor specific patterns of transient synchronization. In this focused review, we further examine the dynamics of entrainment in more detail by simulating simple model networks in various parameter regimes. Our simulations in conjunction with earlier studies point to the key role played by lateral (between inhibitory interneurons) and feedback (from inhibitory interneurons to principal cells) inhibition in the generation of experimentally observed patterns of transient synchrony.},
  journal = {Frontiers in neuroengineering},
  language = {eng},
  pmcid = {PMC3328766},
  pmid = {22529800}
}

@article{Audrain-McGovern_Does_2009,
  title = {Does Delay Discounting Play an Etiological Role in Smoking or Is It a Consequence of Smoking?},
  author = {{Audrain-McGovern}, Janet and Rodriguez, Daniel and Epstein, Leonard H. and Cuevas, Jocelyn and Rodgers, Kelli and Wileyto, E. Paul},
  year = {2009},
  month = aug,
  volume = {103},
  pages = {99--106},
  issn = {0376-8716},
  doi = {10.1016/j.drugalcdep.2008.12.019},
  abstract = {Although higher delay discounting rates have been linked to cigarette smoking, little is known about the stability of delay discounting, whether delay discounting promotes smoking acquisition, whether smoking contributes to impulsive choices, or if different relationships exist in distinct subgroups. This study sought to fill these gaps within a prospective longitudinal cohort study (N=947) spanning mid adolescence to young adulthood (age 15 to 21 years old). Smoking and delay discounting were measured across time. Covariates included peer and household smoking, academic performance, depression, novelty seeking, inattention and hyperactivity/impulsivity symptoms, and alcohol and marijuana use. The associated processes Latent Growth Curve Modeling (LGCM) with paths from the delay discounting level factor (baseline measure) and the trend factor (slope) to the smoking trend factor (slope) fit the data well, X2(19, n=947) = 15.37, p=.70, CFI=1.00, RMSEA=0, WRMR=.36. The results revealed that delay discounting did not change significantly across time. Baseline delay discounting had a significant positive effect on smoking trend ({$\beta$}=.08, z=2.16, p=.03). A standard deviation (SD=1.41) increase in baseline delay discounting resulted in an 11\% increase (OR=1.11, 95\% CI= 1.03, 1.23) in the odds of smoking uptake. The alternative path LCGM revealed that smoking did not significantly impact delay discounting (p's {$>$} .05). Growth Mixture Modeling identified three smoking trajectories: nonsmokers, early/fast smoking adopters, and slow smoking progressors. Delay discounting was higher in the smoking versus nonsmoking trajectories, but did not discriminate between the smoking trajectories, despite different acquisition patterns. Delay discounting may provide a variable by which to screen for smoking vulnerability and help identify subgroups to target for more intensive smoking prevention efforts that include novel behavioral components directed toward aspects of impulsivity.},
  journal = {Drug and alcohol dependence},
  number = {3},
  pmcid = {PMC2743449},
  pmid = {19443136}
}

@article{Averbeck_Theory_2015,
  title = {Theory of {{Choice}} in {{Bandit}}, {{Information Sampling}} and {{Foraging Tasks}}},
  author = {Averbeck, Bruno B.},
  year = {2015},
  month = mar,
  volume = {11},
  pages = {e1004164},
  doi = {10.1371/journal.pcbi.1004164},
  abstract = {Author Summary Numerous choice tasks have been used to study decision processes. Some of these choice tasks, specifically n-armed bandit, information sampling and foraging tasks, pose choices that trade-off immediate and future reward. Specifically, the best choice may not be the choice that pays off the highest reward immediately, and exploration of unknown options vs. exploiting known options can be a normatively useful strategy. We characterized the optimal choice strategies across these tasks using Markov Decision Processes (MDPs). The MDP framework can characterize optimal choice strategies when choices are affected by the value of future rewards. We found that uncertainty and time horizon have important effects on the choice strategies in these tasks. Specifically, in bandit and information sampling tasks, increasing uncertainty increases the value of exploring choice options that tend to pay off in the future, while decreasing uncertainty increases the value of choice options that pay off immediately. These effects are increased when time horizons are longer. Foraging tasks differ in that uncertainty plays a minimal role. However, time horizon is still important in foraging. Specifically, for long time horizons, travel delays to rewards become less relevant.},
  journal = {PLoS Comput Biol},
  number = {3}
}

@article{Ayhan_application_2011,
  title = {An Application of Small-World Cellular Neural Networks on Odor Classification},
  author = {Ayhan, Tuba},
  year = {2011},
  abstract = {Many biological networks are constructed with both regular and random connections between neurons. Bio-inspired systems should prevent this mixed topology of biological networks while the artificial system is still realizable. In this work, a bio-inspired network which has many analog realizations, Cellular Neural Network (CNN) is investigated under existing random connections in addition to its regular connections: Small-World Cellular Neural Network (SWCNN). Antennal Lobe, an organ in the olfaction system of insects, is modeled with SWCNN by extending the network with the use of two types of processors on the same network. The model combined with a classifier, SVM and overall system is tested with a five-class odor classification problem. While all neurons are connected to each other with direct or indirect connections in CNNs, the idea of short-cuts does not provide an improvement in classification performance but the results show that the fault tolerance ability of SWCNN is better than the classical CNN.},
  keywords = {Neural network,Olfaction,Small-world}
}

@article{Baene_Brain_2015,
  title = {Brain {{Circuit}} for {{Cognitive Control Is Shared}} by {{Task}} and {{Language Switching}}},
  author = {Baene, Wouter De and Duyck, Wouter and Brass, Marcel and Carreiras, Manuel},
  year = {2015},
  month = jul,
  doi = {10.1162/jocn_a_00817},
  abstract = {Controlling multiple languages during speech production is believed to rely on functional mechanisms that are (at least partly) shared with domain-general cognitive control in early, highly proficient bilinguals. Recent neuroimaging results have indeed suggested a certain degree of neural overlap between language control and nonverbal cognitive control in bilinguals. However, this evidence is only indirect. Direct evidence for neural overlap between language control and nonverbal cognitive control can only be provided if two prerequisites are met: Language control and nonverbal cognitive control should be compared within the same participants, and the task requirements of both conditions should be closely matched. To provide such direct evidence for the first time, we used fMRI to examine the overlap in brain activation between switch-specific activity in a linguistic switching task and a closely matched nonlinguistic switching task, within participants, in early, highly proficient Spanish\textendash Basque bilingua...},
  journal = {Journal of Cognitive Neuroscience},
  language = {en}
}

@article{Bailey_Neural_2016,
  title = {Neural Substrates Underlying Effort, Time, and Risk-Based Decision Making in Motivated Behavior},
  author = {Bailey, Matthew R. and Simpson, Eleanor H. and Balsam, Peter D.},
  year = {2016},
  month = sep,
  volume = {133},
  pages = {233--256},
  issn = {1074-7427},
  doi = {10.1016/j.nlm.2016.07.015},
  abstract = {All mobile organisms rely on adaptive motivated behavior to overcome the challenges of living in an environment in which essential resources may be limited. A variety of influences ranging from an organism's environment, experiential history, and physiological state all influence a cost-benefit analysis which allows motivation to energize behavior and direct it toward specific goals. Here we review the substantial amount of research aimed at discovering the interconnected neural circuits which allow organisms to carry-out the cost-benefit computations which allow them to behave in adaptive ways. We specifically focus on how the brain deals with different types of costs, including effort requirements, delays to reward and payoff riskiness. An examination of this broad literature highlights the importance of the extended neural circuits which enable organisms to make decisions about these different types of costs. This involves Cortical Structures, including the Anterior Cingulate Cortex (ACC), the Orbital Frontal Cortex (OFC), the Infralimbic Cortex (IL), and prelimbic Cortex (PL), as well as the Baso-Lateral Amygdala (BLA), the Nucleus Accumbens (NAcc), the Ventral Pallidal (VP), the Sub Thalamic Nucleus (STN) among others. Some regions are involved in multiple aspects of cost-benefit computations while the involvement of other regions is restricted to information relating to specific types of costs.},
  journal = {Neurobiology of Learning and Memory},
  keywords = {Animal behavior,Behavioral activation,Cost-benefit computation,Delay-discounting,Effort-based decision making,Motivation,Risk-discounting}
}

@article{Baker_Dissociated_2011,
  title = {Dissociated Roles of the Anterior Cingulate Cortex in Reward and Conflict Processing as Revealed by the Feedback Error-Related Negativity and {{N200}}},
  author = {Baker, Travis E. and Holroyd, Clay B.},
  year = {2011},
  month = apr,
  volume = {87},
  pages = {25--34},
  issn = {0301-0511},
  doi = {10.1016/j.biopsycho.2011.01.010},
  abstract = {The reinforcement learning theory of the error-related negativity (ERN) holds that the impact of reward signals carried by the midbrain dopamine system modulates activity of the anterior cingulate cortex (ACC), alternatively disinhibiting and inhibiting the ACC following unpredicted error and reward events, respectively. According to a recent formulation of the theory, activity that is intrinsic to the ACC produces a component of the event-related brain potential (ERP) called the N200, and following unpredicted rewards, the N200 is suppressed by extrinsically applied positive dopamine reward signals, resulting in an ERP component called the feedback-ERN (fERN). Here we demonstrate that, despite extensive spatial and temporal overlap between the two ERP components, the functional processes indexed by the N200 (conflict) and the fERN (reward) are dissociable. These results point toward avenues for future investigation.},
  journal = {Biological Psychology},
  keywords = {Anterior cingulate cortex,Event-related brain potentials,Feedback error-related negativity,N200,Reinforcement learning,Response conflict,Reward positivity},
  number = {1}
}

@article{Balleine_Goaldirected_1998,
  title = {Goal-Directed Instrumental Action: Contingency and Incentive Learning and Their Cortical Substrates},
  shorttitle = {Goal-Directed Instrumental Action},
  author = {Balleine, B. W. and Dickinson, A.},
  year = {1998 Apr-May},
  volume = {37},
  pages = {407--419},
  issn = {0028-3908},
  abstract = {Instrumental behaviour is controlled by two systems: a stimulus-response habit mechanism and a goal-directed process that involves two forms of learning. The first is learning about the instrumental contingency between the response and reward, whereas the second consists of the acquisition of incentive value by the reward. Evidence for contingency learning comes from studies of reward devaluation and from demonstrations that instrumental performance is sensitive not only the probability of contiguous reward but also to the probability of unpaired rewards. The process of incentive learning is evident in the acquisition of control over performance by primary motivational states. Preliminary lesion studies of the rat suggest that the prelimbic area of prefrontal cortex plays a role in the contingency learning, whereas the incentive learning for food rewards involves the insular cortex.},
  journal = {Neuropharmacology},
  keywords = {Adaptation; Psychological,Animals,Behavior; Animal,Cerebral Cortex,Conditioning; Operant,Goals,Humans,Motivation},
  language = {eng},
  number = {4-5},
  pmid = {9704982}
}

@article{Balleine_Goaldirected_1998a,
  title = {Goal-Directed Instrumental Action: Contingency and Incentive Learning and Their Cortical Substrates},
  shorttitle = {Goal-Directed Instrumental Action},
  author = {Balleine, Bernard W and Dickinson, Anthony},
  year = {1998},
  month = apr,
  volume = {37},
  pages = {407--419},
  issn = {0028-3908},
  doi = {10.1016/S0028-3908(98)00033-1},
  abstract = {Instrumental behaviour is controlled by two systems: a stimulus\textendash response habit mechanism and a goal-directed process that involves two forms of learning. The first is learning about the instrumental contingency between the response and reward, whereas the second consists of the acquisition of incentive value by the reward. Evidence for contingency learning comes from studies of reward devaluation and from demonstrations that instrumental performance is sensitive not only the probability of contiguous reward but also to the probability of unpaired rewards. The process of incentive learning is evident in the acquisition of control over performance by primary motivational states. Preliminary lesion studies of the rat suggest that the prelimibic area of prefrontal cortex plays a role in the contingency learning, whereas the incentive learning for food rewards involves the insular cortex.},
  journal = {Neuropharmacology},
  keywords = {Cortex,Instrumental conditioning,Rats,Reinforcement,Reward},
  number = {4}
}

@article{Bargmann_Comparative_2006,
  title = {Comparative Chemosensation from Receptors to Ecology},
  author = {Bargmann, Cornelia I.},
  year = {2006},
  month = nov,
  volume = {444},
  pages = {295--301},
  issn = {0028-0836},
  doi = {10.1038/nature05402},
  abstract = {Odour perception is initiated by specific interactions between odorants and a large repertoire of receptors in olfactory neurons. During the past few years, considerable progress has been made in tracing olfactory perception from the odorant receptor protein to the activity of olfactory neurons to higher processing centres and, ultimately, to behaviour. The most complete picture is emerging for the simplest olfactory system studied \textemdash{} that of the fruitfly Drosophila melanogaster. Comparison of rodent, insect and nematode olfaction reveals surprising differences and unexpected similarities among chemosensory systems.},
  copyright = {\textcopyright{} 2006 Nature Publishing Group},
  journal = {Nature},
  language = {en},
  number = {7117}
}

@article{Barron_Online_2013,
  title = {Online Evaluation of Novel Choices by Simultaneous Representation of Multiple Memories},
  author = {Barron, Helen C. and Dolan, Raymond J. and Behrens, Timothy E. J.},
  year = {2013},
  month = oct,
  volume = {16},
  pages = {1492--1498},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/nn.3515},
  abstract = {This study used fMRI repetition suppression to demonstrate that human subjects can represent and evaluate novel choice options by invoking multiple memories for previous experiences in hippocampus and medial prefrontal cortex.},
  copyright = {2013 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  journal = {Nature Neuroscience},
  language = {en},
  number = {10}
}

@article{Barron_Reassessing_2015,
  title = {Reassessing {{VMPFC}}: Full of Confidence?},
  shorttitle = {Reassessing {{VMPFC}}},
  author = {Barron, Helen C. and Garvert, Mona M. and Behrens, Timothy E. J.},
  year = {2015},
  month = aug,
  volume = {18},
  pages = {1064--1066},
  issn = {1097-6256},
  doi = {10.1038/nn.4076},
  abstract = {The confidence that we place in our decisions can affect the judgments themselves. The BOLD signal in ventromedial prefrontal cortex automatically reflects the relationship between confidence and judgments on a range of tasks.},
  copyright = {\textcopyright{} 2015 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  journal = {Nature Neuroscience},
  language = {en},
  number = {8}
}

@article{Barthelme_Expectation_2014,
  title = {Expectation {{Propagation}} for {{Likelihood}}-{{Free Inference}}},
  author = {Barthelm{\'e}, Simon and Chopin, Nicolas},
  year = {2014},
  month = jan,
  volume = {109},
  pages = {315--333},
  issn = {0162-1459},
  doi = {10.1080/01621459.2013.864178},
  abstract = {Many models of interest in the natural and social sciences have no closed-form likelihood function, which means that they cannot be treated using the usual techniques of statistical inference. In the case where such models can be efficiently simulated, Bayesian inference is still possible thanks to the approximate Bayesian computation (ABC) algorithm. Although many refinements have been suggested, ABC inference is still far from routine. ABC is often excruciatingly slow due to very low acceptance rates. In addition, ABC requires introducing a vector of ``summary statistics'' s(y), the choice of which is relatively arbitrary, and often require some trial and error, making the whole process laborious for the user. We introduce in this work the EP-ABC algorithm, which is an adaptation to the likelihood-free context of the variational approximation algorithm known as expectation propagation. The main advantage of EP-ABC is that it is faster by a few orders of magnitude than standard algorithms, while producing an overall approximation error that is typically negligible. A second advantage of EP-ABC is that it replaces the usual global ABC constraint {$\Vert$}s(y) - s(y{$\star$}){$\Vert$} {$\leqslant$} {$\epsilon$}, where s(y{$\star$}) is the vector of summary statistics computed on the whole dataset, by n local constraints of the form {$\Vert$}si(yi) - si(y{$\star$}i){$\Vert$} {$\leqslant$} {$\epsilon$} that apply separately to each data point. In particular, it is often possible to take si(yi) = yi, making it possible to do away with summary statistics entirely. In that case, EP-ABC makes it possible to approximate directly the evidence (marginal likelihood) of the model. Comparisons are performed in three real-world applications that are typical of likelihood-free inference, including one application in neuroscience that is novel, and possibly too challenging for standard ABC techniques.},
  journal = {Journal of the American Statistical Association},
  keywords = {Approximate Bayesian computation,Approximate inference,Composite likelihood,Quasi-Monte Carlo},
  number = {505}
}

@article{Basile_Four_2015,
  title = {Four Converging Measures of Temporal Discounting and Their Relationships with Intelligence, Executive Functions, Thinking Dispositions, and Behavioral Outcomes},
  author = {Basile, Alexandra G. and Toplak, Maggie E.},
  year = {2015},
  month = jun,
  volume = {6},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2015.00728},
  abstract = {Temporal discounting is the tendency to devalue temporally distant rewards. Past studies have examined the k-value, the indifference point, and the area under the curve as dependent measures on this task. The current study included these three measures and a fourth measure, called the interest rate total score, which differentiated good from poor choices. The interest rate total score was based on scoring only those items in which the delayed choice should be preferred given the expected return based on simple interest rates. In addition, associations with several individual difference measures were examined including intelligence, executive functions (inhibition, working memory, and set-shifting), thinking dispositions [Need for Cognition and Consideration of Future Consequences (CFCs)] and engagement in substance use and gambling behavior. A staircase temporal discounting task was examined in a sample of 99 university students. Replicating previous studies, temporal discounting increased with longer delays to reward and decreased with higher reward magnitudes. A hyperbolic function accounted for more variance in temporal discounting than an exponential function. Reaction time at the indifference point was significantly longer than at the other choice points. The four dependent measures of temporal discounting were all significantly correlated and were also significantly associated with our individual difference measures. That is, the tendency to wait for a larger delayed reward on all of the temporal discounting measures was associated with higher intelligence, higher executive functions, and more CFCs. Associations between our measures of temporal discounting and outcomes related to substance use and gambling behavior were modest in our university sample.},
  journal = {Frontiers in Psychology},
  pmcid = {PMC4456858},
  pmid = {26097462}
}

@article{Bastos_Canonical_2012,
  title = {Canonical {{Microcircuits}} for {{Predictive Coding}}},
  author = {Bastos, Andre{\dbend}M and Usrey, W. {\dbend}Martin and Adams, Rick{\dbend}A and Mangun, George{\dbend}R and Fries, Pascal and Friston, Karl{\dbend}J},
  year = {2012},
  volume = {76},
  pages = {695--711},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2012.10.038},
  abstract = {This Perspective considers the influential notion of a canonical (cortical) microcircuit in light of recent theories about neuronal processing. Specifically, we conciliate quantitative studies of microcircuitry and the functional logic of neuronal computations. We revisit the established idea that message passing among hierarchical cortical areas implements a form of Bayesian inference - paying careful attention to the implications for intrinsic connections among neuronal populations. By deriving canonical forms for these computations, one can associate specific neuronal populations with specific computational roles. This analysis discloses a remarkable correspondence between the microcircuitry of the cortical column and the connectivity implied by predictive coding. Furthermore, it provides some intuitive insights into the functional asymmetries between feedforward and feedback connections and the characteristic frequencies over which they operate.},
  journal = {Neuron},
  number = {4}
}

@article{Bathellier_Dynamic_2008,
  title = {Dynamic {{Ensemble Odor Coding}} in the {{Mammalian Olfactory Bulb}}: {{Sensory Information}} at {{Different Timescales}}},
  shorttitle = {Dynamic {{Ensemble Odor Coding}} in the {{Mammalian Olfactory Bulb}}},
  author = {Bathellier, Brice and Buhl, Derek L. and Accolla, Riccardo and Carleton, Alan},
  year = {2008},
  month = feb,
  volume = {57},
  pages = {586--598},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2008.02.011},
  abstract = {Summary Neural firing discharges are often temporally patterned, but it is often ambiguous as to whether the temporal features of these patterns constitute a useful code. Here we show in the mouse olfactory bulb that ensembles of projection neurons respond with complex odor- and concentration-specific dynamic activity sequences developing below and above sniffing frequency. Based on this activity, almost optimal discrimination of presented odors was possible during single sniffs, consistent with reported behavioral data. Within a sniff cycle, slower features of the dynamics alone (\&gt;100 ms resolution, including mean firing rate) were sufficient for maximal discrimination. A smaller amount of information was also observed in faster features down to 20\textendash 40 ms resolution. Therefore, mitral cell ensemble activity contains information at different timescales that could be separately or complementarily exploited by downstream brain centers to make odor discriminations. Our results also support suggestive analogies in the dynamics of odor representations between insects and mammals.},
  journal = {Neuron},
  keywords = {SIGNALING,SYSBIO,SYSNEURO},
  number = {4}
}

@article{Baumeister_Ego_1998,
  title = {Ego Depletion: {{Is}} the Active Self a Limited Resource?},
  shorttitle = {Ego Depletion},
  author = {Baumeister, Roy F. and Bratslavsky, Ellen and Muraven, Mark and Tice, Dianne M.},
  year = {1998},
  volume = {74},
  pages = {1252--1265},
  issn = {1939-1315(Electronic),0022-3514(Print)},
  doi = {10.1037/0022-3514.74.5.1252},
  abstract = {Choice, active response, self-regulation, and other volition may all draw on a common inner resource. In Experiment 1, people who forced themselves to eat radishes instead of tempting chocolates subsequently quit faster on unsolvable puzzles than people who had not had to exert self-control over eating. In Experiment 2, making a meaningful personal choice to perform attitude-relevant behavior caused a similar decrement in persistence. In Experiment 3, suppressing emotion led to a subsequent drop in performance of solvable anagrams. In Experiment 4, an initial task requiring high self-regulation made people more passive (i.e., more prone to favor the passive-response option) . These results suggest that the self's capacity for active volition is limited and that a range of seemingly different, unrelated acts share a common resource. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  journal = {Journal of Personality and Social Psychology},
  keywords = {Choice Behavior,Ego,Self-Determination,Volition},
  number = {5}
}

@article{Bays_Computational_2007,
  title = {Computational Principles of Sensorimotor Control That Minimize Uncertainty and Variability},
  author = {Bays, Paul M. and Wolpert, Daniel M.},
  year = {2007},
  volume = {578},
  pages = {387--396},
  issn = {1469-7793},
  doi = {10.1113/jphysiol.2006.120121},
  abstract = {Sensory and motor noise limits the precision with which we can sense the world and act upon it. Recent research has begun to reveal computational principles by which the central nervous system reduces the sensory uncertainty and movement variability arising from this internal noise. Here we review the role of optimal estimation and sensory filtering in extracting the sensory information required for motor planning, and the role of optimal control, motor adaptation and impedance control in the specification of the motor output signal.},
  annotation = {\_eprint: https://physoc.onlinelibrary.wiley.com/doi/pdf/10.1113/jphysiol.2006.120121},
  copyright = {\textcopyright{} 2007 The Journal of Physiology \textcopyright{} 2007 The Physiological Society},
  journal = {The Journal of Physiology},
  language = {en},
  number = {2}
}

@article{Bazhenov_Fast_2005,
  title = {Fast {{Odor Learning Improves Reliability}} of {{Odor Responses}} in the {{Locust Antennal Lobe}}},
  author = {Bazhenov, Maxim and Stopfer, Mark and Sejnowski, Terrence J. and Laurent, Gilles},
  year = {2005},
  month = may,
  volume = {46},
  pages = {483--492},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2005.03.022},
  abstract = {Summary Recordings in the locust antennal lobe (AL) reveal activity-dependent, stimulus-specific changes in projection neuron (PN) and local neuron response patterns over repeated odor trials. During the first few trials, PN response intensity decreases, while spike time precision increases, and coherent oscillations, absent at first, quickly emerge. We examined this ``fast odor learning'' with a realistic computational model of the AL. Activity-dependent facilitation of AL inhibitory synapses was sufficient to simulate physiological recordings of fast learning. In addition, in experiments with noisy inputs, a network including synaptic facilitation of both inhibition and excitation responded with reliable spatiotemporal patterns from trial to trial despite the noise. A network lacking fast plasticity, however, responded with patterns that varied across trials, reflecting the input variability. Thus, our study suggests that fast olfactory learning results from stimulus-specific, activity-dependent synaptic facilitation and may improve the signal-to-noise ratio for repeatedly encountered odor stimuli.},
  journal = {Neuron},
  number = {3}
}

@article{Bazhenov_Model_2001,
  title = {Model of {{Cellular}} and {{Network Mechanisms}} for {{Odor}}-{{Evoked Temporal Patterning}} in the {{Locust Antennal Lobe}}},
  author = {Bazhenov, Maxim and Stopfer, Mark and Rabinovich, Mikhail and Abarbanel, Henry D. I. and Sejnowski, Terrence J. and Laurent, Gilles},
  year = {2001},
  month = may,
  volume = {30},
  pages = {569--581},
  issn = {0896-6273},
  doi = {10.1016/S0896-6273(01)00286-0},
  abstract = {Locust antennal lobe (AL) projection neurons (PNs) respond to olfactory stimuli with sequences of depolarizing and hyperpolarizing epochs, each lasting hundreds of milliseconds. A computer simulation of an AL network was used to test the hypothesis that slow inhibitory connections between local neurons (LNs) and PNs are responsible for temporal patterning. Activation of slow inhibitory receptors on PNs by the same GABAergic synapses that underlie fast oscillatory synchronization of PNs was sufficient to shape slow response modulations. This slow stimulus- and neuron-specific patterning of AL activity was resistant to blockade of fast inhibition. Fast and slow inhibitory mechanisms at synapses between LNs and PNs can thus form dynamical PN assemblies whose elements synchronize transiently and oscillate collectively, as observed not only in the locust AL, but also in the vertebrate olfactory bulb.},
  journal = {Neuron},
  number = {2}
}

@article{Bazhenov_Model_2001a,
  title = {Model of {{Transient Oscillatory Synchronization}} in the {{Locust Antennal Lobe}}},
  author = {Bazhenov, Maxim and Stopfer, Mark and Rabinovich, Mikhail and Huerta, Ramon and Abarbanel, Henry D.I. and Sejnowski, Terrence J. and Laurent, Gilles},
  year = {2001},
  month = may,
  volume = {30},
  pages = {553--567},
  issn = {0896-6273},
  abstract = {Transient pairwise synchronization of locust antennal lobe (AL) projection neurons (PNs) occurs during odor responses. In a Hodgkin-Huxley-type model of the AL, interactions between excitatory PNs and inhibitory local neurons (LNs) created coherent network oscillations during odor stimulation. GABAergic interconnections between LNs led to competition among them such that different groups of LNs oscillated with periodic Ca2+ spikes during different 50\textendash 250 ms temporal epochs, similar to those recorded in vivo. During these epochs, LN-evoked IPSPs caused phase-locked, population oscillations in sets of postsynaptic PNs. The model shows how alternations of the inhibitory drive can temporally encode sensory information in networks of neurons without precisely tuned intrinsic oscillatory properties.},
  journal = {Neuron},
  number = {2},
  pmcid = {PMC2900257},
  pmid = {11395014}
}

@book{Beal_Variational_2003,
  title = {Variational Algorithms for Approximate {{Bayesian}} Inference},
  author = {Beal, Mathew J.},
  year = {2003},
  abstract = {The Bayesian framework for machine learning allows for the incorporation of prior knowledge in a coherent way, avoids overfitting problems, and provides a principled basis for selecting between alternative models. Unfortunately the computations required are usually intractable. This thesis presents a unified variational Bayesian (VB) framework which approximates these computations in models with latent variables using a lower bound on the marginal likelihood. Chapter 1 presents background material on Bayesian inference, graphical models, and propagation algorithms. Chapter 2 forms the theoretical core of the thesis, generalising the expectation-maximisation (EM) algorithm for learning maximum likelihood parameters to the VB EM algorithm which integrates over model parameters. The algorithm is then specialised to the large family of conjugate-exponential (CE) graphical models, and several theorems are presented to pave the road for automated VB derivation procedures in both directed and undirected graphs (Bayesian and Markov networks, respectively). Chapters 3-5 derive and apply the VB EM algorithm to three commonly-used and important models: mixtures of factor analysers, linear dynamical systems, and hidden Markov models. It is shown how model selection tasks such as determining the dimensionality, cardinality, or number of variables are possible using VB approximations. Also explored are methods for combining sampling procedures with variational approximations, to estimate the tightness of VB bounds and to obtain more effective sampling algorithms. Chapter 6 applies VB learning to a long-standing problem of scoring discrete-variable directed acyclic graphs, and compares the performance to annealed importance sampling amongst other methods. Throughout, the VB approximation is compared to other methods including sampling, Cheeseman-Stutz, and asymptotic approximations such as BIC. The thesis concludes with a discussion of evolving directions for model selection including infinite models and alternative approximations to the marginal likelihood.}
}

@article{Beck_Marginalization_2011,
  title = {Marginalization in Neural Circuits with Divisive Normalization.},
  author = {Beck, Jeffrey M. and Latham, Peter E. and Pouget, Alexandre},
  year = {2011},
  month = oct,
  volume = {31},
  pages = {15310--15319},
  doi = {10.1523/JNEUROSCI.1706-11.2011},
  abstract = {A wide range of computations performed by the nervous system involves a type of probabilistic inference known as marginalization. This computation comes up in seemingly unrelated tasks, including causal reasoning, odor recognition, motor control, visual tracking, coordinate transformations, visual search, decision making, and object recognition, to name just a few. The question we address here is: how could neural circuits implement such marginalizations? We show that when spike trains exhibit a particular type of statistics\textendash associated with constant Fano factors and gain-invariant tuning curves, as is often reported in vivo\textendash some of the more common marginalizations can be achieved with networks that implement a quadratic nonlinearity and divisive normalization, the latter being a type of nonlinear lateral inhibition that has been widely reported in neural circuits. Previous studies have implicated divisive normalization in contrast gain control and attentional modulation. Our results raise the possibility that it is involved in yet another, highly critical, computation: near optimal marginalization in a remarkably wide range of tasks.},
  journal = {J Neurosci},
  keywords = {Action Potentials,Computer Simulation,Humans,Models,Nerve Net,Neurological,Neurons,Normal Distribution,physiology,Probability},
  language = {eng},
  number = {43},
  pmid = {22031877}
}

@article{Beck_Probabilistic_2008,
  title = {Probabilistic Population Codes for {{Bayesian}} Decision Making.},
  author = {Beck, Jeffrey M. and Ma, Wei Ji and Kiani, Roozbeh and Hanks, Tim and Churchland, Anne K. and Roitman, Jamie and Shadlen, Michael N. and Latham, Peter E. and Pouget, Alexandre},
  year = {2008},
  month = dec,
  volume = {60},
  pages = {1142--1152},
  doi = {10.1016/j.neuron.2008.09.021},
  abstract = {When making a decision, one must first accumulate evidence, often over time, and then select the appropriate action. Here, we present a neural model of decision making that can perform both evidence accumulation and action selection optimally. More specifically, we show that, given a Poisson-like distribution of spike counts, biological neural networks can accumulate evidence without loss of information through linear integration of neural activity and can select the most likely action through attractor dynamics. This holds for arbitrary correlations, any tuning curves, continuous and discrete variables, and sensory evidence whose reliability varies over time. Our model predicts that the neurons in the lateral intraparietal cortex involved in evidence accumulation encode, on every trial, a probability distribution which predicts the animal's performance. We present experimental evidence consistent with this prediction and discuss other predictions applicable to more general settings.},
  journal = {Neuron},
  keywords = {Action Potentials,Animals,Bayes Theorem,Computer Simulation,Decision making,Haplorhini,Humans,Models,Motion Perception,Neural Networks (Computer),Neurological,Neurons,Nonlinear Dynamics,Photic Stimulation,physiology,Reaction Time,Time Factors},
  language = {eng},
  number = {6},
  pmid = {19109917}
}

@article{Beers_When_2002,
  title = {When {{Feeling Is More Important Than Seeing}} in {{Sensorimotor Adaptation}}},
  author = {van Beers, Robert J. and Wolpert, Daniel M. and Haggard, Patrick},
  year = {2002},
  month = may,
  volume = {12},
  pages = {834--837},
  publisher = {{Elsevier}},
  issn = {0960-9822},
  doi = {10.1016/S0960-9822(02)00836-9},
  journal = {Current Biology},
  language = {English},
  number = {10}
}

@article{Behrens_Learning_2007,
  title = {Learning the Value of Information in an Uncertain World},
  author = {Behrens, Timothy E. J. and Woolrich, Mark W. and Walton, Mark E. and Rushworth, Matthew F. S.},
  year = {2007},
  month = sep,
  volume = {10},
  pages = {1214--1221},
  issn = {1097-6256},
  doi = {10.1038/nn1954},
  abstract = {Our decisions are guided by outcomes that are associated with decisions made in the past. However, the amount of influence each past outcome has on our next decision remains unclear. To ensure optimal decision-making, the weight given to decision outcomes should reflect their salience in predicting future outcomes, and this salience should be modulated by the volatility of the reward environment. We show that human subjects assess volatility in an optimal manner and adjust decision-making accordingly. This optimal estimate of volatility is reflected in the fMRI signal in the anterior cingulate cortex (ACC) when each trial outcome is observed. When a new piece of information is witnessed, activity levels reflect its salience for predicting future outcomes. Furthermore, variations in this ACC signal across the population predict variations in subject learning rates. Our results provide a formal account of how we weigh our different experiences in guiding our future actions.},
  copyright = {\textcopyright{} 2007 Nature Publishing Group},
  journal = {Nature Neuroscience},
  language = {en},
  number = {9}
}

@article{Beierholm_Separate_2011,
  title = {Separate Encoding of Model-Based and Model-Free Valuations in the Human Brain},
  author = {Beierholm, Ulrik R. and Anen, Cedric and Quartz, Steven and Bossaerts, Peter},
  year = {2011},
  month = oct,
  volume = {58},
  pages = {955--962},
  issn = {1095-9572},
  doi = {10.1016/j.neuroimage.2011.06.071},
  abstract = {Behavioral studies have long shown that humans solve problems in two ways, one intuitive and fast (System 1, model-free), and the other reflective and slow (System 2, model-based). The neurobiological basis of dual process problem solving remains unknown due to challenges of separating activation in concurrent systems. We present a novel neuroeconomic task that predicts distinct subjective valuation and updating signals corresponding to these two systems. We found two concurrent value signals in human prefrontal cortex: a System 1 model-free reinforcement signal and a System 2 model-based Bayesian signal. We also found a System 1 updating signal in striatal areas and a System 2 updating signal in lateral prefrontal cortex. Further, signals in prefrontal cortex preceded choices that are optimal according to either updating principle, while signals in anterior cingulate cortex and globus pallidus preceded deviations from optimal choice for reinforcement learning. These deviations tended to occur when uncertainty regarding optimal values was highest, suggesting that disagreement between dual systems is mediated by uncertainty rather than conflict, confirming recent theoretical proposals.},
  journal = {NeuroImage},
  keywords = {Bayes Theorem,Brain,Brain Mapping,Decision Making,Humans,Image Interpretation; Computer-Assisted,Magnetic Resonance Imaging,Problem Solving},
  language = {eng},
  number = {3},
  pmid = {21757014}
}

@article{Bell-Berti_Anticipatory_1979,
  title = {Anticipatory Coarticulation: Some Implications from a Study of Lip Rounding},
  shorttitle = {Anticipatory Coarticulation},
  author = {{Bell-Berti}, F. and Harris, K. S.},
  year = {1979},
  month = may,
  volume = {65},
  pages = {1268--1270},
  issn = {0001-4966},
  doi = {10.1121/1.382794},
  abstract = {The anticipation of articulatory features, in particular lip rounding in anticipation of a rounded vowel, has been reported to occur as many as four segments before the segment for which the feature is specified. In the data presented here, we find that the moter commands for the rounding gesture for /u/ begin a fixed time before the onset of the vowel. This timing is unaffected by the number of consonant segments in the preceding string. Thus, the initiation of lip rounding appears to be linked to other features of the vowel articulation.},
  journal = {The Journal of the Acoustical Society of America},
  keywords = {coarticulation,Electromyography,Humans,Lip,planning,Speech Perception,Speech Production Measurement},
  language = {eng},
  number = {5},
  pmid = {458048}
}

@article{Bell-Berti_Anticipatory_1979a,
  title = {Anticipatory Coarticulation: {{Some}} Implications from a Study of Lip Rounding},
  shorttitle = {Anticipatory Coarticulation},
  author = {Bell-Berti, Fredericka and Harris, Katherine S.},
  year = {1979},
  month = may,
  volume = {65},
  pages = {1268--1270},
  publisher = {{Acoustical Society of America}},
  issn = {0001-4966},
  doi = {10.1121/1.382794},
  journal = {The Journal of the Acoustical Society of America},
  keywords = {coarticulation;planning},
  number = {5}
}

@article{Bennett_Intrinsic_2016,
  title = {Intrinsic {{Valuation}} of {{Information}} in {{Decision Making}} under {{Uncertainty}}},
  author = {Bennett, Daniel and Bode, Stefan and Brydevall, Maja and Warren, Hayley and Murawski, Carsten},
  year = {2016},
  month = jul,
  volume = {12},
  pages = {e1005020},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1005020},
  abstract = {In a dynamic world, an accurate model of the environment is vital for survival, and agents ought regularly to seek out new information with which to update their world models. This aspect of behaviour is not captured well by classical theories of decision making, and the cognitive mechanisms of information seeking are poorly understood. In particular, it is not known whether information is valued only for its instrumental use, or whether humans also assign it a non-instrumental intrinsic value. To address this question, the present study assessed preference for non-instrumental information among 80 healthy participants in two experiments. Participants performed a novel information preference task in which they could choose to pay a monetary cost to receive advance information about the outcome of a monetary lottery. Importantly, acquiring information did not alter lottery outcome probabilities. We found that participants were willing to incur considerable monetary costs to acquire payoff-irrelevant information about the lottery outcome. This behaviour was well explained by a computational cognitive model in which information preference resulted from aversion to temporally prolonged uncertainty. These results strongly suggest that humans assign an intrinsic value to information in a manner inconsistent with normative accounts of decision making under uncertainty. This intrinsic value may be associated with adaptive behaviour in real-world environments by producing a bias towards exploratory and information-seeking behaviour.},
  journal = {PLoS computational biology},
  language = {eng},
  number = {7},
  pmid = {27416034}
}

@article{Bernoulli_Exposition_1954,
  title = {Exposition of a {{New Theory}} on the {{Measurement}} of {{Risk}}},
  author = {Bernoulli, Daniel},
  year = {1954},
  volume = {22},
  pages = {23--36},
  publisher = {{[Wiley, Econometric Society]}},
  issn = {0012-9682},
  doi = {10.2307/1909829},
  journal = {Econometrica},
  number = {1}
}

@article{Berns_Intertemporal_2007,
  title = {Intertemporal Choice--toward an Integrative Framework},
  author = {Berns, Gregory S. and Laibson, David and Loewenstein, George},
  year = {2007},
  month = nov,
  volume = {11},
  pages = {482--488},
  issn = {1364-6613},
  doi = {10.1016/j.tics.2007.08.011},
  abstract = {Intertemporal choices are decisions with consequences that play out over time. These choices range from the prosaic--how much food to eat at a meal--to life-changing decisions about education, marriage, fertility, health behaviors and savings. Intertemporal preferences also affect policy debates about long-run challenges, such as global warming. Historically, it was assumed that delayed rewards were discounted at a constant rate over time. Recent theoretical and empirical advances from economic, psychological and neuroscience perspectives, however, have revealed a more complex account of how individuals make intertemporal decisions. We review and integrate these advances. We emphasize three different, occasionally competing, mechanisms that are implemented in the brain: representation, anticipation and self-control.},
  journal = {Trends in Cognitive Sciences},
  keywords = {Animals,Brain,Choice Behavior,Decision Making,Energy Metabolism,Humans,Time Factors},
  language = {eng},
  number = {11},
  pmid = {17980645}
}

@article{Bialaszek_Physical_2017,
  title = {Physical and Cognitive Effort Discounting across Different Reward Magnitudes: {{Tests}} of Discounting Models},
  shorttitle = {Physical and Cognitive Effort Discounting across Different Reward Magnitudes},
  author = {Bia{\l}aszek, Wojciech and Marcowski, Przemys{\l}aw and Ostaszewski, Pawe{\l}},
  year = {2017},
  month = jul,
  volume = {12},
  pages = {e0182353},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0182353},
  abstract = {The effort required to obtain a rewarding outcome is an important factor in decision-making. Describing the reward devaluation by increasing effort intensity is substantial to understanding human preferences, because every action and choice that we make is in itself effortful. To investigate how reward valuation is affected by physical and cognitive effort, we compared mathematical discounting functions derived from research on discounting. Seven discounting models were tested across three different reward magnitudes. To test the models, data were collected from a total of 114 participants recruited from the general population. For one-parameter models (hyperbolic, exponential, and parabolic), the data were explained best by the exponential model as given by a percentage of explained variance. However, after introducing an additional parameter, data obtained in the cognitive and physical effort conditions were best described by the power function model. Further analysis, using the second order Akaike and Bayesian Information Criteria, which account for model complexity, allowed us to identify the best model among all tested. We found that the power function best described the data, which corresponds to conventional analyses based on the R2 measure. This supports the conclusion that the function best describing reward devaluation by physical and cognitive effort is a concave one and is different from those that describe delay or probability discounting. In addition, consistent magnitude effects were observed that correspond to those in delay discounting research.},
  journal = {PLOS ONE},
  keywords = {Behavior,Behavioral economics,Cognition,Cognitive psychology,Curve fitting,Decision making,Human performance,Psychophysics,unread},
  language = {en},
  number = {7}
}

@article{Bijleveld_feeling_2018,
  title = {The Feeling of Effort during Mental Activity},
  author = {Bijleveld, Erik},
  year = {2018},
  month = aug,
  volume = {63},
  pages = {218--227},
  issn = {1053-8100},
  doi = {10.1016/j.concog.2018.05.013},
  abstract = {The feeling of effort is familiar to most, if not all, humans. Prior research shows that the feeling of effort shapes judgments (e.g., of agency) and decisions (e.g., to quit the current task) in various ways, but the proximal causes of the feeling of effort are not well understood. In this research, I address these proximal causes. In particular, I conducted two preregistered experiments in which participants performed a difficult vs. easy cognitive task, while I measured effort-related phenomenology (feeling of effort) and physiology (pupil dilation) on a moment-to-moment basis. In both experiments, difficult tasks increased the feeling of effort; however, this effect could not be explained by concurrent increases in physiological effort. To explain these findings, I suggest that the feeling of effort during mental activity stems from the decision to exert physiological effort, rather than from physiological effort itself.},
  journal = {Consciousness and Cognition},
  keywords = {Consciousness,Effort,Feeling of effort,Phenomenology,Physiological effort,Pupil dilation}
}

@article{Bisley_Attention_2010,
  title = {Attention, {{Intention}}, and {{Priority}} in the {{Parietal Lobe}}},
  author = {Bisley, James W. and Goldberg, Michael E.},
  year = {2010},
  volume = {33},
  pages = {1--21},
  doi = {10.1146/annurev-neuro-060909-152823},
  abstract = {For many years there has been a debate about the role of the parietal lobe in the generation of behavior. Does it generate movement plans (intention) or choose objects in the environment for further processing? To answer this, we focus on the lateral intraparietal area (LIP), an area that has been shown to play independent roles in target selection for saccades and the generation of visual attention. Based on results from a variety of tasks, we propose that LIP acts as a priority map in which objects are represented by activity proportional to their behavioral priority. We present evidence to show that the priority map combines bottom-up inputs like a rapid visual response with an array of top-down signals like a saccade plan. The spatial location representing the peak of the map is used by the oculomotor system to target saccades and by the visual system to guide visual attention.},
  journal = {Annual Review of Neuroscience},
  keywords = {lateral intraparietal area,LIP,saccade,salience,vision,visual search},
  number = {1},
  pmid = {20192813}
}

@article{Bitzer_Online_2012,
  title = {Online Discrimination of Nonlinear Dynamics with Switching Differential Equations},
  author = {Bitzer, Sebastian},
  year = {2012},
  abstract = {How to recognise whether an observed person walks or runs? We consider a dy- namic environment where observations (e.g. the posture of a person) are caused by different dynamic processes (walking or running) which are active one at a time and which may transition from one to another at any time. For this setup, switch- ing dynamic models have been suggested previously, mostly, for linear and non- linear dynamics in discrete time. Motivated by basic principles of computations in the brain (dynamic, internal models) we suggest a model for switching non- linear differential equations. The switching process in the model is implemented by a Hopfield network and we use parametric dynamic movement primitives to represent arbitrary rhythmic motions. The model generates observed dynamics by linearly interpolating the primitives weighted by the switching variables and it is constructed such that standard filtering algorithms can be applied. In two experi- ments with synthetic planar motion and a human motion capture data set we show that inference with the unscented Kalman filter can successfully discriminate sev- eral dynamic processes online.},
  keywords = {Hierarchical levels,Hopfield,Movement primitives,UKF}
}

@article{Bitzer_Perceptual_2014,
  title = {Perceptual Decision Making: Drift-Diffusion Model Is Equivalent to a {{Bayesian}} Model},
  shorttitle = {Perceptual Decision Making},
  author = {Bitzer, Sebastian and Park, Hame and Blankenburg, Felix and Kiebel, Stefan J.},
  year = {2014},
  volume = {8},
  pages = {102},
  doi = {10.3389/fnhum.2014.00102},
  abstract = {Behavioral data obtained with perceptual decision making experiments are typically analyzed with the drift-diffusion model. This parsimonious model accumulates noisy pieces of evidence toward a decision bound to explain the accuracy and reaction times of subjects. Recently, Bayesian models have been proposed to explain how the brain extracts information from noisy input as typically presented in perceptual decision making tasks. It has long been known that the drift-diffusion model is tightly linked with such functional Bayesian models but the precise relationship of the two mechanisms was never made explicit. Using a Bayesian model, we derived the equations which relate parameter values between these models. In practice we show that this equivalence is useful when fitting multi-subject data. We further show that the Bayesian model suggests different decision variables which all predict equal responses and discuss how these may be discriminated based on neural correlates of accumulated evidence. In addition, we discuss extensions to the Bayesian model which would be difficult to derive for the drift-diffusion model. We suggest that these and other extensions may be highly useful for deriving new experiments which test novel hypotheses.},
  journal = {Frontiers in Human Neuroscience},
  keywords = {Bayesian models,decision variable,drift diffusion model,parameter fitting,perceptual decision making,Reaction Time,uncertainty}
}

@article{Bixter_Adaptive_2013,
  title = {Adaptive Intertemporal Preferences in Foraging-Style Environments},
  author = {Bixter, Michael T. and Luhmann, Christian C.},
  year = {2013},
  month = jun,
  volume = {7},
  issn = {1662-4548},
  doi = {10.3389/fnins.2013.00093},
  abstract = {Decision makers often face choices between smaller more immediate rewards and larger more delayed rewards. For example, when foraging for food, animals must choose between actions that have varying costs (e.g., effort, duration, energy expenditure) and varying benefits (e.g., amount of food intake). The combination of these costs and benefits determine what optimal behavior is. In the present study, we employ a foraging-style task to study how humans make reward-based choices in response to the real-time constraints of a dynamic environment. On each trial participants were presented with two rewards that differed in magnitude and in the delay until their receipt. Because the experiment was of a fixed duration, maximizing earnings required decision makers to determine how to trade off the magnitude and the delay associated with the two rewards on each trial. To evaluate the extent to which participants could adapt to the decision environment, specific task characteristics were manipulated, including reward magnitudes (Experiment 1) and the delay between trials (Experiment 2). Each of these manipulations was designed to alter the pattern of choices made by an optimal decision maker. Several findings are of note. First, different choice strategies were observed with the manipulated environmental constraints. Second, despite contextually-appropriate shifts in behavior between conditions in each experiment, choice patterns deviated from theoretical optimality. In particular, the delays associated with the rewards did not exert a consistent influence on choices as required by exponential discounting. Third, decision makers nevertheless performed surprisingly well in all task environments with any deviations from strict optimality not having particularly deleterious effects on earnings. Taken together, these results suggest that human decision makers are capable of exhibiting intertemporal preferences that reflect a variety of environmental constraints.},
  journal = {Frontiers in Neuroscience},
  pmcid = {PMC3683629},
  pmid = {23785308}
}

@article{Bizzi_Posture_1984,
  title = {Posture Control and Trajectory Formation during Arm Movement},
  author = {Bizzi, E. and Accornero, N. and Chapple, W. and Hogan, N.},
  year = {1984},
  month = nov,
  volume = {4},
  pages = {2738--2744},
  issn = {0270-6474},
  abstract = {One hypothesis for the generation of spatially oriented arm movements by the central nervous system is that a desired joint position is determined by the ratio of the tensions of agonist and antagonist muscles. According to this hypothesis, the transition between equilibrium states should be solely a function of the contraction time of the motor units and the mechanical properties of the arm. We tested this hypothesis in intact and deafferented rhesus monkeys by holding the forearm and measuring the accelerative transient after release of the forearm and by directly measuring the time course of the increase in torque during the movement. Both methods indicated an average time of 400 msec for attaining peak torque in a movement with a duration of 700 msec. In addition, by displacing the arm from its normal trajectory during the movement, we observed that the arm returned neither to the initial nor to the final equilibrium positions, but to points intermediate between them. We conclude that the processes underlying trajectory formation must be more complex than a simple switch between one equilibrium position and another.},
  journal = {The Journal of Neuroscience: The Official Journal of the Society for Neuroscience},
  keywords = {Afferent Pathways,Animals,Arm,Electromyography,Electrophysiology,Macaca mulatta,Motor Neurons,Movement,Muscle Contraction,Muscles,Posture},
  language = {eng},
  number = {11},
  pmcid = {PMC6564726},
  pmid = {6502202}
}

@article{Bleichrodt_ParameterFree_2000,
  title = {A {{Parameter}}-{{Free Elicitation}} of the {{Probability Weighting Function}} in {{Medical Decision Analysis}}},
  author = {Bleichrodt, Han and Pinto, Jose Luis},
  year = {2000},
  month = nov,
  volume = {46},
  pages = {1485--1496},
  issn = {0025-1909},
  doi = {10.1287/mnsc.46.11.1485.12086},
  abstract = {An important reason why people violate expected utility theory is probability weighting. Previous studies on the probability weighting function typically assume a specific parametric form, exclude heterogeneity in individual preferences, and exclusively consider monetary decision making. This study presents a method to elicit the probability weighting function in rank-dependent expected utility theory that makes no prior assumptions about the functional form of the probability weighting function. We use both aggregate and individual subject data, thereby allowing for heterogeneity of individual preferences, and we examine probability weighting in a new domain, medical decision making. There is significant evidence of probability weighting both at the aggregate and at the individual subject level. The modal probability weighting function is inverse S-shaped, displaying both lower subadditivity and upper subadditivity. Probability weighting is in particular relevant at the boundaries of the unit interval. Compared to studies involving monetary outcomes, we generally find more elevation of the probability weighting function. The robustness of the empirical findings on probability weighting indicates its importance. Ignoring probability weighting in modeling decision under risk and in utility measurement is likely to lead to descriptively invalid theories and distorted elicitations.},
  journal = {Management Science},
  number = {11}
}

@article{Blumenschein_Eliciting_2008,
  title = {Eliciting {{Willingness}} to {{Pay Without Bias}}: {{Evidence}} from a {{Field Experiment}}*},
  shorttitle = {Eliciting {{Willingness}} to {{Pay Without Bias}}},
  author = {Blumenschein, Karen and Blomquist, Glenn C. and Johannesson, Magnus and Horn, Nancy and Freeman, Patricia},
  year = {2008},
  month = jan,
  volume = {118},
  pages = {114--137},
  issn = {1468-0297},
  doi = {10.1111/j.1468-0297.2007.02106.x},
  abstract = {Concern exists that hypothetical willingness to pay questions overestimate real willingness to pay. In a field experiment, we compare two methods of removing hypothetical bias, a cheap talk approach and a certainty approach, with real purchases. We find evidence of hypothetical bias for unadulterated contingent valuation. Contingent valuation with certainty statements removes the hypothetical bias, but the cheap talk approach has no significant impact. Our findings suggest that willingness to pay can be accurately estimated by adding a simple follow-up question about the certainty of responses and that cheap talk is not a generally effective approach.},
  journal = {The Economic Journal},
  language = {en},
  number = {525}
}

@article{Boerlin_SpikeBased_2011,
  title = {Spike-{{Based Population Coding}} and {{Working Memory}}},
  author = {Boerlin, Martin and Den{\`e}ve, Sophie},
  year = {2011},
  month = feb,
  volume = {7},
  pages = {e1001080},
  doi = {10.1371/journal.pcbi.1001080},
  abstract = {Abstract Compelling behavioral evidence suggests that humans can make optimal decisions despite the uncertainty inherent in perceptual or motor tasks. A key question in neuroscience is how populations of spiking neurons can implement such probabilistic computations. In this article, we develop a comprehensive framework for optimal, spike-based sensory integration and working memory in a dynamic environment. We propose that probability distributions are inferred spike-per-spike in recurrently connected networks of integrate-and-fire neurons. As a result, these networks can combine sensory cues optimally, track the state of a time-varying stimulus and memorize accumulated evidence over periods much longer than the time constant of single neurons. Importantly, we propose that population responses and persistent working memory states represent entire probability distributions and not only single stimulus values. These memories are reflected by sustained, asynchronous patterns of activity which make relevant information available to downstream neurons within their short time window of integration. Model neurons act as predictive encoders, only firing spikes which account for new information that has not yet been signaled. Thus, spike times signal deterministically a prediction error, contrary to rate codes in which spike times are considered to be random samples of an underlying firing rate. As a consequence of this coding scheme, a multitude of spike patterns can reliably encode the same information. This results in weakly correlated, Poisson-like spike trains that are sensitive to initial conditions but robust to even high levels of external neural noise. This spike train variability reproduces the one observed in cortical sensory spike trains, but cannot be equated to noise. On the contrary, it is a consequence of optimal spike-based inference. In contrast, we show that rate-based models perform poorly when implemented with stochastically spiking neurons. Author Summary Most of our daily actions are subject to uncertainty. Behavioral studies have confirmed that humans handle this uncertainty in a statistically optimal manner. A key question then is what neural mechanisms underlie this optimality, i.e. how can neurons represent and compute with probability distributions. Previous approaches have proposed that probabilities are encoded in the firing rates of neural populations. However, such rate codes appear poorly suited to understand perception in a constantly changing environment. In particular, it is unclear how probabilistic computations could be implemented by biologically plausible spiking neurons. Here, we propose a network of spiking neurons that can optimally combine uncertain information from different sensory modalities and keep this information available for a long time. This implies that neural memories not only represent the most likely value of a stimulus but rather a whole probability distribution over it. Furthermore, our model suggests that each spike conveys new, essential information. Consequently, the observed variability of neural responses cannot simply be understood as noise but rather as a necessary consequence of optimal sensory integration. Our results therefore question strongly held beliefs about the nature of neural "signal" and "noise".},
  annotation = {Deneve (just so that I find it when searching for Deneve without the accent)},
  journal = {PLoS Comput Biol},
  number = {2}
}

@article{Bolenz_Metacontrol_2019,
  title = {Metacontrol of Decision-Making Strategies in Human Aging},
  author = {Bolenz, Florian and Kool, Wouter and Reiter, Andrea MF and Eppinger, Ben},
  editor = {B{\"u}chel, Christian and Kahnt, Thorsten and {Samanez-Larkin}, Greg},
  year = {2019},
  month = aug,
  volume = {8},
  pages = {e49154},
  issn = {2050-084X},
  doi = {10.7554/eLife.49154},
  abstract = {Humans employ different strategies when making decisions. Previous research has reported reduced reliance on model-based strategies with aging, but it remains unclear whether this is due to cognitive or motivational factors. Moreover, it is not clear how aging affects the metacontrol of decision making, that is the dynamic adaptation of decision-making strategies to varying situational demands. In this cross-sectional study, we tested younger and older adults in a sequential decision-making task that dissociates model-free and model-based strategies. In contrast to previous research, model-based strategies led to higher payoffs. Moreover, we manipulated the costs and benefits of model-based strategies by varying reward magnitude and the stability of the task structure. Compared to younger adults, older adults showed reduced model-based decision making and less adaptation of decision-making strategies. Our findings suggest that aging affects the metacontrol of decision-making strategies and that reduced model-based strategies in older adults are due to limited cognitive abilities.},
  journal = {eLife},
  keywords = {decision making,lifespan development,model-based,model-free,reinforcement learning,reward}
}

@article{Boorman_How_2009,
  title = {How {{Green Is}} the {{Grass}} on the {{Other Side}}? {{Frontopolar Cortex}} and the {{Evidence}} in {{Favor}} of {{Alternative Courses}} of {{Action}}},
  shorttitle = {How {{Green Is}} the {{Grass}} on the {{Other Side}}?},
  author = {Boorman, Erie D. and Behrens, Timothy E. J. and Woolrich, Mark W. and Rushworth, Matthew F. S.},
  year = {2009},
  month = jun,
  volume = {62},
  pages = {733--743},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2009.05.014},
  abstract = {Summary Behavioral flexibility is the hallmark of goal-directed behavior. Whereas a great deal is known about the neural substrates of behavioral adjustment when it is explicitly cued by features of the external environment, little is known about how we adapt our behavior when such changes are made on the basis of uncertain evidence. Using a Bayesian reinforcement-learning model and fMRI, we show that frontopolar cortex (FPC) tracks the relative advantage in favor of switching to a foregone alternative when choices are made voluntarily. Changes in FPC functional connectivity occur when subjects finally decide to switch to the alternative behavior. Moreover, interindividual variation in the FPC signal predicts interindividual differences in effectively adapting behavior. By~contrast, ventromedial prefrontal cortex (vmPFC) encodes the relative value of the current decision. Collectively, these findings reveal complementary prefrontal computations essential for promoting short- and long-term behavioral flexibility.},
  journal = {Neuron},
  keywords = {SIGNALING,SYSBIO,SYSNEURO},
  number = {5}
}

@article{Bornstein_Reminders_2017,
  title = {Reminders of Past Choices Bias Decisions for Reward in Humans},
  author = {Bornstein, Aaron M. and Khaw, Mel W. and Shohamy, Daphna and Daw, Nathaniel D.},
  year = {2017},
  month = jun,
  volume = {8},
  pages = {ncomms15958},
  issn = {2041-1723},
  doi = {10.1038/ncomms15958},
  abstract = {{$<$}p{$>$}Previous work has shown that learning models based on running averages of received rewards can account for sequential choices in value based decisions. Here the authors show that such choices can also be influenced by a process of sampling memories for individual past out\&hellip;{$<$}/p{$>$}},
  copyright = {2017 Nature Publishing Group},
  journal = {Nature Communications},
  language = {en}
}

@article{Bota_Architecture_2015,
  title = {Architecture of the Cerebral Cortical Association Connectome Underlying Cognition},
  author = {Bota, Mihail and Sporns, Olaf and Swanson, Larry W.},
  year = {2015},
  month = apr,
  pages = {201504394},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1504394112},
  abstract = {Cognition presumably emerges from neural activity in the network of association connections between cortical regions that is modulated by inputs from sensory and state systems and directs voluntary behavior by outputs to the motor system. To reveal global architectural features of the cortical association connectome, network analysis was performed on {$>$}16,000 reports of histologically defined axonal connections between cortical regions in rat. The network analysis reveals an organization into four asymmetrically interconnected modules involving the entire cortex in a topographic and topologic core\textendash shell arrangement. There is also a topographically continuous U-shaped band of cortical areas that are highly connected with each other as well as with the rest of the cortex extending through all four modules, with the temporal pole of this band (entorhinal area) having the most cortical association connections of all. These results provide a starting point for compiling a mammalian nervous system connectome that could ultimately reveal novel correlations between genome-wide association studies and connectome-wide association studies, leading to new insights into the cellular architecture supporting cognition.},
  journal = {Proceedings of the National Academy of Sciences},
  keywords = {Cerebral Cortex,connectomics,mammal,network analysis,neural connections},
  language = {en},
  pmid = {25848037}
}

@article{Botvinick_Conflict_2001,
  title = {Conflict Monitoring and Cognitive Control},
  author = {Botvinick, M. M. and Braver, T. S. and Barch, D. M. and Carter, C. S. and Cohen, J. D.},
  year = {2001},
  month = jul,
  volume = {108},
  pages = {624--652},
  issn = {0033-295X},
  abstract = {A neglected question regarding cognitive control is how control processes might detect situations calling for their involvement. The authors propose here that the demand for control may be evaluated in part by monitoring for conflicts in information processing. This hypothesis is supported by data concerning the anterior cingulate cortex, a brain area involved in cognitive control, which also appears to respond to the occurrence of conflict. The present article reports two computational modeling studies, serving to articulate the conflict monitoring hypothesis and examine its implications. The first study tests the sufficiency of the hypothesis to account for brain activation data, applying a measure of conflict to existing models of tasks shown to engage the anterior cingulate. The second study implements a feedback loop connecting conflict monitoring to cognitive control, using this to simulate a number of important behavioral phenomena.},
  journal = {Psychological Review},
  keywords = {cognition,Cognitive Science,Computer Simulation,Conflict (Psychology),Frontal Lobe,Humans,Models; Psychological,Neuropsychology},
  language = {eng},
  number = {3},
  pmid = {11488380}
}

@article{Botvinick_Conflict_2004,
  title = {Conflict Monitoring and Anterior Cingulate Cortex: An Update},
  shorttitle = {Conflict Monitoring and Anterior Cingulate Cortex},
  author = {Botvinick, Matthew M. and Cohen, Jonathan D. and Carter, Cameron S.},
  year = {2004},
  month = dec,
  volume = {8},
  pages = {539--546},
  issn = {1364-6613},
  doi = {10.1016/j.tics.2004.10.003},
  abstract = {One hypothesis concerning the human dorsal anterior cingulate cortex (ACC) is that it functions, in part, to signal the occurrence of conflicts in information processing, thereby triggering compensatory adjustments in cognitive control. Since this idea was first proposed, a great deal of relevant empirical evidence has accrued. This evidence has largely corroborated the conflict-monitoring hypothesis, and some very recent work has provided striking new support for the theory. At the same time, other findings have posed specific challenges, especially concerning the way the theory addresses the processing of errors. Recent research has also begun to shed light on the larger function of the ACC, suggesting some new possibilities concerning how conflict monitoring might fit into the cingulate's overall role in cognition and action.},
  journal = {Trends in Cognitive Sciences},
  number = {12}
}

@article{Botvinick_Conflict_2007,
  title = {Conflict Monitoring and Decision Making: {{Reconciling}} Two Perspectives on Anterior Cingulate Function},
  shorttitle = {Conflict Monitoring and Decision Making},
  author = {Botvinick, Matthew M.},
  year = {2007},
  month = dec,
  volume = {7},
  pages = {356--366},
  issn = {1530-7026, 1531-135X},
  doi = {10.3758/CABN.7.4.356},
  journal = {Cognitive, Affective, \& Behavioral Neuroscience},
  keywords = {Cognitive Psychology,Neurosciences},
  language = {en},
  number = {4}
}

@article{Botvinick_Conflict_2007a,
  title = {Conflict Monitoring and Decision Making: {{Reconciling}} Two Perspectives on Anterior Cingulate Function},
  shorttitle = {Conflict Monitoring and Decision Making},
  author = {Botvinick, Matthew M.},
  year = {2007},
  month = dec,
  volume = {7},
  pages = {356--366},
  issn = {1530-7026, 1531-135X},
  doi = {10.3758/CABN.7.4.356},
  journal = {Cognitive, Affective, \& Behavioral Neuroscience},
  keywords = {Cognitive Psychology,Neurosciences},
  language = {en},
  number = {4}
}

@article{Botvinick_Doing_2004,
  title = {Doing without Schema Hierarchies: A Recurrent Connectionist Approach to Normal and Impaired Routine Sequential Action},
  shorttitle = {Doing without Schema Hierarchies},
  author = {Botvinick, Matthew and Plaut, David C.},
  year = {2004},
  month = apr,
  volume = {111},
  pages = {395--429},
  issn = {0033-295X},
  doi = {10.1037/0033-295X.111.2.395},
  abstract = {In everyday tasks, selecting actions in the proper sequence requires a continuously updated representation of temporal context. Previous models have addressed this problem by positing a hierarchy of processing units, mirroring the roughly hierarchical structure of naturalistic tasks themselves. The present study considers an alternative framework, in which the representation of context depends on recurrent connections within a network mapping from environmental inputs to actions. The ability of this approach to account for human performance was evaluated by applying it, through simulation, to a specific everyday task. The resulting model learned to deal flexibly with a complex set of sequencing constraints, encoding contextual information at multiple time scales within a single, distributed internal representation. Degrading this representation led to errors resembling those observed both in everyday behavior and in apraxia. Analysis of the model's function yielded numerous predictions relevant to both normal and apraxic performance.},
  journal = {Psychological Review},
  keywords = {Cognition,Humans,Learning,Neural Networks; Computer,Noise,Recurrence},
  language = {eng},
  number = {2},
  pmid = {15065915}
}

@article{Botvinick_Effort_2009,
  title = {Effort Discounting in Human Nucleus Accumbens},
  author = {Botvinick, Matthew M. and Huffstetler, Stacy and McGuire, Joseph T.},
  year = {2009},
  month = mar,
  volume = {9},
  pages = {16--27},
  issn = {1531-135X},
  doi = {10.3758/CABN.9.1.16},
  abstract = {A great deal of behavioral and economic research suggests that the value attached to a reward stands in inverse relation to the amount of effort required to obtain it, a principle known as effort discounting. In the present article, we present the first direct evidence for a neural analogue of effort discounting. We used fMRI to measure neural responses to monetary rewards in the human nucleus accumbens (NAcc), a structure previously demonstrated to encode reference-dependent reward information. The magnitude of accumbens activation was found to vary with both reward outcome and the degree of mental effort demanded to obtain individual rewards. For a fixed level of reward, the NAcc was less strongly activated following a high-demand for effort than following a low demand. The magnitude of this effect was noted to correlate with preceding activation in the dorsal anterior cingulate cortex, a region that has been proposed to monitor information-processing demands and to mediate in the subjective experience of effort.},
  journal = {Cognitive, Affective, \& Behavioral Neuroscience},
  keywords = {Anterior Cingulate Cortex,Block Type,Delay Discount,Medial Frontal Cortex,Task Block},
  language = {en},
  number = {1}
}

@article{Botvinick_Hierarchically_2009,
  title = {Hierarchically Organized Behavior and Its Neural Foundations: {{A}} Reinforcement Learning Perspective},
  shorttitle = {Hierarchically Organized Behavior and Its Neural Foundations},
  author = {Botvinick, Matthew M. and Niv, Yael and Barto, Andrew C.},
  year = {2009},
  month = dec,
  volume = {113},
  pages = {262--280},
  issn = {0010-0277},
  doi = {10.1016/j.cognition.2008.08.011},
  abstract = {Research on human and animal behavior has long emphasized its hierarchical structure\textemdash the divisibility of ongoing behavior into discrete tasks, which are comprised of subtask sequences, which in turn are built of simple actions. The hierarchical structure of behavior has also been of enduring interest within neuroscience, where it has been widely considered to reflect prefrontal cortical functions. In this paper, we reexamine behavioral hierarchy and its neural substrates from the point of view of recent developments in computational reinforcement learning. Specifically, we consider a set of approaches known collectively as hierarchical reinforcement learning, which extend the reinforcement learning paradigm by allowing the learning agent to aggregate actions into reusable subroutines or skills. A close look at the components of hierarchical reinforcement learning suggests how they might map onto neural structures, in particular regions within the dorsolateral and orbital prefrontal cortex. It also suggests specific ways in which hierarchical reinforcement learning might provide a complement to existing psychological models of hierarchically structured behavior. A particularly important question that hierarchical reinforcement learning brings to the fore is that of how learning identifies new action routines that are likely to provide useful building blocks in solving a wide range of future problems. Here and at many other points, hierarchical reinforcement learning offers an appealing framework for investigating the computational and neural underpinnings of hierarchically structured behavior.},
  journal = {Cognition},
  keywords = {Prefrontal cortex,Reinforcement learning},
  number = {3},
  series = {Reinforcement Learning and Higher Cognition}
}

@article{Botvinick_Hierarchically_2009a,
  title = {Hierarchically Organized Behavior and Its Neural Foundations: {{A}} Reinforcement Learning Perspective},
  shorttitle = {Hierarchically Organized Behavior and Its Neural Foundations},
  author = {Botvinick, Matthew M. and Niv, Yael and Barto, Andrew C.},
  year = {2009},
  month = dec,
  volume = {113},
  pages = {262--280},
  issn = {0010-0277},
  doi = {10.1016/j.cognition.2008.08.011},
  abstract = {Research on human and animal behavior has long emphasized its hierarchical structure\textemdash the divisibility of ongoing behavior into discrete tasks, which are comprised of subtask sequences, which in turn are built of simple actions. The hierarchical structure of behavior has also been of enduring interest within neuroscience, where it has been widely considered to reflect prefrontal cortical functions. In this paper, we reexamine behavioral hierarchy and its neural substrates from the point of view of recent developments in computational reinforcement learning. Specifically, we consider a set of approaches known collectively as hierarchical reinforcement learning, which extend the reinforcement learning paradigm by allowing the learning agent to aggregate actions into reusable subroutines or skills. A close look at the components of hierarchical reinforcement learning suggests how they might map onto neural structures, in particular regions within the dorsolateral and orbital prefrontal cortex. It also suggests specific ways in which hierarchical reinforcement learning might provide a complement to existing psychological models of hierarchically structured behavior. A particularly important question that hierarchical reinforcement learning brings to the fore is that of how learning identifies new action routines that are likely to provide useful building blocks in solving a wide range of future problems. Here and at many other points, hierarchical reinforcement learning offers an appealing framework for investigating the computational and neural underpinnings of hierarchically structured behavior.},
  journal = {Cognition},
  keywords = {Prefrontal cortex,Reinforcement learning},
  number = {3},
  series = {Reinforcement Learning and Higher Cognition}
}

@article{Botvinick_Modelbased_2014,
  title = {Model-Based Hierarchical Reinforcement Learning and Human Action Control},
  author = {Botvinick, Matthew and Weinstein, Ari},
  year = {2014},
  month = nov,
  volume = {369},
  pages = {20130480},
  issn = {0962-8436, 1471-2970},
  doi = {10.1098/rstb.2013.0480},
  abstract = {Recent work has reawakened interest in goal-directed or `model-based' choice, where decisions are based on prospective evaluation of potential action outcomes. Concurrently, there has been growing attention to the role of hierarchy in decision-making and action control. We focus here on the intersection between these two areas of interest, considering the topic of hierarchical model-based control. To characterize this form of action control, we draw on the computational framework of hierarchical reinforcement learning, using this to interpret recent empirical findings. The resulting picture reveals how hierarchical model-based mechanisms might play a special and pivotal role in human decision-making, dramatically extending the scope and complexity of human behaviour.},
  copyright = {. \textcopyright{} 2014 The Authors. Published by the Royal Society under the terms of the Creative Commons Attribution License http://creativecommons.org/licenses/by/4.0/, which permits unrestricted use, provided the original author and source are credited.},
  journal = {Philosophical Transactions of the Royal Society of London B: Biological Sciences},
  language = {en},
  number = {1655},
  pmid = {25267822}
}

@article{Botvinick_Modelbased_2014a,
  title = {Model-Based Hierarchical Reinforcement Learning and Human Action Control},
  author = {Botvinick, Matthew and Weinstein, Ari},
  year = {2014},
  month = nov,
  volume = {369},
  issn = {1471-2970},
  doi = {10.1098/rstb.2013.0480},
  abstract = {Recent work has reawakened interest in goal-directed or 'model-based' choice, where decisions are based on prospective evaluation of potential action outcomes. Concurrently, there has been growing attention to the role of hierarchy in decision-making and action control. We focus here on the intersection between these two areas of interest, considering the topic of hierarchical model-based control. To characterize this form of action control, we draw on the computational framework of hierarchical reinforcement learning, using this to interpret recent empirical findings. The resulting picture reveals how hierarchical model-based mechanisms might play a special and pivotal role in human decision-making, dramatically extending the scope and complexity of human behaviour.},
  journal = {Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences},
  keywords = {Decision Making,goal-directed behaviour,Goals,hierarchy,Humans,Learning,Models; Neurological,Reinforcement (Psychology),reinforcement learning},
  language = {eng},
  number = {1655},
  pmcid = {PMC4186233},
  pmid = {25267822}
}

@article{Botvinick_Motivation_2015,
  title = {Motivation and {{Cognitive Control}}: {{From Behavior}} to {{Neural Mechanism}}},
  shorttitle = {Motivation and {{Cognitive Control}}},
  author = {Botvinick, Matthew and Braver, Todd},
  year = {2015},
  volume = {66},
  pages = {83--113},
  doi = {10.1146/annurev-psych-010814-015044},
  abstract = {Research on cognitive control and executive function has long recognized the relevance of motivational factors. Recently, however, the topic has come increasingly to center stage, with a surge of new studies examining the interface of motivation and cognitive control. In the present article we survey research situated at this interface, considering work from cognitive and social psychology and behavioral economics, but with a particular focus on neuroscience research. We organize existing findings into three core areas, considering them in the light of currently vying theoretical perspectives. Based on the accumulated evidence, we advocate for a view of control function that treats it as a domain of reward-based decision making. More broadly, we argue that neuroscientific evidence plays a critical role in understanding the mechanisms by which motivation and cognitive control interact. Opportunities for further cross-fertilization between behavioral and neuroscientific research are highlighted.},
  journal = {Annual Review of Psychology},
  keywords = {Cognitive control,Motivation,Prefrontal cortex,Reward},
  number = {1},
  pmid = {25251491}
}

@article{Botvinick_Multilevel_2007,
  title = {Multilevel Structure in Behaviour and in the Brain: A Model of {{Fuster}}'s Hierarchy},
  shorttitle = {Multilevel Structure in Behaviour and in the Brain},
  author = {Botvinick, Matthew M},
  year = {2007},
  month = sep,
  volume = {362},
  pages = {1615--1626},
  issn = {0962-8436},
  doi = {10.1098/rstb.2007.2056},
  abstract = {A basic question, intimately tied to the problem of action selection, is that of how actions are assembled into organized sequences. Theories of routine sequential behaviour have long acknowledged that it must rely not only on environmental cues but also on some internal representation of temporal or task context. It is assumed, in most theories, that such internal representations must be organized into a strict hierarchy, mirroring the hierarchical structure of naturalistic sequential behaviour. This article reviews an alternative computational account, which asserts that the representations underlying naturalistic sequential behaviour need not, and arguably cannot, assume a strictly hierarchical form. One apparent liability of this theory is that it seems to contradict neuroscientific evidence indicating that different levels of sequential structure in behaviour are represented at different levels in a hierarchy of cortical areas. New simulations, reported here, show not only that the original computational account can be reconciled with this alignment between behavioural and neural organization, but also that it gives rise to a novel explanation for how this alignment might develop through learning.},
  journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  number = {1485},
  pmcid = {PMC2440775},
  pmid = {17428777}
}

@article{Botvinick_Planning_2012,
  title = {Planning as Inference},
  author = {Botvinick, Matthew and Toussaint, Marc},
  year = {2012},
  month = oct,
  volume = {16},
  pages = {485--488},
  publisher = {{Elsevier}},
  issn = {1364-6613, 1879-307X},
  doi = {10.1016/j.tics.2012.08.006},
  journal = {Trends in Cognitive Sciences},
  language = {English},
  number = {10},
  pmid = {22940577}
}

@article{Bouc_Computational_2016,
  title = {Computational {{Dissection}} of {{Dopamine Motor}} and {{Motivational Functions}} in {{Humans}}},
  author = {Bouc, Rapha{\"e}l Le and Rigoux, Lionel and Schmidt, Liane and Degos, Bertrand and Welter, Marie-Laure and Vidailhet, Marie and Daunizeau, Jean and Pessiglione, Mathias},
  year = {2016},
  month = jun,
  volume = {36},
  pages = {6623--6633},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.3078-15.2016},
  abstract = {Motor dysfunction (e.g., bradykinesia) and motivational deficit (i.e., apathy) are hallmarks of Parkinson's disease (PD). Yet, it remains unclear whether these two symptoms arise from a same dopaminergic dysfunction. Here, we develop a computational model that articulates motor control to economic decision theory, to dissect the motor and motivational functions of dopamine in humans. This model can capture different aspects of the behavior: choice (which action is selected) and vigor (action speed and intensity). It was used to characterize the behavior of 24 PD patients, tested both when medicated and unmedicated, in two behavioral tasks: an incentive motivation task that involved producing a physical effort, knowing that it would be multiplied by reward level to calculate the payoff, and a binary choice task that involved choosing between high reward/high effort and low reward/low effort options. Model-free analyses in both tasks showed the same two effects when comparing unmedicated patients to medicated patients: dopamine depletion (1) decreased the amount of effort that patients were willing to produce for a given reward and (2) slowed down the production of this effort, regardless of reward level. Model-based analyses captured these effects with two independent parameters, namely reward sensitivity and motor activation rate. These two parameters were respectively predictive of medication effects on clinical measures of apathy and motor dysfunction. More generally, we suggest that such computational phenotyping might help characterizing deficits and refining treatments in neuropsychiatric disorders. SIGNIFICANCE STATEMENT Many neurological conditions are characterized by motor and motivational deficits, which both result in reduced behavior. It remains extremely difficult to disentangle whether these patients are simply unable or do not want to produce a behavior. Here, we propose a model-based analysis of the behavior produced in tasks that involve trading physical efforts for monetary rewards, to quantify parameters that capture motor dynamics as well as sensitivity to reward, effort, and fatigue. Applied to Parkinson's disease, this computational analysis revealed two independent effects of dopamine enhancers, which predicted clinical improvement in motor and motivational deficits. Such computational profiling might provide a useful explanatory level, between neural dysfunction and clinical manifestations, for characterizing neuropsychiatric disorders and personalizing treatments.},
  copyright = {Copyright \textcopyright{} 2016 the authors 0270-6474/16/366623-11\$15.00/0},
  journal = {Journal of Neuroscience},
  keywords = {decision making,dopamine,effort,motivation,Parkinson's disease,reward},
  language = {en},
  number = {25},
  pmid = {27335396}
}

@article{Braver_Neural_2003,
  title = {Neural {{Mechanisms}} of {{Transient}} and {{Sustained Cognitive Control}} during {{Task Switching}}},
  author = {Braver, Todd S and Reynolds, Jeremy R and Donaldson, David I},
  year = {2003},
  month = aug,
  volume = {39},
  pages = {713--726},
  issn = {0896-6273},
  doi = {10.1016/S0896-6273(03)00466-5},
  abstract = {A hybrid blocked and event-related functional magnetic resonance imaging (fMRI) study decomposed brain activity during task switching into sustained and transient components. Contrasting task-switching blocks against single-task blocks revealed sustained activation in right anterior prefrontal cortex (PFC). Contrasting task-switch trials against task-repeat and single-task trials revealed activation in left lateral PFC and left superior parietal cortex. In both sets of regions, activation dynamics were strongly modulated by trial-by-trial fluctuations in response speed. In addition, right anterior PFC activity selectively covaried with the magnitude of mixing cost (i.e., task-repeat versus single-task trial performance), and left superior parietal activity selectively covaried with the magnitude of the switching cost (i.e., task-switch versus task-repeat trial performance). These results indicate a functional double dissociation in brain regions supporting different components of cognitive control during task switching and suggest that both sustained and transient control processes mediate the behavioral performance costs of task switching.},
  journal = {Neuron},
  number = {4}
}

@article{Braver_Neural_2003a,
  title = {Neural {{Mechanisms}} of {{Transient}} and {{Sustained Cognitive Control}} during {{Task Switching}}},
  author = {Braver, Todd S and Reynolds, Jeremy R and Donaldson, David I},
  year = {2003},
  month = aug,
  volume = {39},
  pages = {713--726},
  issn = {0896-6273},
  doi = {10.1016/S0896-6273(03)00466-5},
  abstract = {A hybrid blocked and event-related functional magnetic resonance imaging (fMRI) study decomposed brain activity during task switching into sustained and transient components. Contrasting task-switching blocks against single-task blocks revealed sustained activation in right anterior prefrontal cortex (PFC). Contrasting task-switch trials against task-repeat and single-task trials revealed activation in left lateral PFC and left superior parietal cortex. In both sets of regions, activation dynamics were strongly modulated by trial-by-trial fluctuations in response speed. In addition, right anterior PFC activity selectively covaried with the magnitude of mixing cost (i.e., task-repeat versus single-task trial performance), and left superior parietal activity selectively covaried with the magnitude of the switching cost (i.e., task-switch versus task-repeat trial performance). These results indicate a functional double dissociation in brain regions supporting different components of cognitive control during task switching and suggest that both sustained and transient control processes mediate the behavioral performance costs of task switching.},
  journal = {Neuron},
  number = {4}
}

@article{Braver_Neural_2003b,
  title = {Neural {{Mechanisms}} of {{Transient}} and {{Sustained Cognitive Control}} during {{Task Switching}}},
  author = {Braver, Todd S. and Reynolds, Jeremy R. and Donaldson, David I.},
  year = {2003},
  month = aug,
  volume = {39},
  pages = {713--726},
  issn = {0896-6273},
  doi = {10.1016/S0896-6273(03)00466-5},
  abstract = {A hybrid blocked and event-related functional magnetic resonance imaging (fMRI) study decomposed brain activity during task switching into sustained and transient components. Contrasting task-switching blocks against single-task blocks revealed sustained activation in right anterior prefrontal cortex (PFC). Contrasting task-switch trials against task-repeat and single-task trials revealed activation in left lateral PFC and left superior parietal cortex. In both sets of regions, activation dynamics were strongly modulated by trial-by-trial fluctuations in response speed. In addition, right anterior PFC activity selectively covaried with the magnitude of mixing cost (i.e., task-repeat versus single-task trial performance), and left superior parietal activity selectively covaried with the magnitude of the switching cost (i.e., task-switch versus task-repeat trial performance). These results indicate a functional double dissociation in brain regions supporting different components of cognitive control during task switching and suggest that both sustained and transient control processes mediate the behavioral performance costs of task switching.},
  journal = {Neuron},
  language = {English},
  number = {4},
  pmid = {12925284}
}

@article{Braver_variable_2012,
  title = {The Variable Nature of Cognitive Control: A Dual Mechanisms Framework},
  shorttitle = {The Variable Nature of Cognitive Control},
  author = {Braver, Todd S.},
  year = {2012},
  month = feb,
  volume = {16},
  pages = {106--113},
  issn = {1364-6613},
  doi = {10.1016/j.tics.2011.12.010},
  abstract = {A core component of cognitive control \textendash{} the ability to regulate thoughts and actions in accordance with internally represented behavioral goals \textendash{} might be its intrinsic variability. In this article, I describe the dual mechanisms of control (DMC) framework, which postulates that this variability might arise from qualitative distinctions in temporal dynamics between proactive and reactive modes of control. Proactive control reflects the sustained and anticipatory maintenance of goal-relevant information within lateral prefrontal cortex (PFC) to enable optimal cognitive performance, whereas reactive control reflects transient stimulus-driven goal reactivation that recruits lateral PFC (plus a wider brain network) based on interference demands or episodic associations. I summarize recent research that demonstrates how the DMC framework provides a coherent explanation of three sources of cognitive control variation \textendash{} intra-individual, inter-individual and between-groups \textendash{} in terms of proactive versus reactive control biases.},
  journal = {Trends in Cognitive Sciences},
  number = {2}
}

@article{Briys_Risk_1990,
  title = {Risk {{Aversion}} and the {{Propensities}} for {{Self}}-{{Insurance}} and {{Self}}-{{Protection}}},
  author = {Briys, Eric and Schlesinger, Harris},
  year = {1990},
  volume = {57},
  pages = {458--467},
  issn = {0038-4038},
  doi = {10.2307/1060623},
  journal = {Southern Economic Journal},
  number = {2}
}

@article{Brochu_Tutorial_2010,
  title = {A {{Tutorial}} on {{Bayesian Optimization}} of {{Expensive Cost Functions}}, with {{Application}} to {{Active User Modeling}} and {{Hierarchical Reinforcement Learning}}},
  author = {Brochu, Eric and Cora, Vlad M. and {de Freitas}, Nando},
  year = {2010},
  month = dec,
  abstract = {We present a tutorial on Bayesian optimization, a method of finding the maximum of expensive cost functions. Bayesian optimization employs the Bayesian technique of setting a prior over the objective function and combining it with evidence to get a posterior function. This permits a utility-based selection of the next observation to make on the objective function, which must take into account both exploration (sampling from areas of high uncertainty) and exploitation (sampling areas likely to offer improvement over the current best observation). We also present two detailed extensions of Bayesian optimization, with experiments---active user modelling with preferences, and hierarchical reinforcement learning---and a discussion of the pros and cons of Bayesian optimization based on our experiences.},
  archivePrefix = {arXiv},
  eprint = {1012.2599},
  eprinttype = {arxiv},
  journal = {arXiv:1012.2599 [cs]},
  keywords = {Computer Science - Machine Learning,G.1.6,G.3,I.2.6},
  primaryClass = {cs}
}

@article{Bromberg-Martin_Dopamine_2010,
  title = {Dopamine in Motivational Control: Rewarding, Aversive, and Alerting},
  shorttitle = {Dopamine in Motivational Control},
  author = {{Bromberg-Martin}, Ethan S. and Matsumoto, Masayuki and Hikosaka, Okihide},
  year = {2010},
  month = dec,
  volume = {68},
  pages = {815--834},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2010.11.022},
  abstract = {Midbrain dopamine neurons are well known for their strong responses to rewards and their critical role in positive motivation. It has become increasingly clear, however, that dopamine neurons also transmit signals related to salient but non-rewarding experiences such as aversive and alerting events. Here we review recent advances in understanding the reward and non-reward functions of dopamine. Based on this data, we propose that dopamine neurons come in multiple types that are connected with distinct brain networks and have distinct roles in motivational control. Some dopamine neurons encode motivational value, supporting brain networks for seeking, evaluation, and value learning. Others encode motivational salience, supporting brain networks for orienting, cognition, and general motivation. Both types of dopamine neurons are augmented by an alerting signal involved in rapid detection of potentially important sensory cues. We hypothesize that these dopaminergic pathways for value, salience, and alerting cooperate to support adaptive behavior.},
  journal = {Neuron},
  number = {5},
  pmcid = {PMC3032992},
  pmid = {21144997}
}

@article{Broome_Encoding_2006,
  title = {Encoding and {{Decoding}} of {{Overlapping Odor Sequences}}},
  author = {Broome, Bede M. and Jayaraman, Vivek and Laurent, Gilles},
  year = {2006},
  month = aug,
  volume = {51},
  pages = {467--482},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2006.07.018},
  abstract = {Summary Odors evoke complex responses in locust antennal lobe projection neurons (PNs)\textemdash the mitral cell analogs. These patterns evolve over hundreds of milliseconds and contain information about odor identity and concentration. In nature, animals often encounter many odorants in short temporal succession. We explored the effects of such conditions by presenting~two different odors with variable intervening delays. PN ensemble representations tracked stimulus changes and, in some delay conditions, reached states that corresponded neither to the representation of either odor alone nor to the static mixture of the two. We then recorded from Kenyon cells (KCs), the PNs' targets. Their responses were consistent with the PN population's behavior: in some conditions, KCs were recruited that did not fire during single-odor or mixture stimuli. Thus, PN population dynamics are history dependent, and responses of individual KCs are consistent with piecewise temporal decoding of PN output over large sections of the PN population.},
  journal = {Neuron},
  keywords = {SYSNEURO},
  number = {4}
}

@article{Buchsbaum_Metaanalysis_2005,
  title = {Meta-Analysis of Neuroimaging Studies of the {{Wisconsin Card}}-{{Sorting}} Task and Component Processes},
  author = {Buchsbaum, Bradley R. and Greer, Stephanie and Chang, Wei-Li and Berman, Karen Faith},
  year = {2005},
  month = may,
  volume = {25},
  pages = {35--45},
  issn = {1097-0193},
  doi = {10.1002/hbm.20128},
  abstract = {A quantitative meta-analysis using the activation likelihood estimation (ALE) method was used to investigate the brain basis of the Wisconsin Card-Sorting Task (WCST) and two hypothesized component processes, task switching and response suppression. All three meta-analyses revealed distributed frontoparietal activation patterns consistent with the status of the WCST as an attention-demanding executive task. The WCST was associated with extensive bilateral clusters of reliable cross-study activity in the lateral prefrontal cortex, anterior cingulate cortex, and inferior parietal lobule. Task switching revealed a similar, although less robust, frontoparietal pattern with additional clusters of activity in the opercular region of the ventral prefrontal cortex, bilaterally. Response-suppression tasks, represented by studies of the go/no-go paradigm, showed a large and highly right-lateralized region of activity in the right prefrontal cortex. The activation patterns are interpreted as reflecting a neural fractionation of the cognitive components that must be integrated during the performance of the WCST. Hum Brain Mapp 25:35\textendash 45, 2005. \textcopyright{} 2005 Wiley-Liss, Inc.},
  copyright = {Copyright \textcopyright{} 2005 Wiley-Liss, Inc.},
  journal = {Human Brain Mapping},
  keywords = {executive cognition,Meta-analysis,neuroimaging,response-suppression,task-switching,Wisconsin Card-Sorting Test},
  language = {en},
  number = {1}
}

@article{Buck_Information_1996,
  title = {Information {{Coding}} in the {{Vertebrate Olfactory System}}},
  author = {Buck, L B},
  year = {1996},
  volume = {19},
  pages = {517--544},
  doi = {10.1146/annurev.ne.19.030196.002505},
  journal = {Annual Review of Neuroscience},
  number = {1},
  pmid = {8833453}
}

@article{Buesing_Neural_2011,
  title = {Neural {{Dynamics}} as {{Sampling}}: {{A Model}} for {{Stochastic Computation}} in {{Recurrent Networks}} of {{Spiking Neurons}}},
  author = {Buesing, Lars and Bill, Johannes and Nessler, Bernhard and Maass, Wolfgang},
  year = {2011},
  month = nov,
  volume = {7},
  pages = {e1002211},
  doi = {10.1371/journal.pcbi.1002211},
  abstract = {The organization of computations in networks of spiking neurons in the brain is still largely unknown, in particular in view of the inherently stochastic features of their firing activity and the experimentally observed trial-to-trial variability of neural systems in the brain. In principle there exists a powerful computational framework for stochastic computations, probabilistic inference by sampling, which can explain a large number of macroscopic experimental data in neuroscience and cognitive science. But it has turned out to be surprisingly difficult to create a link between these abstract models for stochastic computations and more detailed models of the dynamics of networks of spiking neurons. Here we create such a link and show that under some conditions the stochastic firing activity of networks of spiking neurons can be interpreted as probabilistic inference via Markov chain Monte Carlo (MCMC) sampling. Since common methods for MCMC sampling in distributed systems, such as Gibbs sampling, are inconsistent with the dynamics of spiking neurons, we introduce a different approach based on non-reversible Markov chains that is able to reflect inherent temporal processes of spiking neuronal activity through a suitable choice of random variables. We propose a neural network model and show by a rigorous theoretical analysis that its neural activity implements MCMC sampling of a given distribution, both for the case of discrete and continuous time. This provides a step towards closing the gap between abstract functional models of cortical computation and more detailed models of networks of spiking neurons.},
  journal = {PLoS Comput Biol},
  number = {11}
}

@article{Bullmore_economy_2012,
  title = {The Economy of Brain Network Organization},
  author = {Bullmore, Ed and Sporns, Olaf},
  year = {2012},
  month = may,
  volume = {13},
  pages = {336--349},
  issn = {1471-003X},
  doi = {10.1038/nrn3214},
  abstract = {The brain is expensive, incurring high material and metabolic costs for its size \textemdash{} relative to the size of the body \textemdash{} and many aspects of brain network organization can be mostly explained by a parsimonious drive to minimize these costs. However, brain networks or connectomes also have high topological efficiency, robustness, modularity and a 'rich club' of connector hubs. Many of these and other advantageous topological properties will probably entail a wiring-cost premium. We propose that brain organization is shaped by an economic trade-off between minimizing costs and allowing the emergence of adaptively valuable topological patterns of anatomical or functional connectivity between multiple neuronal populations. This process of negotiating, and re-negotiating, trade-offs between wiring cost and topological value continues over long (decades) and short (millisecond) timescales as brain networks evolve, grow and adapt to changing cognitive demands. An economical analysis of neuropsychiatric disorders highlights the vulnerability of the more costly elements of brain networks to pathological attack or abnormal development.},
  copyright = {\textcopyright{} 2012 Nature Publishing Group},
  journal = {Nature Reviews Neuroscience},
  language = {en},
  number = {5}
}

@article{Bunge_How_2004,
  title = {How We Use Rules to Select Actions: A Review of Evidence from Cognitive Neuroscience},
  shorttitle = {How We Use Rules to Select Actions},
  author = {Bunge, Silvia A.},
  year = {2004},
  month = dec,
  volume = {4},
  pages = {564--579},
  issn = {1530-7026},
  abstract = {Much of our behavior is guided by rules, or prescribed guides for action. In this review, I consider the current state of knowledge of how rules are learned, stored in the brain, and retrieved and used as the need arises. The focus is primarily on studies in humans, but the review is informed by relevant studies in nonhuman primates. Ventrolateral prefrontal cortex (VLPFC) has been implicated in rule learning, retrieval from long-term memory, and on-line maintenance during task preparation. Interactions between VLPFC and temporal cortex are required for rule retrieval in nonhuman primates, and brain imaging findings in humans suggest that rule knowledge is stored in the posterior middle temporal gyrus. Dorsolateral PFC appears to be more closely related to rule-based response selection than to rule retrieval. An important task for the future is to explain how PFC, basal ganglia, and temporal, parietal, and motor cortices interact to produce rule-guided behavior.},
  journal = {Cognitive, Affective \& Behavioral Neuroscience},
  keywords = {cognition,Cues,Humans,Learning,Magnetic Resonance Imaging,Motor Cortex,Neurosciences,Prefrontal cortex,Reaction Time,Temporal Lobe},
  language = {eng},
  number = {4},
  pmid = {15849898}
}

@article{Bunge_How_2004a,
  title = {How We Use Rules to Select Actions: {{A}} Review of Evidence from Cognitive Neuroscience},
  shorttitle = {How We Use Rules to Select Actions},
  author = {Bunge, Silvia A.},
  year = {2004},
  month = dec,
  volume = {4},
  pages = {564--579},
  issn = {1530-7026, 1531-135X},
  doi = {10.3758/CABN.4.4.564},
  abstract = {Much of our behavior is guided by rules, or prescribed guides for action. In this review, I consider the current state of knowledge of how rules are learned, stored in the brain, and retrieved and used as the need arises. The focus is primarily on studies in humans, but the review is informed by relevant studies in nonhuman primates. Ventrolateral prefrontal cortex (VLPFC) has been implicated in rule learning, retrieval from long-term memory, and on-line maintenance during task preparation. Interactions between VLPFC and temporal cortex are required for rule retrieval in nonhuman primates, and brain imaging findings in humans suggest that rule knowledge is stored in the posterior middle temporal gyrus. Dorsolateral PFC appears to be more closely related to rule-based response selection than to rule retrieval. An important task for the future is to explain how PFC, basal ganglia, and temporal, parietal, and motor cortices interact to produce rule-guided behavior.},
  journal = {Cognitive, Affective, \& Behavioral Neuroscience},
  keywords = {Cognitive Psychology,Neurosciences},
  language = {en},
  number = {4}
}

@article{Bunge_Immature_2002,
  title = {Immature {{Frontal Lobe Contributions}} to {{Cognitive Control}} in {{Children}}: {{Evidence}} from {{fMRI}}},
  shorttitle = {Immature {{Frontal Lobe Contributions}} to {{Cognitive Control}} in {{Children}}},
  author = {Bunge, Silvia A. and Dudukovic, Nicole M. and Thomason, Moriah E. and Vaidya, Chandan J. and Gabrieli, John D. E.},
  year = {2002},
  month = jan,
  volume = {33},
  pages = {301--311},
  issn = {0896-6273},
  doi = {10.1016/S0896-6273(01)00583-9},
  abstract = {Event-related fMRI was employed to characterize differences in brain activation between children ages 8\textendash 12 and adults related to two forms of cognitive control: interference suppression and response inhibition. Children were more susceptible to interference and less able to inhibit inappropriate responses than were adults. Effective interference suppression in children was associated with prefrontal activation in the opposite hemisphere relative to adults. In contrast, effective response inhibition in children was associated with activation of posterior, but not prefrontal, regions activated by adults. Children failed to activate a region in right ventrolateral prefrontal cortex that was recruited for both types of cognitive control by adults. Thus, children exhibited immature prefrontal activation that varied according to the type of cognitive control required.},
  journal = {Neuron},
  number = {2}
}

@article{Buonomano_Statedependent_2009,
  title = {State-Dependent Computations: Spatiotemporal Processing in Cortical Networks},
  shorttitle = {State-Dependent Computations},
  author = {Buonomano, Dean V. and Maass, Wolfgang},
  year = {2009},
  month = feb,
  volume = {10},
  pages = {113--125},
  issn = {1471-003X},
  doi = {10.1038/nrn2558},
  abstract = {A conspicuous ability of the brain is to seamlessly assimilate and process spatial and temporal features of sensory stimuli. This ability is indispensable for the recognition of natural stimuli. Yet, a general computational framework for processing spatiotemporal stimuli remains elusive. Recent theoretical and experimental work suggests that spatiotemporal processing emerges from the interaction between incoming stimuli and the internal dynamic state of neural networks, including not only their ongoing spiking activity but also their 'hidden' neuronal states, such as short-term synaptic plasticity.},
  copyright = {\textcopyright{} 2009 Nature Publishing Group},
  journal = {Nature Reviews Neuroscience},
  language = {en},
  number = {2}
}

@book{Burnham_Model_2002,
  title = {Model Selection and Multimodel Inference: A Practical Information-Theoretic Approach},
  author = {Burnham, K. P. and Anderson, D. R.},
  year = {2002},
  edition = {Second},
  publisher = {{Springer}},
  address = {{New York}},
  abstract = {This book is unique in that it covers the philosophy of model-based data analysis and a strategy for the analysis of empirical data. The book introduces information theoretic approaches and focuses critical attention on a priori modeling and the selection of a good approximating model that best represents the inference supported by the data. Kullback-Leibler Information represents a fundamental quantity in science and is Hirotugu Akaike's basis for model selection. The maximized log-likelihood function can be bias-corrected to provide an estimate of expected, relative Kullback-Leibler information. This leads to Akaike's Information Criterion (AIC) and various extensions. These are relatively simple and easy to use in practice. The information theoretic approaches provide a unified and rigorous theory, an extension of likelihood theory, an important application of information theory, and are objective and practical to employ across a very wide class of empirical problems. Model selection, under the information theoretic approach presented here, attempts to identify the (likely) best model, orders the models from best to worst, and measures the plausibility ("calibration") that each model is really the best as an inference. Model selection methods are extended to allow inference from more than a single "best" model. The book presents several new approaches to estimating model selection uncertainty and incorporating selection uncertainty into estimates of precision. An array of examples is given to illustrate various technical issues. This is an applied book written primarily for biologists and statisticians using models for making inferences from empirical data. People interested in the empirical sciences will find this material useful as it offers an alternative to hypothesis testing and Bayesian.},
  language = {English}
}

@book{Burnham_Model_2002a,
  title = {Model Selection and Multimodel Inference. {{A}} Practical Information-Theoretic Approach},
  author = {Burnham, Kenneth P. and Anderson, David R.},
  year = {2002},
  edition = {Second},
  publisher = {{Springer}}
}

@article{Bushdid_Humans_2014,
  title = {Humans {{Can Discriminate More}} than 1 {{Trillion Olfactory Stimuli}}},
  author = {Bushdid, C. and Magnasco, M. O. and Vosshall, L. B. and Keller, A.},
  year = {2014},
  month = mar,
  volume = {343},
  pages = {1370--1372},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1249168},
  abstract = {Humans can discriminate several million different colors and almost half a million different tones, but the number of discriminable olfactory stimuli remains unknown. The lay and scientific literature typically claims that humans can discriminate 10,000 odors, but this number has never been empirically validated. We determined the resolution of the human sense of smell by testing the capacity of humans to discriminate odor mixtures with varying numbers of shared components. On the basis of the results of psychophysical testing, we calculated that humans can discriminate at least 1 trillion olfactory stimuli. This is far more than previous estimates of distinguishable olfactory stimuli. It demonstrates that the human olfactory system, with its hundreds of different olfactory receptors, far outperforms the other senses in the number of physically different stimuli it can discriminate. All the Smells of the World How many odorant stimuli can a normal human being discriminate? During psychophysical tests of odor mixture discrimination, Bushdid et al. (p. 1370) were surprised to find that humans can discriminate among more than a trillion different smells. Because the authors reduced the complexity by investigating only mixtures of 10, 20, or 30 components drawn from a collection of 128 odorous molecules, this astonishingly large number is probably the lower limit of the potential number of olfactory stimuli that humans can distinguish.},
  journal = {Science},
  language = {en},
  number = {6177},
  pmid = {24653035}
}

@article{Butcher_RungeKutta_2007,
  title = {Runge-{{Kutta}} Methods},
  author = {Butcher, John},
  year = {2007},
  volume = {2},
  pages = {3147},
  issn = {1941-6016},
  doi = {10.4249/scholarpedia.3147},
  journal = {Scholarpedia},
  language = {en},
  number = {9}
}

@article{Butepage_Anticipating_2017,
  title = {Anticipating Many Futures: {{Online}} Human Motion Prediction and Synthesis for Human-Robot Collaboration},
  shorttitle = {Anticipating Many Futures},
  author = {B{\"u}tepage, Judith and Kjellstr{\"o}m, Hedvig and Kragic, Danica},
  year = {2017},
  month = feb,
  abstract = {Fluent and safe interactions of humans and robots require both partners to anticipate the others' actions. A common approach to human intention inference is to model specific trajectories towards known goals with supervised classifiers. However, these approaches do not take possible future movements into account nor do they make use of kinematic cues, such as legible and predictable motion. The bottleneck of these methods is the lack of an accurate model of general human motion. In this work, we present a conditional variational autoencoder that is trained to predict a window of future human motion given a window of past frames. Using skeletal data obtained from RGB depth images, we show how this unsupervised approach can be used for online motion prediction for up to 1660 ms. Additionally, we demonstrate online target prediction within the first 300-500 ms after motion onset without the use of target specific training data. The advantage of our probabilistic approach is the possibility to draw samples of possible future motions. Finally, we investigate how movements and kinematic cues are represented on the learned low dimensional manifold.},
  archivePrefix = {arXiv},
  eprint = {1702.08212},
  eprinttype = {arxiv},
  journal = {arXiv:1702.08212 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Human-Computer Interaction,Computer Science - Robotics},
  primaryClass = {cs}
}

@article{Byom_Theory_2013,
  title = {Theory of Mind: Mechanisms, Methods, and New Directions},
  shorttitle = {Theory of Mind},
  author = {Byom, Lindsey Jacquelyn and Mutlu, Bilge},
  year = {2013},
  volume = {7},
  publisher = {{Frontiers}},
  issn = {1662-5161},
  doi = {10.3389/fnhum.2013.00413},
  abstract = {Theory of Mind (ToM) has received significant research attention. Traditional ToM research has provided important understanding of how humans reason about mental states by utilizing shared world knowledge, social cues, and the interpretation of actions, however many current behavioral paradigms are limited to static, ``third-person'' protocols. Emerging experimental approaches such as cognitive simulation and simulated social interaction offer opportunities to investigate ToM in interactive, ``first-person'' and ``second-person'' scenarios while affording greater experimental control. The advantages and limitations of traditional and emerging ToM methodologies are discussed with the intent of advancing the understanding of ToM in socially mediated situations.},
  journal = {Frontiers in Human Neuroscience},
  keywords = {cognitive simulation,simulated social interaction,social cognition,social perception,theory of mind (ToM)},
  language = {English}
}

@article{Cacioppo_Dispositional_1996,
  title = {Dispositional Differences in Cognitive Motivation: {{The}} Life and Times of Individuals Varying in Need for Cognition},
  shorttitle = {Dispositional Differences in Cognitive Motivation},
  author = {Cacioppo, John T. and Petty, Richard E. and Feinstein, Jeffrey A. and Jarvis, W. Blair G.},
  year = {1996},
  volume = {119},
  pages = {197--253},
  issn = {1939-1455(Electronic),0033-2909(Print)},
  doi = {10.1037/0033-2909.119.2.197},
  abstract = {Need for cognition in contemporary literature refers to an individual's tendency to engage in and enjoy effortful cognitive endeavors. Individual differences in need for cognition have been the focus of investigation in over 100 empirical studies. This literature is reviewed, covering the theory and history of this variable, measures of interindividual variations in it, and empirical relationships between it and personality variables, as well as individuals' tendencies to seek and engage in effortful cognitive activity and enjoy cognitively effortful circumstances. The article concludes with discussions of an elaborated theory of the variable, including antecedent conditions; interindividual variations in it related to the manner information is acquired or processed to guide perceptions, judgments, and behavior; and the relationship between it and the 5-factor model of personality structure. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  journal = {Psychological Bulletin},
  keywords = {Cognition,Individual Differences,Literature Review,Motivation,Personality Theory},
  number = {2}
}

@article{Calandra_Bayesian_2016,
  title = {Bayesian Optimization for Learning Gaits under Uncertainty},
  author = {Calandra, Roberto and Seyfarth, Andr{\'e} and Peters, Jan and Deisenroth, Marc Peter},
  year = {2016},
  month = feb,
  volume = {76},
  pages = {5--23},
  issn = {1573-7470},
  doi = {10.1007/s10472-015-9463-9},
  abstract = {Designing gaits and corresponding control policies is a key challenge in robot locomotion. Even with a viable controller parametrization, finding near-optimal parameters can be daunting. Typically, this kind of parameter optimization requires specific expert knowledge and extensive robot experiments. Automatic black-box gait optimization methods greatly reduce the need for human expertise and time-consuming design processes. Many different approaches for automatic gait optimization have been suggested to date. However, no extensive comparison among them has yet been performed. In this article, we thoroughly discuss multiple automatic optimization methods in the context of gait optimization. We extensively evaluate Bayesian optimization, a model-based approach to black-box optimization under uncertainty, on both simulated problems and real robots. This evaluation demonstrates that Bayesian optimization is particularly suited for robotic applications, where it is crucial to find a good set of gait parameters in a small number of experiments.},
  journal = {Annals of Mathematics and Artificial Intelligence},
  language = {en},
  number = {1}
}

@article{Camerer_Effects_1999,
  title = {The {{Effects}} of {{Financial Incentives}} in {{Experiments}}: {{A Review}} and {{Capital}}-{{Labor}}-{{Production Framework}}},
  shorttitle = {The {{Effects}} of {{Financial Incentives}} in {{Experiments}}},
  author = {Camerer, Colin F. and Hogarth, Robin M.},
  year = {1999},
  month = dec,
  volume = {19},
  pages = {7--42},
  issn = {1573-0476},
  doi = {10.1023/A:1007850605129},
  abstract = {We review 74 experiments with no, low, or high performance-based financial incentives. The modal result has no effect on mean performance (though variance is usually reduced by higher payment). Higher incentive does improve performance often, typically judgment tasks that are responsive to better effort. Incentives also reduce ``presentation'' effects (e.g., generosity and risk-seeking). Incentive effects are comparable to effects of other variables, particularly ``cognitive capital'' and task ``production'' demands, and interact with those variables, so a narrow-minded focus on incentives alone is misguided. We also note that no replicated study has made rationality violations disappear purely by raising incentives.},
  journal = {Journal of Risk and Uncertainty},
  keywords = {bounded rationality,experimental economics,experimental methodology,incentives,judgment,rationality},
  language = {en},
  number = {1}
}

@article{Capurro_Temporal_2014,
  title = {Temporal {{Features}} of {{Spike Trains}} in the {{Moth Antennal Lobe Revealed}} by a {{Comparative Time}}-{{Frequency Analysis}}},
  author = {Capurro, Alberto and Baroni, Fabiano and Kuebler, Linda S. and K{\'a}rp{\'a}ti, Zsolt and Dekker, Teun and Lei, Hong and Hansson, Bill S. and Pearce, Timothy C. and Olsson, Shannon B.},
  year = {2014},
  month = jan,
  volume = {9},
  pages = {e84037},
  doi = {10.1371/journal.pone.0084037},
  abstract = {The discrimination of complex sensory stimuli in a noisy environment is an immense computational task. Sensory systems often encode stimulus features in a spatiotemporal fashion through the complex firing patterns of individual neurons. To identify these temporal features, we have developed an analysis that allows the comparison of statistically significant features of spike trains localized over multiple scales of time-frequency resolution. Our approach provides an original way to utilize the discrete wavelet transform to process instantaneous rate functions derived from spike trains, and select relevant wavelet coefficients through statistical analysis. Our method uncovered localized features within olfactory projection neuron (PN) responses in the moth antennal lobe coding for the presence of an odor mixture and the concentration of single component odorants, but not for compound identities. We found that odor mixtures evoked earlier responses in biphasic response type PNs compared to single components, which led to differences in the instantaneous firing rate functions with their signal power spread across multiple frequency bands (ranging from 0 to 45.71 Hz) during a time window immediately preceding behavioral response latencies observed in insects. Odor concentrations were coded in excited response type PNs both in low frequency band differences (2.86 to 5.71 Hz) during the stimulus and in the odor trace after stimulus offset in low (0 to 2.86 Hz) and high (22.86 to 45.71 Hz) frequency bands. These high frequency differences in both types of PNs could have particular relevance for recruiting cellular activity in higher brain centers such as mushroom body Kenyon cells. In contrast, neurons in the specialized pheromone-responsive area of the moth antennal lobe exhibited few stimulus-dependent differences in temporal response features. These results provide interesting insights on early insect olfactory processing and introduce a novel comparative approach for spike train analysis applicable to a variety of neuronal data sets.},
  journal = {PLoS ONE},
  number = {1}
}

@article{Caraco_empirical_1980,
  title = {An Empirical Demonstration of Risk-Sensitive Foraging Preferences},
  author = {Caraco, Thomas and Martindale, Steven and Whittam, Thomas S.},
  year = {1980},
  month = aug,
  volume = {28},
  pages = {820--830},
  issn = {0003-3472},
  doi = {10.1016/S0003-3472(80)80142-4},
  abstract = {We report laboratory experiments with yellow-eyed juncos (Junco phaeonotus) revealing that the birds' foraging preferences for variable rewards respond not only to the mean, but also the variance, of food rewards. The nature of their preferences for variable rewards is related to their expected daily energy budget. We summarize the birds' preferences in utility functions for energetic rewards. Since mean reward size is inadequate to predict their behaviour, we believe that foraging models should consider environmental stochasticity and an animal's response to this variation.},
  journal = {Animal Behaviour},
  number = {3}
}

@article{Caraco_Risksensitivity_1990,
  title = {Risk-Sensitivity: Ambient Temperature Affects Foraging Choice},
  shorttitle = {Risk-Sensitivity},
  author = {Caraco, Thomas and Blanckenhorn, Wolf U. and Gregory, Gina M. and Newman, Jonathan A. and Recer, Gregg M. and Zwicker, Susan M.},
  year = {1990},
  month = feb,
  volume = {39},
  pages = {338--345},
  issn = {0003-3472},
  doi = {10.1016/S0003-3472(05)80879-6},
  abstract = {Short-term physiological requirements strongly constrain some foragers. During the limited time available for foraging, they must consume sufficient food to meet all energetic expenditures for 24 h. Models for risk-sensitive, decision-making predict that such a forager should be risk-averse toward reward variance when the animal expects to meet its requirement, and should be risk-prone toward reward variance when expecting an energetic deficit. Some previous demonstrations of this shift from risk-averse to risk-prone behaviour relied on differences in both pre-experimental deprivation and inter-trial delays within an experiment to vary the subjects' energy budgets, and these differences have allowed an alternate interpretation of observed preferences. Therefore, earlier work on risk-sensitive foraging in small birds was complemented by manipulating ambient temperature to induce positive and negative expected energy budgets. For a given mean reward, the inter-trial delay was the same, constant length at both temperatures. When subjects experienced a positive energy budget (warm temperature), risk-aversion exceeded preference for risk strikingly; the opposite occurred when the subjects could anticipate a negative energy budget (cold temperature). Variation in inter-trial delays could not have influenced the change in preference reported here.},
  journal = {Animal Behaviour},
  number = {2}
}

@article{Cartar_Why_1990,
  title = {Why Are Bumble Bees Risk-Sensitive Foragers?},
  author = {Cartar, R.V. and Dill, L.M.},
  year = {1990},
  volume = {26},
  pages = {121--127},
  doi = {10.1007/BF00171581},
  abstract = {In a controlled laboratory experiment, we re-examined the question of bumble bee risk-sensitivity. Harder and Real's (1987) analysis of previous work on bumble bee risk aversion suggests that risk-sensitivity in these organisms is a result of their maximizing the net rate of energy return (calculated as the average of expected per flower rates). Whether bees are risk-sensitive foragers with respect to minimizing the probability of energetic shortfall is therefore still an open question. We examined how the foraging preferences of bumble bees for nectar reward variation were affected by colony energy reserves, which we manipulated by draining or adding sucrose solution to colony honey pots. Nine workers from four confined colonies of Bombus occidentalis foraged for sucrose solution in two patches of artificial flowers. These patches yielded the same expected rate of net energy intake, but floral volumes were variable in one patch and constant in the other. Our results show that bumble bees can be both risk-averse (preferring constant flowers) and risk-prone (preferring variable flowers), depending on the status of their colony energy reserves. Diet choice in bumble bees appears to be sensitive to the "target value" a colony-level energetic requirement. \textcopyright{} 1990 Springer-Verlag.},
  journal = {Behavioral Ecology and Sociobiology},
  number = {2}
}

@article{Carter_Anterior_2007,
  title = {Anterior Cingulate Cortex and Conflict Detection: {{An}} Update of Theory and Data},
  shorttitle = {Anterior Cingulate Cortex and Conflict Detection},
  author = {Carter, Cameron S. and van Veen, Vincent},
  year = {2007},
  month = dec,
  volume = {7},
  pages = {367--379},
  issn = {1530-7026, 1531-135X},
  doi = {10.3758/CABN.7.4.367},
  abstract = {The dorsal anterior cingulate cortex (ACC) and associated regions of the medial frontal wall have often been hypothesized to play an important role in cognitive control. We have proposed that the ACC's specific role in cognitive control is to detect conflict between simultaneously active, competing representations and to engage the dorsolateral prefrontal cortex (DLPFC) to resolve such conflict. Here we review some of the evidence supporting this theory, from event-related potential (ERP) and fMRI studies. We focus on data obtained from interference tasks, such as the Stroop task, and review the evidence that trial-to-trial changes in control engagement can be understood as driven by conflict detection; the data suggest that levels of activation of the ACC and the DLPFC in such tasks do indeed reflect conflict and control, respectively. We also discuss some discrepant results in the literature that highlight the need for future research.},
  journal = {Cognitive, Affective, \& Behavioral Neuroscience},
  keywords = {Cognitive Psychology,Neurosciences},
  language = {en},
  number = {4}
}

@article{Carvalho_Arrow_2008,
  title = {The {{Arrow}} of {{Time}}: {{How Does}} the {{Brain Represent Natural Temporal Structure}}?},
  shorttitle = {The {{Arrow}} of {{Time}}},
  author = {Carvalho, Fabiana Mesquita and Kriegeskorte, Nikolaus},
  year = {2008},
  month = aug,
  volume = {28},
  pages = {7933--7935},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.1781-08.2008},
  abstract = {There is an extensive literature about the neuronal processes in the visual system that enable us to appreciate spatial structure at different scales. Basically, spatial receptive fields increase in size and complexity from early- to high-level visual areas. But what about our sense of temporal},
  copyright = {Copyright \textcopyright{} 2008 Society for Neuroscience 0270-6474/08/287933-03\$15.00/0},
  journal = {Journal of Neuroscience},
  language = {en},
  number = {32},
  pmid = {18685018}
}

@article{Chapman_Temporal_1996,
  title = {Temporal Discounting and Utility for Health and Money},
  author = {Chapman, Gretchen B.},
  year = {1996},
  volume = {22},
  pages = {771--791},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1285(Electronic),0278-7393(Print)},
  doi = {10.1037/0278-7393.22.3.771},
  abstract = {In 3 experiments choices for hypothetical amounts of future health and money showed that, contrary to normative discounted utility theory, the temporal discount rate, or annual percentage increase in value needed to offset a delay, differed for the 2 domains. Domain independence, defined as the low correlation between health and money discount rates relative to the consistency within each domain, was not due to different utility functions for health and money. Consistent with other research, these results suggest that decision domain affect the cognitive processes used. Despite this domain difference, there were some similarities between the 2 domains. Both health and money decisions revealed that discount rates were larger for short delays, small magnitudes, and gains as compared with losses. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  keywords = {Choice Behavior,Decision Making,Delay Discounting,Expectations,Health,Money,Theories},
  number = {3}
}

@article{Charness_Experimental_2013,
  title = {Experimental Methods: {{Eliciting}} Risk Preferences},
  shorttitle = {Experimental Methods},
  author = {Charness, Gary and Gneezy, Uri and Imas, Alex},
  year = {2013},
  month = mar,
  volume = {87},
  pages = {43--51},
  issn = {0167-2681},
  doi = {10.1016/j.jebo.2012.12.023},
  abstract = {Economists and psychologists have developed a variety of experimental methodologies to elicit and assess individual risk attitudes. Choosing which to utilize, however, is largely dependent on the question one wants to answer, as well as the characteristics of the sample population. The goal of this paper is to present a series of prevailing methods for eliciting risk preferences and outline the advantages and disadvantages of each. We do not attempt to give a comprehensive account of all the methods or nuances of measuring risk, but rather to outline some advantages and disadvantages of different methods.},
  journal = {Journal of Economic Behavior \& Organization},
  keywords = {Elicitation methods,Experimental methodology,Risk preferences}
}

@article{Choi_Consistency_2007,
  title = {Consistency and {{Heterogeneity}} of {{Individual Behavior}} under {{Uncertainty}}},
  author = {Choi, Syngjoo and Fisman, Raymond and Gale, Douglas and Kariv, Shachar},
  year = {2007},
  month = dec,
  volume = {97},
  pages = {1921--1938},
  issn = {0002-8282},
  doi = {10.1257/aer.97.5.1921},
  abstract = {By using graphical representations of simple portfolio choice problems, we generate a very rich dataset to study behavior under uncertainty at the level of the individual subject. We test the data for consistency with the maximization hypothesis, and we estimate preferences using a two-parameter utility function based on Faruk Gul (1991). This specification provides a good interpretation of the data at the individual level and can account for the highly heterogeneous behaviors observed in the laboratory. The parameter estimates jointly describe attitudes toward risk and allow us to characterize the distribution of risk preferences in the population. (JEL D11, D14, D81, G11)},
  journal = {American Economic Review},
  number = {5}
}

@article{Chou_Diversity_2010,
  title = {Diversity and {{Wiring Variability}} of {{Olfactory Local Interneurons}} in the {{Drosophila Antennal Lobe}}},
  author = {Chou, Ya-Hui and Spletter, Maria L. and Yaksi, Emre and Leong, Jonathan C. S. and Wilson, Rachel I. and Luo, Liqun},
  year = {2010},
  month = apr,
  volume = {13},
  pages = {439--449},
  issn = {1097-6256},
  doi = {10.1038/nn.2489},
  abstract = {Local interneurons play essential roles in information processing by neural circuits. Here we present a comprehensive genetic, anatomical, and electrophysiological analysis of local interneurons (LNs) in the Drosophila antennal lobe, the first olfactory processing center in the brain. We find that LNs are diverse in their neurotransmitter profiles, connectivity, and physiological properties. Analysis of {$>$}1500 individual LNs reveals major morphological classes characterized by coarsely stereotyped glomerular innervation patterns. Some of these morphological classes exhibit distinct physiological properties. However, the finer-scale connectivity of an individual LN varies considerably across brains and there is notable physiological variability within each morphological or genetic class. Finally, we show that LN innervation requires interaction with olfactory receptor neurons during development, and some individual variability also likely reflects LN-LN interactions. Our results reveal an unexpected degree of complexity and individual variation in an invertebrate neural circuit, a result that creates challenges for solving the Drosophila connectome.},
  journal = {Nature neuroscience},
  number = {4},
  pmcid = {PMC2847188},
  pmid = {20139975}
}

@article{Churchland_Decisionmaking_2008,
  title = {Decision-Making with Multiple Alternatives},
  author = {Churchland, Anne K. and Kiani, Roozbeh and Shadlen, Michael N.},
  year = {2008},
  month = jun,
  volume = {11},
  pages = {693--702},
  issn = {1097-6256},
  doi = {10.1038/nn.2123},
  abstract = {Simple perceptual tasks have laid the groundwork for understanding the neurobiology of decision-making. Here, we examined this foundation to explain how decision-making circuitry adjusts in the face of a more difficult task. We measured behavioral and physiological responses of monkeys on a two- and four-choice direction-discrimination decision task. For both tasks, firing rates in the lateral intraparietal area appeared to reflect the accumulation of evidence for or against each choice. Evidence accumulation began at a lower firing rate for the four-choice task, but reached a common level by the end of the decision process. The larger excursion suggests that the subjects required more evidence before making a choice. Furthermore, on both tasks, we observed a time-dependent rise in firing rates that may impose a deadline for deciding. These physiological observations constitute an effective strategy for handling increased task difficulty. The differences appear to explain subjects' accuracy and reaction times.},
  copyright = {\textcopyright{} 2008 Nature Publishing Group},
  journal = {Nature Neuroscience},
  language = {en},
  number = {6}
}

@book{Clarke_2001_1968,
  title = {2001: {{A}} Space Odyssey},
  author = {Clarke, Arthur C.},
  year = {1968},
  publisher = {{New American Library}},
  address = {{New york}}
}

@article{Clemens_Efficient_2011,
  title = {Efficient Transformation of an Auditory Population Code in a Small Sensory System},
  author = {Clemens, Jan and Kutzki, Olaf and Ronacher, Bernhard and Schreiber, Susanne and Wohlgemuth, Sandra},
  year = {2011},
  month = aug,
  volume = {108},
  pages = {13812--13817},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1104506108},
  abstract = {Optimal coding principles are implemented in many large sensory systems. They include the systematic transformation of external stimuli into a sparse and decorrelated neuronal representation, enabling a flexible readout of stimulus properties. Are these principles also applicable to size-constrained systems, which have to rely on a limited number of neurons and may only have to fulfill specific and restricted tasks? We studied this question in an insect system\textemdash the early auditory pathway of grasshoppers. Grasshoppers use genetically fixed songs to recognize mates. The first steps of neural processing of songs take place in a small three-layer feed-forward network comprising only a few dozen neurons. We analyzed the transformation of the neural code within this network. Indeed, grasshoppers create a decorrelated and sparse representation, in accordance with optimal coding theory. Whereas the neuronal input layer is best read out as a summed population, a labeled-line population code for temporal features of the song is established after only two processing steps. At this stage, information about song identity is maximal for a population decoder that preserves neuronal identity. We conclude that optimal coding principles do apply to the early auditory system of the grasshopper, despite its size constraints. The inputs, however, are not encoded in a systematic, map-like fashion as in many larger sensory systems. Already at its periphery, part of the grasshopper auditory system seems to focus on behaviorally relevant features, and is in this property more reminiscent of higher sensory areas in vertebrates.},
  journal = {Proceedings of the National Academy of Sciences},
  keywords = {Information theory,invertebrates,metric},
  language = {en},
  number = {33},
  pmid = {21825132}
}

@book{CLHull_Principles_1943,
  title = {Principles of {{Behavior}}},
  author = {CL Hull},
  year = {1943},
  publisher = {{Appleton-Century}},
  address = {{Oxford, England}}
}

@article{Cohen_Model_2008,
  title = {Model Evaluation Using Grouped or Individual Data},
  author = {Cohen, Andrew L. and Sanborn, Adam N. and Shiffrin, Richard M.},
  year = {2008},
  month = aug,
  volume = {15},
  pages = {692--712},
  issn = {1069-9384},
  abstract = {Analyzing the data of individuals has several advantages over analyzing the data combined across the individuals (the latter we term group analysis): Grouping can distort the form of data, and different individuals might perform the task using different processes and parameters. These factors notwithstanding, we demonstrate conditions in which group analysis outperforms individual analysis. Such conditions include those in which there are relatively few trials per subject per condition, a situation that sometimes introduces distortions and biases when models are fit and parameters are estimated. We employed a simulation technique in which data were generated from each of two known models, each with parameter variation across simulated individuals. We examined how well the generating model and its competitor each fared in fitting (both sets of) the data, using both individual and group analysis. We examined the accuracy of model selection (the probability that the correct model would be selected by the analysis method). Trials per condition and individuals per experiment were varied systematically. Three pairs of cognitive models were compared: exponential versus power models of forgetting, generalized context versus prototype models of categorization, and the fuzzy logical model of perception versus the linear integration model of information integration. We show that there are situations in which small numbers of trials per condition cause group analysis to outperform individual analysis. Additional tables and figures may be downloaded from the Psychonomic Society Archive of Norms, Stimuli, and Data, www.psychonomic.org/archive.},
  journal = {Psychonomic Bulletin \& Review},
  keywords = {Bias (Epidemiology),Computer Graphics,Computer Simulation,Data Collection,Data Interpretation; Statistical,Humans,Individuality,Models; Statistical,Retention (Psychology),Verbal Learning},
  language = {eng},
  number = {4},
  pmid = {18792497}
}

@article{Cohen_Variability_2009,
  title = {Variability in Motor Learning: Relocating, Channeling and Reducing Noise},
  shorttitle = {Variability in Motor Learning},
  author = {Cohen, R. G. and Sternad, D.},
  year = {2009},
  month = feb,
  volume = {193},
  pages = {69--83},
  issn = {1432-1106},
  doi = {10.1007/s00221-008-1596-1},
  abstract = {Variability in motor performance decreases with practice but is never entirely eliminated, due in part to inherent motor noise. The present study develops a method that quantifies how performers can shape their performance to minimize the effects of motor noise on the result of the movement. Adopting a statistical approach on sets of data, the method quantifies three components of variability (tolerance, noise, and covariation) as costs with respect to optimal performance. T-Cost quantifies how much the result could be improved if the location of the data were optimal, N-Cost compares actual results to results with optimal dispersion at the same location, and C-Cost represents how much improvement stands to be gained if the data covaried optimally. The TNC-Cost analysis is applied to examine the learning of a throwing task that participants practiced for 6 or 15 days. Using a virtual set-up, 15 participants threw a pendular projectile in a simulated concentric force field to hit a target. Two variables, angle and velocity at release, fully determined the projectile's trajectory and thereby the accuracy of the throw. The task is redundant and the successful solutions define a nonlinear manifold. Analysis of experimental results indicated that all three components were present and that all three decreased across practice. Changes in T-Cost were considerable at the beginning of practice; C-Cost and N-Cost diminished more slowly, with N-Cost remaining the highest. These results showed that performance variability can be reduced by three routes: by tuning tolerance, covariation and noise in execution. We speculate that by exploiting T-Cost and C-Cost, participants minimize the effects of inevitable intrinsic noise.},
  journal = {Experimental Brain Research},
  keywords = {Adult,Biomechanical Phenomena,Female,Humans,Learning,Male,Middle Aged,Motor Skills,Practice; Psychological,Young Adult},
  language = {eng},
  number = {1},
  pmcid = {PMC2756422},
  pmid = {18953531}
}

@article{Cohen_When_2011,
  title = {When Attention Wanders: How Uncontrolled Fluctuations in Attention Affect Performance},
  shorttitle = {When Attention Wanders},
  author = {Cohen, Marlene R. and Maunsell, John H.R.},
  year = {2011},
  month = nov,
  volume = {31},
  pages = {15802--15806},
  issn = {0270-6474},
  doi = {10.1523/JNEUROSCI.3063-11.2011},
  abstract = {No matter how hard subjects concentrate on a task, their minds wander (; ; ; ). Internal fluctuations cannot be measured behaviorally or from conventional neurophysiological measures, so their effects on performance have been difficult to study. Previously, we measured fluctuations in visual attention using the responses of populations of simultaneously recorded neurons in macaque visual cortex (). Here, we use this ability to investigate how attentional fluctuations affect performance. We found that fluctuations attentional fluctuations have large and complex effects on performance whose sign depends on the difficulty of the perceptual judgment. As expected, attention greatly improves the detection of subtle changes in a stimulus. Surprisingly, we found that attending too strongly to a particular stimulus impairs the ability to notice when that stimulus changes dramatically. Our results suggest that all previous reported measures of behavioral performance should be viewed as amalgamations of different attentional states, whether or not those studies specifically addressed attention.},
  journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
  number = {44},
  pmcid = {PMC3579494},
  pmid = {22049423}
}

@article{Colby_Visual_1996,
  title = {Visual, Presaccadic, and Cognitive Activation of Single Neurons in Monkey Lateral Intraparietal Area},
  author = {Colby, C. L. and Duhamel, J. R. and Goldberg, M. E.},
  year = {1996},
  month = nov,
  volume = {76},
  pages = {2841--2852},
  issn = {0022-3077, 1522-1598},
  abstract = {1. Posterior parietal cortex contains neurons that are visually responsive and active in relation to saccadic eye movements. We recorded from single neurons in a subregion of parietal cortex, the lateral intraparietal area (LIP), in alert rhesus monkeys. To characterize more completely the circumstances under which LIP neurons are responsive, we used five tasks designed to test the impact of sensory, motor, and cognitive factors. We obtained quantitative data in multiple tasks in 91 neurons. We measured neural activity during central fixation and in relation to stimulus onset and saccade onset. 2. LIP neurons have visual responses to the onset of a stationary stimulus in the receptive field. These visual responses occurred both in tasks that require a subsequent eye movement toward the stimulus and in tasks in which eye movements are not permitted, indicating that this activity is sensory rather than presaccadic. 3. Visual responses were enhanced when the monkey had to use information provided by the stimulus to guide its behavior. The amplitude of the sensory response to a given stimulus was increased in a task in which the monkey would subsequently make a saccade to the location signaled by the stimulus, as compared with the amplitude of the visual response in a simple fixation task. 4. The visual response was also enhanced when the monkey attended to the stimulus without looking at it. This result shows that enhancement does not reflect saccade preparation because the response is enhanced even when the monkey is not permitted to make a saccade. Instead, enhancement reflects the allocation of attention to the spatial locus of the receptive field. 5. Many LIP neurons had saccade-related activity in addition to their visual responses. The visual response for most neurons was stronger than the saccade-related activation. 6. Saccade-related activity was independent of visual activity. Similar presaccadic activity was observed in trials that included a recent visual stimulus (memory-guided saccade task) and in trials with no visual stimulus (learned saccade task). 7. We observed increases in activity during fixation in tasks in which the monkey could anticipate the onset of a behaviorally significant stimulus. LIP neurons usually showed low levels of background firing in the fixation task during the period before stimulus onset. This background activity was increased in the peripheral attention and memory-guided saccade tasks during the period when the monkey was waiting for a behaviorally relevant stimulus to appear. 8. The results from these several tasks indicate that LIP neurons are activated in a variety of circumstances and are not involved exclusively in sensory processing or motor planning. The modulation of sensory responses by attention and anticipation suggests that cognitive factors play a major role in parietal function.},
  copyright = {Copyright \textcopyright{} 1996 the American Physiological Society},
  journal = {Journal of Neurophysiology},
  language = {en},
  number = {5},
  pmid = {8930237}
}

@article{Coutureau_Inactivation_2003,
  title = {Inactivation of the Infralimbic Prefrontal Cortex Reinstates Goal-Directed Responding in Overtrained Rats},
  author = {Coutureau, Etienne and Killcross, Simon},
  year = {2003},
  month = nov,
  volume = {146},
  pages = {167--174},
  issn = {0166-4328},
  doi = {10.1016/j.bbr.2003.09.025},
  abstract = {Over the course of extended training, instrumental responding in rats shows a transition from goal-dependent performance to goal-independent performance, as assessed by sensitivity to reward-devaluation induced by taste aversions or specific satiety. It has been suggested that this reflects the gradual dominance of reflexive, habit-based responding over voluntary, goal-directed actions. Previous research suggests that lesions of the medial prefrontal cortex disrupt this interaction between goal-directed and habitual responding. More specifically, whereas lesions of the prelimbic prefrontal cortex appear to disrupt normal goal-directed responding, lesions of the infralimbic prefrontal cortex cause animals to remain goal-directed even after substantial overtraining. The current experiment explored further the nature of this interaction between actions and habits. Rats were given extended training of an instrumental lever press response before bilateral intracerebral cannulae giving access to the infralimbic cortex were implanted. Following further reminder training all animals were given a test of goal sensitivity by specific-satiety devaluation of the instrumental outcome, or a matched reward, prior to extinction tests. Before these tests, half of the animals received bilateral infusions of muscimol into the infralimbic cortex, and the remainder, control vehicle infusions. As expected after extended instrumental training, control-infused animals showed habitual performance that was not selectively influenced by devaluation of the instrumental outcome. In contrast, animals receiving temporary inactivation of the infralimbic cortex by muscimol showed selective sensitivity to devaluation of the instrumental outcome, indicating a reinstatement of goal-directed responding in these animals. This suggests that the development of habitual responding reflects the active inhibition of goal-directed responses that are mediated by action-outcome associations.},
  journal = {Behavioural Brain Research},
  keywords = {Infralimbic,Intracerebral,Muscimol},
  number = {1},
  series = {The {{Rodent Prefrontal Cortex}}}
}

@article{Cox_Abstract_2020,
  title = {Abstract Inference of Unchosen Option Values},
  author = {Cox, Karin M. and Fiez, Julie A.},
  year = {2020},
  volume = {51},
  pages = {909--921},
  issn = {1460-9568},
  doi = {10.1111/ejn.14577},
  abstract = {Reinforcement learning research has pursued a persistent question: Does reward feedback prompt inferences that transcend simple associations? Reversal learning data suggest an affirmative answer: When the positive stimulus (S+) becomes the negative stimulus (S-), trained humans rapidly switch to choosing the former S-. The operations supporting such inferences remain ambiguous. Do participants identify transitions between stimulus-specific contexts (i.e., A+B- and A-B+), or deduce values by learning the abstract contingency structure? Across two experiments, we probed humans' use of abstract rules to infer the values of unchosen alternatives. In Experiment 1, 37 participants attempted a task that originally demonstrated monkeys' difficulty with this form of inference. We presented modified discrimination problems in which the initially chosen stimulus (abstract inference group) or unchosen stimulus (control group) was replaced with a novel stimulus of identical status on Trial 2. In the abstract inference condition, accurate performance can be achieved by applying the consistent contingency structure (but not memory of stimulus-specific reward associations) to infer to the unchosen stimulus' value. The abstract inference group learned to make accurate choices, but only after committing substantially more errors than were observed among control participants\textemdash suggesting that unchosen value inferences are infrequently drawn in standard discrimination scenarios. In Experiment 2, 17 participants completed abstract inference problems that had been modified to be suitable for fMRI investigations. Behavioral results both corroborated the Experiment 1 trends and further revealed marked individual differences in explicit awareness of the novel stimulus values.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/ejn.14577},
  copyright = {\textcopyright{} 2019 Federation of European Neuroscience Societies and John Wiley \& Sons Ltd},
  journal = {European Journal of Neuroscience},
  keywords = {decision making,inference,learning,reinforcement,reward},
  language = {en},
  number = {3}
}

@article{Craig_Investigation_2016,
  title = {Investigation of {{Biases}} and {{Compensatory Strategies Using}} a {{Probabilistic Variant}} of the {{Wisconsin Card Sorting Test}}},
  author = {Craig, Alexis B. and Phillips, Matthew E. and Zaldivar, Andrew and Bhattacharyya, Rajan and Krichmar, Jeffrey L.},
  year = {2016},
  pages = {17},
  doi = {10.3389/fpsyg.2016.00017},
  abstract = {The Wisconsin Card Sorting Test (WCST) evaluates a subject's ability to shift to a new pattern of behavior in response to the presentation of unexpected negative feedback. The present study introduces a novel version of the traditional WCST by integrating a probabilistic component into its traditional rule shifting to add uncertainty to the task, as well as the option to forage for information during any particular trial. These changes transformed a task that is trivial for neurotypical individuals into a challenging environment useful for evaluating biases and compensatory strategizing. Sixty subjects performed the probabilistic WCST at four uncertainty levels to determine the effect of uncertainty on subject performance and strategy. Results revealed that increasing the level of uncertainty during a run of trials correlated with a reduction in rational strategizing in favor of both random choice and information foraging, evoking biases and suboptimal strategies such as satisfaction of search, negativity bias, and probability matching.},
  journal = {Cognitive Science},
  keywords = {cognitive biases,decision-making,probability matching,uncertainty,Wisconsin Card Sorting Test}
}

@article{Critchfield_Temporal_2001,
  title = {Temporal Discounting: Basic Research and the Analysis of Socially Important Behavior.},
  shorttitle = {Temporal Discounting},
  author = {Critchfield, T S and Kollins, S H},
  year = {2001},
  volume = {34},
  pages = {101--122},
  issn = {0021-8855},
  doi = {10.1901/jaba.2001.34-101},
  abstract = {Recent basic research on human temporal discounting is reviewed to illustrate procedures, summarize key findings, and draw parallels with both nonhuman animal research and conceptual writings on self-control. Lessons derived from this research are then applied to the challenge of analyzing socially important behaviors such as drug abuse, eating and exercise, and impulsiveness associated with attention deficit hyperactivity disorder. Attending to the broader temporal context in which behavior occurs may aid in the analysis of socially important behavior. Applying this perspective to the study of behavior in natural environments also highlights the importance of combining methodological flexibility with conceptual rigor to promote the extension of applied behavior analysis to a broader array of socially important behaviors.},
  journal = {Journal of Applied Behavior Analysis},
  number = {1},
  pmcid = {PMC1284292},
  pmid = {11317983}
}

@article{Critchley_Neural_2001,
  title = {Neural {{Activity}} in the {{Human Brain Relating}} to {{Uncertainty}} and {{Arousal}} during {{Anticipation}}},
  author = {Critchley, Hugo D and Mathias, Christopher J and Dolan, Raymond J},
  year = {2001},
  month = feb,
  volume = {29},
  pages = {537--545},
  issn = {0896-6273},
  doi = {10.1016/S0896-6273(01)00225-2},
  abstract = {We used functional magnetic resonance neuroimaging to measure brain activity during delay between reward-related decisions and their outcomes, and the modulation of this delay activity by uncertainty and arousal. Feedback, indicating financial gain or loss, was given following a fixed delay. Anticipatory arousal was indexed by galvanic skin conductance. Delay-period activity was associated with bilateral activation in orbital and medial prefrontal, temporal, and right parietal cortices. During delay, activity in anterior cingulate and orbitofrontal cortices was modulated by outcome uncertainty, whereas anterior cingulate, dorsolateral prefrontal, and parietal cortices activity was modulated by degree of anticipatory arousal. A distinct region of anterior cingulate was commonly activated by both uncertainty and arousal. Our findings highlight distinct contributions of cognitive uncertainty and autonomic arousal to anticipatory neural activity in prefrontal cortex.},
  journal = {Neuron},
  number = {2}
}

@article{Critchley_Neural_2001a,
  title = {Neural {{Activity}} in the {{Human Brain Relating}} to {{Uncertainty}} and {{Arousal}} during {{Anticipation}}},
  author = {Critchley, Hugo D and Mathias, Christopher J and Dolan, Raymond J},
  year = {2001},
  month = feb,
  volume = {29},
  pages = {537--545},
  issn = {0896-6273},
  doi = {10.1016/S0896-6273(01)00225-2},
  abstract = {We used functional magnetic resonance neuroimaging to measure brain activity during delay between reward-related decisions and their outcomes, and the modulation of this delay activity by uncertainty and arousal. Feedback, indicating financial gain or loss, was given following a fixed delay. Anticipatory arousal was indexed by galvanic skin conductance. Delay-period activity was associated with bilateral activation in orbital and medial prefrontal, temporal, and right parietal cortices. During delay, activity in anterior cingulate and orbitofrontal cortices was modulated by outcome uncertainty, whereas anterior cingulate, dorsolateral prefrontal, and parietal cortices activity was modulated by degree of anticipatory arousal. A distinct region of anterior cingulate was commonly activated by both uncertainty and arousal. Our findings highlight distinct contributions of cognitive uncertainty and autonomic arousal to anticipatory neural activity in prefrontal cortex.},
  journal = {Neuron},
  number = {2}
}

@article{Croxson_EffortBased_2009,
  title = {Effort-{{Based Cost}}\textendash{{Benefit Valuation}} and the {{Human Brain}}},
  author = {Croxson, Paula L. and Walton, Mark E. and O'Reilly, Jill X. and Behrens, Timothy E. J. and Rushworth, Matthew F. S.},
  year = {2009},
  month = apr,
  volume = {29},
  pages = {4531--4541},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.4515-08.2009},
  abstract = {In both the wild and the laboratory, animals' preferences for one course of action over another reflect not just reward expectations but also the cost in terms of effort that must be invested in pursuing the course of action. The ventral striatum and dorsal anterior cingulate cortex (ACCd) are implicated in the making of cost\textendash benefit decisions in the rat, but there is little information about how effort costs are processed and influence calculations of expected net value in other mammals including humans. We performed a functional magnetic resonance imaging study to determine whether and where activity in the human brain was available to guide effort-based cost\textendash benefit valuation. Subjects were scanned while they performed a series of effortful actions to obtain secondary reinforcers. At the beginning of each trial, subjects were presented with one of eight different visual cues that they had learned indicated how much effort the course of action would entail and how much reward could be expected at its completion. Cue-locked activity in the ventral striatum and midbrain reflected the net value of the course of action, signaling the expected amount of reward discounted by the amount of effort to be invested. Activity in ACCd also reflected the interaction of both expected reward and effort costs. Posterior orbitofrontal and insular activity, however, only reflected the expected reward magnitude. The ventral striatum and anterior cingulate cortex may be the substrate of effort-based cost\textendash benefit valuation in primates as well as in rats.},
  copyright = {Copyright \textcopyright{} 2009 Society for Neuroscience 0270-6474/09/294531-11\$15.00/0},
  journal = {Journal of Neuroscience},
  language = {en},
  number = {14},
  pmid = {19357278}
}

@article{Crump_Contextual_2010,
  title = {Contextual Control over Task-Set Retrieval},
  author = {Crump, Matthew J. C. and Logan, Gordon D.},
  year = {2010},
  month = nov,
  volume = {72},
  pages = {2047--2053},
  issn = {1943-3921, 1943-393X},
  doi = {10.3758/BF03196681},
  abstract = {Contextual cues signaling task likelihood or the likelihood of task repetition are known to modulate the size of switch costs. We follow up on the finding by Leboe, Wong, Crump, and Stobbe (2008) that location cues predictive of the proportion of switch or repeat trials modulate switch costs. Their design employed one cue per task, whereas our experiment employed two cues per task, which allowed separate assessment of modulations to the cue-repetition benefit, a measure of lower level cue-encoding processes, and to the task-alternation cost, a measure of higher level processes representing task-set information. We demonstrate that location information predictive of switch proportion modulates performance at the level of task-set representations. Furthermore, we demonstrate that contextual control occurs even when subjects are unaware of the associations between context and switch likelihood. We discuss the notion that contextual information provides rapid, unconscious control over the extent to which prior task-set representations are retrieved in the service of guiding online performance. M. J. C. Crump, matt.crump@vanderbilt.edu},
  journal = {Attention, Perception, \& Psychophysics},
  keywords = {Cognitive Psychology},
  language = {en},
  number = {8}
}

@article{CuevasRivera_ContextDependent_2018,
  title = {Context-{{Dependent Risk Aversion}}: {{A Model}}-{{Based Approach}}},
  shorttitle = {Context-{{Dependent Risk Aversion}}},
  author = {Cuevas Rivera, Dar{\'i}o and Ott, Florian and Markovic, Dimitrije and Strobel, Alexander and Kiebel, Stefan J.},
  year = {2018},
  volume = {9},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2018.02053},
  abstract = {Most research on risk aversion in behavioral science with human subjects has focused on a component of risk aversion that does not adapt itself to context. More recently, studies have explored risk aversion adaptation to changing circumstances in sequential decision-making tasks. It is an open question whether one can identify evidence, at the single subject level, for such risk aversion adaptation. We conducted a behavioral experiment on human subjects, using a sequential decision making task. We developed a model-based approach for estimating the adaptation of risk-taking behavior with single-trial resolution by modelling a subject's goals and internal representation of task contingencies. Using this model-based approach, we estimated the subject-specific adaptation of risk aversion depending on the current task context. We found striking inter-subject variations in the adaptation of risk-taking behavior. We show that these differences can be explained by differences in subjects' internal representations of task contingencies and goals. We discuss that the proposed approach can be adapted to a wide range of experimental paradigms and be used to analyze behavioral measures other than risk aversion.},
  journal = {Frontiers in Psychology},
  keywords = {active inference,Decision Making,Models,risk aversion,single subject,Theoretical},
  language = {English}
}

@article{CuevasRivera_Modeling_2020,
  title = {Modeling Dynamic Allocation of Effort in a Sequential Task Using Discounting Models},
  author = {Cuevas Rivera, Dario and Strobel, Alexander and Goschke, Thomas and Kiebel, Stefan J.},
  year = {2020},
  volume = {14},
  issn = {1662-453X},
  doi = {10.3389/fnins.2020.00242},
  abstract = {Most rewards in our lives require effort to obtain them. It is known that effort is seen by humans as carrying an intrinsic disutility which devalues the obtainable reward. Established models for effort discounting account for this by using participant-specific discounting parameters inferred from experiments. These parameters offer only a static glance into the bigger picture of effort exertion. The mechanism underlying the dynamic changes in a participant's willingness to exert effort is still unclear and an active topic of research. Here, we modeled dynamic effort exertion as a consequence of effort- and probability-discounting mechanisms during goal reaching, sequential behavior. To do this, we developed a novel sequential decision-making task in which participants make binary choices to reach a minimum number of points. Importantly, the time points and circumstances of effort allocation are decided by participants according to their own preferences and not imposed directly by the task. Using the computational model to analyze participants' choices, we show that the dynamics of effort exertion arise from a combination of changing task needs and forward planning. In other words, the interplay between a participant's inferred discounting parameters is sufficient to explain the dynamic allocation of effort during goal reaching. Using formal model comparison, we also infer the forward-planning strategy used by participants. The model allows us to characterize a participant's effort exertion in terms of only a few parameters. Moreover, the model can be adapted to a number of tasks used in establishing the neural underpinnings of forward-planning behavior and meta-control, allowing for the characterization of behavior in terms of model parameters.},
  journal = {Frontiers in Neuroscience},
  keywords = {computational modeling,Decision Making,discounting,effort,goal-directed action,Sequential},
  language = {English}
}

@article{CuevasRivera_Modelling_2015,
  title = {Modelling {{Odor Decoding}} in the {{Antennal Lobe}} by {{Combining Sequential Firing Rate Models}} with {{Bayesian Inference}}},
  author = {Cuevas Rivera, Dario and Bitzer, Sebastian and Kiebel, Stefan J.},
  year = {2015},
  month = oct,
  volume = {11},
  pages = {e1004528},
  doi = {10.1371/journal.pcbi.1004528},
  abstract = {Author Summary Odor recognition in the insect brain is amazingly fast but still not fully understood. It is known that recognition is performed in three stages. In the first stage, the sensors respond to an odor by displaying a reproducible neuronal pattern. This code is turned, in the second and third stages, into a sparse code, that is, only relatively few neurons activate over hundreds of milliseconds. It is generally assumed that the insect brain uses this temporal code to recognize an odor. We propose a new model of how this temporal code emerges using sequential activation of groups of neurons. We show that these sequential activations underlie a fast and accurate recognition which is highly robust against neuronal or sensory noise. This model replicates several key experimental findings and explains how the insect brain achieves both speed and robustness of odor recognition as observed in experiments.},
  journal = {PLoS Comput Biol},
  number = {10}
}

@article{Culbreth_Reduced_2016,
  title = {Reduced Model-Based Decision-Making in Schizophrenia},
  author = {Culbreth, Adam J. and Westbrook, Andrew and Daw, Nathaniel D. and Botvinick, Matthew and Barch, Deanna M.},
  year = {2016},
  month = aug,
  volume = {125},
  pages = {777--787},
  issn = {1939-1846},
  doi = {10.1037/abn0000164},
  abstract = {Individuals with schizophrenia have a diminished ability to use reward history to adaptively guide behavior. However, tasks traditionally used to assess such deficits often rely on multiple cognitive and neural processes, leaving etiology unresolved. In the current study, we adopted recent computational formalisms of reinforcement learning to distinguish between model-based and model-free decision-making in hopes of specifying mechanisms associated with reinforcement-learning dysfunction in schizophrenia. Under this framework, decision-making is model-free to the extent that it relies solely on prior reward history, and model-based if it relies on prospective information such as motivational state, future consequences, and the likelihood of obtaining various outcomes. Model-based and model-free decision-making was assessed in 33 schizophrenia patients and 30 controls using a 2-stage 2-alternative forced choice task previously demonstrated to discern individual differences in reliance on the 2 forms of reinforcement-learning. We show that, compared with controls, schizophrenia patients demonstrate decreased reliance on model-based decision-making. Further, parameter estimates of model-based behavior correlate positively with IQ and working memory measures, suggesting that model-based deficits seen in schizophrenia may be partially explained by higher-order cognitive deficits. These findings demonstrate specific reinforcement-learning and decision-making deficits and thereby provide valuable insights for understanding disordered behavior in schizophrenia. (PsycINFO Database Record},
  journal = {Journal of Abnormal Psychology},
  keywords = {Adult,Decision Making,Female,Humans,Individuality,Male,Models; Psychological,Reward,Schizophrenic Psychology},
  language = {eng},
  number = {6},
  pmcid = {PMC4980177},
  pmid = {27175984}
}

@article{Cummings_Homegrown_1995,
  title = {Homegrown {{Values}} and {{Hypothetical Surveys}}: {{Is}} the {{Dichotomous Choice Approach Incentive}}-{{Compatible}}?},
  shorttitle = {Homegrown {{Values}} and {{Hypothetical Surveys}}},
  author = {Cummings, Ronald G. and Harrison, Glenn and Rutstrom, Elisabet},
  year = {1995},
  volume = {85},
  pages = {260--66},
  journal = {American Economic Review},
  number = {1}
}

@article{Cunillera_Brain_2011,
  title = {Brain Oscillatory Activity Associated with Task Switching and Feedback Processing},
  author = {Cunillera, Toni and Fuentemilla, Llu{\'i}s and Peria{\~n}ez, Jose and {Marco-Pallar{\`e}s}, Josep and Kr{\"a}mer, Ulrike M. and C{\`a}mara, Estela and M{\"u}nte, Thomas F. and {Rodr{\'i}guez-Fornells}, Antoni},
  year = {2011},
  month = dec,
  volume = {12},
  pages = {16--33},
  issn = {1530-7026, 1531-135X},
  doi = {10.3758/s13415-011-0075-5},
  abstract = {In this study, we sought to dissociate event-related potentials (ERPs) and the oscillatory activity associated with signals indicating feedback about performance (outcome-based behavioral adjustment) and the signals indicating the need to change or maintain a task set (rule-based behavioral adjustment). With this purpose in mind, we noninvasively recorded electroencephalographic signals, using a modified version of the Wisconsin card sorting task, in which feedback processing and task switching could be studied separately. A similar late positive component was observed for the switch and correct feedback signals on the first trials of a series, but feedback-related negativity was observed only for incorrect feedback. Moreover, whereas theta power showed a significant increase after a switch cue and after the first positive feedback of a new series, a selective frontal beta\textendash gamma increase was observed exclusively in the first positive feedback (i.e., after the selection of the new rule). Importantly, for the switch cue, beta\textendash alpha activity was suppressed rather than increased. This clear dissociation between the cue and feedback stimuli in task switching emphasizes the need to accurately study brain oscillatory activity to disentangle the role of different cognitive control processes.},
  journal = {Cognitive, Affective, \& Behavioral Neuroscience},
  keywords = {Cognitive Psychology,ERPs,Executive functions,Feedback processing,Neurosciences,Reinforcement learning,Task switching,Time frequency},
  language = {en},
  number = {1}
}

@article{Danielmeier_Posterior_2011,
  title = {Posterior {{Medial Frontal Cortex Activity Predicts Post}}-{{Error Adaptations}} in {{Task}}-{{Related Visual}} and {{Motor Areas}}},
  author = {Danielmeier, Claudia and Eichele, Tom and Forstmann, Birte U. and Tittgemeyer, Marc and Ullsperger, Markus},
  year = {2011},
  month = feb,
  volume = {31},
  pages = {1780--1789},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.4299-10.2011},
  abstract = {As Seneca the Younger put it, ``To err is human, but to persist is diabolical.'' To prevent repetition of errors, human performance monitoring often triggers adaptations such as general slowing and/or attentional focusing. The posterior medial frontal cortex (pMFC) is assumed to monitor performance problems and to interact with other brain areas that implement the necessary adaptations. Whereas previous research showed interactions between pMFC and lateral-prefrontal regions, here we demonstrate that upon the occurrence of errors the pMFC selectively interacts with perceptual and motor regions and thereby drives attentional focusing toward task-relevant information and induces motor adaptation observed as post-error slowing. Functional magnetic resonance imaging data from an interference task reveal that error-related pMFC activity predicts the following: (1) subsequent activity enhancement in perceptual areas encoding task-relevant stimulus features; (2) activity suppression in perceptual areas encoding distracting stimulus features; and (3) post-error slowing-related activity decrease in the motor system. Additionally, diffusion-weighted imaging revealed a correlation of individual post-error slowing and white matter integrity beneath pMFC regions that are connected to the motor inhibition system, encompassing right inferior frontal gyrus and subthalamic nucleus. Thus, disturbances in task performance are remedied by functional interactions of the pMFC with multiple task-related brain regions beyond prefrontal cortex that result in a broad repertoire of adaptive processes at perceptual as well as motor levels.},
  journal = {The Journal of Neuroscience},
  language = {en},
  number = {5},
  pmid = {21289188}
}

@article{DArdenne_BOLD_2008,
  title = {{{BOLD Responses Reflecting Dopaminergic Signals}} in the {{Human Ventral Tegmental Area}}},
  author = {D'Ardenne, Kimberlee and McClure, Samuel M. and Nystrom, Leigh E. and Cohen, Jonathan D.},
  year = {2008},
  month = feb,
  volume = {319},
  pages = {1264--1267},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1150605},
  abstract = {Current theories hypothesize that dopamine neuronal firing encodes reward prediction errors. Although studies in nonhuman species provide direct support for this theory, functional magnetic resonance imaging (fMRI) studies in humans have focused on brain areas targeted by dopamine neurons [ventral striatum (VStr)] rather than on brainstem dopaminergic nuclei [ventral tegmental area (VTA) and substantia nigra]. We used fMRI tailored to directly image the brainstem. When primary rewards were used in an experiment, the VTA blood oxygen level\textendash dependent (BOLD) response reflected a positive reward prediction error, whereas the VStr encoded positive and negative reward prediction errors. When monetary gains and losses were used, VTA BOLD responses reflected positive reward prediction errors modulated by the probability of winning. We detected no significant VTA BOLD response to nonrewarding events. In humans, activity measurements in a small midbrain region show that resident dopamine-containing neurons accurately predict rewards in a learning task. In humans, activity measurements in a small midbrain region show that resident dopamine-containing neurons accurately predict rewards in a learning task.},
  copyright = {American Association for the Advancement of Science},
  journal = {Science},
  keywords = {unread},
  language = {en},
  number = {5867},
  pmid = {18309087}
}

@article{Daunizeau_Dynamic_2011,
  title = {Dynamic Causal Modelling: {{A}} Critical Review of the Biophysical and Statistical Foundations},
  shorttitle = {Dynamic Causal Modelling},
  author = {Daunizeau, J. and David, O. and Stephan, K. E.},
  year = {2011},
  month = sep,
  volume = {58},
  pages = {312--322},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2009.11.062},
  abstract = {The goal of dynamic causal modelling (DCM) of neuroimaging data is to study experimentally induced changes in functional integration among brain regions. This requires (i) biophysically plausible and physiologically interpretable models of neuronal network dynamics that can predict distributed brain responses to experimental stimuli and (ii) efficient statistical methods for parameter estimation and model comparison. These two key components of DCM have been the focus of more than thirty methodological articles since the seminal work of Friston and colleagues published in 2003. In this paper, we provide a critical review of the current state-of-the-art of DCM. We inspect the properties of DCM in relation to the most common neuroimaging modalities (fMRI and EEG/MEG) and the specificity of inference on neural systems that can be made from these data. We then discuss both the plausibility of the underlying biophysical models and the robustness of the statistical inversion techniques. Finally, we discuss potential extensions of the current DCM framework, such as stochastic DCMs, plastic DCMs and field DCMs.},
  journal = {NeuroImage},
  number = {2}
}

@article{Daunizeau_Observing_2010,
  title = {Observing the {{Observer}} ({{I}}): {{Meta}}-{{Bayesian Models}} of {{Learning}} and {{Decision}}-{{Making}}},
  shorttitle = {Observing the {{Observer}} ({{I}})},
  author = {Daunizeau, Jean and den Ouden, Hanneke E. M. and Pessiglione, Matthias and Kiebel, Stefan J. and Stephan, Klaas E. and Friston, Karl J.},
  year = {2010},
  month = dec,
  volume = {5},
  pages = {e15554},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0015554},
  abstract = {In this paper, we present a generic approach that can be used to infer how subjects make optimal decisions under uncertainty. This approach induces a distinction between a subject's  perceptual  model, which underlies the representation of a hidden ``state of affairs'' and a  response  model, which predicts the ensuing behavioural (or neurophysiological) responses to those inputs. We start with the premise that subjects continuously update a probabilistic representation of the causes of their sensory inputs to optimise their behaviour. In addition, subjects have preferences or goals that guide decisions about actions given the above uncertain representation of these hidden causes or state of affairs. From a Bayesian decision theoretic perspective, uncertain representations are so-called ``posterior'' beliefs, which are influenced by subjective ``prior'' beliefs. Preferences and goals are encoded through a ``loss'' (or ``utility'') function, which measures the cost incurred by making any admissible decision for any given (hidden) state of affair. By assuming that subjects make optimal decisions on the basis of updated (posterior) beliefs and utility (loss) functions, one can evaluate the likelihood of observed behaviour. Critically, this enables one to `` observe the observer '', i.e. identify (context- or subject-dependent) prior beliefs and utility-functions using psychophysical or neurophysiological measures. In this paper, we describe the main theoretical components of this  meta-Bayesian  approach (i.e. a Bayesian treatment of Bayesian decision theoretic predictions). In a companion paper (`Observing the observer (II): deciding when to decide'), we describe a concrete implementation of it and demonstrate its utility by applying it to simulated and real reaction time data from an associative learning task.},
  journal = {PLOS ONE},
  keywords = {Approximation methods,Behavior,Covariance,Decision Making,Experimental psychology,Game theory,Learning,Sensory perception},
  number = {12}
}

@article{Daunizeau_Variational_2009,
  title = {Variational {{Bayesian}} Identification and Prediction of Stochastic Nonlinear Dynamic Causal Models},
  author = {Daunizeau, J. and Friston, K. J. and Kiebel, S. J.},
  year = {2009},
  month = nov,
  volume = {238},
  pages = {2089--2118},
  issn = {0167-2789},
  doi = {10.1016/j.physd.2009.08.002},
  abstract = {In this paper, we describe a general variational Bayesian approach for approximate inference on nonlinear stochastic dynamic models. This scheme extends established approximate inference on hidden-states to cover: (i) nonlinear evolution and observation functions, (ii) unknown parameters and (precision) hyperparameters and (iii) model comparison and prediction under uncertainty. Model identification or inversion entails the estimation of the marginal likelihood or evidence of a model. This difficult integration problem can be finessed by optimising a free-energy bound on the evidence using results from variational calculus. This yields a deterministic update scheme that optimises an approximation to the posterior density on the unknown model variables. We derive such a variational Bayesian scheme in the context of nonlinear stochastic dynamic hierarchical models, for both model identification and time-series prediction. The computational complexity of the scheme is comparable to that of an extended Kalman filter, which is critical when inverting high dimensional models or long time-series. Using Monte-Carlo simulations, we assess the estimation efficiency of this variational Bayesian approach using three stochastic variants of chaotic dynamic systems. We also demonstrate the model comparison capabilities of the method, its self-consistency and its predictive power.},
  journal = {Physica D: Nonlinear Phenomena},
  keywords = {Approximate inference,DCM,EM,Free-energy,Kalman filter,Laplace approximation,Model comparison,Nonlinear state-space models,Nonlinear stochastic dynamical systems,Rauch smoother,SDE,Variational Bayes},
  number = {21}
}

@article{Davidson_Scaling_2004,
  title = {Scaling down Motor Memories: De-Adaptation after Motor Learning},
  shorttitle = {Scaling down Motor Memories},
  author = {Davidson, Paul R. and Wolpert, Daniel M.},
  year = {2004},
  month = nov,
  volume = {370},
  pages = {102--107},
  issn = {0304-3940},
  doi = {10.1016/j.neulet.2004.08.003},
  abstract = {Although adaptation to novel motor tasks is sometimes a very slow process, de-adaptation is usually extremely rapid. Such rapid de-adaptation is seen in dynamic learning in which subjects can take hundreds of movements to learn a novel force environment but only a few movements to de-adapt back to a normal or "null" force environment. We investigated whether this effect is unique to the null environment or reveals a more general rapid adaptation mechanism by studying how subjects behave when their dynamic environment changes. We observed that after learning a dynamic force field, subjects took longer to de-adapt when the forces were turned off than to adapt to a novel scaled-down version of the experienced field. This demonstrates that rapid adaptation is not unique to the "null" force environment. Moreover, we examined subjects' ability to adapt from a learned field to either a scaled down field or to a field in which the sign of the forces changed. Even though in both conditions the required change in force output was identical, subjects were significantly faster at adapting to the scaled down field. The result suggests that rapid de-adaptation reflects a capacity to scale down the relative contribution of existing control modules to the motor output.},
  journal = {Neuroscience Letters},
  keywords = {Adaptation; Physiological,Adult,Female,Humans,Learning,Male,Memory,Movement,Periodicity,Psychomotor Performance,Time Factors},
  language = {eng},
  number = {2-3},
  pmid = {15488303}
}

@article{Davis_Human_2005,
  title = {Human {{Anterior Cingulate Cortex Neurons Encode Cognitive}} and {{Emotional Demands}}},
  author = {Davis, Karen D. and Taylor, Keri S. and Hutchison, William D. and Dostrovsky, Jonathan O. and McAndrews, Mary P. and Richter, Erich O. and Lozano, Andres M.},
  year = {2005},
  month = sep,
  volume = {25},
  pages = {8402--8406},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.2315-05.2005},
  abstract = {The cortical mechanisms and substrates of cognitive and emotional demands are poorly understood. Lesion studies and functional imaging implicate the anterior cingulate cortex (ACC). The caudal ACC (cACC) has been implicated in cognitive processes such as attention, salience, interference, and response competition, mostly on the basis of neuroimaging results. To test the hypothesis that individual cACC neurons subserve these functions, we monitored neuronal activity from single cells in the cACC while subjects were engaged in a mental arithmetic task, the cognitively demanding counting Stroop task, and/or the emotional Stroop interference task. We now report the first direct measures of single neurons in humans identifying a population of cACC neurons that respond differentially or in a graded manner to cognitively demanding high- and low-conflict Stroop tasks, including those with emotional valence. These data indicate that cACC neurons may be acting as salience detectors when faced with conflict and difficult or emotional stimuli, consistent with neuroimaging results of cACC responses to abrupt sensory, novel, task-relevant, or painful stimuli.},
  copyright = {Copyright \textcopyright{} 2005 Society for Neuroscience 0270-6474/05/258402-05.00/0},
  journal = {Journal of Neuroscience},
  keywords = {attention,cingulate,cognition,emotion,OCD,salience,Stroop},
  language = {en},
  number = {37},
  pmid = {16162922}
}

@article{Daw_Cortical_2006,
  title = {Cortical Substrates for Exploratory Decisions in Humans},
  author = {Daw, Nathaniel D. and O'Doherty, John P. and Dayan, Peter and Seymour, Ben and Dolan, Raymond J.},
  year = {2006},
  month = jun,
  volume = {441},
  pages = {876--879},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/nature04766},
  abstract = {Humans are remarkably curious, and that is useful in helping us to learn about new environments and possibilities. But curiosity killed the cat, they say, and it also carries with it substantial potential risks and costs for us. Statisticians, engineers and economists have long considered ways of balancing the costs and benefits of exploration. Tests involving a gambling task and an fMRI brain scanner now show that humans appear to obey similar principles when considering their options. The players had to balance the desire to select the richest option based on accumulated experience against the desire to choose a less familiar option that might have a larger payoff. The frontopolar cortex, a brain area known to be involved in cognitive control, was preferentially active during exploratory decisions. The results suggest a neurobiological account of human exploration and point to a new area for behavioural and neural investigations.},
  copyright = {2006 Nature Publishing Group},
  journal = {Nature},
  language = {en},
  number = {7095}
}

@article{Daw_ModelBased_2011,
  title = {Model-{{Based Influences}} on {{Humans}}' {{Choices}} and {{Striatal Prediction Errors}}},
  author = {Daw, Nathaniel D. and Gershman, Samuel J. and Seymour, Ben and Dayan, Peter and Dolan, Raymond J.},
  year = {2011},
  month = mar,
  volume = {69},
  pages = {1204--1215},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2011.02.027},
  journal = {Neuron},
  language = {English},
  number = {6},
  pmid = {21435563}
}

@article{Daw_Uncertaintybased_2005,
  title = {Uncertainty-Based Competition between Prefrontal and Dorsolateral Striatal Systems for Behavioral Control},
  author = {Daw, Nathaniel D. and Niv, Yael and Dayan, Peter},
  year = {2005},
  month = dec,
  volume = {8},
  pages = {1704--1711},
  issn = {1097-6256},
  doi = {10.1038/nn1560},
  abstract = {A broad range of neural and behavioral data suggests that the brain contains multiple systems for behavioral choice, including one associated with prefrontal cortex and another with dorsolateral striatum. However, such a surfeit of control raises an additional choice problem: how to arbitrate between the systems when they disagree. Here, we consider dual-action choice systems from a normative perspective, using the computational theory of reinforcement learning. We identify a key trade-off pitting computational simplicity against the flexible and statistically efficient use of experience. The trade-off is realized in a competition between the dorsolateral striatal and prefrontal systems. We suggest a Bayesian principle of arbitration between them according to uncertainty, so each controller is deployed when it should be most accurate. This provides a unifying account of a wealth of experimental evidence about the factors favoring dominance by either system.},
  copyright = {\textcopyright{} 2005 Nature Publishing Group},
  journal = {Nature Neuroscience},
  language = {en},
  number = {12}
}

@article{Dayan_Improving_1993,
  title = {Improving {{Generalization}} for {{Temporal Difference Learning}}: {{The Successor Representation}}},
  shorttitle = {Improving {{Generalization}} for {{Temporal Difference Learning}}},
  author = {Dayan, Peter},
  year = {1993},
  month = jul,
  volume = {5},
  pages = {613--624},
  issn = {0899-7667},
  doi = {10.1162/neco.1993.5.4.613},
  abstract = {Estimation of returns over time, the focus of temporal difference (TD) algorithms, imposes particular constraints on good function approximators or representations. Appropriate generalization between states is determined by how similar their successors are, and representations should follow suit. This paper shows how TD machinery can be used to learn such representations, and illustrates, using a navigation task, the appropriately distributed nature of the result.},
  journal = {Neural Computation},
  number = {4}
}

@article{Dayan_Modelbased_2014,
  title = {Model-Based and Model-Free {{Pavlovian}} Reward Learning: {{Revaluation}}, Revision, and Revelation},
  shorttitle = {Model-Based and Model-Free {{Pavlovian}} Reward Learning},
  author = {Dayan, Peter and Berridge, Kent C.},
  year = {2014},
  month = jun,
  volume = {14},
  pages = {473--492},
  issn = {1530-7026, 1531-135X},
  doi = {10.3758/s13415-014-0277-8},
  abstract = {Evidence supports at least two methods for learning about reward and punishment and making predictions for guiding actions. One method, called model-free, progressively acquires cached estimates of the long-run values of circumstances and actions from retrospective experience. The other method, called model-based, uses representations of the environment, expectations, and prospective calculations to make cognitive predictions of future value. Extensive attention has been paid to both methods in computational analyses of instrumental learning. By contrast, although a full computational analysis has been lacking, Pavlovian learning and prediction has typically been presumed to be solely model-free. Here, we revise that presumption and review compelling evidence from Pavlovian revaluation experiments showing that Pavlovian predictions can involve their own form of model-based evaluation. In model-based Pavlovian evaluation, prevailing states of the body and brain influence value computations, and thereby produce powerful incentive motivations that can sometimes be quite new. We consider the consequences of this revised Pavlovian view for the computational landscape of prediction, response, and choice. We also revisit differences between Pavlovian and instrumental learning in the control of incentive motivation.},
  journal = {Cognitive, Affective, \& Behavioral Neuroscience},
  language = {en},
  number = {2}
}

@article{Dayan_Reward_2002,
  title = {Reward, {{Motivation}}, and {{Reinforcement Learning}}},
  author = {Dayan, Peter and Balleine, Bernard W.},
  year = {2002},
  month = oct,
  volume = {36},
  pages = {285--298},
  issn = {0896-6273},
  doi = {10.1016/S0896-6273(02)00963-7},
  abstract = {There is substantial evidence that dopamine is involved in reward learning and appetitive conditioning. However, the major reinforcement learning-based theoretical models of classical conditioning (crudely, prediction learning) are actually based on rules designed to explain instrumental conditioning (action learning). Extensive anatomical, pharmacological, and psychological data, particularly concerning the impact of motivational manipulations, show that these models are unreasonable. We review the data and consider the involvement of a rich collection of different neural systems in various aspects of these forms of conditioning. Dopamine plays a pivotal, but complicated, role.},
  journal = {Neuron},
  keywords = {unread},
  number = {2}
}

@inproceedings{Dearden_Model_1999,
  title = {Model {{Based Bayesian Exploration}}},
  booktitle = {Proceedings of the {{Fifteenth Conference}} on {{Uncertainty}} in {{Artificial Intelligence}}},
  author = {Dearden, Richard and Friedman, Nir and Andre, David},
  year = {1999},
  pages = {150--159},
  publisher = {{Morgan Kaufmann Publishers Inc.}},
  address = {{San Francisco, CA, USA}},
  abstract = {Reinforcement learning systems are often concerned with balancing exploration of untested actions against exploitation of actions that are known to be good. The benefit of exploration can be estimated using the classical notion of Value of Information - the expected improvement in future decision quality arising from the information acquired by exploration. Estimating this quantity requires an assessment of the agent's uncertainty about its current value estimates for states. In this paper we investigate ways to represent and reason about this uncertainty in algorithms where the system attempts to learn a model of its environment. We explicitly represent uncertainty about the parameters of the model and build probability distributions over Q-values based on these. These distributions are used to compute a myopic approximation to the value of information for each action and hence to select the action that best balances exploration and exploitation},
  isbn = {978-1-55860-614-2},
  series = {{{UAI}}'99}
}

@article{DeBaene_Brain_2015,
  title = {Brain {{Circuit}} for {{Cognitive Control Is Shared}} by {{Task}} and {{Language Switching}}},
  author = {De Baene, Wouter and Duyck, Wouter and Brass, Marcel and Carreiras, Manuel},
  year = {2015},
  month = sep,
  volume = {27},
  pages = {1752--1765},
  issn = {0898-929X, 1530-8898},
  doi = {10.1162/jocn_a_00817},
  journal = {Journal of Cognitive Neuroscience},
  language = {en},
  number = {9}
}

@article{deC.Hamilton_scaling_2004,
  title = {The Scaling of Motor Noise with Muscle Strength and Motor Unit Number in Humans},
  author = {{de C. Hamilton}, Antonia F. and Jones, Kelvin E. and Wolpert, Daniel M.},
  year = {2004},
  month = aug,
  volume = {157},
  pages = {417--430},
  issn = {1432-1106},
  doi = {10.1007/s00221-004-1856-7},
  abstract = {Understanding the origin of noise, or variability, in the motor system is an important step towards understanding how accurate movements are performed. Variability of joint torque during voluntary activation is affected by many factors such as the precision of the descending motor commands, the number of muscles that cross the joint, their size and the number of motor units in each. To investigate the relationship between the peripheral factors and motor noise, the maximum voluntary torque produced at a joint and the coefficient of variation of joint torque were recorded from six adult human subjects for four muscle/joint groups in the arm. It was found that the coefficient of variation of torque decreases systematically as the maximum voluntary torque increases. This decreasing coefficient of variation means that a given torque or force can be more accurately generated by a stronger muscle than a weaker muscle. Simulations demonstrated that muscles with different strengths and different numbers of motor units could account for the experimental data. In the simulations, the magnitude of the coefficient of variation of muscle force depended primarily on the number of motor units innervating the muscle, which relates positively to muscle strength. This result can be generalised to the situation where more than one muscle is available to perform a task, and a muscle activation pattern must be selected. The optimal muscle activation pattern required to generate a target torque using a group of muscles, while minimizing the consequences of signal dependent noise, is derived.},
  journal = {Experimental Brain Research},
  language = {en},
  number = {4}
}

@article{DeKleijn_Everyday_2014,
  title = {Everyday Robotic Action: Lessons from Human Action Control},
  shorttitle = {Everyday Robotic Action},
  author = {De Kleijn, Roy and Kachergis, George and Hommel, Bernhard},
  year = {2014},
  volume = {8},
  publisher = {{Frontiers}},
  issn = {1662-5218},
  doi = {10.3389/fnbot.2014.00013},
  abstract = {Robots are increasingly capable of performing everyday human activities such as cooking, cleaning, and doing the laundry. This requires the real-time planning and execution of complex, temporally-extended sequential actions under high degrees of uncertainty, which provides many challenges to traditional approaches to robot action control. We argue that important lessons in this respect can be learned from research on human action control. We provide a brief overview of available psychological insights into this issue and focus on four principles that we think could be particularly beneficial for robot control: the integration of symbolic and subsymbolic planning of action sequences, the integration of feedforward and feedback control, the clustering of complex actions into subcomponents, and the contextualization of action-control structures through goal representations.},
  journal = {Frontiers in Neurorobotics},
  keywords = {Action control,action sequencing,complex action,goal-directed behavior,naturalistic action},
  language = {English}
}

@article{DeMartino_Confidence_2013,
  title = {Confidence in Value-Based Choice},
  author = {De Martino, Benedetto and Fleming, Stephen M. and Garrett, Neil and Dolan, Raymond J.},
  year = {2013},
  month = jan,
  volume = {16},
  pages = {105--110},
  issn = {1097-6256},
  doi = {10.1038/nn.3279},
  abstract = {Decisions are never perfect, with confidence in one's choices fluctuating over time. How subjective confidence and valuation of choice options interact at the level of brain and behavior is unknown. Using a dynamic model of the decision process, we show that confidence reflects the evolution of a decision variable over time, explaining the observed relation between confidence, value, accuracy and reaction time. As predicted by our dynamic model, we show that a functional magnetic resonance imaging signal in human ventromedial prefrontal cortex (vmPFC) reflects both value comparison and confidence in the value comparison process. Crucially, individuals varied in how they related confidence to accuracy, allowing us to show that this introspective ability is predicted by a measure of functional connectivity between vmPFC and rostrolateral prefrontal cortex. Our findings provide a mechanistic link between noise in value comparison and metacognitive awareness of choice, enabling us both to want and to express knowledge of what we want.},
  copyright = {\textcopyright{} 2012 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  journal = {Nature Neuroscience},
  keywords = {Printed},
  language = {en},
  number = {1}
}

@article{DeMartino_Frames_2006,
  title = {Frames, {{Biases}}, and {{Rational Decision}}-{{Making}} in the {{Human Brain}}},
  author = {De Martino, Benedetto and Kumaran, Dharshan and Seymour, Ben and Dolan, Raymond J.},
  year = {2006},
  month = aug,
  volume = {313},
  pages = {684--687},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1128356},
  abstract = {Human choices are remarkably susceptible to the manner in which options are presented. This so-called ``framing effect'' represents a striking violation of standard economic accounts of human rationality, although its underlying neurobiology is not understood. We found that the framing effect was specifically associated with amygdala activity, suggesting a key role for an emotional system in mediating decision biases. Moreover, across individuals, orbital and medial prefrontal cortex activity predicted a reduced susceptibility to the framing effect. This finding highlights the importance of incorporating emotional processes within models of human choice and suggests how the brain may modulate the effect of these biasing influences to approximate rationality.},
  journal = {Science},
  language = {en},
  number = {5787},
  pmid = {16888142}
}

@article{Deneve_Bayesian_2008,
  title = {Bayesian Spiking Neurons {{I}}: Inference},
  author = {Den{\`e}ve, Sophie},
  year = {2008},
  month = jan,
  volume = {20},
  pages = {91--117},
  doi = {10.1162/neco.2008.20.1.91},
  abstract = {We show that the dynamics of spiking neurons can be interpreted as a form of Bayesian inference in time. Neurons that optimally integrate evidence about events in the external world exhibit properties similar to leaky integrate-and-fire neurons with spike-dependent adaptation and maximally respond to fluctuations of their input. Spikes signal the occurrence of new information-what cannot be predicted from the past activity. As a result, firing statistics are close to Poisson, albeit providing a deterministic representation of probabilities.},
  journal = {Neural Comput},
  keywords = {Action Potentials,Adaptation,Algorithms,Animals,Bayes Theorem,Central Nervous System,Computer Simulation,Humans,Markov Chains,Models,Movement,Nerve Net,Neural Networks (Computer),Neurons,Perception,Physiological,physiology,Statistical,Synaptic Transmission},
  language = {eng},
  number = {1},
  pmid = {18045002}
}

@article{Deneve_Optimal_2007,
  title = {Optimal {{Sensorimotor Integration}} in {{Recurrent Cortical Networks}}: {{A Neural Implementation}} of {{Kalman Filters}}},
  shorttitle = {Optimal {{Sensorimotor Integration}} in {{Recurrent Cortical Networks}}},
  author = {Den{\`e}ve, Sophie and Duhamel, Jean-Ren{\'e} and Pouget, Alexandre},
  year = {2007},
  month = may,
  volume = {27},
  pages = {5744--5756},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.3985-06.2007},
  abstract = {Several behavioral experiments suggest that the nervous system uses an internal model of the dynamics of the body to implement a close approximation to a Kalman filter. This filter can be used to perform a variety of tasks nearly optimally, such as predicting the sensory consequence of motor action, integrating sensory and body posture signals, and computing motor commands. We propose that the neural implementation of this Kalman filter involves recurrent basis function networks with attractor dynamics, a kind of architecture that can be readily mapped onto cortical circuits. In such networks, the tuning curves to variables such as arm velocity are remarkably noninvariant in the sense that the amplitude and width of the tuning curves of a given neuron can vary greatly depending on other variables such as the position of the arm or the reliability of the sensory feedback. This property could explain some puzzling properties of tuning curves in the motor and premotor cortex, and it leads to several new predictions.},
  journal = {The Journal of Neuroscience},
  keywords = {basis functions,Kalman filter,line attractors,motor control,population code,sensorimotor integration},
  language = {en},
  number = {21},
  pmid = {17522318}
}

@article{Deneve_Optimal_2007a,
  title = {Optimal Sensorimotor Integration in Recurrent Cortical Networks: A Neural Implementation of {{Kalman}} Filters.},
  author = {Den{\`e}ve, Sophie and Duhamel, Jean-Ren{\'e} and Pouget, Alexandre},
  year = {2007},
  month = may,
  volume = {27},
  pages = {5744--5756},
  doi = {10.1523/JNEUROSCI.3985-06.2007},
  abstract = {Several behavioral experiments suggest that the nervous system uses an internal model of the dynamics of the body to implement a close approximation to a Kalman filter. This filter can be used to perform a variety of tasks nearly optimally, such as predicting the sensory consequence of motor action, integrating sensory and body posture signals, and computing motor commands. We propose that the neural implementation of this Kalman filter involves recurrent basis function networks with attractor dynamics, a kind of architecture that can be readily mapped onto cortical circuits. In such networks, the tuning curves to variables such as arm velocity are remarkably noninvariant in the sense that the amplitude and width of the tuning curves of a given neuron can vary greatly depending on other variables such as the position of the arm or the reliability of the sensory feedback. This property could explain some puzzling properties of tuning curves in the motor and premotor cortex, and it leads to several new predictions.},
  journal = {J Neurosci},
  keywords = {Cerebral Cortex,Nerve Net,Neural Networks (Computer),physiology,Psychomotor Performance,Systems Integration},
  language = {eng},
  number = {21},
  pmid = {17522318}
}

@article{Deserno_Ventral_2015,
  title = {Ventral Striatal Dopamine Reflects Behavioral and Neural Signatures of Model-Based Control during Sequential Decision Making},
  author = {Deserno, Lorenz and Huys, Quentin J. M. and Boehme, Rebecca and Buchert, Ralph and Heinze, Hans-Jochen and Grace, Anthony A. and Dolan, Raymond J. and Heinz, Andreas and Schlagenhauf, Florian},
  year = {2015},
  month = feb,
  volume = {112},
  pages = {1595--1600},
  issn = {1091-6490},
  doi = {10.1073/pnas.1417219112},
  abstract = {Dual system theories suggest that behavioral control is parsed between a deliberative "model-based" and a more reflexive "model-free" system. A balance of control exerted by these systems is thought to be related to dopamine neurotransmission. However, in the absence of direct measures of human dopamine, it remains unknown whether this reflects a quantitative relation with dopamine either in the striatum or other brain areas. Using a sequential decision task performed during functional magnetic resonance imaging, combined with striatal measures of dopamine using [(18)F]DOPA positron emission tomography, we show that higher presynaptic ventral striatal dopamine levels were associated with a behavioral bias toward more model-based control. Higher presynaptic dopamine in ventral striatum was associated with greater coding of model-based signatures in lateral prefrontal cortex and diminished coding of model-free prediction errors in ventral striatum. Thus, interindividual variability in ventral striatal presynaptic dopamine reflects a balance in the behavioral expression and the neural signatures of model-free and model-based control. Our data provide a novel perspective on how alterations in presynaptic dopamine levels might be accompanied by a disruption of behavioral control as observed in aging or neuropsychiatric diseases such as schizophrenia and addiction.},
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  keywords = {Adult,Behavior,Corpus Striatum,decision making,Decision Making,dopamine,Dopamine,Female,fMRI,Humans,Magnetic Resonance Imaging,Male,Middle Aged,PET,Positron-Emission Tomography,reinforcement learning,Young Adult},
  language = {eng},
  number = {5},
  pmcid = {PMC4321318},
  pmid = {25605941}
}

@article{Deserno_Ventral_2015a,
  title = {Ventral Striatal Dopamine Reflects Behavioral and Neural Signatures of Model-Based Control during Sequential Decision Making},
  author = {Deserno, Lorenz and Huys, Quentin J. M. and Boehme, Rebecca and Buchert, Ralph and Heinze, Hans-Jochen and Grace, Anthony A. and Dolan, Raymond J. and Heinz, Andreas and Schlagenhauf, Florian},
  year = {2015},
  month = feb,
  volume = {112},
  pages = {1595--1600},
  issn = {0027-8424},
  doi = {10.1073/pnas.1417219112},
  abstract = {Whether humans make choices based on a deliberative ``model-based'' or a reflexive ``model-free'' system of behavioral control remains an ongoing topic of research. Dopamine is implicated in motivational drive as well as in planning future actions. Here, we demonstrate that higher presynaptic dopamine in human ventral striatum is associated with more pronounced model-based behavioral control, as well as an enhanced coding of model-based signatures in lateral prefrontal cortex and diminished coding of model-free learning signals in ventral striatum. Our study links ventral striatal presynaptic dopamine to a balance between two distinct modes of behavioral control in humans. The findings have implications for neuropsychiatric diseases associated with alterations of dopamine neurotransmission and a disrupted balance of behavioral control., Dual system theories suggest that behavioral control is parsed between a deliberative ``model-based'' and a more reflexive ``model-free'' system. A balance of control exerted by these systems is thought to be related to dopamine neurotransmission. However, in the absence of direct measures of human dopamine, it remains unknown whether this reflects a quantitative relation with dopamine either in the striatum or other brain areas. Using a sequential decision task performed during functional magnetic resonance imaging, combined with striatal measures of dopamine using [18F]DOPA positron emission tomography, we show that higher presynaptic ventral striatal dopamine levels were associated with a behavioral bias toward more model-based control. Higher presynaptic dopamine in ventral striatum was associated with greater coding of model-based signatures in lateral prefrontal cortex and diminished coding of model-free prediction errors in ventral striatum. Thus, interindividual variability in ventral striatal presynaptic dopamine reflects a balance in the behavioral expression and the neural signatures of model-free and model-based control. Our data provide a novel perspective on how alterations in presynaptic dopamine levels might be accompanied by a disruption of behavioral control as observed in aging or neuropsychiatric diseases such as schizophrenia and addiction.},
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  number = {5},
  pmcid = {PMC4321318},
  pmid = {25605941}
}

@article{Dezfouli_Actions_2013,
  title = {Actions, {{Action Sequences}} and {{Habits}}: {{Evidence That Goal}}-{{Directed}} and {{Habitual Action Control Are Hierarchically Organized}}},
  shorttitle = {Actions, {{Action Sequences}} and {{Habits}}},
  author = {Dezfouli, Amir and Balleine, Bernard W.},
  year = {2013},
  month = dec,
  volume = {9},
  pages = {e1003364},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1003364},
  abstract = {Behavioral evidence suggests that instrumental conditioning is governed by two forms of action control: a goal-directed and a habit learning process. Model-based reinforcement learning (RL) has been argued to underlie the goal-directed process; however, the way in which it interacts with habits and the structure of the habitual process has remained unclear. According to a flat architecture, the habitual process corresponds to model-free RL, and its interaction with the goal-directed process is coordinated by an external arbitration mechanism. Alternatively, the interaction between these systems has recently been argued to be hierarchical, such that the formation of action sequences underlies habit learning and a goal-directed process selects between goal-directed actions and habitual sequences of actions to reach the goal. Here we used a two-stage decision-making task to test predictions from these accounts. The hierarchical account predicts that, because they are tied to each other as an action sequence, selecting a habitual action in the first stage will be followed by a habitual action in the second stage, whereas the flat account predicts that the statuses of the first and second stage actions are independent of each other. We found, based on subjects' choices and reaction times, that human subjects combined single actions to build action sequences and that the formation of such action sequences was sufficient to explain habitual actions. Furthermore, based on Bayesian model comparison, a family of hierarchical RL models, assuming a hierarchical interaction between habit and goal-directed processes, provided a better fit of the subjects' behavior than a family of flat models. Although these findings do not rule out all possible model-free accounts of instrumental conditioning, they do show such accounts are not necessary to explain habitual actions and provide a new basis for understanding how goal-directed and habitual action control interact.},
  journal = {PLOS Computational Biology},
  keywords = {Behavior,Decision making,Habits,Learning,Machine learning,Reaction time,Sequence analysis,Signal inhibition},
  language = {en},
  number = {12}
}

@article{Dezfouli_Actions_2013a,
  title = {Actions, {{Action Sequences}} and {{Habits}}: {{Evidence That Goal}}-{{Directed}} and {{Habitual Action Control Are Hierarchically Organized}}},
  shorttitle = {Actions, {{Action Sequences}} and {{Habits}}},
  author = {Dezfouli, Amir and Balleine, Bernard W.},
  year = {2013},
  month = dec,
  volume = {9},
  pages = {e1003364},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1003364},
  abstract = {Behavioral evidence suggests that instrumental conditioning is governed by two forms of action control: a goal-directed and a habit learning process. Model-based reinforcement learning (RL) has been argued to underlie the goal-directed process; however, the way in which it interacts with habits and the structure of the habitual process has remained unclear. According to a flat architecture, the habitual process corresponds to model-free RL, and its interaction with the goal-directed process is coordinated by an external arbitration mechanism. Alternatively, the interaction between these systems has recently been argued to be hierarchical, such that the formation of action sequences underlies habit learning and a goal-directed process selects between goal-directed actions and habitual sequences of actions to reach the goal. Here we used a two-stage decision-making task to test predictions from these accounts. The hierarchical account predicts that, because they are tied to each other as an action sequence, selecting a habitual action in the first stage will be followed by a habitual action in the second stage, whereas the flat account predicts that the statuses of the first and second stage actions are independent of each other. We found, based on subjects' choices and reaction times, that human subjects combined single actions to build action sequences and that the formation of such action sequences was sufficient to explain habitual actions. Furthermore, based on Bayesian model comparison, a family of hierarchical RL models, assuming a hierarchical interaction between habit and goal-directed processes, provided a better fit of the subjects' behavior than a family of flat models. Although these findings do not rule out all possible model-free accounts of instrumental conditioning, they do show such accounts are not necessary to explain habitual actions and provide a new basis for understanding how goal-directed and habitual action control interact.},
  journal = {PLOS Computational Biology},
  keywords = {Behavior,Decision making,Habits,Learning,Machine learning,Reaction time,Sequence analysis,Signal inhibition},
  language = {en},
  number = {12}
}

@article{Dezfouli_Actions_2013b,
  title = {Actions, {{Action Sequences}} and {{Habits}}: {{Evidence That Goal}}-{{Directed}} and {{Habitual Action Control Are Hierarchically Organized}}},
  shorttitle = {Actions, {{Action Sequences}} and {{Habits}}},
  author = {Dezfouli, Amir and Balleine, Bernard W.},
  year = {2013},
  month = dec,
  volume = {9},
  pages = {e1003364},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1003364},
  abstract = {Behavioral evidence suggests that instrumental conditioning is governed by two forms of action control: a goal-directed and a habit learning process. Model-based reinforcement learning (RL) has been argued to underlie the goal-directed process; however, the way in which it interacts with habits and the structure of the habitual process has remained unclear. According to a flat architecture, the habitual process corresponds to model-free RL, and its interaction with the goal-directed process is coordinated by an external arbitration mechanism. Alternatively, the interaction between these systems has recently been argued to be hierarchical, such that the formation of action sequences underlies habit learning and a goal-directed process selects between goal-directed actions and habitual sequences of actions to reach the goal. Here we used a two-stage decision-making task to test predictions from these accounts. The hierarchical account predicts that, because they are tied to each other as an action sequence, selecting a habitual action in the first stage will be followed by a habitual action in the second stage, whereas the flat account predicts that the statuses of the first and second stage actions are independent of each other. We found, based on subjects' choices and reaction times, that human subjects combined single actions to build action sequences and that the formation of such action sequences was sufficient to explain habitual actions. Furthermore, based on Bayesian model comparison, a family of hierarchical RL models, assuming a hierarchical interaction between habit and goal-directed processes, provided a better fit of the subjects' behavior than a family of flat models. Although these findings do not rule out all possible model-free accounts of instrumental conditioning, they do show such accounts are not necessary to explain habitual actions and provide a new basis for understanding how goal-directed and habitual action control interact.},
  journal = {PLOS Computational Biology},
  keywords = {Behavior,Decision making,Habits,Learning,Machine learning,Reaction time,Sequence analysis,Signal inhibition},
  language = {en},
  number = {12}
}

@article{Dezfouli_Habits_2012,
  title = {Habits, Action Sequences and Reinforcement Learning},
  author = {Dezfouli, Amir and Balleine, Bernard W.},
  year = {2012},
  month = apr,
  volume = {35},
  pages = {1036--1051},
  issn = {1460-9568},
  doi = {10.1111/j.1460-9568.2012.08050.x},
  abstract = {It is now widely accepted that instrumental actions can be either goal-directed or habitual; whereas the former are rapidly acquired and regulated by their outcome, the latter are reflexive, elicited by antecedent stimuli rather than their consequences. Model-based reinforcement learning (RL) provides an elegant description of goal-directed action. Through exposure to states, actions and rewards, the agent rapidly constructs a model of the world and can choose an appropriate action based on quite abstract changes in environmental and evaluative demands. This model is powerful but has a problem explaining the development of habitual actions. To account for habits, theorists have argued that another action controller is required, called model-free RL, that does not form a model of the world but rather caches action values within states allowing a state to select an action based on its reward history rather than its consequences. Nevertheless, there are persistent problems with important predictions from the model; most notably the failure of model-free RL correctly to predict the insensitivity of habitual actions to changes in the action-reward contingency. Here, we suggest that introducing model-free RL in instrumental conditioning is unnecessary, and demonstrate that reconceptualizing habits as action sequences allows model-based RL to be applied to both goal-directed and habitual actions in a manner consistent with what real animals do. This approach has significant implications for the way habits are currently investigated and generates new experimental predictions.},
  journal = {The European Journal of Neuroscience},
  keywords = {Animals,Goals,Habits,Humans,Learning,Random Allocation,Reinforcement (Psychology),unread},
  language = {eng},
  number = {7},
  pmcid = {PMC3325518},
  pmid = {22487034}
}

@article{Dickinson_Actions_1985,
  title = {Actions and Habits: The Development of Behavioural Autonomy},
  shorttitle = {Actions and Habits},
  author = {Dickinson, A.},
  year = {1985},
  month = feb,
  volume = {308},
  pages = {67--78},
  issn = {0080-4622, 2054-0280},
  doi = {10.1098/rstb.1985.0010},
  abstract = {The study of animal behaviour has been dominated by two general models. According to the mechanistic stimulus-response model, a particular behaviour is either an innate or an acquired habit which is simply triggered by the appropriate stimulus. By contrast, the teleological model argues that, at least, some activities are purposive actions controlled by the current value of their goals through knowledge about the instrumental relations between the actions and their consequences. The type of control over any particular behaviour can be determined by a goal revaluation procedure. If the anim al's performance changes appropriately following an alteration in the value of the goal or reward without further experience of the instrumental relationship, the behaviour should be regarded as a purposive action. On the other hand, the stimulus-response model is more appropriate for an activity whose performance is autonomous of the current value of the goal. By using this assay, we have found that a simple food-rewarded activity is sensitive to reward devaluation in rats following limited but not extended training. The development of this behavioural autonomy with extended training appears to depend not upon the am ount of training per se, but rather upon the fact that the animal no longer experiences the correlation between variations in performance and variations in the associated consequences during overtraining. In agreement with this idea, limited exposure to an instrumental relationship that arranges a low correlation between performance and reward rates also favours the development of behavioural autonomy. Thus, the same activity can be either an action or a habit depending upon the type of training it has received.},
  copyright = {Scanned images copyright \textcopyright{} 2017, Royal Society},
  journal = {Phil. Trans. R. Soc. Lond. B},
  language = {en},
  number = {1135}
}

@article{Diehl_Effects_1995,
  title = {Effects of {{Feedback Complexity}} on {{Dynamic Decision Making}}},
  author = {Diehl, Ernst and Sterman, John D.},
  year = {1995},
  month = may,
  volume = {62},
  pages = {198--215},
  issn = {0749-5978},
  doi = {10.1006/obhd.1995.1043},
  abstract = {Prior research shows people suffer from misperceptions of feedback, generating systematic dysfunctional behavior in the presence of dynamic complexity - settings with multiple feedback loops, time delays, and nonlinearities. However, prior work has not adequately mapped the effect of these elements of complexity on performance. We report an experiment where subjects managed an inventory in the face of stochastic sales, a classic dynamic decision task. We vary the time delays and strength of the feedback loops to explore the impact of these elements of dynamic complexity on behavior. Subjects faced financial incentives and had opportunities to learn. Yet performance was significantly worse than optimal across all conditions. Subjects outperformed a naive "do-nothing" rule in the simple conditions, but performance deteriorated dramatically with increasing time delays and feedback effects, and most were outperformed by the do-nothing rule in the complex conditions. Regression analysis of subjects{${'}$} decisions showed most ignored the supply line of pending production and undercontrolled the system. Undercontrol increased significantly with growing time delays and feedback strength, showing subjects were insufficiently adaptive despite perfect knowledge of system structure and parameters. Subjects{${'}$} understanding of complex feedback settings declines as delays between cause and effect increase and as actions have stronger side effects. Few indications were found of active experimentation or learning: the need to control seemed to override the ability to learn.},
  journal = {Organizational Behavior and Human Decision Processes},
  number = {2}
}

@article{Ditzen_Odor_2003,
  title = {Odor {{Similarity Does Not Influence}} the {{Time Needed}} for {{Odor Processing}}},
  author = {Ditzen, Mathias and Evers, Jan-Felix and Galizia, C. Giovanni},
  year = {2003},
  month = nov,
  volume = {28},
  pages = {781--789},
  issn = {0379-864X, 1464-3553},
  doi = {10.1093/chemse/bjg070},
  abstract = {The brain's link between perception and action involves several steps, which include stimulus transduction, neuronal coding of the stimulus, comparison to a memory template and choice of an appropriate behavioral response. All of these need time, and many studies report that the time needed to compare two stimuli correlates inversely with the perceived distance between them. We developed a behavioral assay in which we tested the time that a honeybee needs to discriminate between odors consisting of mixtures of two components, and included both very similar and very different stimuli spanning four log-concentration ranges. Bees learned to discriminate all odors, including very similar odors and the same odor at different concentrations. Even though discriminating two very similar odors appears to be a more difficult task than discriminating two very distinct substances, we found that the time needed to make a choice for or against an odor was independent of odor similarity. Our data suggest that, irrespective of the nature of the olfactory code, the bee olfactory system evaluates odor quality after a constant interval. This may ensure that odors are only assessed after the olfactory network has optimized its representation.},
  journal = {Chemical Senses},
  keywords = {honeybee; odor concentrations; odor mixtures; olfaction; response time},
  language = {en},
  number = {9},
  pmid = {14654446}
}

@article{Ditzen_Odor_2003a,
  title = {Odor {{Similarity Does Not Influence}} the {{Time Needed}} for {{Odor Processing}}},
  author = {Ditzen, Mathias and Evers, Jan-Felix and Galizia, C. Giovanni},
  year = {2003},
  month = nov,
  volume = {28},
  pages = {781--789},
  issn = {0379-864X, 1464-3553},
  doi = {10.1093/chemse/bjg070},
  abstract = {The brain's link between perception and action involves several steps, which include stimulus transduction, neuronal coding of the stimulus, comparison to a memory template and choice of an appropriate behavioral response. All of these need time, and many studies report that the time needed to compare two stimuli correlates inversely with the perceived distance between them. We developed a behavioral assay in which we tested the time that a honeybee needs to discriminate between odors consisting of mixtures of two components, and included both very similar and very different stimuli spanning four log-concentration ranges. Bees learned to discriminate all odors, including very similar odors and the same odor at different concentrations. Even though discriminating two very similar odors appears to be a more difficult task than discriminating two very distinct substances, we found that the time needed to make a choice for or against an odor was independent of odor similarity. Our data suggest that, irrespective of the nature of the olfactory code, the bee olfactory system evaluates odor quality after a constant interval. This may ensure that odors are only assessed after the olfactory network has optimized its representation.},
  journal = {Chemical Senses},
  keywords = {honeybee; odor concentrations; odor mixtures; olfaction; response time},
  language = {en},
  number = {9},
  pmid = {14654446}
}

@article{Dolan_Goals_2013,
  title = {Goals and {{Habits}} in the {{Brain}}},
  author = {Dolan, Ray J. and Dayan, Peter},
  year = {2013},
  month = oct,
  volume = {80},
  pages = {312--325},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2013.09.007},
  abstract = {An enduring and richly elaborated dichotomy in cognitive neuroscience is that of reflective versus reflexive decision making and choice. Other literatures refer to the two ends of what is likely to be a spectrum with terms such as goal-directed versus habitual, model-based versus model-free or prospective versus retrospective. One of the most rigorous traditions of experimental work in the field started with studies in rodents and graduated via human versions and enrichments of those experiments to a current state in which new paradigms are probing and challenging the very heart of the distinction. We review four generations of work in this tradition and provide pointers to the forefront of the field's fifth generation., Dolan and Dayan provide a computational perspective on two fundamental forms of control, goal directed and habitual. They discuss how these forms of control are expressed in the human brain and how dominance of one or other of these systems may contribute to psychopathology.},
  journal = {Neuron},
  number = {2},
  pmcid = {PMC3807793},
  pmid = {24139036}
}

@article{Doll_Modelbased_2015,
  title = {Model-Based Choices Involve Prospective Neural Activity},
  author = {Doll, Bradley B. and Duncan, Katherine D. and Simon, Dylan A. and Shohamy, Daphna and Daw, Nathaniel D.},
  year = {2015},
  month = may,
  volume = {18},
  pages = {767--772},
  issn = {1546-1726},
  doi = {10.1038/nn.3981},
  abstract = {Decisions may arise via 'model-free' repetition of previously reinforced actions or by 'model-based' evaluation, which is widely thought to follow from prospective anticipation of action consequences using a learned map or model. While choices and neural correlates of decision variables sometimes reflect knowledge of their consequences, it remains unclear whether this actually arises from prospective evaluation. Using functional magnetic resonance imaging and a sequential reward-learning task in which paths contained decodable object categories, we found that humans' model-based choices were associated with neural signatures of future paths observed at decision time, suggesting a prospective mechanism for choice. Prospection also covaried with the degree of model-based influences on neural correlates of decision variables and was inversely related to prediction error signals thought to underlie model-free learning. These results dissociate separate mechanisms underlying model-based and model-free evaluation and support the hypothesis that model-based influences on choices and neural decision variables result from prospection.},
  journal = {Nature Neuroscience},
  keywords = {Adult,Anticipation; Psychological,Choice Behavior,Decision Making,Female,Forecasting,Functional Neuroimaging,Games; Experimental,Humans,Learning,Magnetic Resonance Imaging,Male,Models; Neurological,Reward,Young Adult},
  language = {eng},
  number = {5},
  pmcid = {PMC4414826},
  pmid = {25799041}
}

@article{Doll_ubiquity_2012,
  title = {The Ubiquity of Model-Based Reinforcement Learning},
  author = {Doll, Bradley B and Simon, Dylan A and Daw, Nathaniel D},
  year = {2012},
  month = dec,
  volume = {22},
  pages = {1075--1081},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2012.08.003},
  abstract = {The reward prediction error theory of dopamine function has enjoyed great success in the neuroscience of learning and decision-making. This theory is derived from model-free reinforcement learning in which choices are made simply on the basis of previously realized rewards. Recently, attention has turned to correlates of more flexible, albeit computationally complex, model-based methods in the brain. These methods are distinguished from model-free learning by their evaluation of candidate actions using expected future outcomes according to a world model. Puzzlingly, signatures from these computations seem to be pervasive in the very same regions previously thought to support model-free learning. Here, we review recent behavioral and neural evidence about these two systems, in attempt to reconcile their enigmatic cohabitation in the brain.},
  journal = {Current opinion in neurobiology},
  number = {6},
  pmcid = {PMC3513648},
  pmid = {22959354}
}

@misc{DominiqueMakowski_easystats_2019,
  title = {Easystats/{{bayestestR}}: 0.0.1},
  shorttitle = {Easystats/{{bayestestR}}},
  author = {Dominique Makowski and Daniel L{\"u}decke},
  year = {2019},
  month = feb,
  doi = {10.5281/zenodo.2556486},
  abstract = {Initial stable pre-release.},
  howpublished = {Zenodo},
  keywords = {Bayesian,R}
}

@article{Dorris_Activity_2004,
  title = {Activity in {{Posterior Parietal Cortex Is Correlated}} with the {{Relative Subjective Desirability}} of {{Action}}},
  author = {Dorris, Michael C. and Glimcher, Paul W.},
  year = {2004},
  month = oct,
  volume = {44},
  pages = {365--378},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2004.09.009},
  abstract = {Behavioral studies suggest that making a decision involves representing the overall desirability of all available actions and then selecting that action that is most desirable. Physiological studies have proposed that neurons in the parietal cortex play a role in selecting movements for execution. To test the hypothesis that these parietal neurons encode the subjective desirability of making particular movements, we exploited Nash's game theoretic equilibrium, during which the subjective desirability of multiple actions should be equal for human players. Behavior measured during a strategic game suggests that monkeys' choices, like those of humans, are guided by subjective desirability. Under these conditions, activity in the parietal cortex was correlated with the relative subjective desirability of actions irrespective of the specific combination of reward magnitude, reward probability, and response probability associated with each action. These observations may help place many recent findings regarding the posterior parietal cortex into a common conceptual framework.},
  journal = {Neuron},
  number = {2}
}

@incollection{Doucet_Tutorial_2011,
  title = {A {{Tutorial}} on {{Particle Filtering}} and {{Smoothing}}: {{Fifteen}} Years Later},
  booktitle = {Oxford {{Handbook}} of {{Nonlinear Filtering}}},
  author = {Doucet, Arnaud and Johansen, Adam M.},
  year = {2011},
  publisher = {{Oxford University Press}},
  abstract = {Optimal estimation problems for non-linear non-Gaussian state-space models do not typically admit analytic solutions. Since their introduction in 1993, particle filtering methods have become a very popular class of algorithms to solve these estimation problems numerically in an online manner, i.e. recursively as observations become available, and are now routinely used in fields as diverse as computer vision, econometrics, robotics and navigation. The objective of this tutorial is to provide a complete, up-to-date survey of this field as of 2008. Basic and advanced particle methods for filtering as well as smoothing are presented.}
}

@book{Doya_Bayesian_2006,
  title = {Bayesian {{Brain}}},
  editor = {Doya, Kenji and Ishii, Shin and Pouget, Alexandre and Rao, Rajesh P. N.},
  year = {2006},
  publisher = {{MIT Press}},
  abstract = {A Bayesian approach can contribute to an understanding of the brain on multiple levels, by giving normative predictions about how an ideal sensory system should combine prior knowledge and observation, by providing mechanistic interpretation of the dynamic functioning of the brain circuit, and by suggesting optimal ways of deciphering experimental data. Bayesian Brain brings together contributions from both experimental and theoretical neuroscientists that examine the brain mechanisms of perception, decision making, and motor control according to the concepts of Bayesian estimation. After an overview of the mathematical concepts, including Bayes' theorem, that are basic to understanding the approaches discussed, contributors discuss how Bayesian concepts can be used for interpretation of such neurobiological data as neural spikes and functional brain imaging. Next, contributors examine the modeling of sensory processing, including the neural coding of information about the outside world. Finally, contributors explore dynamic processes for proper behaviors, including the mathematics of the speed and accuracy of perceptual decisions and neural models of belief propagation.}
}

@article{Dreisbach_Preparatory_2002,
  title = {Preparatory Processes in the Task-Switching Paradigm: {{Evidence}} from the Use of Probability Cues},
  shorttitle = {Preparatory Processes in the Task-Switching Paradigm},
  author = {Dreisbach, Gesine and Haider, Hilde and Kluwe, Rainer H.},
  year = {2002},
  volume = {28},
  pages = {468--483},
  issn = {1939-1285(Electronic);0278-7393(Print)},
  doi = {10.1037/0278-7393.28.3.468},
  abstract = {The purpose of the investigations was to dissociate processes of task preparation from task execution in the task-switching paradigm. The basic assumption was that task repetitions have 2 advantages over task shifts: an activation advantage as a result of the execution of the same task type in the pretrial, and an expectation advantage, because participants, in general, implicitly expect a repetition. In Experiments 1-3, the authors explicitly manipulated expectancies by presenting cues that announced a shift and/or a repetition with probabilities of 1.00, .75, .50, or .25. Increasing latencies with decreasing probability for shifts and repetitions show that the expectation advantage can be equalized by preparation. However, the activation advantage represented by constant shift costs between tasks of the same probability is not penetrable by preparation. In Experiments 4 and 5, the authors found evidence that preparation involves activation of the expected task and inhibition of distracting tasks.},
  copyright = {(c) 2012 APA, all rights reserved},
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  keywords = {*Attention,*Expectations,*Human Information Storage,*Practice,*Task Analysis,Costs and Cost Analysis,Cues,Distraction,Latent Inhibition,performance,Probability,Task switching},
  number = {3}
}

@article{Duan_Visual_2015,
  title = {Visual {{Attention Model Based}} on {{Statistical Properties}} of {{Neuron Responses}}},
  author = {Duan, Haibin and Wang, Xiaohua},
  year = {2015},
  month = mar,
  volume = {5},
  doi = {10.1038/srep08873},
  abstract = {Visual attention is a mechanism of the visual system that can select relevant objects from a specific scene. Interactions among neurons in multiple cortical areas are considered to be involved in attentional allocation. However, the characteristics of the encoded features and neuron responses in those attention related cortices are indefinite. Therefore, further investigations carried out in this study aim at demonstrating that unusual regions arousing more attention generally cause particular neuron responses. We suppose that visual saliency is obtained on the basis of neuron responses to contexts in natural scenes. A bottom-up visual attention model is proposed based on the self-information of neuron responses to test and verify the hypothesis. Four different color spaces are adopted and a novel entropy-based combination scheme is designed to make full use of color information. Valuable regions are highlighted while redundant backgrounds are suppressed in the saliency maps obtained by the proposed model. Comparative results reveal that the proposed model outperforms several state-of-the-art models. This study provides insights into the neuron responses based saliency detection and may underlie the neural mechanism of early visual cortices for bottom-up visual attention.},
  copyright = {\textcopyright{} 2015 Macmillan Publishers Limited. All rights reserved},
  journal = {Scientific Reports},
  keywords = {Attention,Biophysical models},
  language = {en}
}

@article{Duan_Visual_2015a,
  title = {Visual {{Attention Model Based}} on {{Statistical Properties}} of {{Neuron Responses}}},
  author = {Duan, Haibin and Wang, Xiaohua},
  year = {2015},
  month = mar,
  volume = {5},
  doi = {10.1038/srep08873},
  abstract = {Visual attention is a mechanism of the visual system that can select relevant objects from a specific scene. Interactions among neurons in multiple cortical areas are considered to be involved in attentional allocation. However, the characteristics of the encoded features and neuron responses in those attention related cortices are indefinite. Therefore, further investigations carried out in this study aim at demonstrating that unusual regions arousing more attention generally cause particular neuron responses. We suppose that visual saliency is obtained on the basis of neuron responses to contexts in natural scenes. A bottom-up visual attention model is proposed based on the self-information of neuron responses to test and verify the hypothesis. Four different color spaces are adopted and a novel entropy-based combination scheme is designed to make full use of color information. Valuable regions are highlighted while redundant backgrounds are suppressed in the saliency maps obtained by the proposed model. Comparative results reveal that the proposed model outperforms several state-of-the-art models. This study provides insights into the neuron responses based saliency detection and may underlie the neural mechanism of early visual cortices for bottom-up visual attention.},
  copyright = {\textcopyright{} 2015 Macmillan Publishers Limited. All rights reserved},
  journal = {Scientific Reports},
  keywords = {Attention,Biophysical models},
  language = {en}
}

@article{Duarte_Dynamics_1998,
  title = {Dynamics of the {{Attractor}} in the {{Lotka}}\textendash{{Volterra Equations}}},
  author = {Duarte, Pedro and Fernandes, Rui L. and Oliva, Waldyr M.},
  year = {1998},
  month = oct,
  volume = {149},
  pages = {143--189},
  issn = {0022-0396},
  doi = {10.1006/jdeq.1998.3443},
  abstract = {We show that for stable dissipative Lotka\textendash Volterra systems the dynamics on the attractor are hamiltonian and we argue that complex dynamics can occur},
  journal = {Journal of Differential Equations},
  number = {1}
}

@article{Dunne_involvement_2016,
  title = {The Involvement of Model-Based but Not Model-Free Learning Signals during Observational Reward Learning in the Absence of Choice},
  author = {Dunne, Simon and D'Souza, Arun and O'Doherty, John P.},
  year = {2016},
  month = jun,
  volume = {115},
  pages = {3195--3203},
  issn = {0022-3077, 1522-1598},
  doi = {10.1152/jn.00046.2016},
  abstract = {A major open question is whether computational strategies thought to be used during experiential learning, specifically model-based and model-free reinforcement learning, also support observational learning. Furthermore, the question of how observational learning occurs when observers must learn about the value of options from observing outcomes in the absence of choice has not been addressed. In the present study we used a multi-armed bandit task that encouraged human participants to employ both experiential and observational learning while they underwent functional magnetic resonance imaging (fMRI). We found evidence for the presence of model-based learning signals during both observational and experiential learning in the intraparietal sulcus. However, unlike during experiential learning, model-free learning signals in the ventral striatum were not detectable during this form of observational learning. These results provide insight into the flexibility of the model-based learning system, implicating this system in learning during observation as well as from direct experience, and further suggest that the model-free reinforcement learning system may be less flexible with regard to its involvement in observational learning.},
  copyright = {Copyright \textcopyright{} 2016 the American Physiological Society},
  journal = {Journal of Neurophysiology},
  language = {en},
  number = {6},
  pmid = {27052578}
}

@article{Dyer_Relative_1982,
  title = {Relative {{Risk Aversion}}},
  author = {Dyer, James S. and Sarin, Rakesh K.},
  year = {1982},
  month = aug,
  volume = {28},
  pages = {875--886},
  publisher = {{INFORMS}},
  issn = {0025-1909},
  doi = {10.1287/mnsc.28.8.875},
  abstract = {An individual's preference for risky alternatives is influenced by the strength of preference he feels for the consequences and his attitude toward risk taking. Conventional measures of risk attitude confound these two factors. In this paper we formally separate these factors and explore how this separation might significantly enhance our understanding of decision making under risk.We introduce a new measure of risk attitude defined relative to strength of preference. This measure is based on comparing an individual's von Neumann-Morgenstern utility function to his strength of preference function. The properties of this measure of relative risk attitude are developed.The concept of relative risk attitude has several important implications. First, it provides a better description of an individual's attitude toward risk. Second, it provides a better way to combine preferences of various experts in the context of multicriteria decision making. Finally, it provides a better insight into the implications of some commonly employed preference aggregation rules in group decision making.},
  journal = {Management Science},
  number = {8}
}

@article{Ebitz_Neuronal_2015,
  title = {Neuronal Activity in Primate Dorsal Anterior Cingulate Cortex Signals Task Conflict and Predicts Adjustments in Pupil-Linked Arousal},
  author = {Ebitz, R. Becket and Platt, Michael L.},
  year = {2015},
  month = feb,
  volume = {85},
  pages = {628--640},
  issn = {1097-4199},
  doi = {10.1016/j.neuron.2014.12.053},
  abstract = {Whether driving a car, shopping for food, or paying attention in a classroom of boisterous teenagers, it's often hard to maintain focus on goals in the face of distraction. Brain imaging studies in humans implicate the dorsal anterior cingulate cortex (dACC) in regulating the conflict between goals and distractors. Here we show that single dACC neurons signal conflict between task goals and distractors in the rhesus macaque, particularly for biologically relevant social stimuli. For some neurons, task conflict signals predicted subsequent changes in pupil size-a peripheral index of arousal linked to noradrenergic tone-associated with reduced distractor interference. dACC neurons also responded to errors, and these signals predicted adjustments in pupil size. These findings provide the first neurophysiological endorsement of the hypothesis that dACC regulates conflict, in part, via modulation of pupil-linked processes such as arousal.},
  journal = {Neuron},
  keywords = {Animals,Arousal,Conflict (Psychology),Forecasting,Gyrus Cinguli,Macaca mulatta,Neurons,Photic Stimulation,Psychomotor Performance,Pupil},
  language = {eng},
  number = {3},
  pmcid = {PMC4319115},
  pmid = {25654259}
}

@article{Ebitz_Neuronal_2015a,
  title = {Neuronal {{Activity}} in {{Primate Dorsal Anterior Cingulate Cortex Signals Task Conflict}} and {{Predicts Adjustments}} in {{Pupil}}-{{Linked Arousal}}},
  author = {Ebitz, R. Becket and Platt, Michael L.},
  year = {2015},
  month = feb,
  volume = {85},
  pages = {628--640},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2014.12.053},
  abstract = {Summary Whether driving a car, shopping for food, or paying attention in a classroom of boisterous teenagers, it's often hard to maintain focus on goals in the~face of distraction. Brain imaging studies in humans implicate the dorsal anterior cingulate cortex (dACC) in regulating the conflict between goals and distractors. Here we show that single dACC neurons signal conflict between task goals and distractors in the rhesus macaque, particularly for biologically relevant social stimuli. For some neurons, task conflict signals predicted subsequent changes in pupil size\textemdash a peripheral index of arousal linked to noradrenergic tone\textemdash associated with reduced distractor interference. dACC neurons also responded to errors, and these signals predicted adjustments in pupil size. These findings provide the first neurophysiological endorsement of the hypothesis that dACC regulates conflict, in part, via modulation of pupil-linked processes such as arousal.},
  journal = {Neuron},
  number = {3}
}

@article{Ebitz_Neuronal_2015b,
  title = {Neuronal {{Activity}} in {{Primate Dorsal Anterior Cingulate Cortex Signals Task Conflict}} and {{Predicts Adjustments}} in {{Pupil}}-{{Linked Arousal}}},
  author = {Ebitz, R. Becket and Platt, Michael L.},
  year = {2015},
  month = feb,
  volume = {85},
  pages = {628--640},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2014.12.053},
  abstract = {Summary Whether driving a car, shopping for food, or paying attention in a classroom of boisterous teenagers, it's often hard to maintain focus on goals in the~face of distraction. Brain imaging studies in humans implicate the dorsal anterior cingulate cortex (dACC) in regulating the conflict between goals and distractors. Here we show that single dACC neurons signal conflict between task goals and distractors in the rhesus macaque, particularly for biologically relevant social stimuli. For some neurons, task conflict signals predicted subsequent changes in pupil size\textemdash a peripheral index of arousal linked to noradrenergic tone\textemdash associated with reduced distractor interference. dACC neurons also responded to errors, and these signals predicted adjustments in pupil size. These findings provide the first neurophysiological endorsement of the hypothesis that dACC regulates conflict, in part, via modulation of pupil-linked processes such as arousal.},
  journal = {Neuron},
  number = {3}
}

@article{Economides_Arbitration_2015,
  title = {Arbitration between Controlled and Impulsive Choices},
  author = {Economides, M. and {Guitart-Masip}, M. and {Kurth-Nelson}, Z. and Dolan, R. J.},
  year = {2015},
  month = apr,
  volume = {109},
  pages = {206--216},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2014.12.071},
  abstract = {The impulse to act for immediate reward often conflicts with more deliberate evaluations that support long-term benefit. The neural architecture that negotiates this conflict remains unclear. One account proposes a single neural circuit that evaluates both immediate and delayed outcomes, while another outlines separate impulsive and patient systems that compete for behavioral control. Here we designed a task in which a complex payout structure divorces the immediate value of acting from the overall long-term value, within the same outcome modality. Using model-based fMRI in humans, we demonstrate separate neural representations of immediate and long-term values, with the former tracked in the anterior caudate (AC) and the latter in the ventromedial prefrontal cortex (vmPFC). Crucially, when subjects' choices were compatible with long-run consequences, value signals in AC were down-weighted and those in vmPFC were enhanced, while the opposite occurred when choice was impulsive. Thus, our data implicate a trade-off in value representation between AC and vmPFC as underlying controlled versus impulsive choice.},
  journal = {NeuroImage},
  keywords = {Decision-making,fMRI,Self-control,Striatum,Value,Ventromedial prefrontal cortex}
}

@article{Economides_ModelBased_2015,
  title = {Model-{{Based Reasoning}} in {{Humans Becomes Automatic}} with {{Training}}},
  author = {Economides, Marcos and {Kurth-Nelson}, Zeb and L{\"u}bbert, Annika and {Guitart-Masip}, Marc and Dolan, Raymond J.},
  year = {2015},
  month = sep,
  volume = {11},
  pages = {e1004463},
  doi = {10.1371/journal.pcbi.1004463},
  abstract = {Author Summary Automaticity develops with task familiarity. One possible explanation is that automaticity arises when performance of the task becomes habitual, or model-free. Here we asked whether goal-directed, or model-based, reasoning could also become automatic, or resistant to distraction. We used a well-characterized task that differentiates model-based from model-free action. We replicate previous findings that distraction strongly impairs model-based reasoning in task-naive subjects. However, in subjects with prior exposure to the task, distraction does not impair model-based reasoning. This suggests that humans can deploy sophisticated and flexible reasoning more extensively than previously thought.},
  journal = {PLoS Comput Biol},
  number = {9}
}

@article{Edwards_AlphaBeta_1961,
  title = {The {{Alpha}}-{{Beta Heuristic}}},
  author = {Edwards, D. J. and Hart, T. P.},
  year = {1961},
  month = dec,
  abstract = {The Alpha-Beta heuristic is a method for pruning unneeded branches from the move tree of a game. The algorithm makes use of information gained about part of the tree to reject those branches which will not affect the principle variation.},
  language = {en\_US}
}

@article{Egner_Cognitive_2005,
  title = {Cognitive Control Mechanisms Resolve Conflict through Cortical Amplification of Task-Relevant Information},
  author = {Egner, Tobias and Hirsch, Joy},
  year = {2005},
  month = dec,
  volume = {8},
  pages = {1784--1790},
  issn = {1097-6256},
  doi = {10.1038/nn1594},
  abstract = {A prominent model of how the brain regulates attention proposes that the anterior cingulate cortex monitors the occurrence of conflict between incompatible response tendencies and signals this information to a cognitive control system in dorsolateral prefrontal cortex. Cognitive control is thought to resolve conflict through the attentional biasing of perceptual processing, emphasizing task-relevant stimulus information. It is not known, however, whether conflict resolution is mediated by amplifying neural representations of task-relevant information, inhibiting representations of task-irrelevant information, or both. Here we manipulated trial-by-trial levels of conflict and control during a Stroop task using face stimuli, while recording hemodynamic responses from human visual cortex specialized for face processing. We show that, in response to high conflict, cognitive control mechanisms enhance performance by transiently amplifying cortical responses to task-relevant information rather than by inhibiting responses to task-irrelevant information. These results implicate attentional target-feature amplification as the primary mechanism for conflict resolution through cognitive control.},
  copyright = {\textcopyright{} 2005 Nature Publishing Group},
  journal = {Nature Neuroscience},
  language = {en},
  number = {12}
}

@article{Egner_Cognitive_2005a,
  title = {Cognitive Control Mechanisms Resolve Conflict through Cortical Amplification of Task-Relevant Information},
  author = {Egner, Tobias and Hirsch, Joy},
  year = {2005},
  month = dec,
  volume = {8},
  pages = {1784--1790},
  issn = {1097-6256},
  doi = {10.1038/nn1594},
  abstract = {A prominent model of how the brain regulates attention proposes that the anterior cingulate cortex monitors the occurrence of conflict between incompatible response tendencies and signals this information to a cognitive control system in dorsolateral prefrontal cortex. Cognitive control is thought to resolve conflict through the attentional biasing of perceptual processing, emphasizing task-relevant stimulus information. It is not known, however, whether conflict resolution is mediated by amplifying neural representations of task-relevant information, inhibiting representations of task-irrelevant information, or both. Here we manipulated trial-by-trial levels of conflict and control during a Stroop task using face stimuli, while recording hemodynamic responses from human visual cortex specialized for face processing. We show that, in response to high conflict, cognitive control mechanisms enhance performance by transiently amplifying cortical responses to task-relevant information rather than by inhibiting responses to task-irrelevant information. These results implicate attentional target-feature amplification as the primary mechanism for conflict resolution through cognitive control.},
  copyright = {\textcopyright{} 2005 Nature Publishing Group},
  journal = {Nature Neuroscience},
  language = {en},
  number = {12}
}

@article{Endres_Feature_2010,
  title = {Feature Extraction from Spike Trains with {{Bayesian}} Binning: `{{Latency}} Is Where the Signal Starts'},
  shorttitle = {Feature Extraction from Spike Trains with {{Bayesian}} Binning},
  author = {Endres, Dominik and Oram, Mike},
  year = {2010},
  month = aug,
  volume = {29},
  pages = {149--169},
  issn = {0929-5313, 1573-6873},
  doi = {10.1007/s10827-009-0157-3},
  abstract = {The peristimulus time histogram (PSTH) and its more continuous cousin, the spike density function (SDF) are staples in the analytic toolkit of neurophysiologists. The former is usually obtained by binning spike trains, whereas the standard method for the latter is smoothing with a Gaussian kernel. Selection of a bin width or a kernel size is often done in an relatively arbitrary fashion, even though there have been recent attempts to remedy this situation (DiMatteo et al., Biometrika 88(4):1055\textendash 1071, 2001; Shimazaki and Shinomoto 2007a, Neural Comput 19(6):1503\textendash 1527, 2007b, c; Cunningham et al. 2008). We develop an exact Bayesian, generative model approach to estimating PSTHs. Advantages of our scheme include automatic complexity control and error bars on its predictions. We show how to perform feature extraction on spike trains in a principled way, exemplified through latency and firing rate posterior distribution evaluations on repeated and single trial data. We also demonstrate using both simulated and real neuronal data that our approach provides a more accurate estimates of the PSTH and the latency than current competing methods. We employ the posterior distributions for an information theoretic analysis of the neural code comprised of latency and firing rate of neurons in high-level visual area STSa. A software implementation of our method is available at the machine learning open source software repository (www.mloss.org, project `binsdfc').},
  journal = {Journal of Computational Neuroscience},
  keywords = {Bayesian methods,Human Genetics,Information theory,Neurology,Neurosciences,PSTH,Response latency,SDF,Spike train analysis,Theory of Computation},
  language = {en},
  number = {1-2}
}

@article{Ennis_multidimensional_1988,
  title = {A Multidimensional Stochastic Theory of Similarity},
  author = {Ennis, Daniel M. and Palen, Joseph J. and Mullen, Kenneth},
  year = {1988},
  month = dec,
  volume = {32},
  pages = {449--465},
  issn = {0022-2496},
  doi = {10.1016/0022-2496(88)90023-5},
  abstract = {A multidimensional theory of similarity in which the mental representations of stimulus objects are assumed to be drawn from multivariate normal distributions is described. A distance-based similarity function is defined and the expected value of similarity is derived. This theory is the basis for a possible explanation of paradoxical results with highly similar stimuli regarding the form of the similarity function and the distance metric. A stochastic approach to multidimensional scaling based on same-different judgments is demonstrated using artificial and real data sets. The theory of similarity presented is used as a basis for a Thurstonian extension of Shepard's model of identification performance.},
  journal = {Journal of Mathematical Psychology},
  number = {4}
}

@article{Estes_Risks_2005,
  title = {Risks of Drawing Inferences about Cognitive Processes from Model Fits to Individual versus Average Performance},
  author = {Estes, W. K. and Maddox, W. T.},
  year = {2005},
  month = jun,
  volume = {12},
  pages = {403--408},
  issn = {1069-9384},
  doi = {10.3758/BF03193784},
  abstract = {With the goal of drawing inferences about underlying processes from fits of theoretical models to cognitive data, we examined the tradeciff of risks of depending on model fits to individual performance versus risks of depending on fits to averaged data with respect to estimation of values of a model's parameters. Comparisons based on several models applied to experiments on recognition and categorization and to artificial, computer-generated data showed that results of using the two types of model fitting are strongly determined by two factors: model complexity and number of subjects. Reasonably accurate information about true parameter values was found only for model fits to individual performance and then only for some of the parameters of a complex model. Suggested guidelines are given for circumventing a variety of obstacles to successful recovery of useful estimates of a model's parameters from applications to cognitive data.},
  annotation = {WOS:000231606500002},
  journal = {Psychonomic Bulletin \& Review},
  keywords = {dangers,decision,familiarity,memory,recognition,strength},
  language = {English},
  number = {3}
}

@article{Estle_Differential_2006,
  title = {Differential Effects of Amount on Temporal and Probability Discounting of Gains and Losses},
  author = {Estle, Sara J. and Green, Leonard and Myerson, Joel and Holt, Daniel D.},
  year = {2006},
  month = jun,
  volume = {34},
  pages = {914--928},
  issn = {1532-5946},
  doi = {10.3758/BF03193437},
  abstract = {In four experiments, we compared the effects of delay, probability, and monetary amount on the subjective value of gains and losses. For delayed gains, smaller amounts were discounted more steeply than larger amounts, whereas the opposite pattern was observed with probabilistic gains. For both delayed and probabilistic losses, however, amount had much smaller and less reliable effects on discounting. Taken together, the pattern of differential magnitude effects leads to delayed gains' being discounted significantly more steeply than delayed losses, but only at smaller amounts, whereas probabilistic gains are discounted significantly more steeply than probabilistic losses, but only at larger amounts. Even though the same hyperbola-like function described both individual and group discounting of delayed and probabilistic gains and losses, the present findings suggest that different processes are involved in discounting positive and negative outcomes. Raw data may be downloaded from www.psychonomic.org/archive.},
  journal = {Memory \& Cognition},
  keywords = {Discount Function,Magnitude Effect,Probabilistic Loss,Probability Discount,Prospect Theory},
  language = {en},
  number = {4}
}

@article{Everitt_Neural_2005,
  title = {Neural Systems of Reinforcement for Drug Addiction: From Actions to Habits to Compulsion},
  shorttitle = {Neural Systems of Reinforcement for Drug Addiction},
  author = {Everitt, Barry J. and Robbins, Trevor W.},
  year = {2005},
  month = nov,
  volume = {8},
  pages = {1481--1489},
  issn = {1546-1726},
  doi = {10.1038/nn1579},
  abstract = {Drug addiction is increasingly viewed as the endpoint of a series of transitions from initial drug use\textemdash when a drug is voluntarily taken because it has reinforcing, often hedonic, effects\textemdash through loss of control over this behavior, such that it becomes habitual and ultimately compulsive. Here we discuss evidence that these transitions depend on interactions between pavlovian and instrumental learning processes. We hypothesize that the change from voluntary drug use to more habitual and compulsive drug use represents a transition at the neural level from prefrontal cortical to striatal control over drug seeking and drug taking behavior as well as a progression from ventral to more dorsal domains of the striatum, involving its dopaminergic innervation. These neural transitions may themselves depend on the neuroplasticity in both cortical and striatal structures that is induced by chronic self-administration of drugs.*Note: In the version of this article initially published, there is an error in Figure 1. Please see the PDF for details.},
  copyright = {2005 Nature Publishing Group},
  journal = {Nature Neuroscience},
  language = {en},
  number = {11}
}

@article{Fan_activation_2005,
  title = {The Activation of Attentional Networks},
  author = {Fan, Jin and McCandliss, Bruce D. and Fossella, John and Flombaum, Jonathan I. and Posner, Michael I.},
  year = {2005},
  month = jun,
  volume = {26},
  pages = {471--479},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2005.02.004},
  abstract = {Alerting, orienting, and executive control are widely thought to be relatively independent aspects of attention that are linked to separable brain regions. However, neuroimaging studies have yet to examine evidence for the anatomical separability of these three aspects of attention in the same subjects performing the same task. The attention network test (ANT) examines the effects of cues and targets within a single reaction time task to provide a means of exploring the efficiency of the alerting, orienting, and executive control networks involved in attention. It also provides an opportunity to examine the brain activity of these three networks as they operate in a single integrated task. We used event-related functional magnetic resonance imaging (fMRI) to explore the brain areas involved in the three attention systems targeted by the ANT. The alerting contrast showed strong thalamic involvement and activation of anterior and posterior cortical sites. As expected, the orienting contrast activated parietal sites and frontal eye fields. The executive control network contrast showed activation of the anterior cingulate along with several other brain areas. With some exceptions, activation patterns of these three networks within this single task are consistent with previous fMRI studies that have been studied in separate tasks. Overall, the fMRI results suggest that the functional contrasts within this single task differentially activate three separable anatomical networks related to the components of attention.},
  journal = {NeuroImage},
  keywords = {Alerting,Attention,Attentional networks,executive control,fMRI,Orienting},
  number = {2}
}

@article{Fan_information_2014,
  title = {An Information Theory Account of Cognitive Control},
  author = {Fan, Jin},
  year = {2014},
  volume = {8},
  pages = {680},
  issn = {1662-5161},
  doi = {10.3389/fnhum.2014.00680},
  abstract = {Our ability to efficiently process information and generate appropriate responses depends on the processes collectively called cognitive control. Despite a considerable focus in the literature on the cognitive control of information processing, neural mechanisms underlying control are still unclear, and have not been characterized by considering the quantity of information to be processed. A novel and comprehensive account of cognitive control is proposed using concepts from information theory, which is concerned with communication system analysis and the quantification of information. This account treats the brain as an information-processing entity where cognitive control and its underlying brain networks play a pivotal role in dealing with conditions of uncertainty. This hypothesis and theory article justifies the validity and properties of such an account and relates experimental findings to the frontoparietal network under the framework of information theory.},
  journal = {Frontiers in Human Neuroscience},
  language = {eng},
  pmcid = {PMC4151034},
  pmid = {25228875}
}

@article{Fan_information_2014a,
  title = {An Information Theory Account of Cognitive Control},
  author = {Fan, Jin},
  year = {2014},
  month = sep,
  volume = {8},
  issn = {1662-5161},
  doi = {10.3389/fnhum.2014.00680},
  abstract = {Our ability to efficiently process information and generate appropriate responses depends on the processes collectively called cognitive control. Despite a considerable focus in the literature on the cognitive control of information processing, neural mechanisms underlying control are still unclear, and have not been characterized by considering the quantity of information to be processed. A novel and comprehensive account of cognitive control is proposed using concepts from information theory, which is concerned with communication system analysis and the quantification of information. This account treats the brain as an information-processing entity where cognitive control and its underlying brain networks play a pivotal role in dealing with conditions of uncertainty. This hypothesis and theory article justifies the validity and properties of such an account and relates experimental findings to the frontoparietal network under the framework of information theory.},
  journal = {Frontiers in Human Neuroscience},
  pmcid = {PMC4151034},
  pmid = {25228875}
}

@article{Fantino_How_2007,
  title = {How Reinforcer Type Affects Choice in Economic Games},
  author = {Fantino, Edmund and Gaitan, Santino and Kennelly, Art and {Stolarz-Fantino}, Stephanie},
  year = {2007},
  month = jun,
  volume = {75},
  pages = {107--114},
  issn = {0376-6357},
  doi = {10.1016/j.beproc.2007.02.001},
  abstract = {Behavioral economists stress that experiments on judgment and decision-making using economic games should be played with real money if the results are\ldots},
  journal = {Behavioural Processes},
  language = {en},
  number = {2}
}

@article{Farkhooi_Sequential_2009,
  title = {Sequential Sparsing by Successive Adapting Neural Populations},
  author = {Farkhooi, Farzad and Muller, Eilif and Nawrot, Martin P.},
  year = {2009},
  month = jul,
  volume = {10},
  pages = {O10},
  issn = {1471-2202},
  doi = {10.1186/1471-2202-10-S1-O10},
  copyright = {2009 Farkhooi et al; licensee BioMed Central Ltd.},
  journal = {BMC Neuroscience},
  language = {en},
  number = {Suppl 1}
}

@article{Fernandez_Associative_2009,
  title = {Associative {{Conditioning Tunes Transient Dynamics}} of {{Early Olfactory Processing}}},
  author = {Fernandez, Patricia C. and Locatelli, Fernando F. and {Person-Rennell}, Nicole and Deleo, Gregory and Smith, Brian H.},
  year = {2009},
  month = aug,
  volume = {29},
  pages = {10191--10202},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.1874-09.2009},
  abstract = {Odors evoke complex spatiotemporal responses in the insect antennal lobe (AL) and mammalian olfactory bulb. However, the behavioral relevance of spatiotemporal coding remains unclear. In the present work we combined behavioral analyses with calcium imaging of odor induced activity in the honeybee AL to evaluate the relevance of this temporal dimension in the olfactory code. We used a new way for evaluation of odor similarity of binary mixtures in behavioral studies, which involved testing whether a match of odor-sampling time is necessary between training and testing conditions for odor recognition during associative learning. Using graded changes in the similarity of the mixture ratios, we found high correlations between the behavioral generalization across those mixtures and a gradient of activation in AL output. Furthermore, short odor stimuli of 500 ms or less affected how well odors were matched with a memory template, and this time corresponded to a shift from a sampling-time-dependent to a sampling-time-independent memory. Accordingly, 375 ms corresponded to the time required for spatiotemporal AL activity patterns to reach maximal separation according to imaging studies. Finally, we compared spatiotemporal representations of binary mixtures in trained and untrained animals. AL activity was modified by conditioning to improve separation of odor representations. These data suggest that one role of reinforcement is to ``tune'' the AL such that relevant odors become more discriminable.},
  journal = {The Journal of Neuroscience},
  language = {en},
  number = {33},
  pmid = {19692594}
}

@article{Fischer_Sleep_2002,
  title = {Sleep Forms Memory for Finger Skills},
  author = {Fischer, Stefan and Hallschmid, Manfred and Elsner, Anna Lisa and Born, Jan},
  year = {2002},
  month = sep,
  volume = {99},
  pages = {11987--11991},
  publisher = {{National Academy of Sciences}},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.182178199},
  abstract = {Practicing a motor skill triggers a process of memory consolidation that continues for hours after practice has ended, and becomes manifest in an improved skill at later testing. We used a sequential motor task (finger-to-thumb opposition task) to show that, in humans, the formation of motor skill memories essentially benefits from sleep. Independent of whether placed during daytime or nighttime, sleep after practice enhanced speed of sequence performance on average by 33.5\% and reduced error rate by 30.1\% as compared with corresponding intervals of wakefulness. The effect of sleep after learning proved to be stable when retesting was postponed for another night, to exclude effects of sleep loss and to assure that all subjects had sufficient sleep before retrieval testing. Also, the consolidating effect of sleep was specific for the motor sequence learned. It did not generalize to a similar sequence containing identical movement segments in a different order. Retention periods of wakefulness improved performance only moderately and only if placed during daytime. The observations demonstrate a critical role of sleep for storing and optimizing motor skills.},
  chapter = {Biological Sciences},
  copyright = {Copyright \textcopyright{} 2002, The National Academy of Sciences},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {18},
  pmid = {12193650}
}

@article{Fiser_Statistically_2010,
  title = {Statistically Optimal Perception and Learning: From Behavior to Neural Representations.},
  author = {Fiser, J{\'o}zsef and Berkes, Pietro and Orb{\'a}n, Gergo and Lengyel, M{\'a}t{\'e}},
  year = {2010},
  month = mar,
  volume = {14},
  pages = {119--130},
  doi = {10.1016/j.tics.2010.01.003},
  abstract = {Human perception has recently been characterized as statistical inference based on noisy and ambiguous sensory inputs. Moreover, suitable neural representations of uncertainty have been identified that could underlie such probabilistic computations. In this review, we argue that learning an internal model of the sensory environment is another key aspect of the same statistical inference procedure and thus perception and learning need to be treated jointly. We review evidence for statistically optimal learning in humans and animals, and re-evaluate possible neural representations of uncertainty based on their potential to support statistically optimal learning. We propose that spontaneous activity can have a functional role in such representations leading to a new, sampling-based, framework of how the cortex represents information and uncertainty.},
  journal = {Trends Cogn Sci},
  keywords = {Animals,Cerebral Cortex,Humans,Learning,Models,Neurological,Perception,Statistical},
  language = {eng},
  number = {3},
  pmid = {20153683}
}

@article{FitzGerald_Active_2015,
  title = {Active Inference, Evidence Accumulation and the Urn Task},
  author = {FitzGerald, Thomas HB and Schwartenbeck, Philipp and Moutoussis, Michael and Dolan, Raymond J and Friston, Karl},
  year = {2015},
  month = feb,
  volume = {27},
  pages = {306--328},
  issn = {0899-7667},
  doi = {10.1162/NECO_a_00699},
  abstract = {Deciding how much evidence to accumulate before making a decision is a problem we and other animals often face, but one which is not completely understood. This issue is particularly important because a tendency to sample less information (often known as reflection impulsivity) is a feature in several psychopathologies, such as psychosis. A formal understanding information sampling may therefore clarify the computational anatomy of psychopathology. In this theoretical paper, we consider evidence accumulation in terms of active (Bayesian) inference using a generic model of Markov decision processes. Here, agents are equipped with beliefs about their own behaviour \textendash{} in this case, that they will make informed decisions. Normative decision-making is then modelled using variational Bayes to minimise surprise about choice outcomes. Under this scheme, different facets of belief updating map naturally onto the functional anatomy of the brain (at least at a heuristic level). Of particular interest is the key role played by the expected precision of beliefs about control, which we have previously suggested may be encoded by dopaminergic neurons in the midbrain. We show that manipulating expected precision strongly affects how much information an agent characteristically samples, and thus provides a possible link between impulsivity and dopaminergic dysfunction. Our study therefore represents a step towards understanding evidence accumulation in terms of neurobiologically plausible Bayesian inference, and may cast light on why this process is disordered in psychopathology.},
  journal = {Neural computation},
  number = {2},
  pmcid = {PMC4426890},
  pmid = {25514108}
}

@article{Flagel_selective_2011,
  title = {A Selective Role for Dopamine in Stimulus\textendash Reward Learning},
  author = {Flagel, Shelly B. and Clark, Jeremy J. and Robinson, Terry E. and Mayo, Leah and Czuj, Alayna and Willuhn, Ingo and Akers, Christina A. and Clinton, Sarah M. and Phillips, Paul E. M. and Akil, Huda},
  year = {2011},
  month = jan,
  volume = {469},
  pages = {53--57},
  issn = {1476-4687},
  doi = {10.1038/nature09588},
  abstract = {Individuals make choices and prioritize goals using complex processes that assign value to rewards and associated stimuli. During Pavlovian learning, previously neutral stimuli that predict rewards can acquire motivational properties, becoming attractive and desirable incentive stimuli. However, whether a cue acts solely as a predictor of reward, or also serves as an incentive stimulus, differs between individuals. Thus, individuals vary in the degree to which cues bias choice and potentially promote maladaptive behaviour. Here we use rats that differ in the incentive motivational properties they attribute to food cues to probe the role of the neurotransmitter dopamine in stimulus\textendash reward learning. We show that intact dopamine transmission is not required for all forms of learning in which reward cues become effective predictors. Rather, dopamine acts selectively in a form of stimulus\textendash reward learning in which incentive salience is assigned to reward cues. In individuals with a propensity for this form of learning, reward cues come to powerfully motivate and control behaviour. This work provides insight into the neurobiology of a form of stimulus\textendash reward learning that confers increased susceptibility to disorders of impulse control.},
  copyright = {2010 Nature Publishing Group},
  journal = {Nature},
  language = {en},
  number = {7328}
}

@article{Flash_coordination_1985,
  title = {The Coordination of Arm Movements: An Experimentally Confirmed Mathematical Model},
  shorttitle = {The Coordination of Arm Movements},
  author = {Flash, T. and Hogan, N.},
  year = {1985},
  month = jul,
  volume = {5},
  pages = {1688--1703},
  publisher = {{Society for Neuroscience}},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.05-07-01688.1985},
  abstract = {This paper presents studies of the coordination of voluntary human arm movements. A mathematical model is formulated which is shown to predict both the qualitative features and the quantitative details observed experimentally in planar, multijoint arm movements. Coordination is modeled mathematically by defining an objective function, a measure of performance for any possible movement. The unique trajectory which yields the best performance is determined using dynamic optimization theory. In the work presented here, the objective function is the square of the magnitude of jerk (rate of change of acceleration) of the hand integrated over the entire movement. This is equivalent to assuming that a major goal of motor coordination is the production of the smoothest possible movement of the hand. Experimental observations of human subjects performing voluntary unconstrained movements in a horizontal plane are presented. They confirm the following predictions of the mathematical model: unconstrained point-to-point motions are approximately straight with bell-shaped tangential velocity profiles; curved motions (through an intermediate point or around an obstacle) have portions of low curvature joined by portions of high curvature; at points of high curvature, the tangential velocity is reduced; the durations of the low-curvature portions are approximately equal. The theoretical analysis is based solely on the kinematics of movement independent of the dynamics of the musculoskeletal system and is successful only when formulated in terms of the motion of the hand in extracorporal space. The implications with respect to movement organization are discussed.},
  chapter = {Articles},
  copyright = {\textcopyright{} 1985 by Society for Neuroscience},
  journal = {Journal of Neuroscience},
  keywords = {model,unread},
  language = {en},
  number = {7},
  pmid = {4020415}
}

@article{Floden_Task_2010,
  title = {Task {{Context}} and {{Frontal Lobe Activation}} in the {{Stroop Task}}},
  author = {Floden, Darlene and Vallesi, Antonino and Stuss, Donald T.},
  year = {2010},
  month = mar,
  volume = {23},
  pages = {867--879},
  issn = {0898-929X},
  doi = {10.1162/jocn.2010.21492},
  abstract = {The ability to step outside a routine\textemdash to select a new response over a habitual one\textemdash is a cardinal function of the frontal lobes. A large body of neuroimaging work now exists pointing to increased activation within the anterior cingulate when stimuli evoke competing responses (incongruent trials) relative to when responses converge (congruent trials). However, lesion evidence that the ACC is necessary in this situation is inconsistent. We hypothesized that this may be a consequence of different task procedures (context) used in lesion and neuroimaging studies. The present study attempted to reconcile the lesion and the fMRI findings by having subjects perform clinical and experimental versions of the Stroop task during BOLD fMRI acquisition. We examined the relationship of brain activation patterns, specifically within the anterior cingulate and left dorsolateral frontal regions, to congruent and incongruent trial types in different task presentations or contexts. The results confirmed our hypothesis that ACC activity is relatively specific to unblocked\textendash uncued incongruent Stroop conditions that have not been used in large neuropsychological studies. Moreover, the size of the behavioral Stroop interference effect was significantly correlated with activity in ACC and left dorsolateral regions, although in different directions. The current results are discussed in terms of previous proposals for the functional roles of these regions in activating, monitoring, and task setting, and the relation of these findings to the disparate reports in recent case series is considered.},
  journal = {Journal of Cognitive Neuroscience},
  number = {4}
}

@article{Flossmann_Somatostatin_2019,
  title = {Somatostatin {{Interneurons Promote Neuronal Synchrony}} in the {{Neonatal Hippocampus}}},
  author = {Flossmann, Tom and Kaas, Thomas and Rahmati, Vahid and Kiebel, Stefan J. and Witte, Otto W. and Holthoff, Knut and Kirmse, Knut},
  year = {2019},
  month = mar,
  volume = {26},
  pages = {3173-3182.e5},
  issn = {2211-1247},
  doi = {10.1016/j.celrep.2019.02.061},
  journal = {Cell Reports},
  keywords = {development,GABA,hippocampus,interneurons,optogenetics},
  language = {English},
  number = {12},
  pmid = {30893591}
}

@article{Forano_Timescales_2020,
  title = {Timescales of Motor Memory Formation in Dual-Adaptation},
  author = {Forano, Marion and Franklin, David W.},
  year = {2020},
  month = oct,
  volume = {16},
  pages = {e1008373},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1008373},
  abstract = {The timescales of adaptation to novel dynamics are well explained by a dual-rate model with slow and fast states. This model can predict interference, savings and spontaneous recovery, but cannot account for adaptation to multiple tasks, as each new task drives unlearning of the previously learned task. Nevertheless, in the presence of appropriate contextual cues, humans are able to adapt simultaneously to opposing dynamics. Consequently this model was expanded, suggesting that dual-adaptation occurs through a single fast process and multiple slow processes. However, such a model does not predict spontaneous recovery within dual-adaptation. Here we assess the existence of multiple fast processes by examining the presence of spontaneous recovery in two experimental variations of an adaptation-de-adaptation-error-clamp paradigm within dual-task adaptation in humans. In both experiments, evidence for spontaneous recovery towards the initially learned dynamics (A) was found in the error-clamp phase, invalidating the one-fast-two-slow dual-rate model. However, as adaptation is not only constrained to two timescales, we fit twelve multi-rate models to the experimental data. BIC model comparison again supported the existence of two fast processes, but extended the timescales to include a third rate: the ultraslow process. Even within our single day experiment, we found little evidence for decay of the learned memory over several hundred error-clamp trials. Overall, we show that dual-adaptation can be best explained by a two-fast-triple-rate model over the timescales of adaptation studied here. Longer term learning may require even slower timescales, explaining why we never forget how to ride a bicycle.},
  journal = {PLOS Computational Biology},
  keywords = {Cerebellum,Experimental design,Kinematics,Learning,Memory,Memory recall,Robotics,Simulation and modeling},
  language = {en},
  number = {10}
}

@article{Foudil_ContextDependent_2020,
  title = {Context-{{Dependent Coding}} of {{Temporal Distance Between Cinematic Events}} in the {{Human Precuneus}}},
  author = {Foudil, Samy-Adrien and Kwok, Sze Chai and Macaluso, Emiliano},
  year = {2020},
  month = mar,
  volume = {40},
  pages = {2129--2138},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.2296-19.2020},
  abstract = {How temporal and contextual information interactively impact on behavior and brain activity during the retrieval of temporal order about naturalistic episodes remains incompletely understood. Here, we used fMRI to examine the effects of contextual signals derived from the content of the movie on the neural correlates underlying memory retrieval of temporal-order in human subjects of both sexes. By contrasting SAME versus DIFF storyline conditions during the retrieval of the temporal order of cinematic events, we found that the activation in the precuneus, as well as behavior, are significantly modulated according to storyline condition, supporting our prediction of contextual information contributing to temporal retrieval. We suggest that the precuneus engages in memory retrieval via reconstructive mechanisms, entailing search within a movie-specific, situational knowledge-structure. Furthermore, information-based analyses of multivoxel activity revealed that the precuneus also contains a context-independent linear representation of temporal distances, consistent with a chronological organization of memory traces. We thus put forward that the retrieval of the temporal-order of naturalistic events encoded in rich and dynamic contexts relies on the joint contribution of chronological and reconstructive mechanisms, both of which rely on the medioposterior parietal cortex in humans. SIGNIFICANCE STATEMENT Successful retrieval of episodic memory is dependent on both temporal and contextual signals. However, when contextual signals derived from multiple storylines or narratives are complex and intertwined, the behavioral and neural correlates underpinning the interplay between time and context is not completely understood. Here we characterized the activation level and multivoxel pattern of BOLD signals underlying the modulation of such contextual information during temporal order judgment in the precuneus. Our findings provide us with an elucidation of subprocesses implicating the medial parietal cortex in realizing temporal organization of episodic details.},
  copyright = {Copyright \textcopyright{} 2020 the authors},
  journal = {Journal of Neuroscience},
  keywords = {context,fMRI,memory,naturalistic,precuneus,time},
  language = {en},
  number = {10},
  pmid = {31996453}
}

@article{Freedman_histogram_1981,
  title = {On the Histogram as a Density Estimator:{{L2}} Theory},
  shorttitle = {On the Histogram as a Density Estimator},
  author = {Freedman, David and Diaconis, Persi},
  year = {1981},
  month = dec,
  volume = {57},
  pages = {453--476},
  issn = {0044-3719, 1432-2064},
  doi = {10.1007/BF01025868},
  abstract = {No Abstract available for this article.},
  journal = {Zeitschrift f\"ur Wahrscheinlichkeitstheorie und Verwandte Gebiete},
  language = {en},
  number = {4}
}

@article{Friedrich_Dynamic_2001,
  title = {Dynamic {{Optimization}} of {{Odor Representations}} by {{Slow Temporal Patterning}} of {{Mitral Cell Activity}}},
  author = {Friedrich, Rainer W. and Laurent, Gilles},
  year = {2001},
  month = feb,
  volume = {291},
  pages = {889--894},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.291.5505.889},
  abstract = {Mitral cells (MCs) in the olfactory bulb (OB) respond to odors with slow temporal firing patterns. The representation of each odor by activity patterns across the MC population thus changes continuously throughout a stimulus, in an odor-specific manner. In the zebrafish OB, we found that this distributed temporal patterning progressively reduced the similarity between ensemble representations of related odors, thereby making each odor's representation more specific over time. The tuning of individual MCs was not sharpened during this process. Hence, the individual responses of MCs did not become more specific, but the odor-coding MC assemblies changed such that their overlap decreased. This optimization of ensemble representations did not occur among olfactory afferents but resulted from OB circuit dynamics. Time can therefore gradually optimize stimulus representations in a sensory network.},
  journal = {Science},
  language = {en},
  number = {5505},
  pmid = {11157170}
}

@article{Friedrich_Multiplexing_2004,
  title = {Multiplexing Using Synchrony in the Zebrafish Olfactory Bulb},
  author = {Friedrich, Rainer W. and Habermann, Christopher J. and Laurent, Gilles},
  year = {2004},
  month = aug,
  volume = {7},
  pages = {862--871},
  issn = {1097-6256},
  doi = {10.1038/nn1292},
  abstract = {In the olfactory bulb (OB) of zebrafish and other species, odors evoke fast oscillatory population activity and specific firing rate patterns across mitral cells (MCs). This activity evolves over a few hundred milliseconds from the onset of the odor stimulus. Action potentials of odor-specific MC subsets phase-lock to the oscillation, defining small and distributed ensembles within the MC population output. We found that oscillatory field potentials in the zebrafish OB propagate across the OB in waves. Phase-locked MC action potentials, however, were synchronized without a time lag. Firing rate patterns across MCs analyzed with low temporal resolution were informative about odor identity. When the sensitivity for phase-locked spiking was increased, activity patterns became progressively more informative about odor category. Hence, information about complementary stimulus features is conveyed simultaneously by the same population of neurons and can be retrieved selectively by biologically plausible mechanisms, indicating that seemingly alternative coding strategies operating on different time scales may coexist.},
  copyright = {\textcopyright{} 2004 Nature Publishing Group},
  journal = {Nature Neuroscience},
  language = {en},
  number = {8}
}

@article{Friston_Action_2010,
  title = {Action and Behavior: A Free-Energy Formulation},
  shorttitle = {Action and Behavior},
  author = {Friston, Karl J. and Daunizeau, Jean and Kilner, James and Kiebel, Stefan J.},
  year = {2010},
  month = feb,
  volume = {102},
  pages = {227--260},
  issn = {0340-1200, 1432-0770},
  doi = {10.1007/s00422-010-0364-z},
  abstract = {We have previously tried to explain perceptual inference and learning under a free-energy principle that pursues Helmholtz's agenda to understand the brain in terms of energy minimization. It is fairly easy to show that making inferences about the causes of sensory data can be cast as the minimization of a free-energy bound on the likelihood of sensory inputs, given an internal model of how they were caused. In this article, we consider what would happen if the data themselves were sampled to minimize this bound. It transpires that the ensuing active sampling or inference is mandated by ergodic arguments based on the very existence of adaptive agents. Furthermore, it accounts for many aspects of motor behavior; from retinal stabilization to goal-seeking. In particular, it suggests that motor control can be understood as fulfilling prior expectations about proprioceptive sensations. This formulation can explain why adaptive behavior emerges in biological agents and suggests a simple alternative to optimal control theory. We illustrate these points using simulations of oculomotor control and then apply to same principles to cued and goal-directed movements. In short, the free-energy formulation may provide an alternative perspective on the motor control that places it in an intimate relationship with perception.},
  journal = {Biological Cybernetics},
  keywords = {Bayesian,Bioinformatics,Computational,Computer Appl. in Life Sciences,Control,Hierarchical,Motor,Neurobiology,Neurosciences,Priors,Statistical Physics; Dynamical Systems and Complexity},
  language = {en},
  number = {3}
}

@article{Friston_Action_2011,
  title = {Action Understanding and Active Inference},
  author = {Friston, Karl and Mattout, J{\'e}r{\'e}mie and Kilner, James},
  year = {2011},
  month = feb,
  volume = {104},
  pages = {137--160},
  issn = {0340-1200, 1432-0770},
  doi = {10.1007/s00422-011-0424-z},
  abstract = {We have suggested that the mirror-neuron system might be usefully understood as implementing Bayes-optimal perception of actions emitted by oneself or others. To substantiate this claim, we present neuronal simulations that show the same representations can prescribe motor behavior and encode motor intentions during action\textendash observation. These simulations are based on the free-energy formulation of active inference, which is formally related to predictive coding. In this scheme, (generalised) states of the world are represented as trajectories. When these states include motor trajectories they implicitly entail intentions (future motor states). Optimizing the representation of these intentions enables predictive coding in a prospective sense. Crucially, the same generative models used to make predictions can be deployed to predict the actions of self or others by simply changing the bias or precision (i.e. attention) afforded to proprioceptive signals. We illustrate these points using simulations of handwriting to illustrate neuronally plausible generation and recognition of itinerant (wandering) motor trajectories. We then use the same simulations to produce synthetic electrophysiological responses to violations of intentional expectations. Our results affirm that a Bayes-optimal approach provides a principled framework, which accommodates current thinking about the mirror-neuron system. Furthermore, it endorses the general formulation of action as active inference.},
  journal = {Biological Cybernetics},
  keywords = {Actionobservation,Bioinformatics,Computer Appl. in Life Sciences,Free-energy,Generative models,Inference,Mirror-neuron system,Neurobiology,Neurosciences,Perception,Precision,Predictive coding,Statistical Physics; Dynamical Systems and Complexity},
  language = {en},
  number = {1-2}
}

@article{Friston_Action_2011a,
  title = {Action Understanding and Active Inference},
  author = {Friston, Karl and Mattout, J{\'e}r{\'e}mie and Kilner, James},
  year = {2011},
  month = feb,
  volume = {104},
  pages = {137--160},
  issn = {0340-1200},
  doi = {10.1007/s00422-011-0424-z},
  abstract = {We have suggested that the mirror-neuron system might be usefully understood as implementing Bayes-optimal perception of actions emitted by oneself or others. To substantiate this claim, we present neuronal simulations that show the same representations can prescribe motor behavior and encode motor intentions during action\textendash observation. These simulations are based on the free-energy formulation of active inference, which is formally related to predictive coding. In this scheme, (generalised) states of the world are represented as trajectories. When these states include motor trajectories they implicitly entail intentions (future motor states). Optimizing the representation of these intentions enables predictive coding in a prospective sense. Crucially, the same generative models used to make predictions can be deployed to predict the actions of self or others by simply changing the bias or precision (i.e. attention) afforded to proprioceptive signals. We illustrate these points using simulations of handwriting to illustrate neuronally plausible generation and recognition of itinerant (wandering) motor trajectories. We then use the same simulations to produce synthetic electrophysiological responses to violations of intentional expectations. Our results affirm that a Bayes-optimal approach provides a principled framework, which accommodates current thinking about the mirror-neuron system. Furthermore, it endorses the general formulation of action as active inference.},
  journal = {Biological cybernetics},
  number = {1-2},
  pmcid = {PMC3491875},
  pmid = {21327826}
}

@article{Friston_Active_2012,
  title = {Active Inference and Agency: Optimal Control without Cost Functions},
  shorttitle = {Active Inference and Agency},
  author = {Friston, Karl and Samothrakis, Spyridon and Montague, Read},
  year = {2012},
  month = aug,
  volume = {106},
  pages = {523--541},
  issn = {0340-1200, 1432-0770},
  doi = {10.1007/s00422-012-0512-8},
  abstract = {This paper describes a variational free-energy formulation of (partially observable) Markov decision problems in decision making under uncertainty. We show that optimal control can be cast as active inference. In active inference, both action and posterior beliefs about hidden states minimise a free energy bound on the negative log-likelihood of observed states, under a generative model. In this setting, reward or cost functions are absorbed into prior beliefs about state transitions and terminal states. Effectively, this converts optimal control into a pure inference problem, enabling the application of standard Bayesian filtering techniques. We then consider optimal trajectories that rest on posterior beliefs about hidden states in the future. Crucially, this entails modelling control as a hidden state that endows the generative model with a representation of agency. This leads to a distinction between models with and without inference on hidden control states; namely, agency-free and agency-based models, respectively.},
  journal = {Biological Cybernetics},
  keywords = {Action,Agency,Bayesian,Bioinformatics,Computer Appl. in Life Sciences,Free energy,Inference,Neurobiology,Neurosciences,Optimal control,Partially observable Markov decision processes,Statistical Physics; Dynamical Systems and Complexity},
  language = {en},
  number = {8-9}
}

@article{Friston_Active_2015,
  title = {Active Inference and Epistemic Value},
  author = {Friston, Karl and Rigoli, Francesco and Ognibene, Dimitri and Mathys, Christoph and Fitzgerald, Thomas and Pezzulo, Giovanni},
  year = {2015},
  month = feb,
  volume = {0},
  pages = {1--28},
  issn = {1758-8928},
  doi = {10.1080/17588928.2015.1020053},
  abstract = {We offer a formal treatment of choice behavior based on the premise that agents minimize the expected free energy of future outcomes. Crucially, the negative free energy or quality of a policy can be decomposed into extrinsic and epistemic (or intrinsic) value. Minimizing expected free energy is therefore equivalent to maximizing extrinsic value or expected utility (defined in terms of prior preferences or goals), while maximizing information gain or intrinsic value (or reducing uncertainty about the causes of valuable outcomes). The resulting scheme resolves the exploration-exploitation dilemma: Epistemic value is maximized until there is no further information gain, after which exploitation is assured through maximization of extrinsic value. This is formally consistent with the Infomax principle, generalizing formulations of active vision based upon salience (Bayesian surprise) and optimal decisions based on expected utility and risk-sensitive (Kullback-Leibler) control. Furthermore, as with previous active inference formulations of discrete (Markovian) problems, ad hoc softmax parameters become the expected (Bayes-optimal) precision of beliefs about, or confidence in, policies. This article focuses on the basic theory, illustrating the ideas with simulations. A key aspect of these simulations is the similarity between precision updates and dopaminergic discharges observed in conditioning paradigms.},
  journal = {Cognitive Neuroscience},
  number = {0},
  pmid = {25689102}
}

@article{Friston_Active_2015a,
  title = {Active Inference and Epistemic Value},
  author = {Friston, Karl and Rigoli, Francesco and Ognibene, Dimitri and Mathys, Christoph and Fitzgerald, Thomas and Pezzulo, Giovanni},
  year = {2015},
  volume = {6},
  pages = {187--214},
  issn = {1758-8936},
  doi = {10.1080/17588928.2015.1020053},
  abstract = {We offer a formal treatment of choice behavior based on the premise that agents minimize the expected free energy of future outcomes. Crucially, the negative free energy or quality of a policy can be decomposed into extrinsic and epistemic (or intrinsic) value. Minimizing expected free energy is therefore equivalent to maximizing extrinsic value or expected utility (defined in terms of prior preferences or goals), while maximizing information gain or intrinsic value (or reducing uncertainty about the causes of valuable outcomes). The resulting scheme resolves the exploration-exploitation dilemma: Epistemic value is maximized until there is no further information gain, after which exploitation is assured through maximization of extrinsic value. This is formally consistent with the Infomax principle, generalizing formulations of active vision based upon salience (Bayesian surprise) and optimal decisions based on expected utility and risk-sensitive (Kullback-Leibler) control. Furthermore, as with previous active inference formulations of discrete (Markovian) problems, ad hoc softmax parameters become the expected (Bayes-optimal) precision of beliefs about, or confidence in, policies. This article focuses on the basic theory, illustrating the ideas with simulations. A key aspect of these simulations is the similarity between precision updates and dopaminergic discharges observed in conditioning paradigms.},
  journal = {Cognitive Neuroscience},
  keywords = {active inference,Agency,Bayes Theorem,Bayesian inference,Bayesian surprise,bounded rationality,Choice Behavior,Concept Formation,Decision Making,epistemic value,Exploitation,Exploration,Free energy,Humans,information gain,Knowledge,Memory; Short-Term,Models; Psychological,utility theory},
  language = {eng},
  number = {4},
  pmid = {25689102}
}

@article{Friston_Active_2016,
  title = {Active Inference and Learning},
  author = {Friston, Karl and FitzGerald, Thomas and Rigoli, Francesco and Schwartenbeck, Philipp and O'Doherty, John and Pezzulo, Giovanni},
  year = {2016},
  month = sep,
  volume = {68},
  pages = {862--879},
  issn = {0149-7634},
  doi = {10.1016/j.neubiorev.2016.06.022},
  abstract = {This paper offers an active inference account of choice behaviour and learning. It focuses on the distinction between goal-directed and habitual behaviour and how they contextualise each other. We show that habits emerge naturally (and autodidactically) from sequential policy optimisation when agents are equipped with state-action policies. In active inference, behaviour has explorative (epistemic) and exploitative (pragmatic) aspects that are sensitive to ambiguity and risk respectively, where epistemic (ambiguity-resolving) behaviour enables pragmatic (reward-seeking) behaviour and the subsequent emergence of habits. Although goal-directed and habitual policies are usually associated with model-based and model-free schemes, we find the more important distinction is between belief-free and belief-based schemes. The underlying (variational) belief updating provides a comprehensive (if metaphorical) process theory for several phenomena, including the transfer of dopamine responses, reversal learning, habit formation and devaluation. Finally, we show that active inference reduces to a classical (Bellman) scheme, in the absence of ambiguity.},
  journal = {Neuroscience \& Biobehavioral Reviews},
  keywords = {active inference,Bayesian inference,Bayesian surprise,epistemic value,Exploitation,Exploration,Free energy,Goal-directed,Habit learning,information gain}
}

@article{Friston_Active_2016a,
  title = {Active {{Inference}} and {{Learning}} in the {{Cerebellum}}},
  author = {Friston, Karl and Herreros, Ivan},
  year = {2016},
  month = jul,
  volume = {28},
  pages = {1812--1839},
  issn = {0899-7667},
  doi = {10.1162/NECO_a_00863},
  abstract = {This letter offers a computational account of Pavlovian conditioning in the cerebellum based on active inference and predictive coding. Using eyeblink conditioning as a canonical paradigm, we formulate a minimal generative model that can account for spontaneous blinking, startle responses, and (delay or trace) conditioning. We then establish the face validity of the model using simulated responses to unconditioned and conditioned stimuli to reproduce the sorts of behavior that are observed empirically. The scheme's anatomical validity is then addressed by associating variables in the predictive coding scheme with nuclei and neuronal populations to match the (extrinsic and intrinsic) connectivity of the cerebellar (eyeblink conditioning) system. Finally, we try to establish predictive validity by reproducing selective failures of delay conditioning, trace conditioning, and extinction using (simulated and reversible) focal lesions. Although rather metaphorical, the ensuing scheme can account for a remarkable range of anatomical and neurophysiological aspects of cerebellar circuitry\textemdash and the specificity of lesion-deficit mappings that have been established experimentally. From a computational perspective, this work shows how conditioning or learning can be formulated in terms of minimizing variational free energy (or maximizing Bayesian model evidence) using exactly the same principles that underlie predictive coding in perception.},
  journal = {Neural Computation},
  number = {9}
}

@article{Friston_Active_2016b,
  title = {Active Inference and Learning},
  author = {Friston, Karl and FitzGerald, Thomas and Rigoli, Francesco and Schwartenbeck, Philipp and O Doherty, John and Pezzulo, Giovanni},
  year = {2016},
  month = sep,
  volume = {68},
  pages = {862--879},
  issn = {1873-7528},
  doi = {10.1016/j.neubiorev.2016.06.022},
  abstract = {This paper offers an active inference account of choice behaviour and learning. It focuses on the distinction between goal-directed and habitual behaviour and how they contextualise each other. We show that habits emerge naturally (and autodidactically) from sequential policy optimisation when agents are equipped with state-action policies. In active inference, behaviour has explorative (epistemic) and exploitative (pragmatic) aspects that are sensitive to ambiguity and risk respectively, where epistemic (ambiguity-resolving) behaviour enables pragmatic (reward-seeking) behaviour and the subsequent emergence of habits. Although goal-directed and habitual policies are usually associated with model-based and model-free schemes, we find the more important distinction is between belief-free and belief-based schemes. The underlying (variational) belief updating provides a comprehensive (if metaphorical) process theory for several phenomena, including the transfer of dopamine responses, reversal learning, habit formation and devaluation. Finally, we show that active inference reduces to a classical (Bellman) scheme, in the absence of ambiguity.},
  journal = {Neuroscience and Biobehavioral Reviews},
  keywords = {Active inference,Bayesian inference,Bayesian surprise,Choice Behavior,Dopamine,Epistemic value,Exploitation,Exploration,Free energy,Goal-directed,Habit learning,Habits,Information gain,Learning,Reward},
  language = {eng},
  pmcid = {PMC5167251},
  pmid = {27375276}
}

@article{Friston_anatomy_2013,
  title = {The Anatomy of Choice: Active Inference and Agency},
  shorttitle = {The Anatomy of Choice},
  author = {Friston, Karl and Schwartenbeck, Philipp and Fitzgerald, Thomas and Moutoussis, Michael and Behrens, Tim and Dolan, Raymond J.},
  year = {2013},
  volume = {7},
  pages = {598},
  doi = {10.3389/fnhum.2013.00598},
  abstract = {This paper considers agency in the setting of embodied or active inference. In brief, we associate a sense of agency with prior beliefs about action and ask what sorts of beliefs underlie optimal behavior. In particular, we consider prior beliefs that action minimizes the Kullback\textendash Leibler (KL) divergence between desired states and attainable states in the future. This allows one to formulate bounded rationality as approximate Bayesian inference that optimizes a free energy bound on model evidence. We show that constructs like expected utility, exploration bonuses, softmax choice rules and optimism bias emerge as natural consequences of this formulation. Previous accounts of active inference have focused on predictive coding and Bayesian filtering schemes for minimizing free energy. Here, we consider variational Bayes as an alternative scheme that provides formal constraints on the computational anatomy of inference and action\textemdash constraints that are remarkably consistent with neuroanatomy. Furthermore, this scheme contextualizes optimal decision theory and economic (utilitarian) formulations as pure inference problems. For example, expected utility theory emerges as a special case of free energy minimization, where the sensitivity or inverse temperature (of softmax functions and quantal response equilibria) has a unique and Bayes-optimal solution\textemdash that minimizes free energy. This sensitivity corresponds to the precision of beliefs about behavior, such that attainable goals are afforded a higher precision or confidence. In turn, this means that optimal behavior entails a representation of confidence about outcomes that are under an agent's control.},
  journal = {Frontiers in Human Neuroscience},
  keywords = {active inference,Agency,Bayesian,bounded rationality,embodied cognition,Free energy,Inference,utility theory}
}

@article{Friston_anatomy_2014,
  title = {The Anatomy of Choice: Dopamine and Decision-Making},
  shorttitle = {The Anatomy of Choice},
  author = {Friston, Karl and Schwartenbeck, Philipp and FitzGerald, Thomas and Moutoussis, Michael and Behrens, Timothy and Dolan, Raymond J.},
  year = {2014},
  month = nov,
  volume = {369},
  pages = {20130481},
  issn = {0962-8436, 1471-2970},
  doi = {10.1098/rstb.2013.0481},
  abstract = {This paper considers goal-directed decision-making in terms of embodied or active inference. We associate bounded rationality with approximate Bayesian inference that optimizes a free energy bound on model evidence. Several constructs such as expected utility, exploration or novelty bonuses, softmax choice rules and optimism bias emerge as natural consequences of free energy minimization. Previous accounts of active inference have focused on predictive coding. In this paper, we consider variational Bayes as a scheme that the brain might use for approximate Bayesian inference. This scheme provides formal constraints on the computational anatomy of inference and action, which appear to be remarkably consistent with neuroanatomy. Active inference contextualizes optimal decision theory within embodied inference, where goals become prior beliefs. For example, expected utility theory emerges as a special case of free energy minimization, where the sensitivity or inverse temperature (associated with softmax functions and quantal response equilibria) has a unique and Bayes-optimal solution. Crucially, this sensitivity corresponds to the precision of beliefs about behaviour. The changes in precision during variational updates are remarkably reminiscent of empirical dopaminergic responses\textemdash and they may provide a new perspective on the role of dopamine in assimilating reward prediction errors to optimize decision-making.},
  copyright = {. \textcopyright{} 2014 The Authors. Published by the Royal Society under the terms of the Creative Commons Attribution License http://creativecommons.org/licenses/by/4.0/, which permits unrestricted use, provided the original author and source are credited.},
  journal = {Philosophical Transactions of the Royal Society of London B: Biological Sciences},
  language = {en},
  number = {1655},
  pmid = {25267823}
}

@article{Friston_Empirical_2015,
  title = {Empirical {{Bayes}} for {{DCM}}: {{A Group Inversion Scheme}}},
  shorttitle = {Empirical {{Bayes}} for {{DCM}}},
  author = {Friston, Karl and Zeidman, Peter and Litvak, Vladimir},
  year = {2015},
  month = nov,
  volume = {9},
  issn = {1662-5137},
  doi = {10.3389/fnsys.2015.00164},
  abstract = {This technical note considers a simple but important methodological issue in estimating effective connectivity; namely, how do we integrate measurements from multiple subjects to infer functional brain architectures that are conserved over subjects. We offer a solution to this problem that rests on a generalization of random effects analyses to Bayesian inference about nonlinear models of electrophysiological time-series data. Specifically, we present an empirical Bayesian scheme for group or hierarchical models, in the setting of dynamic causal modeling (DCM). Recent developments in approximate Bayesian inference for hierarchical models enable the efficient estimation of group effects in DCM studies of multiple trials, sessions, or subjects. This approach estimates second (e.g., between-subject) level parameters based on posterior estimates from the first (e.g., within-subject) level. Here, we use empirical priors from the second level to iteratively optimize posterior densities over parameters at the first level. The motivation for this iterative application is to finesse the local minima problem inherent in the (first level) inversion of nonlinear and ill-posed models. Effectively, the empirical priors shrink the first level parameter estimates toward the global maximum, to provide more robust and efficient estimates of within (and between-subject) effects. This paper describes the inversion scheme using a worked example based upon simulated electrophysiological responses. In a subsequent paper, we will assess its robustness and reproducibility using an empirical example.},
  journal = {Frontiers in Systems Neuroscience},
  pmcid = {PMC4661273},
  pmid = {26640432}
}

@article{Friston_free_2006,
  title = {A Free Energy Principle for the Brain},
  author = {Friston, Karl and Kilner, James and Harrison, Lee},
  year = {2006 Jul-Sep},
  volume = {100},
  pages = {70--87},
  issn = {0928-4257},
  doi = {10.1016/j.jphysparis.2006.10.001},
  abstract = {By formulating Helmholtz's ideas about perception, in terms of modern-day theories, one arrives at a model of perceptual inference and learning that can explain a remarkable range of neurobiological facts: using constructs from statistical physics, the problems of inferring the causes of sensory input and learning the causal structure of their generation can be resolved using exactly the same principles. Furthermore, inference and learning can proceed in a biologically plausible fashion. The ensuing scheme rests on Empirical Bayes and hierarchical models of how sensory input is caused. The use of hierarchical models enables the brain to construct prior expectations in a dynamic and context-sensitive fashion. This scheme provides a principled way to understand many aspects of cortical organisation and responses. In this paper, we show these perceptual processes are just one aspect of emergent behaviours of systems that conform to a free energy principle. The free energy considered here measures the difference between the probability distribution of environmental quantities that act on the system and an arbitrary distribution encoded by its configuration. The system can minimise free energy by changing its configuration to affect the way it samples the environment or change the distribution it encodes. These changes correspond to action and perception respectively and lead to an adaptive exchange with the environment that is characteristic of biological systems. This treatment assumes that the system's state and structure encode an implicit and probabilistic model of the environment. We will look at the models entailed by the brain and how minimisation of its free energy can explain its dynamics and structure.},
  journal = {Journal of Physiology, Paris},
  keywords = {Afferent Pathways,Animals,Attention,Bayes Theorem,Brain,Brain Mapping,Computer Simulation,Entropy,Humans,Learning,Models; Neurological,Probability,Visual Perception},
  language = {eng},
  number = {1-3},
  pmid = {17097864}
}

@article{Friston_free_2006a,
  title = {A Free Energy Principle for the Brain},
  author = {Friston, Karl and Kilner, James and Harrison, Lee},
  year = {2006},
  month = jul,
  volume = {100},
  pages = {70--87},
  issn = {0928-4257},
  doi = {10.1016/j.jphysparis.2006.10.001},
  abstract = {By formulating Helmholtz's ideas about perception, in terms of modern-day theories, one arrives at a model of perceptual inference and learning that can explain a remarkable range of neurobiological facts: using constructs from statistical physics, the problems of inferring the causes of sensory input and learning the causal structure of their generation can be resolved using exactly the same principles. Furthermore, inference and learning can proceed in a biologically plausible fashion. The ensuing scheme rests on Empirical Bayes and hierarchical models of how sensory input is caused. The use of hierarchical models enables the brain to construct prior expectations in a dynamic and context-sensitive fashion. This scheme provides a principled way to understand many aspects of cortical organisation and responses. In this paper, we show these perceptual processes are just one aspect of emergent behaviours of systems that conform to a free energy principle. The free energy considered here measures the difference between the probability distribution of environmental quantities that act on the system and an arbitrary distribution encoded by its configuration. The system can minimise free energy by changing its configuration to affect the way it samples the environment or change the distribution it encodes. These changes correspond to action and perception respectively and lead to an adaptive exchange with the environment that is characteristic of biological systems. This treatment assumes that the system's state and structure encode an implicit and probabilistic model of the environment. We will look at the models entailed by the brain and how minimisation of its free energy can explain its dynamics and structure.},
  journal = {Journal of Physiology-Paris},
  keywords = {Action,Attention,Free energy,Hierarchical,Inference,Learning,Perception,Selection,Variational Bayes},
  number = {1\textendash 3},
  series = {Theoretical and {{Computational Neuroscience}}: {{Understanding Brain Functions}}}
}

@article{Friston_free_2006b,
  title = {A Free Energy Principle for the Brain},
  author = {Friston, Karl and Kilner, James and Harrison, Lee},
  year = {2006},
  month = jul,
  volume = {100},
  pages = {70--87},
  issn = {0928-4257},
  doi = {10.1016/j.jphysparis.2006.10.001},
  abstract = {By formulating Helmholtz's ideas about perception, in terms of modern-day theories, one arrives at a model of perceptual inference and learning that can explain a remarkable range of neurobiological facts: using constructs from statistical physics, the problems of inferring the causes of sensory input and learning the causal structure of their generation can be resolved using exactly the same principles. Furthermore, inference and learning can proceed in a biologically plausible fashion. The ensuing scheme rests on Empirical Bayes and hierarchical models of how sensory input is caused. The use of hierarchical models enables the brain to construct prior expectations in a dynamic and context-sensitive fashion. This scheme provides a principled way to understand many aspects of cortical organisation and responses. In this paper, we show these perceptual processes are just one aspect of emergent behaviours of systems that conform to a free energy principle. The free energy considered here measures the difference between the probability distribution of environmental quantities that act on the system and an arbitrary distribution encoded by its configuration. The system can minimise free energy by changing its configuration to affect the way it samples the environment or change the distribution it encodes. These changes correspond to action and perception respectively and lead to an adaptive exchange with the environment that is characteristic of biological systems. This treatment assumes that the system's state and structure encode an implicit and probabilistic model of the environment. We will look at the models entailed by the brain and how minimisation of its free energy can explain its dynamics and structure.},
  journal = {Journal of Physiology-Paris},
  keywords = {Action,Attention,Free energy,Hierarchical,Inference,Learning,Perception,Selection,Variational Bayes},
  number = {1\textendash 3},
  series = {Theoretical and {{Computational Neuroscience}}: {{Understanding Brain Functions}}}
}

@article{Friston_freeenergy_2010,
  title = {The Free-Energy Principle: A Unified Brain Theory?},
  shorttitle = {The Free-Energy Principle},
  author = {Friston, Karl},
  year = {2010},
  month = feb,
  volume = {11},
  pages = {127--138},
  issn = {1471-0048},
  doi = {10.1038/nrn2787},
  abstract = {A free-energy principle has been proposed recently that accounts for action, perception and learning. This Review looks at some key brain theories in the biological (for example, neural Darwinism) and physical (for example, information theory and optimal control theory) sciences from the free-energy perspective. Crucially, one key theme runs through each of these theories - optimization. Furthermore, if we look closely at what is optimized, the same quantity keeps emerging, namely value (expected reward, expected utility) or its complement, surprise (prediction error, expected cost). This is the quantity that is optimized under the free-energy principle, which suggests that several global brain theories might be unified within a free-energy framework.},
  journal = {Nature Reviews. Neuroscience},
  keywords = {Animals,Brain,cognition,Humans,Learning,Nerve Net,Perception,Psychological Theory},
  language = {eng},
  number = {2},
  pmid = {20068583}
}

@article{Friston_freeenergy_2010a,
  title = {The Free-Energy Principle: A Unified Brain Theory?},
  shorttitle = {The Free-Energy Principle},
  author = {Friston, Karl},
  year = {2010},
  month = feb,
  volume = {11},
  pages = {127--138},
  issn = {1471-003X},
  doi = {10.1038/nrn2787},
  abstract = {A free-energy principle has been proposed recently that accounts for action, perception and learning. This Review looks at some key brain theories in the biological (for example, neural Darwinism) and physical (for example, information theory and optimal control theory) sciences from the free-energy perspective. Crucially, one key theme runs through each of these theories \textemdash{} optimization. Furthermore, if we look closely at what is optimized, the same quantity keeps emerging, namely value (expected reward, expected utility) or its complement, surprise (prediction error, expected cost). This is the quantity that is optimized under the free-energy principle, which suggests that several global brain theories might be unified within a free-energy framework.},
  copyright = {\textcopyright{} 2010 Nature Publishing Group},
  journal = {Nature Reviews Neuroscience},
  language = {en},
  number = {2}
}

@article{Friston_freeenergy_2010b,
  title = {The Free-Energy Principle: A Unified Brain Theory?},
  shorttitle = {The Free-Energy Principle},
  author = {Friston, Karl},
  year = {2010},
  month = feb,
  volume = {11},
  pages = {127--138},
  issn = {1471-003X},
  doi = {10.1038/nrn2787},
  abstract = {A free-energy principle has been proposed recently that accounts for action, perception and learning. This Review looks at some key brain theories in the biological (for example, neural Darwinism) and physical (for example, information theory and optimal control theory) sciences from the free-energy perspective. Crucially, one key theme runs through each of these theories \textemdash{} optimization. Furthermore, if we look closely at what is optimized, the same quantity keeps emerging, namely value (expected reward, expected utility) or its complement, surprise (prediction error, expected cost). This is the quantity that is optimized under the free-energy principle, which suggests that several global brain theories might be unified within a free-energy framework.},
  copyright = {\textcopyright{} 2010 Nature Publishing Group},
  journal = {Nature Reviews Neuroscience},
  language = {en},
  number = {2}
}

@article{Friston_Generalised_2010,
  title = {Generalised {{Filtering}}},
  author = {Friston, Karl and Stephan, Klaas and Li, Baojuan and Daunizeau, Jean},
  year = {2010},
  month = jun,
  volume = {2010},
  pages = {e621670},
  issn = {1024-123X},
  doi = {10.1155/2010/621670},
  abstract = {We describe a Bayesian filtering scheme for nonlinear state-space models in continuous time. This scheme is called Generalised Filtering and furnishes posterior (conditional) densities on hidden states and unknown parameters generating observed data. Crucially, the scheme operates online, assimilating data to optimize the conditional density on time-varying states and time-invariant parameters. In contrast to Kalman and Particle smoothing, Generalised Filtering does not require a backwards pass. In contrast to variational schemes, it does not assume conditional independence between the states and parameters. Generalised Filtering optimises the conditional density with respect to a free-energy bound on the model's log-evidence. This optimisation uses the generalised motion of hidden states and parameters, under the prior assumption that the motion of the parameters is small. We describe the scheme, present comparative evaluations with a fixed-form variational version, and conclude with an illustrative application to a nonlinear state-space model of brain imaging time-series.},
  journal = {Mathematical Problems in Engineering},
  language = {en}
}

@article{Friston_Post_2011,
  title = {Post Hoc {{Bayesian}} Model Selection},
  author = {Friston, Karl and Penny, Will},
  year = {2011},
  month = jun,
  volume = {56},
  pages = {2089--2099},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2011.03.062},
  abstract = {This note describes a Bayesian model selection or optimization procedure for post hoc inferences about reduced versions of a full model. The scheme provides the evidence (marginal likelihood) for any reduced model as a function of the posterior density over the parameters of the full model. It rests upon specifying models through priors on their parameters, under the assumption that the likelihood remains the same for all models considered. This provides a quick and efficient scheme for scoring arbitrarily large numbers of models, after inverting a single (full) model. In turn, this enables the selection among discrete models that are distinguished by the presence or absence of free parameters, where free parameters are effectively removed from the model using very precise shrinkage priors. An alternative application of this post hoc model selection considers continuous model spaces, defined in terms of hyperparameters (sufficient statistics) of the prior density over model parameters. In this instance, the prior (model) can be optimized with respect to its evidence. The expressions for model evidence become remarkably simple under the Laplace (Gaussian) approximation to the posterior density. Special cases of this scheme include Savage\textendash Dickey density ratio tests for reduced models and automatic relevance determination in model optimization. We illustrate the approach using general linear models and a more complicated nonlinear state-space model.},
  journal = {NeuroImage},
  keywords = {Automatic relevance determination,Bayesian model evidence,Hyperparameters,Model selection,SavageDickey density ratio},
  number = {4}
}

@article{Friston_Reinforcement_2009,
  title = {Reinforcement {{Learning}} or {{Active Inference}}?},
  author = {Friston, Karl J. and Daunizeau, Jean and Kiebel, Stefan J.},
  year = {2009},
  month = jul,
  volume = {4},
  pages = {e6421},
  doi = {10.1371/journal.pone.0006421},
  abstract = {This paper questions the need for reinforcement learning or control theory when optimising behaviour. We show that it is fairly simple to teach an agent complicated and adaptive behaviours using a free-energy formulation of perception. In this formulation, agents adjust their internal states and sampling of the environment to minimize their free-energy. Such agents learn causal structure in the environment and sample it in an adaptive and self-supervised fashion. This results in behavioural policies that reproduce those optimised by reinforcement learning and dynamic programming. Critically, we do not need to invoke the notion of reward, value or utility. We illustrate these points by solving a benchmark problem in dynamic programming; namely the mountain-car problem, using active perception or inference under the free-energy principle. The ensuing proof-of-concept may be important because the free-energy formulation furnishes a unified account of both action and perception and may speak to a reappraisal of the role of dopamine in the brain.},
  journal = {PLoS ONE},
  number = {7}
}

@article{Friston_theory_2005,
  title = {A Theory of Cortical Responses},
  author = {Friston, Karl},
  year = {2005},
  month = apr,
  volume = {360},
  pages = {815--836},
  issn = {0962-8436, 1471-2970},
  doi = {10.1098/rstb.2005.1622},
  abstract = {This article concerns the nature of evoked brain responses and the principles underlying their generation. We start with the premise that the sensory brain has evolved to represent or infer the causes of changes in its sensory inputs. The problem of inference is well formulated in statistical terms. The statistical fundaments of inference may therefore afford important constraints on neuronal implementation. By formulating the original ideas of Helmholtz on perception, in terms of modern-day statistical theories, one arrives at a model of perceptual inference and learning that can explain a remarkable range of neurobiological facts. It turns out that the problems of inferring the causes of sensory input (perceptual inference) and learning the relationship between input and cause (perceptual learning) can be resolved using exactly the same principle. Specifically, both inference and learning rest on minimizing the brain's free energy, as defined in statistical physics. Furthermore, inference and learning can proceed in a biologically plausible fashion. Cortical responses can be seen as the brain's attempt to minimize the free energy induced by a stimulus and thereby encode the most likely cause of that stimulus. Similarly, learning emerges from changes in synaptic efficacy that minimize the free energy, averaged over all stimuli encountered. The underlying scheme rests on empirical Bayes and hierarchical models of how sensory input is caused. The use of hierarchical models enables the brain to construct prior expectations in a dynamic and context-sensitive fashion. This scheme provides a principled way to understand many aspects of cortical organization and responses. The aim of this article is to encompass many apparently unrelated anatomical, physiological and psychophysical attributes of the brain within a single theoretical perspective. In terms of cortical architectures, the theoretical treatment predicts that sensory cortex should be arranged hierarchically, that connections should be reciprocal and that forward and backward connections should show a functional asymmetry (forward connections are driving, whereas backward connections are both driving and modulatory). In terms of synaptic physiology, it predicts associative plasticity and, for dynamic models, spike-timing-dependent plasticity. In terms of electrophysiology, it accounts for classical and extra classical receptive field effects and long-latency or endogenous components of evoked cortical responses. It predicts the attenuation of responses encoding prediction error with perceptual learning and explains many phenomena such as repetition suppression, mismatch negativity (MMN) and the P300 in electroencephalography. In psychophysical terms, it accounts for the behavioural correlates of these physiological phenomena, for example, priming and global precedence. The final focus of this article is on perceptual learning as measured with the MMN and the implications for empirical studies of coupling among cortical areas using evoked sensory responses.},
  copyright = {\textcopyright{} 2005 The Royal Society},
  journal = {Philosophical Transactions of the Royal Society of London B: Biological Sciences},
  language = {en},
  number = {1456},
  pmid = {15937014}
}

@article{Friston_variational_2008,
  title = {{{DEM}}: {{A}} Variational Treatment of Dynamic Systems},
  shorttitle = {{{DEM}}},
  author = {Friston, K. J. and {Trujillo-Barreto}, N. and Daunizeau, J.},
  year = {2008},
  month = jul,
  volume = {41},
  pages = {849--885},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2008.02.054},
  abstract = {This paper presents a variational treatment of dynamic models that furnishes time-dependent conditional densities on the path or trajectory of a system's states and the time-independent densities of its parameters. These are obtained by maximising a variational action with respect to conditional densities, under a fixed-form assumption about their form. The action or path-integral of free-energy represents a lower bound on the model's log-evidence or marginal likelihood required for model selection and averaging. This approach rests on formulating the optimisation dynamically, in generalised coordinates of motion. The resulting scheme can be used for online Bayesian inversion of nonlinear dynamic causal models and is shown to outperform existing approaches, such as Kalman and particle filtering. Furthermore, it provides for dual and triple inferences on a system's states, parameters and hyperparameters using exactly the same principles. We refer to this approach as dynamic expectation maximisation (DEM).},
  journal = {NeuroImage},
  keywords = {Action,Bayesian filtering,Dynamic expectation maximisation,Dynamical systems,Free energy,Nonlinear,Variational Bayes,Variational filtering},
  number = {3}
}

@article{Fujiwara_Postsynaptic_2014,
  title = {Postsynaptic {{Odorant Concentration Dependent Inhibition Controls Temporal Properties}} of {{Spike Responses}} of {{Projection Neurons}} in the {{Moth Antennal Lobe}}},
  author = {Fujiwara, Terufumi and Kazawa, Tomoki and Haupt, Stephan Shuichi and Kanzaki, Ryohei},
  year = {2014},
  month = feb,
  volume = {9},
  pages = {e89132},
  doi = {10.1371/journal.pone.0089132},
  abstract = {Although odorant concentration-response characteristics of olfactory neurons have been widely investigated in a variety of animal species, the effect of odorant concentration on neural processing at circuit level is still poorly understood. Using calcium imaging in the silkmoth (Bombyx mori) pheromone processing circuit of the antennal lobe (AL), we studied the effect of odorant concentration on second-order projection neuron (PN) responses. While PN calcium responses of dendrites showed monotonic increases with odorant concentration, calcium responses of somata showed decreased responses at higher odorant concentrations due to postsynaptic inhibition. Simultaneous calcium imaging and electrophysiology revealed that calcium responses of PN somata but not dendrites reflect spiking activity. Inhibition shortened spike response duration rather than decreasing peak instantaneous spike frequency (ISF). Local interneurons (LNs) that were specifically activated at high odorant concentrations at which PN responses were suppressed are the putative source of inhibition. Our results imply the existence of an intraglomerular mechanism that preserves time resolution in olfactory processing over a wide odorant concentration range.},
  journal = {PLoS ONE},
  number = {2}
}

@article{Fujiwara_Postsynaptic_2014a,
  title = {Postsynaptic {{Odorant Concentration Dependent Inhibition Controls Temporal Properties}} of {{Spike Responses}} of {{Projection Neurons}} in the {{Moth Antennal Lobe}}},
  author = {Fujiwara, Terufumi and Kazawa, Tomoki and Haupt, Stephan Shuichi and Kanzaki, Ryohei},
  year = {2014},
  month = feb,
  volume = {9},
  pages = {e89132},
  doi = {10.1371/journal.pone.0089132},
  abstract = {Although odorant concentration-response characteristics of olfactory neurons have been widely investigated in a variety of animal species, the effect of odorant concentration on neural processing at circuit level is still poorly understood. Using calcium imaging in the silkmoth (Bombyx mori) pheromone processing circuit of the antennal lobe (AL), we studied the effect of odorant concentration on second-order projection neuron (PN) responses. While PN calcium responses of dendrites showed monotonic increases with odorant concentration, calcium responses of somata showed decreased responses at higher odorant concentrations due to postsynaptic inhibition. Simultaneous calcium imaging and electrophysiology revealed that calcium responses of PN somata but not dendrites reflect spiking activity. Inhibition shortened spike response duration rather than decreasing peak instantaneous spike frequency (ISF). Local interneurons (LNs) that were specifically activated at high odorant concentrations at which PN responses were suppressed are the putative source of inhibition. Our results imply the existence of an intraglomerular mechanism that preserves time resolution in olfactory processing over a wide odorant concentration range.},
  journal = {PLoS ONE},
  number = {2}
}

@article{Galizia_Olfactory_2014,
  title = {Olfactory Coding in the Insect Brain: Data and Conjectures},
  shorttitle = {Olfactory Coding in the Insect Brain},
  author = {Galizia, C Giovanni},
  year = {2014},
  month = jun,
  volume = {39},
  pages = {1784--1795},
  issn = {0953-816X},
  doi = {10.1111/ejn.12558},
  abstract = {Much progress has been made recently in understanding how olfactory coding works in insect brains. Here, I propose a wiring diagram for the major steps from the first processing network (the antennal lobe) to behavioral readout. I argue that the sequence of lateral inhibition in the antennal lobe, non-linear synapses, threshold-regulating gated spring network, selective lateral inhibitory networks across glomeruli, and feedforward inhibition to the lateral protocerebrum cover most of the experimental results from different research groups and model species. I propose that the main difference between mushroom bodies and the lateral protocerebrum is not about learned vs. innate behavior. Rather, mushroom bodies perform odor identification, whereas the lateral protocerebrum performs odor evaluation (both learned and innate). I discuss the concepts of labeled line and combinatorial coding and postulate that, under restrictive experimental conditions, these networks lead to an apparent existence of `labeled line' coding for special odors. Modulatory networks are proposed as switches between different evaluating systems in the lateral protocerebrum. A review of experimental data and theoretical conjectures both contribute to this synthesis, creating new hypotheses for future research.},
  journal = {The European Journal of Neuroscience},
  number = {11},
  pmcid = {PMC4237541},
  pmid = {24698302}
}

@article{Gallagher_Health_2012,
  title = {Health Message Framing Effects on Attitudes, Intentions, and Behavior: A Meta-Analytic Review},
  shorttitle = {Health Message Framing Effects on Attitudes, Intentions, and Behavior},
  author = {Gallagher, Kristel M. and Updegraff, John A.},
  year = {2012},
  month = feb,
  volume = {43},
  pages = {101--116},
  issn = {1532-4796},
  doi = {10.1007/s12160-011-9308-7},
  abstract = {BACKGROUND: Message framing has been an important focus in health communication research, yet prior meta-analyses found limited support for using framing to increase persuasiveness of health messages. PURPOSE: This meta-analysis distinguished the outcomes used to assess the persuasive impact of framed messages (attitudes, intentions, or behavior). METHODS: One hundred eighty-nine effect sizes were identified from 94 peer-reviewed, published studies which compared the persuasive impact of gain- and loss-framed messages. RESULTS: Gain-framed messages were more likely than loss-framed messages to encourage prevention behaviors (r\,=\,0.083, p\,=\,0.002), particularly for skin cancer prevention, smoking cessation, and physical activity. No effect of framing was found when persuasion was assessed by attitudes/intentions or among studies encouraging detection. CONCLUSIONS: Gain-framed messages appear to be more effective than loss-framed messages in promoting prevention behaviors. Research should examine the contexts in which loss-framed messages are most effective, and the processes that mediate the effects of framing on behavior.},
  journal = {Annals of Behavioral Medicine: A Publication of the Society of Behavioral Medicine},
  keywords = {Health Behavior,Health Communication,Health Knowledge; Attitudes; Practice,Health Promotion,Humans,Intention,Persuasive Communication},
  language = {eng},
  number = {1},
  pmid = {21993844}
}

@article{Geffen_Neural_2009,
  title = {Neural {{Encoding}} of {{Rapidly Fluctuating Odors}}},
  author = {Geffen, Maria N. and Broome, Bede M. and Laurent, Gilles and Meister, Markus},
  year = {2009},
  month = feb,
  volume = {61},
  pages = {570--586},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2009.01.021},
  abstract = {Summary Olfactory processing in the insect antennal lobe is a highly dynamic process, yet it has been studied primarily with static step stimuli. To approximate the rapid odor fluctuations encountered in nature, we presented flickering ``white-noise'' odor stimuli to the antenna of the locust and recorded spike trains from antennal lobe projection neurons (PNs). The responses varied greatly across PNs and across odors for the same PN. Surprisingly, this diversity across the population was highly constrained, and most responses were captured by a quantitative model with just 3 parameters. Individual PNs were found to communicate odor information at rates up to {$\sim$}4 bits/s. A small group of PNs was sufficient to provide an accurate representation of the dynamic odor time course, whose quality was maximal for fluctuations of frequency {$\sim$}0.8 Hz. We develop a simple model for the encoding of dynamic odor stimuli that accounts for many prior observations on the population response.},
  journal = {Neuron},
  keywords = {SIGNALING,SYSNEURO},
  number = {4}
}

@article{Geffen_Neural_2009a,
  title = {Neural {{Encoding}} of {{Rapidly Fluctuating Odors}}},
  author = {Geffen, Maria N. and Broome, Bede M. and Laurent, Gilles and Meister, Markus},
  year = {2009},
  month = feb,
  volume = {61},
  pages = {570--586},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2009.01.021},
  abstract = {Summary Olfactory processing in the insect antennal lobe is a highly dynamic process, yet it has been studied primarily with static step stimuli. To approximate the rapid odor fluctuations encountered in nature, we presented flickering ``white-noise'' odor stimuli to the antenna of the locust and recorded spike trains from antennal lobe projection neurons (PNs). The responses varied greatly across PNs and across odors for the same PN. Surprisingly, this diversity across the population was highly constrained, and most responses were captured by a quantitative model with just 3 parameters. Individual PNs were found to communicate odor information at rates up to {$\sim$}4 bits/s. A small group of PNs was sufficient to provide an accurate representation of the dynamic odor time course, whose quality was maximal for fluctuations of frequency {$\sim$}0.8 Hz. We develop a simple model for the encoding of dynamic odor stimuli that accounts for many prior observations on the population response.},
  journal = {Neuron},
  keywords = {SIGNALING,SYSNEURO},
  number = {4}
}

@article{Gelman_Posterior_1996,
  title = {Posterior {{Predictive Assessment}} of {{Model Fitness Via Realized Discrepancies}}},
  author = {Gelman, Andrew and Meng, Xiao-li and Stern, Hal},
  year = {1996},
  pages = {733--807},
  abstract = {Abstract: This paper considers Bayesian counterparts of the classical tests for goodness of fit and their use in judging the fit of a single Bayesian model to the observed data. We focus on posterior predictive assessment, in a framework that also includes conditioning on auxiliary statistics. The Bayesian formulation facilitates the construction and calculation of a meaningful reference distribution not only for any (classical) statistic, but also for any parameter-dependent ``statistic '' or discrepancy. The latter allows us to propose the realized discrepancy assessment of model fitness, which directly measures the true discrepancy between data and the posited model, for any aspect of the model which we want to explore. The computation required for the realized discrepancy assessment is a straightforward byproduct of the posterior simulation used for the original Bayesian analysis. We illustrate with three applied examples. The first example, which serves mainly to motivate the work, illustrates the difficulty of classical tests in assessing the fitness of a Poisson model to a positron emission tomography image that is constrained to be nonnegative. The second and third examples illustrate the details of the posterior predictive approach in two problems: estimation in a model with inequality constraints on the parameters, and estimation in a mixture model. In all three examples, standard test statistics (either a {$\chi$} 2 or a likelihood ratio) are not pivotal: the difficulty is not just how to compute the reference distribution for the test, but that in the classical framework no such distribution exists, independent of the unknown model parameters. Key words and phrases: Bayesian p-value, {$\chi$} 2 test, discrepancy, graphical assessment, mixture model, model criticism, posterior predictive p-value, prior predictive},
  journal = {Statistica Sinica}
}

@article{Gerkin_number_2015,
  title = {The Number of Olfactory Stimuli That Humans Can Discriminate Is Still Unknown},
  author = {Gerkin, Richard C. and Castro, Jason B.},
  year = {2015},
  month = jul,
  volume = {4},
  pages = {e08127},
  issn = {2050-084X},
  doi = {10.7554/eLife.08127},
  abstract = {It was recently proposed (Bushdid et al., 2014) that humans can discriminate between at least a trillion olfactory stimuli. Here we show that this claim is the result of a fragile estimation framework capable of producing nearly any result from the reported data, including values tens of orders of magnitude larger or smaller than the one originally reported in (Bushdid et al., 2014). Additionally, the formula used to derive this estimate is well-known to provide an upper bound, not a lower bound as reported. That is to say, the actual claim supported by the calculation is in fact that humans can discriminate at most one trillion olfactory stimuli. We conclude that there is no evidence for the original claim.DOI: http://dx.doi.org/10.7554/eLife.08127.001View Full TextTo Top It was recently proposed (Bushdid et al., 2014) that humans can discriminate between at least a trillion olfactory stimuli. Here we show that this claim is the result of a fragile estimation framework capable of producing nearly any result from the reported data, including values tens of orders of magnitude larger or smaller than the one originally reported in (Bushdid et al., 2014). Additionally, the formula used to derive this estimate is well-known to provide an upper bound, not a lower bound as reported. That is to say, the actual claim supported by the calculation is in fact that humans can discriminate at most one trillion olfactory stimuli. We conclude that there is no evidence for the original claim. DOI: http://dx.doi.org/10.7554/eLife.08127.001 Scientists are interested in the number of colors, sounds and smells we can distinguish because this information can shed light onto how our brains process these senses both in health and disease. It is relatively straightforward to determine how many colors we can see or sounds we can hear because these stimuli are well defined by physical properties such as wavelength. We know the range of wavelengths that the eye can see or the ear can hear, and we can also understand how two such stimuli (e.g., red and blue) are arranged perceptually (think of a color wheel). It is harder, however, to do the same for smell because most `olfactory stimuli' consist of mixtures of different odor molecules. Moreover, we understand much less about how olfactory stimuli are arranged perceptually. In 2014 researchers at Rockefeller University reported that humans can distinguish more than one trillion smells from one another. To calculate this number the researchers tested the ability of human subjects to discriminate between mixtures of different odor molecules. Each mixture consisted of 10, 20 or 30 molecules selected from a chemical library of 128 different odor molecules. Since each mixture of 10 molecules could contain any 10 of the 128 molecules, more than 200 trillion combinations were possible; the number of possible combinations for the 20- and 30-molecule mixtures were even higher. The aim of the experiment was to identify\textemdash by sampling from this very large number of combinations\textemdash the number of molecules that two mixtures could have in common and still be distinguishable to the typical person. The Rockefeller team used this number and a geometrical analogy to conclude that humans could discriminate at least 1.72 trillion odors, which was much higher than expected from previous reports and anecdotes. Now Gerkin and Castro report that the claims made in the Rockefeller study are unsupported because of flaws in the design of the analytical framework used to make sense of the data. In particular, Gerkin and Castro report that the results are extremely sensitive to some parameters of the experimental and analytical design, such as the number of subjects tested, whereas the results of a robust analysis would not be so sensitive to such factors. By modestly varying any of these parameters it is possible to obtain almost any value for the number of smells that can be discriminated. Moreover, the geometrical analogy used set an upper bound on the final answer, rather than a lower bound: in other words, even assuming that the rest of the analysis was robust, the result should have been that humans can discriminate `no more than' 1.72 trillion smells rather than `at least'. In a separate paper Meister also reports that the 1.72 trillion smells claim is unjustified. DOI: http://dx.doi.org/10.7554/eLife.08127.002},
  copyright = {\textcopyright{} 2015, Gerkin and Castro. This article is distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use and redistribution provided that the original author and source are credited.},
  journal = {eLife},
  language = {en}
}

@article{Gershman_Context_2010,
  title = {Context, Learning, and Extinction},
  author = {Gershman, Samuel J. and Blei, David M. and Niv, Yael},
  year = {2010},
  month = jan,
  volume = {117},
  pages = {197--209},
  issn = {1939-1471},
  doi = {10.1037/a0017808},
  abstract = {A. Redish et al. (2007) proposed a reinforcement learning model of context-dependent learning and extinction in conditioning experiments, using the idea of "state classification" to categorize new observations into states. In the current article, the authors propose an interpretation of this idea in terms of normative statistical inference. They focus on renewal and latent inhibition, 2 conditioning paradigms in which contextual manipulations have been studied extensively, and show that online Bayesian inference within a model that assumes an unbounded number of latent causes can characterize a diverse set of behavioral results from such manipulations, some of which pose problems for the model of Redish et al. Moreover, in both paradigms, context dependence is absent in younger animals, or if hippocampal lesions are made prior to training. The authors suggest an explanation in terms of a restricted capacity to infer new causes.},
  journal = {Psychological Review},
  keywords = {Bayes Theorem,Conditioning; Classical,Extinction; Psychological,hippocampus,Humans,Learning,Models; Psychological,Semantics},
  language = {eng},
  number = {1},
  pmid = {20063968}
}

@article{Gershman_Learning_2010,
  title = {Learning Latent Structure: {{Carving}} Nature at Its Joints},
  shorttitle = {Learning Latent Structure},
  author = {Gershman, Samuel J. and Niv, Yael},
  year = {2010},
  month = apr,
  volume = {20},
  pages = {251--256},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2010.02.008},
  abstract = {Reinforcement learning algorithms provide powerful explanations for simple learning and decision making behaviors and the functions of their underlying neural substrates. Unfortunately, in real world situations that involve many stimuli and actions, these algorithms learn pitifully slowly, exposing their inferiority in comparison to animal and human learning. Here we suggest that one reason for this discrepancy is that humans and animals take advantage of structure that is inherent in real-world tasks to simplify the learning problem. We survey an emerging literature on ``structure learning''\textemdash using experience to infer the structure of a task\textemdash and how this can be of service to reinforcement learning, with an emphasis on structure in perception and action.},
  journal = {Current opinion in neurobiology},
  number = {2},
  pmcid = {PMC2862793},
  pmid = {20227271}
}

@incollection{Gershman_Neural_2010,
  title = {The {{Neural Costs}} of {{Optimal Control}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 23},
  author = {Gershman, Samuel J. and Wilson, Robert C.},
  year = {2010},
  abstract = {Optimal control entails combining probabilities and utilities. However, for most practical problems, probability densities can be represented only approximately. Choosing an approximation requires balancing the benefits of an accurate approximation against the costs of computing it. We propose a variational framework for achieving this balance and apply it to the problem of how a neural population code should optimally represent a distribution under resource constraints. The essence of our analysis is the conjecture that population codes are organized to maximize a lower bound on the log expected utility. This theory can account for a plethora of experimental data, including the reward-modulation of sensory receptive fields, GABAergic effects on saccadic movements, and risk aversion in decisions under uncertainty.}
}

@article{Gershman_Retrospective_2014,
  title = {Retrospective Revaluation in Sequential Decision Making: A Tale of Two Systems},
  shorttitle = {Retrospective Revaluation in Sequential Decision Making},
  author = {Gershman, Samuel J. and Markman, Arthur B. and Otto, A. Ross},
  year = {2014},
  month = feb,
  volume = {143},
  pages = {182--194},
  issn = {1939-2222},
  doi = {10.1037/a0030844},
  abstract = {Recent computational theories of decision making in humans and animals have portrayed 2 systems locked in a battle for control of behavior. One system--variously termed model-free or habitual--favors actions that have previously led to reward, whereas a second--called the model-based or goal-directed system--favors actions that causally lead to reward according to the agent's internal model of the environment. Some evidence suggests that control can be shifted between these systems using neural or behavioral manipulations, but other evidence suggests that the systems are more intertwined than a competitive account would imply. In 4 behavioral experiments, using a retrospective revaluation design and a cognitive load manipulation, we show that human decisions are more consistent with a cooperative architecture in which the model-free system controls behavior, whereas the model-based system trains the model-free system by replaying and simulating experience.},
  journal = {Journal of Experimental Psychology. General},
  keywords = {Decision Making,Humans,Models; Psychological,Neuropsychological Tests,Reinforcement (Psychology)},
  language = {eng},
  number = {1},
  pmid = {23230992}
}

@article{Ghavami_Neuronal_2019,
  title = {Neuronal {{Synchronization Can Control}} the {{Energy Efficiency}} of {{Inter}}-Spike {{Interval Coding}}},
  author = {Ghavami, S. and Rahmati, V. and Lahouti, F. and Schwabe, L.},
  year = {2019},
  pages = {1--1},
  doi = {10.1109/TMBMC.2019.2937291},
  abstract = {The role of synchronous firing in sensory coding and cognition remains controversial. While studies, focusing on its mechanistic consequences in attentional tasks, suggest that synchronization dynamically boosts sensory processing, others failed to find significant synchronization levels in such tasks. We attempt to understand both lines of evidence within a coherent theoretical framework. We conceptualize synchronization as an independent control parameter to study how the postsynaptic neuron transmits the average firing activity of a presynaptic population, in the presence of synchronization. We apply the Berger-Levy theory of energy efficient information transmission to interpret simulations of a Hodgkin-Huxley-type postsynaptic neuron model, where we varied the firing rate and synchronization level in the presynaptic population independently. We find that for a fixed presynaptic firing rate the simulated postsynaptic interspike interval distribution depends on the synchronization level and is well-described by a generalized extreme value distribution. For synchronization levels of 15\% to 50\%, we find that the optimal distribution of presynaptic firing rate, maximizing the mutual information per unit cost, is maximized at 30\% synchronization level. These results suggest that the statistics and energy efficiency of neuronal communication channels, through which the input rate is communicated, can be dynamically adapted by the synchronization level.},
  journal = {IEEE Transactions on Molecular, Biological and Multi-Scale Communications},
  keywords = {Adaptation models,Biological system modeling,Encoding,Energy efficiency,Firing,Information theory,Neuronal communication,Neuronal Synchronization,Neurons,Optimization.,Synchronization}
}

@article{Glascher_States_2010,
  title = {States versus {{Rewards}}: {{Dissociable Neural Prediction Error Signals Underlying Model}}-{{Based}} and {{Model}}-{{Free Reinforcement Learning}}},
  shorttitle = {States versus {{Rewards}}},
  author = {Gl{\"a}scher, Jan and Daw, Nathaniel and Dayan, Peter and O'Doherty, John P.},
  year = {2010},
  month = may,
  volume = {66},
  pages = {585--595},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2010.04.016},
  journal = {Neuron},
  keywords = {SYSNEURO},
  language = {English},
  number = {4},
  pmid = {20510862}
}

@article{Gold_neural_2007,
  title = {The Neural Basis of Decision Making},
  author = {Gold, Joshua},
  year = {2007},
  abstract = {The study of decision making spans such varied fields as neuro- science, psychology, economics, statistics, political science, and com- puter science. Despite this diversity of applications, most decisions share common elements including deliberation and commitment. Here we evaluate recent progress in understanding how these basic elements of decision formation are implemented in the brain. We focus on simple decisions that can be studied in the laboratory but emphasize general principles likely to extend to other settings.},
  keywords = {Decision making,review}
}

@article{Goschke_Dysfunctions_2014,
  title = {Dysfunctions of Decision-Making and Cognitive Control as Transdiagnostic Mechanisms of Mental Disorders: Advances, Gaps, and Needs in Current Research},
  shorttitle = {Dysfunctions of Decision-Making and Cognitive Control as Transdiagnostic Mechanisms of Mental Disorders},
  author = {Goschke, Thomas},
  year = {2014},
  month = jan,
  volume = {23 Suppl 1},
  pages = {41--57},
  issn = {1557-0657},
  doi = {10.1002/mpr.1410},
  abstract = {Disadvantageous decision-making and impaired volitional control over actions, thoughts, and emotions are characteristics of a wide range of mental disorders such as addiction, eating disorders, depression, and anxiety disorders and may reflect transdiagnostic core mechanisms and possibly vulnerability factors. Elucidating the underlying neurocognitive mechanisms is a precondition for moving from symptom-based to mechanism-based disorder classifications and ultimately mechanism-targeted interventions. However, despite substantial advances in basic research on decision-making and cognitive control, there are still profound gaps in our current understanding of dysfunctions of these processes in mental disorders. Central unresolved questions are: (i) to which degree such dysfunctions reflect transdiagnostic mechanisms or disorder-specific patterns of impairment; (ii) how phenotypical features of mental disorders relate to dysfunctional control parameter settings and aberrant interactions between large-scale brain systems involved in habit and reward-based learning, performance monitoring, emotion regulation, and cognitive control; (iii) whether cognitive control impairments are consequences or antecedent vulnerability factors of mental disorders; (iv) whether they reflect generalized competence impairments or context-specific performance failures; (v) whether not only impaired but also chronic over-control contributes to mental disorders. In the light of these gaps, needs for future research are: (i) an increased focus on basic cognitive-affective mechanisms underlying decision and control dysfunctions across disorders; (ii) longitudinal-prospective studies systematically incorporating theory-driven behavioural tasks and neuroimaging protocols to assess decision-making and control dysfunctions and aberrant interactions between underlying large-scale brain systems; (iii) use of latent-variable models of cognitive control rather than single tasks; (iv) increased focus on the interplay of implicit and explicit cognitive-affective processes; (v) stronger focus on computational models specifying neurocognitive mechanisms underlying phenotypical expressions of mental disorders.},
  journal = {International Journal of Methods in Psychiatric Research},
  keywords = {Biomedical Research,Cognition Disorders,cognitive control,Decision Making,decision-making,Health Services Needs and Demand,Humans,large-scale brain systems,Mental Disorders,Mood Disorders,Neuropsychological Tests,transdiagnostic mechanisms,volition},
  language = {eng},
  pmid = {24375535}
}

@article{Goutte_Clustering_1999,
  title = {On {{Clustering fMRI Time Series}}},
  author = {Goutte, Cyril and Toft, Peter and Rostrup, Egill and Nielsen, Finn {\AA}. and Hansen, Lars Kai},
  year = {1999},
  month = mar,
  volume = {9},
  pages = {298--310},
  issn = {1053-8119},
  doi = {10.1006/nimg.1998.0391},
  abstract = {Analysis of fMRI time series is often performed by extracting one or more parameters for the individual voxels. Methods based, e.g., on various statistical tests are then used to yield parameters corresponding to probability of activation or activation strength. However, these methods do not indicate whether sets of voxels are activated in a similar way or in different ways. Typically, delays between two activated signals are not identified. In this article, we use clustering methods to detect similarities in activation between voxels. We employ a novel metric that measures the similarity between the activation stimulus and the fMRI signal. We present two different clustering algorithms and use them to identify regions of similar activations in an fMRI experiment involving a visual stimulus.},
  journal = {NeuroImage},
  number = {3}
}

@article{Goutte_Feature_2001,
  title = {Feature-space Clustering for {{fMRI}} Meta-analysis},
  author = {Goutte, Cyril and Hansen, Lars Kai and Liptrot, Matthew G. and Rostrup, Egill},
  year = {2001},
  month = jul,
  volume = {13},
  pages = {165--183},
  issn = {1097-0193},
  doi = {10.1002/hbm.1031},
  journal = {Human Brain Mapping},
  language = {en},
  number = {3}
}

@article{Green_Amount_1999,
  title = {Amount of Reward Has Opposite Effects on the Discounting of Delayed and Probabilistic Outcomes},
  author = {Green, L. and Myerson, J. and Ostaszewski, P.},
  year = {1999},
  month = mar,
  volume = {25},
  pages = {418--427},
  issn = {0278-7393},
  abstract = {Previous research has shown that the value of large future rewards is discounted less steeply than is the value of small future rewards. These experiments extended this line of research to probabilistic rewards. Two experiments replicated the standard findings for delayed rewards but demonstrated that amount has an opposite effect on the discounting of probabilistic rewards. That is, large probabilistic amounts were discounted at the same or higher rates than small amounts. Although amount had opposite effects on the discounting of delayed and probabilistic rewards, nevertheless, the same form of mathematical function accurately described discounting of both types of reward. The findings suggest that fundamentally similar, but not identical, processes are involved in decision making regarding delayed and probabilistic rewards. The implications of these findings for impulsivity and self-control are discussed.},
  journal = {Journal of Experimental Psychology. Learning, Memory, and Cognition},
  keywords = {Adolescent,Adult,Female,Humans,Male,Models; Statistical,Reward},
  language = {eng},
  number = {2},
  pmid = {10093208}
}

@article{Green_Discounting_1994,
  title = {Discounting of {{Delayed Rewards}}: {{A Life}}-{{Span Comparison}}},
  shorttitle = {Discounting of {{Delayed Rewards}}},
  author = {Green, Leonard and Fry, Astrid F and Myerson, Joel},
  year = {1994},
  month = jan,
  volume = {5},
  pages = {33--36},
  issn = {0956-7976},
  doi = {10.1111/j.1467-9280.1994.tb00610.x},
  abstract = {In this study, children, young adults, and older adults chose between immediate and delayed hypothetical monetary rewards The amount of the delayed reward was held constant while its delay was varied All three age groups showed delay discounting, that is, the amount of an immediate reward judged to be of equal value to the delayed reward decreased as a function of delay The rate of discounting was highest for children and lowest for older adults, predicting a life-span developmental trend toward increased self-control Discounting of delayed rewards by all three age groups was well described by a single function with age-sensitive parameters (all R2s {$>$} 94) Thus, even though there are quantitative age differences in delay discounting, the existence of an age-invariant form of discount function suggests that the process of choosing between rewards of different amounts and delays is qualitatively similar across the life span},
  journal = {Psychological Science},
  language = {en},
  number = {1}
}

@article{Green_Discounting_1999,
  title = {Discounting of Delayed Rewards across the Life Span: Age Differences in Individual Discounting Functions},
  shorttitle = {Discounting of Delayed Rewards across the Life Span},
  author = {Green, L. and Myerson, J. and Ostaszewski, P.},
  year = {1999},
  month = may,
  volume = {46},
  pages = {89--96},
  issn = {0376-6357},
  doi = {10.1016/S0376-6357(99)00021-2},
  abstract = {The present effort addressed both the issue of the generality of choice models and the issue of possible qualitative developmental change in temporal discounting by examining behavior at the individual level across the life span. Data from individual children, young adults, and older adults who participated in two previous studies were analyzed [Green, L., Fry, A.F., Myerson, J., 1994. Discounting of delayed rewards: a life-span comparison. Psychol. Sci. 5, 33-36; Green, L., Myerson, J., Lichtman, D., Rosen, S., Fry, A., 1996. Temporal discounting in choice between delayed rewards: the role of age and income. Psychol. Aging 11, 79-84]. At all ages, a hyperbola-like function originally proposed by Green et al. (1994) based on group data, provided the best description of individual discounting functions. Two developmental trends were observed. The rate at which individuals discounted the value of delayed rewards decreased with age, and there was a systematic change in the shape of the discounting function. Each of these trends was reflected in a separate parameter of the model. The fact that the same mathematical model described the behavior of individuals of different ages suggests that age and individual differences in the discounting of delayed rewards are primarily quantitative in nature and reflect variations on fundamentally similar choice processes.},
  journal = {Behavioural Processes},
  keywords = {Children,Delayed rewards,Discounting,Life span,Older adults},
  language = {eng},
  number = {1},
  pmid = {24925501}
}

@article{Green_Discounting_2004,
  title = {A {{Discounting Framework}} for {{Choice With Delayed}} and {{Probabilistic Rewards}}},
  author = {Green, Leonard and Myerson, Joel},
  year = {2004},
  month = sep,
  volume = {130},
  pages = {769--792},
  issn = {0033-2909},
  doi = {10.1037/0033-2909.130.5.769},
  abstract = {When choosing between delayed or uncertain outcomes, individuals discount the value of such outcomes on the basis of the expected time to or the likelihood of their occurrence. In an integrative review of the expanding experimental literature on discounting, the authors show that although the same form of hyperbola-like function describes discounting of both delayed and probabilistic outcomes, a variety of recent findings are inconsistent with a single-process account. The authors also review studies that compare discounting in different populations and discuss the theoretical and practical implications of the findings. The present effort illustrates the value of studying choice involving both delayed and probabilistic outcomes within a general discounting framework that uses similar experimental procedures and a common analytical approach.},
  journal = {Psychological bulletin},
  number = {5},
  pmcid = {PMC1382186},
  pmid = {15367080}
}

@article{Green_Discounting_2004a,
  title = {A {{Discounting Framework}} for {{Choice With Delayed}} and {{Probabilistic Rewards}}},
  author = {Green, Leonard and Myerson, Joel},
  year = {2004},
  month = sep,
  volume = {130},
  pages = {769--792},
  issn = {0033-2909},
  doi = {10.1037/0033-2909.130.5.769},
  abstract = {When choosing between delayed or uncertain outcomes, individuals discount the value of such outcomes on the basis of the expected time to or the likelihood of their occurrence. In an integrative review of the expanding experimental literature on discounting, the authors show that although the same form of hyperbola-like function describes discounting of both delayed and probabilistic outcomes, a variety of recent findings are inconsistent with a single-process account. The authors also review studies that compare discounting in different populations and discuss the theoretical and practical implications of the findings. The present effort illustrates the value of studying choice involving both delayed and probabilistic outcomes within a general discounting framework that uses similar experimental procedures and a common analytical approach.},
  journal = {Psychological bulletin},
  number = {5},
  pmcid = {PMC1382186},
  pmid = {15367080}
}

@article{Green_Temporal_1996,
  title = {Temporal Discounting in Choice between Delayed Rewards: The Role of Age and Income},
  shorttitle = {Temporal Discounting in Choice between Delayed Rewards},
  author = {Green, L. and Myerson, J. and Lichtman, D. and Rosen, S. and Fry, A.},
  year = {1996},
  month = mar,
  volume = {11},
  pages = {79--84},
  issn = {0882-7974},
  doi = {10.1037//0882-7974.11.1.79},
  abstract = {This study examined the effects of age and income temporal discounting (i.e. the decrease in the subjective value of a reward as the delay to its receipt increases). The value of delayed hypothetical monetary rewards was discounted at similar rates by adults of different ages but similar income levels, but at different rates by adults of similar age but different income levels. Specifically, lower income older adults showed a greater degree of temporal discounting than did either upper income older adults or upper income younger adults, but there were no age differences in discounting between the upper income groups. Comparison of these findings with those of a previous study (Green, Fry, \& Myerson, 1994) suggests that impulsivity in decision making declines rapidly in young adulthood, reaching stable levels in the 30s. Further, age and income appear to interact in determining the impulsivity of decision making by adults.},
  journal = {Psychology and Aging},
  keywords = {Adult,Aged,Aging,Choice Behavior,Female,Humans,Income,Internal-External Control,Male,Middle Aged,Motivation,Reinforcement Schedule,Time Perception},
  language = {eng},
  number = {1},
  pmid = {8726373}
}

@article{Grinband_dorsal_2011,
  title = {The Dorsal Medial Frontal Cortex Is Sensitive to Time on Task, Not Response Conflict or Error Likelihood},
  author = {Grinband, Jack and Savitskaya, Judith and Wager, Tor D. and Teichert, Tobias and Ferrera, Vincent P. and Hirsch, Joy},
  year = {2011},
  month = jul,
  volume = {57},
  pages = {303--311},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2010.12.027},
  abstract = {The dorsal medial frontal cortex (dMFC) is highly active during choice behavior. Though many models have been proposed to explain dMFC function, the conflict monitoring model is the most influential. It posits that dMFC is primarily involved in detecting interference between competing responses thus signaling the need for control. It accurately predicts increased neural activity and response time (RT) for incompatible (high-interference) vs. compatible (low-interference) decisions. However, it has been shown that neural activity can increase with time on task, even when no decisions are made. Thus, the greater dMFC activity on incompatible trials may stem from longer RTs rather than response conflict. This study shows that (1) the conflict monitoring model fails to predict the relationship between error likelihood and RT, and (2) the dMFC activity is not sensitive to congruency, error likelihood, or response conflict, but is monotonically related to time on task.},
  journal = {NeuroImage},
  number = {2}
}

@article{Gruntman_Integration_2013,
  title = {Integration of the Olfactory Code across Dendritic Claws of Single Mushroom Body Neurons},
  author = {Gruntman, Eyal and Turner, Glenn C.},
  year = {2013},
  month = dec,
  volume = {16},
  pages = {1821--1829},
  issn = {1546-1726},
  doi = {10.1038/nn.3547},
  abstract = {In the olfactory system, sensory inputs are arranged in different glomerular channels, which respond in combinatorial ensembles to the various chemical features of an odor. We investigated where and how this combinatorial code is read out deeper in the brain. We exploited the unique morphology of neurons in the Drosophila mushroom body, which receive input on large dendritic claws. Imaging odor responses of these dendritic claws revealed that input channels with distinct odor tuning converge on individual mushroom body neurons. We determined how these inputs interact to drive the cell to spike threshold using intracellular recordings to examine mushroom body responses to optogenetically controlled input. Our results provide an elegant explanation for the characteristic selectivity of mushroom body neurons: these cells receive different types of input and require those inputs to be coactive to spike. These results establish the mushroom body as an important site of integration in the fly olfactory system.},
  journal = {Nature Neuroscience},
  keywords = {Animals,Animals; Genetically Modified,Calcium,Dendrites,Drosophila,Drosophila Proteins,Electric Stimulation,Female,Luminescent Proteins,Membrane Potentials,Models; Neurological,Mushroom Bodies,Neurons,Odors,Olfactory Pathways,Patch-Clamp Techniques,Photic Stimulation,Rhodopsin,Synapses},
  language = {eng},
  number = {12},
  pmcid = {PMC3908930},
  pmid = {24141312}
}

@article{Gruntman_Integration_2013a,
  title = {Integration of the Olfactory Code across Dendritic Claws of Single Mushroom Body Neurons},
  author = {Gruntman, Eyal and Turner, Glenn C.},
  year = {2013},
  month = dec,
  volume = {16},
  pages = {1821--1829},
  issn = {1097-6256},
  doi = {10.1038/nn.3547},
  abstract = {In the olfactory system, sensory inputs are arranged in different glomerular channels, which respond in combinatorial ensembles to the various chemical features of an odor. Here we investigate where and how this combinatorial code is read out deeper in the brain. We exploit the unique morphology of neurons in the mushroom body (MB), which receive input on large dendritic claws. Imaging odor responses of these dendritic claws shows that input channels with distinct odor tuning converge on individual MB neurons. We determined how these inputs interact to drive the cell to spike threshold using intracellular recordings to examine MB responses to optogenetically controlled input. Our results provide an elegant explanation for the characteristic selectivity of MB neurons: these cells receive different types of input, and require those inputs to be coactive in order to spike. These results establish the MB as an important site of integration in the fly olfactory system.},
  journal = {Nature neuroscience},
  number = {12},
  pmcid = {PMC3908930},
  pmid = {24141312}
}

@article{Gu_Controllability_2015,
  title = {Controllability of Structural Brain Networks},
  author = {Gu, Shi and Pasqualetti, Fabio and Cieslak, Matthew and Telesford, Qawi K. and Yu, Alfred B. and Kahn, Ari E. and Medaglia, John D. and Vettel, Jean M. and Miller, Michael B. and Grafton, Scott T. and Bassett, Danielle S.},
  year = {2015},
  month = oct,
  volume = {6},
  pages = {8414},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/ncomms9414},
  abstract = {Cognitive function is driven by dynamic interactions between large-scale neural circuits or networks, enabling behaviour. However, fundamental principles constraining these dynamic network processes have remained elusive. Here we use tools from control and network theories to offer a mechanistic explanation for how the brain moves between cognitive states drawn from the network organization of white matter microstructure. Our results suggest that densely connected areas, particularly in the default mode system, facilitate the movement of the brain to many easily reachable states. Weakly connected areas, particularly in cognitive control systems, facilitate the movement of the brain to difficult-to-reach states. Areas located on the boundary between network communities, particularly in attentional control systems, facilitate the integration or segregation of diverse cognitive systems. Our results suggest that structural network differences between cognitive circuits dictate their distinct roles in controlling trajectories of brain network function.},
  copyright = {2015 The Author(s)},
  journal = {Nature Communications},
  keywords = {unread},
  language = {en},
  number = {1}
}

@article{Gureckis_Shortterm_2009,
  title = {Short-Term Gains, Long-Term Pains: {{How}} Cues about State Aid Learning in Dynamic Environments},
  shorttitle = {Short-Term Gains, Long-Term Pains},
  author = {Gureckis, Todd M. and Love, Bradley C.},
  year = {2009},
  month = dec,
  volume = {113},
  pages = {293--313},
  issn = {0010-0277},
  doi = {10.1016/j.cognition.2009.03.013},
  abstract = {Successful investors seeking returns, animals foraging for food, and pilots controlling aircraft all must take into account how their current decisions will impact their future standing. One challenge facing decision makers is that options that appear attractive in the short-term may not turn out best in the long run. In this paper, we explore human learning in a dynamic decision making task which places short- and long-term rewards in conflict. Our goal in these studies was to evaluate how people's mental representation of a task affects their ability to discover an optimal decision strategy. We find that perceptual cues that readily align with the underlying state of the task environment help people overcome the impulsive appeal of short-term rewards. Our experimental manipulations, predictions, and analyses are motivated by current work in reinforcement learning which details how learners value delayed outcomes in sequential tasks and the importance that ``state'' identification plays in effective learning.},
  journal = {Cognition},
  keywords = {Decision Making,Dynamic control task,Learning,Q-learning,Reinforcement learning,Self-control,State,Temporal difference,Temporal discounting},
  number = {3},
  series = {Reinforcement Learning and Higher Cognition}
}

@article{Gutig_tempotron_2006,
  title = {The Tempotron: A Neuron That Learns Spike Timing\textendash Based Decisions},
  shorttitle = {The Tempotron},
  author = {G{\"u}tig, Robert and Sompolinsky, Haim},
  year = {2006},
  month = mar,
  volume = {9},
  pages = {420--428},
  issn = {1097-6256},
  doi = {10.1038/nn1643},
  abstract = {The timing of action potentials in sensory neurons contains substantial information about the eliciting stimuli. Although the computational advantages of spike timing\textendash based neuronal codes have long been recognized, it is unclear whether, and if so how, neurons can learn to read out such representations. We propose a new, biologically plausible supervised synaptic learning rule that enables neurons to efficiently learn a broad range of decision rules, even when information is embedded in the spatiotemporal structure of spike patterns rather than in mean firing rates. The number of categorizations of random spatiotemporal patterns that a neuron can implement is several times larger than the number of its synapses. The underlying nonlinear temporal computation allows neurons to access information beyond single-neuron statistics and to discriminate between inputs on the basis of multineuronal spike statistics. Our work demonstrates the high capacity of neural systems to learn to decode information embedded in distributed patterns of spike synchrony. Note: The PDF version of this article was corrected on the 14th of February, and the HTML version on the 16th of February. Please see the PDF for details.},
  copyright = {\textcopyright{} 2006 Nature Publishing Group},
  journal = {Nature Neuroscience},
  language = {en},
  number = {3}
}

@article{Haar_Motor_2020,
  title = {Motor Learning in Real-World Pool Billiards},
  author = {Haar, Shlomi and {van Assel}, Camille M. and Faisal, A. Aldo},
  year = {2020},
  month = nov,
  volume = {10},
  issn = {2045-2322},
  doi = {10.1038/s41598-020-76805-9},
  abstract = {The neurobehavioral mechanisms of human motor-control and learning evolved in free behaving, real-life settings, yet this is studied mostly in reductionistic lab-based experiments. Here we take a step towards a more real-world motor neuroscience using wearables for naturalistic full-body motion-tracking and the sports of pool billiards to frame a real-world skill learning experiment. First, we asked if well-known features of motor learning in lab-based experiments generalize to a real-world task. We found similarities in many features such as multiple learning rates, and the relationship between task-related variability and motor learning. Our data-driven approach reveals the structure and complexity of movement, variability, and motor learning, enabling an in-depth understanding of the structure of motor learning in three ways: First, while expecting most of the movement learning is done by the cue-wielding arm, we find that motor learning affects the whole body, changing motor-control from head to toe. Second, during learning, all subjects decreased their movement variability and their variability in the outcome. Subjects who were initially more variable were also more variable after learning. Lastly, when screening the link across subjects between initial variability in individual joints and learning, we found that only the initial variability in the right forearm supination shows a significant correlation to the subjects' learning rates. This is in-line with the relationship between learning and variability: while learning leads to an overall reduction in movement variability, only initial variability in specific task-relevant dimensions can facilitate faster learning.},
  journal = {Scientific Reports},
  pmcid = {PMC7674448},
  pmid = {33208785}
}

@article{Hagger_Ego_2010,
  title = {Ego Depletion and the Strength Model of Self-Control: A Meta-Analysis},
  shorttitle = {Ego Depletion and the Strength Model of Self-Control},
  author = {Hagger, Martin S. and Wood, Chantelle and Stiff, Chris and Chatzisarantis, Nikos L. D.},
  year = {2010},
  month = jul,
  volume = {136},
  pages = {495--525},
  issn = {1939-1455},
  doi = {10.1037/a0019486},
  abstract = {According to the strength model, self-control is a finite resource that determines capacity for effortful control over dominant responses and, once expended, leads to impaired self-control task performance, known as ego depletion. A meta-analysis of 83 studies tested the effect of ego depletion on task performance and related outcomes, alternative explanations and moderators of the effect, and additional strength model hypotheses. Results revealed a significant effect of ego depletion on self-control task performance. Significant effect sizes were found for ego depletion on effort, perceived difficulty, negative affect, subjective fatigue, and blood glucose levels. Small, nonsignificant effects were found for positive affect and self-efficacy. Moderator analyses indicated minimal variation in the effect across sphere of depleting and dependent task, frequently used depleting and dependent tasks, presentation of tasks as single or separate experiments, type of dependent measure and control condition task, and source laboratory. The effect size was moderated by depleting task duration, task presentation by the same or different experimenters, intertask interim period, dependent task complexity, and use of dependent tasks in the choice and volition and cognitive spheres. Motivational incentives, training on self-control tasks, and glucose supplementation promoted better self-control in ego-depleted samples. Expecting further acts of self-control exacerbated the effect. Findings provide preliminary support for the ego-depletion effect and strength model hypotheses. Support for motivation and fatigue as alternative explanations for ego depletion indicate a need to integrate the strength model with other theories. Findings provide impetus for future investigation testing additional hypotheses and mechanisms of the ego-depletion effect.},
  journal = {Psychological Bulletin},
  keywords = {Ego,Humans,Internal-External Control,Models; Psychological,Self Concept,Task Performance and Analysis},
  language = {eng},
  number = {4},
  pmid = {20565167}
}

@article{Haken_Dynamic_1990,
  title = {Dynamic Pattern Recognition of Coordinated Biological Motion},
  author = {Haken, H. and Kelso, J. A. S. and Fuchs, A. and Pandya, A. S.},
  year = {1990},
  month = jan,
  volume = {3},
  pages = {395--401},
  issn = {0893-6080},
  doi = {10.1016/0893-6080(90)90022-D},
  abstract = {We develop an algorithm that enables the identification and categorization of visually created patterns of coordinated biological motion, specifically, different multijoint limb trajectories produced by humans. The algorithm uses identified collective variables or order parameters as the basis for encoding these patterns, obtained through experimental studies of phase transitions by Kelso and colleagues. Thus, meaningful information for recognizing dynamic visual patterns resides in attractors of the order parameter dynamics. In a neural net, these order parameters represent different macrostates of the net as a whole (rather than the interactions of single neurons), thereby constituting a synergetically organized neural field, in the fashion of a Gestalt-like process.},
  journal = {Neural Networks},
  language = {en},
  number = {4}
}

@article{Hamilton_Controlling_2002,
  title = {Controlling the {{Statistics}} of {{Action}}: {{Obstacle Avoidance}}},
  shorttitle = {Controlling the {{Statistics}} of {{Action}}},
  author = {Hamilton, Antonia F. de C. and Wolpert, Daniel M.},
  year = {2002},
  month = may,
  volume = {87},
  pages = {2434--2440},
  publisher = {{American Physiological Society}},
  issn = {0022-3077},
  doi = {10.1152/jn.2002.87.5.2434},
  abstract = {Task optimization in the presence of signal-dependent noise (TOPS) has been proposed as a general framework for planning goal-directed movements. Within this framework, the motor command is assumed to be corrupted by signal-dependent noise, which leads to a distribution of possible movements. A task can then be equated with optimizing some function of the statistics of this distribution. We found the optimal trajectory for obstacle avoidance by minimizing the mean-squared error at the end of the movement while keeping the probability of collision with the obstacle below a fixed limit. The optimal paths accurately predicted the empirical trajectories. This demonstrates that controlling the statistics of movements in the presence of signal-dependent noise may be a fundamental and unifying principle of goal-directed movements.},
  journal = {Journal of Neurophysiology},
  number = {5}
}

@article{Hansson_Function_2000,
  title = {Function and {{Morphology}} of the {{Antennal Lobe}}: {{New Developments}}},
  shorttitle = {Function and {{Morphology}} of the {{Antennal Lobe}}},
  author = {Hansson, B. S. and Anton, S.},
  year = {2000},
  volume = {45},
  pages = {203--231},
  doi = {10.1146/annurev.ento.45.1.203},
  abstract = {The antennal lobe of insects has emerged as an excellent model for olfactory processing in the CNS. In the present review we compile data from areas where substantial progress has been made during recent years: structure-function relationships within the glomerular array, integration and blend specificity, time coding and the effects of neuroactive substances and hormones on antennal lobe processing.},
  journal = {Annual Review of Entomology},
  keywords = {integration,neuroethology,olfaction,pharmacology,time coding},
  number = {1},
  pmid = {10761576}
}

@article{Hanuschkin_reafferent_2011,
  title = {A Reafferent and Feed-Forward Model of Song Syntax Generation in the {{Bengalese}} Finch},
  author = {Hanuschkin, Alexander and Diesmann, Markus and Morrison, Abigail},
  year = {2011},
  month = mar,
  volume = {31},
  pages = {509--532},
  issn = {0929-5313, 1573-6873},
  doi = {10.1007/s10827-011-0318-z},
  abstract = {Adult Bengalese finches generate a variable song that obeys a distinct and individual syntax. The syntax is gradually lost over a period of days after deafening and is recovered when hearing is restored. We present a spiking neuronal network model of the song syntax generation and its loss, based on the assumption that the syntax is stored in reafferent connections from the auditory to the motor control area. Propagating synfire activity in the HVC codes for individual syllables of the song and priming signals from the auditory network reduce the competition between syllables to allow only those transitions that are permitted by the syntax. Both imprinting of song syntax within HVC and the interaction of the reafferent signal with an efference copy of the motor command are sufficient to explain the gradual loss of syntax in the absence of auditory feedback. The model also reproduces for the first time experimental findings on the influence of altered auditory feedback on the song syntax generation, and predicts song- and species-specific low frequency components in the LFP. This study illustrates how sequential compositionality following a defined syntax can be realized in networks of spiking neurons.},
  journal = {Journal of Computational Neuroscience},
  keywords = {Bengalese finch,Compositionality,Efference copy,Feed-forward network,Human Genetics,HVC,motor control,Neurology,Neurosciences,Reafferent,Spike synchrony,Synfire chains,Syntax generation,Theory of Computation},
  language = {en},
  number = {3}
}

@article{Harris_Signaldependent_1998,
  title = {Signal-Dependent Noise Determines Motor Planning},
  author = {Harris, C. M. and Wolpert, D. M.},
  year = {1998},
  month = aug,
  volume = {394},
  pages = {780--784},
  issn = {0028-0836},
  doi = {10.1038/29528},
  abstract = {When we make saccadic eye movements or goal-directed arm movements, there is an infinite number of possible trajectories that the eye or arm could take to reach the target. However, humans show highly stereotyped trajectories in which velocity profiles of both the eye and hand are smooth and symmetric for brief movements. Here we present a unifying theory of eye and arm movements based on the single physiological assumption that the neural control signals are corrupted by noise whose variance increases with the size of the control signal. We propose that in the presence of such signal-dependent noise, the shape of a trajectory is selected to minimize the variance of the final eye or arm position. This minimum-variance theory accurately predicts the trajectories of both saccades and arm movements and the speed-accuracy trade-off described by Fitt's law. These profiles are robust to changes in the dynamics of the eye or arm, as found empirically. Moreover, the relation between path curvature and hand velocity during drawing movements reproduces the empirical 'two-thirds power law. This theory provides a simple and powerful unifying perspective for both eye and arm movement control.},
  journal = {Nature},
  keywords = {Animals,Arm,Haplorhini,Humans,Models; Neurological,Motor Activity,Motor Neurons,Saccades},
  language = {eng},
  number = {6695},
  pmid = {9723616}
}

@article{Hartley_WellWorn_2003,
  title = {The {{Well}}-{{Worn Route}} and the {{Path Less Traveled}}: {{Distinct Neural Bases}} of {{Route Following}} and {{Wayfinding}} in {{Humans}}},
  shorttitle = {The {{Well}}-{{Worn Route}} and the {{Path Less Traveled}}},
  author = {Hartley, Tom and Maguire, Eleanor A. and Spiers, Hugo J. and Burgess, Neil},
  year = {2003},
  month = mar,
  volume = {37},
  pages = {877--888},
  issn = {0896-6273},
  doi = {10.1016/S0896-6273(03)00095-3},
  abstract = {Finding one's way in a large-scale environment may engage different cognitive processes than following a familiar route. The neural bases of these processes were investigated using functional MRI (fMRI). Subjects found their way in one virtual-reality town and followed a well-learned route in another. In a control condition, subjects followed a visible trail. Within subjects, accurate wayfinding activated the right posterior hippocampus. Between-subjects correlations with performance showed that good navigators (i.e., accurate wayfinders) activated the anterior hippocampus during wayfinding and head of caudate during route following. These results coincide with neurophysiological evidence for distinct response (caudate) and place (hippocampal) representations supporting navigation. We argue that the type of representation used influences both performance and concomitant fMRI activation patterns.},
  journal = {Neuron},
  number = {5}
}

@article{Hartmann_Parabolic_2013,
  title = {Parabolic Discounting of Monetary Rewards by Physical Effort},
  author = {Hartmann, Matthias N. and Hager, Oliver M. and Tobler, Philippe N. and Kaiser, Stefan},
  year = {2013},
  month = nov,
  volume = {100},
  pages = {192--196},
  issn = {0376-6357},
  doi = {10.1016/j.beproc.2013.09.014},
  abstract = {When humans and other animals make decisions in their natural environments prospective rewards have to be weighed against costs. It is well established that increasing costs lead to devaluation or discounting of reward. While our knowledge about discount functions for time and probability costs is quite advanced, little is known about how physical effort discounts reward. In the present study we compared three different models in a binary choice task in which human participants had to squeeze a handgrip to earn monetary rewards: a linear, a hyperbolic, and a parabolic model. On the group as well as the individual level, the concave parabolic model explained most variance of the choice data, thus contrasting with the typical hyperbolic discounting of reward value by delay. Research on effort discounting is not only important to basic science but also holds the potential to quantify aberrant motivational states in neuropsychiatric disorders.},
  journal = {Behavioural Processes},
  keywords = {Decision-making,Discounting,Effort discounting,Effort-based decision making,Reward,unread}
}

@article{Hasson_Hierarchy_2008,
  title = {A {{Hierarchy}} of {{Temporal Receptive Windows}} in {{Human Cortex}}},
  author = {Hasson, Uri and Yang, Eunice and Vallines, Ignacio and Heeger, David J. and Rubin, Nava},
  year = {2008},
  month = mar,
  volume = {28},
  pages = {2539--2550},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.5487-07.2008},
  abstract = {Real-world events unfold at different time scales and, therefore, cognitive and neuronal processes must likewise occur at different time scales. We present a novel procedure that identifies brain regions responsive to sensory information accumulated over different time scales. We measured functional magnetic resonance imaging activity while observers viewed silent films presented forward, backward, or piecewise-scrambled in time. Early visual areas (e.g., primary visual cortex and the motion-sensitive area MT+) exhibited high response reliability regardless of disruptions in temporal structure. In contrast, the reliability of responses in several higher brain areas, including the superior temporal sulcus (STS), precuneus, posterior lateral sulcus (LS), temporal parietal junction (TPJ), and frontal eye field (FEF), was affected by information accumulated over longer time scales. These regions showed highly reproducible responses for repeated forward, but not for backward or piecewise-scrambled presentations. Moreover, these regions exhibited marked differences in temporal characteristics, with LS, TPJ, and FEF responses depending on information accumulated over longer durations ({$\sim$}36 s) than STS and precuneus ({$\sim$}12 s). We conclude that, similar to the known cortical hierarchy of spatial receptive fields, there is a hierarchy of progressively longer temporal receptive windows in the human brain.},
  copyright = {Copyright \textcopyright{} 2008 Society for Neuroscience 0270-6474/08/282539-12\$15.00/0},
  journal = {Journal of Neuroscience},
  keywords = {cortex,fMRI,functional organization,receptive fields,temporal coding,time},
  language = {en},
  number = {10},
  pmid = {18322098}
}

@article{Hayden_Economic_2018,
  title = {Economic Choice: The Foraging Perspective},
  shorttitle = {Economic Choice},
  author = {Hayden, Benjamin Y},
  year = {2018},
  month = dec,
  volume = {24},
  pages = {1--6},
  issn = {2352-1546},
  doi = {10.1016/j.cobeha.2017.12.002},
  abstract = {Foraging theory offers an alternative foundation for understanding economic choice, one that sees economic choices as the outcome of psychological processes that evolved to help our ancestors search for food. Most of the choices encountered by foragers are between pursuing an encountered prey (accept) and ignoring it in favor of continued search (reject). Binary choices, which typically occur between simultaneously presented items, are special case, and are resolved through paired alternating accept\textendash reject decisions limited by the narrow focus of attention. The foraging approach also holds out promise for helping to understand self-control and invites a reconceptualization of the mechanisms of binary choice, the relationship between choosing and stopping, and of the meaning of reward value.},
  journal = {Current Opinion in Behavioral Sciences},
  series = {Survival Circuits}
}

@article{Hayden_Surprise_2011,
  title = {Surprise {{Signals}} in {{Anterior Cingulate Cortex}}: {{Neuronal Encoding}} of {{Unsigned Reward Prediction Errors Driving Adjustment}} in {{Behavior}}},
  shorttitle = {Surprise {{Signals}} in {{Anterior Cingulate Cortex}}},
  author = {Hayden, Benjamin Y. and Heilbronner, Sarah R. and Pearson, John M. and Platt, Michael L.},
  year = {2011},
  month = mar,
  volume = {31},
  pages = {4178--4187},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.4652-10.2011},
  abstract = {In attentional models of learning, associations between actions and subsequent rewards are stronger when outcomes are surprising, regardless of their valence. Despite the behavioral evidence that surprising outcomes drive learning, neural correlates of unsigned reward prediction errors remain elusive. Here we show that in a probabilistic choice task, trial-to-trial variations in preference track outcome surprisingness. Concordant with this behavioral pattern, responses of neurons in macaque (Macaca mulatta) dorsal anterior cingulate cortex (dACC) to both large and small rewards were enhanced when the outcome was surprising. Moreover, when, on some trials, probabilities were hidden, neuronal responses to rewards were reduced, consistent with the idea that the absence of clear expectations diminishes surprise. These patterns are inconsistent with the idea that dACC neurons track signed errors in reward prediction, as dopamine neurons do. Our results also indicate that dACC neurons do not signal conflict. In the context of other studies of dACC function, these results suggest a link between reward-related modulations in dACC activity and attention and motor control processes involved in behavioral adjustment. More speculatively, these data point to a harmonious integration between reward and learning accounts of ACC function on one hand, and attention and cognitive control accounts on the other.},
  journal = {The Journal of Neuroscience},
  language = {en},
  number = {11},
  pmid = {21411658}
}

@book{Haykin_Kalman_2001,
  title = {Kalman {{Filtering}} and {{Neural Networks}}},
  editor = {Haykin, Simon},
  year = {2001},
  publisher = {{John Wiley \& Sons, Inc.}},
  abstract = {This self-contained book, consisting of seven chapters, is devoted to Kalman filter theory applied to the training and use of neural networks, and some applications of learning algorithms derived in this way. It is organized as follows: - Chapter 1 presents an introductory treatment of Kalman filters, with emphasis on basic Kalman filter theory, the Rauch-Tung-Striebel smoother, and the extended Kalman filter. - Chapter 2 presents the theoretical basis of a powerful learning algorithm for the training of feedforward and recurrent multilayered perceptrons, based on the decoupled extended Kalman filter (DEKF); the theory presented here also includes a novel technique called multistreaming. - Chapters 3 and 4 present applications of the DEKF learning algorithm to the study of image sequences and the dynamic reconstruction of chaotic processes, respectively. - Chapter 5 studies the dual estimation problem, which refers to the problem of simultaneously estimating the state of a nonlinear dynamical system and the model that gives rise to the underlying dynamics of the system. - Chapter 6 studies how to learn stochastic nonlinear dynamics. This difficult learning task is solved in an elegant manner by combining two algorithms: 1. The expectation-maximization (EM) algorithm, which provides an iterative procedure for maximum-likelihood estimation with missing hidden variables. 2. The extended Kalman smoothing (EKS) algorithm for a refined estimation of the state. - Chapter 7 studies yet another novel idea the unscented Kalman filter the performance of which is superior to that of the extended Kalman filter. Except for Chapter 1, all the other chapters present illustrative applications of the learning algorithms described here, some of which involve the use of simulated as well as real-life data. Much of the material presented here has not appeared in book form before. This volume should be of serious interest to researchers in neural networks and nonlinear dynamical systems.}
}

@article{Heinbockel_Glomerular_2013,
  title = {Glomerular Interactions in Olfactory Processing Channels of the Antennal Lobes},
  author = {Heinbockel, Thomas and Shields, Vonnie D. C. and Reisenman, Carolina E.},
  year = {2013},
  month = nov,
  volume = {199},
  pages = {929--946},
  issn = {0340-7594},
  doi = {10.1007/s00359-013-0842-6},
  abstract = {An open question in olfactory coding is the extent of interglomerular connectivity: do olfactory glomeruli and their neurons regulate the odorant responses of neurons innervating other glomeruli? In the olfactory system of the moth Manduca sexta, the response properties of different types of antennal olfactory receptor cells are known. Likewise, a subset of antennal lobe glomeruli has been functionally characterized and the olfactory tuning of their innervating neurons identified. This provides a unique opportunity to determine functional interactions between glomeruli of known input, specifically, (1) glomeruli processing plant odors and (2) glomeruli activated by antennal stimulation with pheromone components of conspecific females. Several studies describe reciprocal inhibitory effects between different types of pheromone-responsive projection neurons suggesting lateral inhibitory interactions between pheromone component-selective glomerular neural circuits. Furthermore, antennal lobe projection neurons that respond to host plant volatiles and innervate single, ordinary glomeruli are inhibited during antennal stimulation with the female's sex pheromone. The studies demonstrate the existence of lateral inhibitory effects in response to behaviorally significant odorant stimuli and irrespective of glomerular location in the antennal lobe. Inhibitory interactions are present within and between olfactory subsystems (pheromonal and non-pheromonal subsystems), potentially to enhance contrast and strengthen odorant discrimination.},
  journal = {Journal of comparative physiology. A, Neuroethology, sensory, neural, and behavioral physiology},
  number = {11},
  pmcid = {PMC4066976},
  pmid = {23893248}
}

@article{Heisenberg_Mushroom_2003,
  title = {Mushroom Body Memoir: From Maps to Models},
  shorttitle = {Mushroom Body Memoir},
  author = {Heisenberg, Martin},
  year = {2003},
  month = apr,
  volume = {4},
  pages = {266--275},
  issn = {1471-003X},
  doi = {10.1038/nrn1074},
  abstract = {Genetic intervention in the fly Drosophila melanogaster has provided strong evidence that the mushroom bodies of the insect brain act as the seat of a memory trace for odours. This localization gives the mushroom bodies a place in a network model of olfactory memory that is based on the functional anatomy of the olfactory system. In the model, complex odour mixtures are assumed to be represented by activated sets of intrinsic mushroom body neurons. Conditioning renders an extrinsic mushroom-body output neuron specifically responsive to such a set. Mushroom bodies have a second, less understood function in the organization of the motor output. The development of a circuit model that also addresses this function might allow the mushroom bodies to throw light on the basic operating principles of the brain.},
  copyright = {\textcopyright{} 2003 Nature Publishing Group},
  journal = {Nature Reviews Neuroscience},
  language = {en},
  number = {4}
}

@article{Henry_Increased_1960,
  title = {Increased {{Response Latency}} for {{Complicated Movements}} and {{A}} ``{{Memory Drum}}'' {{Theory}} of {{Neuromotor Reaction}}},
  author = {Henry, Franklin M. and Rogers, Donald E.},
  year = {1960},
  month = oct,
  volume = {31},
  pages = {448--458},
  publisher = {{Routledge}},
  issn = {1067-1188},
  doi = {10.1080/10671188.1960.10762052},
  abstract = {The theory proposes a nonconscious mechanism that uses stored information (motor memory) to channel existing nervous impulses from brain waves and general afferent stimuli into the appropriate neuromotor coordination centers, subcenters, and efferent nerves, thus causing the desired movement. A consequent hypothesis requires that the simple reaction time will become longer when the response movement is required to be of greater complexity. Data obtained on college men and women, and 12- and 8-year-old boys, are in agreement with the hypothesis. Replacing a very simple finger movement with an arm movement of moderate complexity slows the reaction by about 20 percent; additional complexity produces a further slowing of 7 percent. The speed of the arm movement is considerably faster in college men than in younger boys or in college women. The correlation between reaction time and speed of movement averages approximately zero. Individual differences in ability to make a fast arm movement are about 70 percent specific to the particular movement being made; ``general ability for arm speed'' occurs only to the extent of 30 percent.},
  annotation = {\_eprint: https://doi.org/10.1080/10671188.1960.10762052},
  journal = {Research Quarterly. American Association for Health, Physical Education and Recreation},
  number = {3}
}

@article{Hertwig_Experimental_2001,
  title = {Experimental Practices in Economics: A Methodological Challenge for Psychologists?},
  shorttitle = {Experimental Practices in Economics},
  author = {Hertwig, R. and Ortmann, A.},
  year = {2001},
  month = jun,
  volume = {24},
  pages = {383-403; discussion 403-451},
  issn = {0140-525X},
  abstract = {This target article is concerned with the implications of the surprisingly different experimental practices in economics and in areas of psychology relevant to both economists and psychologists, such as behavioral decision making. We consider four features of experimentation in economics, namely, script enactment, repeated trials, performance-based monetary payments, and the proscription against deception, and compare them to experimental practices in psychology, primarily in the area of behavioral decision making. Whereas economists bring a precisely defined "script" to experiments for participants to enact, psychologists often do not provide such a script, leaving participants to infer what choices the situation affords. By often using repeated experimental trials, economists allow participants to learn about the task and the environment; psychologists typically do not. Economists generally pay participants on the basis of clearly defined performance criteria; psychologists usually pay a flat fee or grant a fixed amount of course credit. Economists virtually never deceive participants; psychologists, especially in some areas of inquiry, often do. We argue that experimental standards in economics are regulatory in that they allow for little variation between the experimental practices of individual researchers. The experimental standards in psychology, by contrast, are comparatively laissez-faire. We believe that the wider range of experimental practices in psychology reflects a lack of procedural regularity that may contribute to the variability of empirical findings in the research fields under consideration. We conclude with a call for more research on the consequences of methodological preferences, such as the use on monetary payments, and propose a "do-it-both-ways" rule regarding the enactment of scripts, repetition of trials, and performance-based monetary payments. We also argue, on pragmatic grounds, that the default practice should be not to deceive participants.},
  journal = {The Behavioral and Brain Sciences},
  keywords = {Deception,Decision Making,Economics,Humans,Knowledge of Results (Psychology),Learning,Motivation,Practice (Psychology),Psychological Theory,Psychology,Research Design,Reward,Role Playing},
  language = {eng},
  number = {3},
  pmid = {11682798}
}

@article{Hesselmann_Spontaneous_2008,
  title = {Spontaneous Local Variations in Ongoing Neural Activity Bias Perceptual Decisions},
  author = {Hesselmann, Guido and Kell, Christian A. and Eger, Evelyn and Kleinschmidt, Andreas},
  year = {2008},
  month = aug,
  volume = {105},
  pages = {10984--10989},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.0712043105},
  abstract = {Neural variability in responding to identical repeated stimuli has been related to trial-by-trial fluctuations in ongoing activity, yet the neural and perceptual consequences of these fluctuations remain poorly understood. Using functional neuroimaging, we recorded brain activity in subjects who reported perceptual decisions on an ambiguous figure, Rubin's vase-faces picture, which was briefly presented at variable intervals of {$\geq$}20 s. Prestimulus activity in the fusiform face area, a cortical region preferentially responding to faces, was higher when subjects subsequently perceived faces instead of the vase. This finding suggests that endogenous variations in prestimulus neuronal activity biased subsequent perceptual inference. Furnishing evidence that evoked sensory responses, we then went on to show that the pre- and poststimulus activity interact in a nonlinear way and the ensuing perceptual decisions depend upon the prestimulus context in which they occur.},
  journal = {Proceedings of the National Academy of Sciences},
  keywords = {BOLD fMRI,fusiform face area,ongoing activity,prestimulus activity,Visual Perception},
  language = {en},
  number = {31},
  pmid = {18664576}
}

@article{Hey_Investigating_1994,
  title = {Investigating {{Generalizations}} of {{Expected Utility Theory Using Experimental Data}}},
  author = {Hey, John D. and Orme, Chris},
  year = {1994},
  volume = {62},
  pages = {1291--1326},
  issn = {0012-9682},
  doi = {10.2307/2951750},
  abstract = {A number of generalizations of the expected utility preference functional are estimated using experimentally generated data involving 100 pairwise choice questions repeated on two separate occasions. Likelihood ratio tests are conducted to investigate the statistical superiority of the various generalizations, and the Akaike information criterion is used to distinguish between them. The economic superiority of the various generalizations is also explored and the paper concludes that, for many subjects, the superiority of several of the generalizations is not established.},
  journal = {Econometrica},
  number = {6}
}

@article{Hofmann_Optimal_2001,
  title = {The {{Optimal Discretization}} of {{Stochastic Differential Equations}}},
  author = {Hofmann, Norbert and {M{\"u}ller-Gronbach}, Thomas and Ritter, Klaus},
  year = {2001},
  month = mar,
  volume = {17},
  pages = {117--153},
  issn = {0885-064X},
  doi = {10.1006/jcom.2000.0570},
  abstract = {We study pathwise approximation of scalar stochastic differential equations. The mean squared L2-error and the expected number n of evaluations of the driving Brownian motion are used for the comparison of arbitrary methods. We introduce an adaptive discretization that reflects the local properties of every single trajectory. The corresponding error tends to zero like c{$\cdot$}n-1/2, where c is the average of the diffusion coefficient in space and time. Our method is justified by the matching lower bound for arbitrary methods that are based on n evaluations on the average. Hence the adaptive discretization is asymptotically optimal. The new method is very easy to implement, and about 7 additional arithmetical operations are needed per evaluation of the Brownian motion. Hereby we can determine the complexity of pathwise approximation of stochastic differential equations. We illustrate the power of our method already for moderate accuracies by means of a simulation experiment.},
  journal = {Journal of Complexity},
  keywords = {adaptive discretization,asymptotic optimality,complexity,lower bounds,pathwise approximation,stochastic differential equation},
  number = {1}
}

@article{Hogan_organizing_1984,
  title = {An Organizing Principle for a Class of Voluntary Movements},
  author = {Hogan, N.},
  year = {1984},
  month = nov,
  volume = {4},
  pages = {2745--2754},
  publisher = {{Society for Neuroscience}},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.04-11-02745.1984},
  abstract = {This paper presents a mathematical model which predicts both the major qualitative features and, within experimental error, the quantitative details of a class of perturbed and unperturbed large-amplitude, voluntary movements performed at intermediate speed by primates. A feature of the mathematical model is that a concise description of the behavioral organization of the movement has been formulated which is separate and distinct from the description of the dynamics of movement execution. Based on observations of voluntary movements in primates, the organization has been described as though the goal were to make the smoothest movement possible under the circumstances, i.e., to minimize the accelerative transients. This has been formalized by using dynamic optimization theory to determine the movement which minimizes the rate of change of acceleration (jerk) of the limb. Based on observations of muscle mechanics, the concept of a ``virtual position'' determined by the active states of the muscles is rigorously defined as one of the mechanical consequences of the neural commands to the muscles. This provides insight into the mechanics of perturbed and unperturbed movements and is a useful aid in the separation of the descriptions of movement organization and movement execution.},
  chapter = {Articles},
  copyright = {\textcopyright{} 1984 by Society for Neuroscience},
  journal = {Journal of Neuroscience},
  language = {en},
  number = {11},
  pmid = {6502203}
}

@article{Holroyd_Motivation_2012,
  title = {Motivation of Extended Behaviors by Anterior Cingulate Cortex},
  author = {Holroyd, Clay B. and Yeung, Nick},
  year = {2012},
  month = feb,
  volume = {16},
  pages = {122--128},
  issn = {1879-307X},
  doi = {10.1016/j.tics.2011.12.008},
  abstract = {Intense research interest over the past decade has yielded diverse and often discrepant theories about the function of anterior cingulate cortex (ACC). In particular, a dichotomy has emerged between neuropsychological theories suggesting a primary role for ACC in motivating or 'energizing' behavior, and neuroimaging-inspired theories emphasizing its contribution to cognitive control and reinforcement learning. To reconcile these views, we propose that ACC supports the selection and maintenance of 'options' - extended, context-specific sequences of behavior directed toward particular goals - that are learned through a process of hierarchical reinforcement learning. This theory accounts for ACC activity in relation to learning and control while simultaneously explaining the effects of ACC damage as disrupting the motivational context supporting the production of goal-directed action sequences.},
  journal = {Trends in Cognitive Sciences},
  keywords = {Akinetic Mutism,Behavior,Dopamine,Goals,Gyrus Cinguli,Humans,Motivation,Psychomotor Performance,Reinforcement (Psychology)},
  language = {eng},
  number = {2},
  pmid = {22226543}
}

@article{Holroyd_Motivation_2012a,
  title = {Motivation of Extended Behaviors by Anterior Cingulate Cortex},
  author = {Holroyd, Clay B. and Yeung, Nick},
  year = {2012},
  month = feb,
  volume = {16},
  pages = {122--128},
  issn = {1364-6613},
  doi = {10.1016/j.tics.2011.12.008},
  abstract = {Intense research interest over the past decade has yielded diverse and often discrepant theories about the function of anterior cingulate cortex (ACC). In particular, a dichotomy has emerged between neuropsychological theories suggesting a primary role for ACC in motivating or `energizing' behavior, and neuroimaging-inspired theories emphasizing its contribution to cognitive control and reinforcement learning. To reconcile these views, we propose that ACC supports the selection and maintenance of `options' \textendash{} extended, context-specific sequences of behavior directed toward particular goals \textendash{} that are learned through a process of hierarchical reinforcement learning. This theory accounts for ACC activity in relation to learning and control while simultaneously explaining the effects of ACC damage as disrupting the motivational context supporting the production of goal-directed action sequences.},
  journal = {Trends in Cognitive Sciences},
  number = {2}
}

@article{Homberg_Structure_1989,
  title = {Structure and {{Function}} of the {{Deutocerebrum}} in {{Insects}}},
  author = {Homberg, U and Christensen, T A and Hildebrand, J G},
  year = {1989},
  volume = {34},
  pages = {477--501},
  doi = {10.1146/annurev.en.34.010189.002401},
  journal = {Annual Review of Entomology},
  number = {1},
  pmid = {2648971}
}

@article{Hommel_Theory_2001,
  title = {The {{Theory}} of {{Event Coding}} ({{TEC}}): {{A}} Framework for Perception and Action Planning},
  shorttitle = {The {{Theory}} of {{Event Coding}} ({{TEC}})},
  author = {Hommel, Bernhard and M{\"u}sseler, Jochen and Aschersleben, Gisa and Prinz, Wolfgang},
  year = {2001},
  month = oct,
  volume = {24},
  pages = {849--878},
  issn = {1469-1825},
  doi = {10.1017/S0140525X01000103},
  abstract = {Traditional approaches to human information processing tend to deal with perception and action planning in isolation, so that an adequate account of the perception-action interface is still missing. On the perceptual side, the dominant cognitive view largely underestimates, and thus fails to account for, the impact of action-related processes on both the processing of perceptual information and on perceptual learning. On the action side, most approaches conceive of action planning as a mere continuation of stimulus processing, thus failing to account for the goal-directedness of even the simplest reaction in an experimental task. We propose a new framework for a more adequate theoretical treatment of perception and action planning, in which perceptual contents and action plans are coded in a common representational medium by feature codes with distal reference. Perceived events (perceptions) and to-be-produced events (actions) are equally represented by integrated, task-tuned networks of feature codes \textendash{} cognitive structures we call event codes. We give an overview of evidence from a wide variety of empirical domains, such as spatial stimulus-response compatibility, sensorimotor synchronization, and ideomotor action, showing that our main assumptions are well supported by the data.},
  journal = {Behavioral and Brain Sciences},
  number = {05}
}

@article{Hommel_Theory_2019,
  title = {Theory of {{Event Coding}} ({{TEC}}) {{V2}}.0: {{Representing}} and Controlling Perception and Action},
  shorttitle = {Theory of {{Event Coding}} ({{TEC}}) {{V2}}.0},
  author = {Hommel, Bernhard},
  year = {2019},
  month = oct,
  volume = {81},
  pages = {2139--2154},
  publisher = {{Springer}},
  address = {{New York}},
  issn = {1943-3921},
  doi = {10.3758/s13414-019-01779-4},
  abstract = {This article provides an update of the Theory of Event Coding (TEC), which claims that perception and action are identical processes operating on the same codes - event files consisting of integrated networks of sensorimotor feature codes. The original version of the theory emphasized its representational underpinnings, but recent theoretical developments provide the basis for a more integrated view consisting of both the codes that are shared between perception and action in the control processes operating on these codes. Four developments are discussed in more detail: The degree to which the integration and retrieval of event files depends on current goals, how metacontrol states impact the handling of event files, how feature binding relates to event learning, and how the integration of non-social events relates to the integration of social events. Case examples using various versions of the Simon task are used to explain how the new version of TEC explains interactions between perception and action in non-social and social situations.},
  annotation = {WOS:000495781400003},
  journal = {Attention Perception \& Psychophysics},
  keywords = {Cognitive and attentional control,cognitive control,consequences,direction,feature bindings,files,impact,integration,neurofeedback,Perception and action,s-r compatibility,stimulus-response compatibility},
  language = {English},
  number = {7}
}

@article{Houston_Clarifying_2014,
  title = {Clarifying the Relationship between Prospect Theory and Risk-Sensitive Foraging Theory},
  author = {Houston, Alasdair I. and Fawcett, Tim W. and Mallpress, Dave E. W. and McNamara, John M.},
  year = {2014},
  month = nov,
  volume = {35},
  pages = {502--507},
  issn = {1090-5138, 1879-0607},
  doi = {10.1016/j.evolhumbehav.2014.06.010},
  journal = {Evolution and Human Behavior},
  keywords = {Daily energy budget rule,Expected utility theory,loss aversion,Reference point,Reflection effect,Reproductive value,State-dependent behaviour},
  language = {English},
  number = {6}
}

@article{Houston_sequential_1982,
  title = {A Sequential Approach to Risk-Taking},
  author = {Houston, Alasdair and McNamara, John},
  year = {1982},
  month = nov,
  volume = {30},
  pages = {1260--1261},
  issn = {0003-3472},
  doi = {10.1016/S0003-3472(82)80225-X},
  journal = {Animal Behaviour},
  keywords = {unread},
  number = {4}
}

@article{Hu_Functional_2010,
  title = {Functional Feedback from Mushroom Bodies to Antennal Lobes in the {{Drosophila}} Olfactory Pathway},
  author = {Hu, Aiqun and Zhang, Wei and Wang, Zuoren},
  year = {2010},
  month = may,
  pages = {200914912},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.0914912107},
  abstract = {Feedback plays important roles in sensory processing. Mushroom bodies are believed to be involved in olfactory learning/memory and multisensory integration in insects. Previous cobalt-labeling studies have suggested the existence of feedback from the mushroom bodies to the antennal lobes in the honey bee. In this study, the existence of functional feedback from Drosophila mushroom bodies to the antennal lobes was investigated through ectopic expression of the ATP receptor P2X2 in the Kenyon cells of mushroom bodies. Activation of Kenyon cells induced depolarization in projection neurons and local interneurons in the antennal lobes in a nicotinic receptor-dependent manner. Activation of Kenyon cell axons in the {$\beta\gamma$}-lobes in the mushroom body induced more potent responses in the antennal lobe neurons than activation of Kenyon cell somata. Our results indicate that functional feedback from Kenyon cells to projection neurons and local interneurons is present in Drosophila and is likely mediated by the {$\beta\gamma$}-lobes. The presence of this functional feedback from the mushroom bodies to the antennal lobes suggests top-down modulation of olfactory information processing in Drosophila.},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  pmid = {20479249}
}

@article{Huang_Functional_2010,
  title = {Functional {{Connectivity}} and {{Selective Odor Responses}} of {{Excitatory Local Interneurons}} in {{Drosophila Antennal Lobe}}},
  author = {Huang, Ju and Zhang, Wei and Qiao, Wenhui and Hu, Aiqun and Wang, Zuoren},
  year = {2010},
  month = sep,
  volume = {67},
  pages = {1021--1033},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2010.08.025},
  abstract = {Summary Local interneurons in the Drosophila antennal lobe are thought to play important roles in shaping odor responses. However, the physiological properties of excitatory local interneurons (eLNs) and their connectivity in the antennal lobe remain unclear. We first characterized the firing patterns of krasavietz-Gal4-labeled eLNs (krasavietz eLNs) in response to depolarizing currents. Paired recordings of krasavietz eLNs and PNs showed reciprocal excitatory connections mediated by dendrodendritic cholinergic synapses and gap junctions. Reciprocal connections were also found between two krasavietz eLNs but were rare between krasavietz eLNs and inhibitory LNs. Analysis of response onset latencies showed that krasavietz eLNs received monosynaptic inputs from ORNs. Furthermore, each eLN responded with distinct patterns to different odors, and each odor elicited distinct responses in different eLNs, with specific temporal patterns of spiking, indicating that eLNs serve specific coding functions in addition to global excitation in Drosophila olfactory processing.},
  journal = {Neuron},
  number = {6}
}

@article{Huys_Bonsai_2012,
  title = {Bonsai {{Trees}} in {{Your Head}}: {{How}} the {{Pavlovian System Sculpts Goal}}-{{Directed Choices}} by {{Pruning Decision Trees}}},
  shorttitle = {Bonsai {{Trees}} in {{Your Head}}},
  author = {Huys, Quentin J. M. and Eshel, Neir and O'Nions, Elizabeth and Sheridan, Luke and Dayan, Peter and Roiser, Jonathan P.},
  year = {2012},
  month = mar,
  volume = {8},
  pages = {e1002410},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1002410},
  abstract = {When planning a series of actions, it is usually infeasible to consider all potential future sequences; instead, one must prune the decision tree. Provably optimal pruning is, however, still computationally ruinous and the specific approximations humans employ remain unknown. We designed a new sequential reinforcement-based task and showed that human subjects adopted a simple pruning strategy: during mental evaluation of a sequence of choices, they curtailed any further evaluation of a sequence as soon as they encountered a large loss. This pruning strategy was Pavlovian: it was reflexively evoked by large losses and persisted even when overwhelmingly counterproductive. It was also evident above and beyond loss aversion. We found that the tendency towards Pavlovian pruning was selectively predicted by the degree to which subjects exhibited sub-clinical mood disturbance, in accordance with theories that ascribe Pavlovian behavioural inhibition, via serotonin, a role in mood disorders. We conclude that Pavlovian behavioural inhibition shapes highly flexible, goal-directed choices in a manner that may be important for theories of decision-making in mood disorders.},
  journal = {PLOS Computational Biology},
  keywords = {Decision making,Decision tree learning,Decision trees,Depression,Emotions,Learning,Psychometrics,Serotonin},
  language = {en},
  number = {3}
}

@article{Ikegaya_Synfire_2004,
  title = {Synfire {{Chains}} and {{Cortical Songs}}: {{Temporal Modules}} of {{Cortical Activity}}},
  shorttitle = {Synfire {{Chains}} and {{Cortical Songs}}},
  author = {Ikegaya, Yuji and Aaron, Gloster and Cossart, Rosa and Aronov, Dmitriy and Lampl, Ilan and Ferster, David and Yuste, Rafael},
  year = {2004},
  month = apr,
  volume = {304},
  pages = {559--564},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1093173},
  abstract = {How can neural activity propagate through cortical networks built with weak, stochastic synapses? We find precise repetitions of spontaneous patterns of synaptic inputs in neocortical neurons in vivo and in vitro. These patterns repeat after minutes, maintaining millisecond accuracy. Calcium imaging of slices reveals reactivation of sequences of cells during the occurrence of repeated intracellular synaptic patterns. The spontaneous activity drifts with time, engaging different cells. Sequences of active neurons have distinct spatial structures and are repeated in the same order over tens of seconds, revealing modular temporal dynamics. Higher order sequences are replayed with compressed timing.},
  journal = {Science},
  language = {en},
  number = {5670},
  pmid = {15105494}
}

@article{Imbo_role_2007,
  title = {The Role of Working Memory in the Carry Operation of Mental Arithmetic: {{Number}} and Value of the Carry},
  shorttitle = {The Role of Working Memory in the Carry Operation of Mental Arithmetic},
  author = {Imbo, Ineke and Vandierendonck, Andr{\'e} and Rammelaere, Stijn De},
  year = {2007},
  month = may,
  volume = {60},
  pages = {708--731},
  issn = {1747-0218},
  doi = {10.1080/17470210600762447},
  abstract = {Two experiments were conducted to investigate the role of phonological and executive working-memory components in the carry operation in mental arithmetic. We manipulated the number of carry operations, as previous research had done, but also the value that had to be carried. Results of these experiments show that in addition to the number of carry operations, the value of the carry is also an important variable determining the difficulty of arithmetical sums. Furthermore, both variables (number and value) interacted with each other in such a way that the combination of multiple carries and values of carries larger than one resulted in more difficult problems irrespective of the presence of a working-memory load. The findings with respect to working-memory load suggest that mainly the central executive is important in handling the number of carry operations as well as the value that has to be carried. The implications of the present findings for our views on mental arithmetic and its reliance on working memory are discussed.},
  journal = {The Quarterly Journal of Experimental Psychology},
  number = {5}
}

@article{Inzlicht_Effort_2018,
  title = {The {{Effort Paradox}}: {{Effort Is Both Costly}} and {{Valued}}},
  shorttitle = {The {{Effort Paradox}}},
  author = {Inzlicht, Michael and Shenhav, Amitai and Olivola, Christopher Y.},
  year = {2018},
  month = apr,
  volume = {22},
  pages = {337--349},
  issn = {1364-6613},
  doi = {10.1016/j.tics.2018.01.007},
  abstract = {According to prominent models in cognitive psychology, neuroscience, and economics, effort (be it physical or mental) is costly: when given a choice, humans and non-human animals alike tend to avoid effort. Here, we suggest that the opposite is also true and review extensive evidence that effort can also add value. Not only can the same outcomes be more rewarding if we apply more (not less) effort, sometimes we select options precisely because they require effort. Given the increasing recognition of effort's role in motivation, cognitive control, and value-based decision-making, considering this neglected side of effort will not only improve formal computational models, but also provide clues about how to promote sustained mental effort across time.},
  journal = {Trends in cognitive sciences},
  number = {4},
  pmcid = {PMC6172040},
  pmid = {29477776}
}

@article{Inzlicht_Six_2015,
  title = {Six {{Questions}} for the {{Resource Model}} of {{Control}} (and {{Some Answers}})},
  author = {Inzlicht, Michael and Berkman, Elliot},
  year = {2015},
  month = oct,
  volume = {9},
  pages = {511--524},
  issn = {1751-9004},
  doi = {10.1111/spc3.12200},
  abstract = {The resource model of self-control casts self-control as a capacity that relies on some limited resource that exhausts with use. The model captured our imagination and brought much-needed attention on an important yet neglected psychological construct. Despite its success, basic issues with the model remain. Here, we ask six questions: (i) Does self-control really wane over time? (ii) Is ego depletion a form of mental fatigue? (iii) What is the resource that is depleted by ego depletion? (iv) How can changes in motivation, perception, and expectations replenish an exhausted resource? (v) Has the revised resource model unwittingly become a model about motivation? (vi) Do self-control exercises increase self-control? By providing some answers to these questions \textendash{} including conducting a meta-analysis of the self-control training literature \textendash{} we highlight how the resource model needs to be revised if not supplanted altogether.},
  journal = {Social and personality psychology compass},
  number = {10},
  pmcid = {PMC5621751},
  pmid = {28966660}
}

@article{Iodice_Fatigue_2017,
  title = {Fatigue Increases the Perception of Future Effort during Decision Making},
  author = {Iodice, Pierpaolo and Calluso, Cinzia and Barca, Laura and Bertollo, Maurizio and Ripari, Patrizio and Pezzulo, Giovanni},
  year = {2017},
  month = nov,
  volume = {33},
  pages = {150--160},
  issn = {1469-0292},
  doi = {10.1016/j.psychsport.2017.08.013},
  abstract = {Objectives When making a decision, humans and other animals consider both the value of the alternatives and their associated effort. Accordingly, several studies have shown that the value-functions of rewards decrease proportionally to the effort required to secure them (effort-discounting). Nevertheless, it is unclear whether and how the momentary physiological condition of the body (e.g., fatigue) influences cost-benefit computations and the evaluation of future prospects. Design Participants were asked to make a series of effort-based choices between two different effort-demanding monetary outcomes, which varied both in reward magnitudes (money) and effort (time to be spent cycling on a bicycle ergometer at submaximal performance of {$\sim$}70\% of Vo2max after the experimental session). The tests were performed in two conditions: when participants were fatigued versus not fatigued. Methods Visual presentation of the choice alternatives and recordings of the subjects' responses were performed using the Mouse Tracker software, which allowed the recording of the kinematics of the mouse movements associated with the choice of 20 human subjects. Results Our findings show that fatigued participants increased their preference for less-costly offers, which indicates effort-discount (i.e., decrease of participants' value functions). Kinematic analysis of participants' choices revealed the dynamical signature of this preference shift: while non-fatigued participants had a strong initial bias for the higher-value, higher-effort choice offer, this bias lacked in fatigued participants. Conclusions Our results suggest that increased fatigue levels may ``scale up'' effort-costs, counteracting the (otherwise default) choice of higher-valued offers. These results are relevant for the ongoing debate on whether and why fatigue impairs athletes' ability to select actions optimally.},
  journal = {Psychology of Sport and Exercise},
  keywords = {Decision-making,Effort-discounting,Exercise performance,Fatigue,Perceived exertion}
}

@article{Ipata_Activity_2006,
  title = {Activity in the {{Lateral Intraparietal Area Predicts}} the {{Goal}} and {{Latency}} of {{Saccades}} in a {{Free}}-{{Viewing Visual Search Task}}},
  author = {Ipata, Anna E. and Gee, Angela L. and Goldberg, Michael E. and Bisley, James W.},
  year = {2006},
  month = apr,
  volume = {26},
  pages = {3656--3661},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.5074-05.2006},
  abstract = {The purpose of saccadic eye movements is to facilitate vision, by placing the fovea on interesting objects in the environment. Eye movements are not made for reward, and they are rarely restricted. Despite this, most of our knowledge about the neural genesis of eye movements comes from experiments in which specific eye movements are rewarded or restricted. Such experiments have demonstrated that activity in the lateral intraparietal (LIP) area of the monkey correlates with the monkey's planning of a memory-guided saccade or deciding where, on the basis of motion information, to make a saccade. However, other experiments have shown that neural activity in LIP can easily be dissociated from the generation of saccadic eye movements, especially when sophisticated behavioral paradigms dissociate the monkey's locus of attention from the goal of an intended saccade. In this study, we trained monkeys to report the results of a visual search task by making a nontargeting hand movement. Once the task began, the monkeys were entirely free to move their eyes, and rewards were not contingent on the monkeys making specific eye movements. We found that neural activity in LIP predicted not only the goal of the monkey's saccades but also their saccadic latencies.},
  journal = {The Journal of Neuroscience},
  keywords = {Attention,free viewing,monkey,oculomotor,parietal cortex,saccade,visual search},
  language = {en},
  number = {14},
  pmid = {16597719}
}

@article{Ito_Sparse_2008,
  title = {Sparse Odor Representation and Olfactory Learning},
  author = {Ito, Iori and Ong, Rose Chik-ying and Raman, Baranidharan and Stopfer, Mark},
  year = {2008},
  month = oct,
  volume = {11},
  pages = {1177--1184},
  issn = {1097-6256},
  doi = {10.1038/nn.2192},
  abstract = {Sensory systems create neural representations of environmental stimuli and these representations can be associated with other stimuli through learning. Are spike patterns the neural representations that get directly associated with reinforcement during conditioning? In the moth Manduca sexta, we found that odor presentations that support associative conditioning elicited only one or two spikes on the odor's onset (and sometimes offset) in each of a small fraction of Kenyon cells. Using associative conditioning procedures that effectively induced learning and varying the timing of reinforcement relative to spiking in Kenyon cells, we found that odor-elicited spiking in these cells ended well before the reinforcement was delivered. Furthermore, increasing the temporal overlap between spiking in Kenyon cells and reinforcement presentation actually reduced the efficacy of learning. Thus, spikes in Kenyon cells do not constitute the odor representation that coincides with reinforcement, and Hebbian spike timing\textendash dependent plasticity in Kenyon cells alone cannot underlie this learning.},
  copyright = {\textcopyright{} 2008 Nature Publishing Group},
  journal = {Nature Neuroscience},
  language = {en},
  number = {10}
}

@article{Itti_Computational_2001,
  title = {Computational Modelling of Visual Attention},
  author = {Itti, Laurent and Koch, Christof},
  year = {2001},
  month = mar,
  volume = {2},
  pages = {194--203},
  issn = {1471-003X},
  doi = {10.1038/35058500},
  abstract = {Five important trends have emerged from recent work on computational models of focal visual attention that emphasize the bottom-up, image-based control of attentional deployment. First, the perceptual saliency of stimuli critically depends on the surrounding context. Second, a unique 'saliency map' that topographically encodes for stimulus conspicuity over the visual scene has proved to be an efficient and plausible bottom-up control strategy. Third, inhibition of return, the process by which the currently attended location is prevented from being attended again, is a crucial element of attentional deployment. Fourth, attention and eye movements tightly interplay, posing computational challenges with respect to the coordinate system used to control attention. And last, scene understanding and object recognition strongly constrain the selection of attended locations. Insights from these five key areas provide a framework for a computational and neurobiological understanding of visual attention.},
  copyright = {\textcopyright{} 2001 Nature Publishing Group},
  journal = {Nature Reviews Neuroscience},
  language = {en},
  number = {3}
}

@article{Izhikevich_FitzHughNagumo_2006,
  title = {{{FitzHugh}}-{{Nagumo}} Model},
  author = {Izhikevich, Eugene and FitzHugh, Richard},
  year = {2006},
  volume = {1},
  pages = {1349},
  issn = {1941-6016},
  doi = {10.4249/scholarpedia.1349},
  journal = {Scholarpedia},
  language = {en},
  number = {9}
}

@article{Jiang_Bayesian_2014,
  title = {Bayesian Modeling of Flexible Cognitive Control},
  author = {Jiang, Jiefeng and Heller, Katherine and Egner, Tobias},
  year = {2014},
  month = oct,
  volume = {46, Part 1},
  pages = {30--43},
  issn = {0149-7634},
  doi = {10.1016/j.neubiorev.2014.06.001},
  abstract = {``Cognitive control'' describes endogenous guidance of behavior in situations where routine stimulus-response associations are suboptimal for achieving a desired goal. The computational and neural mechanisms underlying this capacity remain poorly understood. We examine recent advances stemming from the application of a Bayesian learner perspective that provides optimal prediction for control processes. In reviewing the application of Bayesian models to cognitive control, we note that an important limitation in current models is a lack of a plausible mechanism for the flexible adjustment of control over conflict levels changing at varying temporal scales. We then show that flexible cognitive control can be achieved by a Bayesian model with a volatility-driven learning mechanism that modulates dynamically the relative dependence on recent and remote experiences in its prediction of future control demand. We conclude that the emergent Bayesian perspective on computational mechanisms of cognitive control holds considerable promise, especially if future studies can identify neural substrates of the variables encoded by these models, and determine the nature (Bayesian or otherwise) of their neural implementation.},
  journal = {Neuroscience \& Biobehavioral Reviews},
  keywords = {Bayesian models,Cognitive control,Conflict,Conflict adaptation,Congruency sequence effect,Proportion congruency effect},
  series = {Micro- and {{Macro}}-{{Perspectives}} on {{Cognitive Conflict Control}}}
}

@article{Jiang_Bayesian_2014a,
  title = {Bayesian Modeling of Flexible Cognitive Control},
  author = {Jiang, Jiefeng and Heller, Katherine and Egner, Tobias},
  year = {2014},
  month = oct,
  volume = {46, Part 1},
  pages = {30--43},
  issn = {0149-7634},
  doi = {10.1016/j.neubiorev.2014.06.001},
  abstract = {``Cognitive control'' describes endogenous guidance of behavior in situations where routine stimulus-response associations are suboptimal for achieving a desired goal. The computational and neural mechanisms underlying this capacity remain poorly understood. We examine recent advances stemming from the application of a Bayesian learner perspective that provides optimal prediction for control processes. In reviewing the application of Bayesian models to cognitive control, we note that an important limitation in current models is a lack of a plausible mechanism for the flexible adjustment of control over conflict levels changing at varying temporal scales. We then show that flexible cognitive control can be achieved by a Bayesian model with a volatility-driven learning mechanism that modulates dynamically the relative dependence on recent and remote experiences in its prediction of future control demand. We conclude that the emergent Bayesian perspective on computational mechanisms of cognitive control holds considerable promise, especially if future studies can identify neural substrates of the variables encoded by these models, and determine the nature (Bayesian or otherwise) of their neural implementation.},
  journal = {Neuroscience \& Biobehavioral Reviews},
  keywords = {Bayesian models,Cognitive control,Conflict,Conflict adaptation,Congruency sequence effect,Proportion congruency effect},
  series = {Micro- and {{Macro}}-{{Perspectives}} on {{Cognitive Conflict Control}}}
}

@article{Jiang_Clustering_2013,
  title = {Clustering {{Uncertain Data Based}} on {{Probability Distribution Similarity}}},
  author = {Jiang, B. and Pei, J. and Tao, Y. and Lin, X.},
  year = {2013},
  month = apr,
  volume = {25},
  pages = {751--763},
  issn = {1041-4347},
  doi = {10.1109/TKDE.2011.221},
  abstract = {Clustering on uncertain data, one of the essential tasks in mining uncertain data, posts significant challenges on both modeling similarity between uncertain objects and developing efficient computational methods. The previous methods extend traditional partitioning clustering methods like \$(k)\$-means and density-based clustering methods like DBSCAN to uncertain data, thus rely on geometric distances between objects. Such methods cannot handle uncertain objects that are geometrically indistinguishable, such as products with the same mean but very different variances in customer ratings. Surprisingly, probability distributions, which are essential characteristics of uncertain objects, have not been considered in measuring similarity between uncertain objects. In this paper, we systematically model uncertain objects in both continuous and discrete domains, where an uncertain object is modeled as a continuous and discrete random variable, respectively. We use the well-known Kullback-Leibler divergence to measure similarity between uncertain objects in both the continuous and discrete cases, and integrate it into partitioning and density-based clustering methods to cluster uncertain objects. Nevertheless, a na\"ive implementation is very costly. Particularly, computing exact KL divergence in the continuous case is very costly or even infeasible. To tackle the problem, we estimate KL divergence in the continuous case by kernel density estimation and employ the fast Gauss transform technique to further speed up the computation. Our extensive experiment results verify the effectiveness, efficiency, and scalability of our approaches.},
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  keywords = {Cameras,Clustering,Clustering algorithms,data mining,DBSCAN,density estimation,density-based clustering method,discrete domains,Educational institutions,fast Gauss transform,Gauss transform,geometric distance,k-means clustering method,Kernel,kernel density estimation,KL divergence,Measurement uncertainty,partitioning clustering method,pattern clustering,probabilistic distribution,Probability distribution,probability distribution similarity,Random variables,similarity measure,similarity modeling,statistical distributions,uncertain data,uncertain data clustering,uncertain object clustering,uncertain object handling,uncertainty handling,wavelet transforms},
  number = {4}
}

@article{Jiang_Conflict_2015,
  title = {Conflict Awareness Dissociates Theta-Band Neural Dynamics of the Medial Frontal and Lateral Frontal Cortex during Trial-by-Trial Cognitive Control},
  author = {Jiang, Jun and Zhang, Qinglin and {van Gaal}, Simon},
  year = {2015},
  month = aug,
  volume = {116},
  pages = {102--111},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2015.04.062},
  abstract = {Recent findings have refuted the common assumption that executive control functions of the prefrontal cortex exclusively operate consciously, suggesting that many, if not all, cognitive processes could potentially operate unconsciously. However, although many cognitive functions can be launched unconsciously, several theoretical models of consciousness assume that there are crucial qualitative differences between conscious and unconscious processes. We hypothesized that the potential benefit of awareness in cognitive control mechanisms might become apparent when high control has to be maintained across time and requires the interaction between a set of distant frontal brain regions. To test this, we extracted oscillatory power dynamics from electroencephalographic data recorded while participants performed a task in which conflict awareness was manipulated by masking the conflict-inducing stimulus. We observed that instantaneous conflict as well as across trial conflict adaptation mechanisms were associated with medial frontal theta-band power modulations, irrespective of conflict awareness. However, and crucially, across-trial conflict adaptation processes reflected in increased theta-band power over dorsolateral frontal cortex were observed after fully conscious conflict only. This suggests that initial conflict detection and subsequent control adaptation by the medial frontal cortex are automatic and unconscious, whereas the routing of information from the medial frontal cortex to the lateral prefrontal cortex is a unique feature of conscious cognitive control.},
  journal = {NeuroImage}
}

@article{Johnson_Cerebral_2005,
  title = {The {{Cerebral Response}} during {{Subjective Choice}} with and without {{Self}}-Reference},
  author = {Johnson, Sterling C. and Schmitz, Taylor W. and {Kawahara-Baccus}, Tisha N. and Rowley, Howard A. and Alexander, Andrew L. and Lee, Jonghoon and Davidson, Richard J.},
  year = {2005},
  month = dec,
  volume = {17},
  pages = {1897--1906},
  issn = {0898-929X},
  doi = {10.1162/089892905775008607},
  journal = {Journal of Cognitive Neuroscience},
  number = {12}
}

@article{Jones_computational_2002,
  title = {A Computational Model of Anterior Cingulate Function in Speeded Response Tasks: Effects of Frequency, Sequence, and Conflict},
  shorttitle = {A Computational Model of Anterior Cingulate Function in Speeded Response Tasks},
  author = {Jones, Andrew D. and Cho, Raymond Y. and Nystrom, Leigh E. and Cohen, Jonathan D. and Braver, Todd S.},
  year = {2002},
  month = dec,
  volume = {2},
  pages = {300--317},
  issn = {1530-7026},
  abstract = {A growing body of evidence from functional neuroimaging and computational modeling studies indicates that the anterior cingulate cortex (ACC) detects the presence of response conflict and conveys this information to other brain regions, enabling subsequent adjustments in cognitive control. The present study examined previous empirical findings of increased ACC for low-frequency stimuli across three distinct speeded response tasks (two-alternative forced choice, go/no-go, and oddball). Simulations conducted in a neural network model incorporating sequential priming mechanisms (developed in Cho et al., 2002) confirmed that a computational measure of response conflict was higher on low-frequency trials across all three tasks. In addition, the model captured detailed aspects of behavioral reaction time and accuracy data, predicted the dynamics of ACC activity related to trial sequence effects, and provided evidence for the functional role of conflict information in performance monitoring and optimization. The results indicate that the conflict-monitoring hypothesis, augmented by mechanisms for encoding stimulus history, can explain key phenomena associated with performance in sequential speeded response tasks.},
  journal = {Cognitive, Affective \& Behavioral Neuroscience},
  keywords = {Adolescent,Adult,Brain Mapping,Conflict (Psychology),Evoked Potentials,Female,Gyrus Cinguli,Humans,Magnetic Resonance Imaging,Male,Neural Networks (Computer),Psychomotor Performance,Reaction Time,Task Performance and Analysis},
  language = {eng},
  number = {4},
  pmid = {12641175}
}

@article{Jones_Natural_2007,
  title = {Natural Stimuli Evoke Dynamic Sequences of States in Sensory Cortical Ensembles},
  author = {Jones, Lauren M. and Fontanini, Alfredo and Sadacca, Brian F. and Miller, Paul and Katz, Donald B.},
  year = {2007},
  month = nov,
  volume = {104},
  pages = {18772--18777},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.0705546104},
  abstract = {Although temporal coding is a frequent topic of neurophysiology research, trial-to-trial variability in temporal codes is typically dismissed as noise and thought to play no role in sensory function. Here, we show that much of this supposed ``noise'' faithfully reflects stimulus-related processes carried out in coherent neural networks. Cortical neurons responded to sensory stimuli by progressing through sequences of states, identifiable only in examinations of simultaneously recorded ensembles. The specific times at which ensembles transitioned from state to state varied from trial to trial, but the state sequences were reliable and stimulus-specific. Thus, the characterization of ensemble responses in terms of state sequences captured facets of sensory processing that are missing from, and obscured in, other analyses. This work provides evidence that sensory neurons act as parts of a systems-level dynamic process, the nature of which can best be appreciated through observation of distributed ensembles.},
  journal = {Proceedings of the National Academy of Sciences},
  keywords = {gustatory,hidden Markov model},
  language = {en},
  number = {47},
  pmid = {18000059}
}

@book{Jones_SciPy_2001,
  title = {{{SciPy}}: {{Open}} Source Scientific Tools for {{Python}}},
  author = {Jones, Eric and Oliphant, Travis and Peterson, Pearu and others},
  year = {2001}
}

@article{Jortner_simple_2007,
  title = {A Simple Connectivity Scheme for Sparse Coding in an Olfactory System},
  author = {Jortner, Ron A. and Farivar, S. Sarah and Laurent, Gilles},
  year = {2007},
  month = feb,
  volume = {27},
  pages = {1659--1669},
  issn = {0270-6474},
  doi = {10.1523/JNEUROSCI.4171-06.2007},
  abstract = {Recent studies, using unbiased sampling of neuronal activity in vivo, indicate the existence of sparse codes in the brain. These codes are characterized by highly specific, associative (i.e., dependent on combinations of features) and often invariant neuronal responses. Sparse representations present many advantages for memory storage and are, thus, of wide interest in sensory physiology. Here, we study the statistics of connectivity in an olfactory network that contributes to the generation of such codes: Kenyon cells (KCs), the intrinsic neurons of the mushroom body (a structure involved in learning and memory in insects) receive inputs from a small population of broadly tuned principal neurons; from these inputs, KCs generate exquisitely selective responses and, thus, sparse representations. We find, surprisingly, that KCs are on average each connected to about 50\% of their input population. Simple analysis indicates that such connectivity indeed maximizes the difference between input vectors to KCs and helps to explain their high specificity.},
  annotation = {WOS:000244239600018},
  journal = {Journal of Neuroscience},
  number = {7}
}

@inproceedings{Julier_New_1997,
  title = {New Extension of the {{Kalman}} Filter to Nonlinear Systems},
  booktitle = {Proc. {{SPIE}} 3068, {{Signal Processing}}, {{Sensor Fusion}}, and {{Target Recognition VI}}},
  author = {Julier, Simon J. and Uhlmann, Jeffrey K.},
  year = {1997},
  month = jul,
  pages = {182--193},
  doi = {10.1117/12.280797},
  abstract = {The Kalman Filter (KF) is one of the most widely used methods for tracking and estimation due to its simplicity, optimality, tractability and robustness. However, the application of the KF to nonlinear systems can be difficult. The most common approach is to use the Extended Kalman Filter (EKF) which simply linearizes all nonlinear models so that the traditional linear Kalman filter can be applied. Although the EKF (in its many forms) is a widely used filtering strategy, over thirty years of experience with it has led to a general consensus within the tracking and control community that it is difficult to implement, difficult to tune, and only reliable for systems which are almost linear on the time scale of the update intervals. In this paper a new linear estimator is developed and demonstrated. Using the principle that a set of discretely sampled points can be used to parameterize mean and covariance, the estimator yields performance equivalent to the KF for linear systems yet generalizes elegantly to nonlinear systems without the linearization steps required by the EKF. We show analytically that the expected performance of the new approach is superior to that of the EKF and, in fact, is directly comparable to that of the second order Gauss filter. The method is not restricted to assuming that the distributions of noise sources are Gaussian. We argue that the ease of implementation and more accurate estimation features of the new filter recommend its use over the EKF in virtually all applications.}
}

@inproceedings{Julier_New_1997a,
  title = {New Extension of the {{Kalman}} Filter to Nonlinear Systems},
  author = {Julier, Simon J. and Uhlmann, Jeffrey K.},
  year = {1997},
  volume = {3068},
  pages = {182--193},
  doi = {10.1117/12.280797},
  abstract = {The Kalman Filter (KF) is one of the most widely used methods for tracking and estimation due to its simplicity, optimality, tractability and robustness. However, the application of the KF to nonlinear systems can be difficult. The most common approach is to use the Extended Kalman Filter (EKF) which simply linearizes all nonlinear models so that the traditional linear Kalman filter can be applied. Although the EKF (in its many forms) is a widely used filtering strategy, over thirty years of experience with it has led to a general consensus within the tracking and control community that it is difficult to implement, difficult to tune, and only reliable for systems which are almost linear on the time scale of the update intervals. In this paper a new linear estimator is developed and demonstrated. Using the principle that a set of discretely sampled points can be used to parameterize mean and covariance, the estimator yields performance equivalent to the KF for linear systems yet generalizes elegantly to nonlinear systems without the linearization steps required by the EKF. We show analytically that the expected performance of the new approach is superior to that of the EKF and, in fact, is directly comparable to that of the second order Gauss filter. The method is not restricted to assuming that the distributions of noise sources are Gaussian. We argue that the ease of implementation and more accurate estimation features of the new filter recommend its use over the EKF in virtually all applications.}
}

@article{Jullien_Should_1999,
  title = {Should {{More Risk}}-{{Averse Agents Exert More Effort}}?},
  author = {Jullien, Bruno and Salani{\'e}, Bernard and Salani{\'e}, Fran{\c c}ois},
  year = {1999},
  month = jun,
  volume = {24},
  pages = {19--28},
  issn = {1573-6954},
  doi = {10.1023/A:1008729115022},
  abstract = {Consider an agent facing a risky distribution of losses who can change this distribution by exerting some effort. Should he exert more effort when he becomes more risk-averse? For instance, should we expect more risk-averse drivers to drive more cautiously? In this article, we give sufficient conditions under which the answer is positive, using results presented in Jewitt (1989). We first extend the standard models of self-insurance and self-protection and show that the comparative statics depends only on the effect of effort on the net loss. We then present conditions for the continuous case with applications.},
  journal = {The Geneva Papers on Risk and Insurance Theory},
  keywords = {comparative statics,self-insurance,self-protection},
  language = {en},
  number = {1}
}

@article{Kacelnik_Risky_1996,
  title = {Risky {{Theories}}\textemdash{{The Effects}} of {{Variance}} on {{Foraging Decisions}}},
  author = {Kacelnik, Alex and Bateson, Melissa},
  year = {1996},
  month = sep,
  volume = {36},
  pages = {402--434},
  issn = {1540-7063},
  doi = {10.1093/icb/36.4.402},
  abstract = {This paper concerns the response of foraging animals to variability in rate of gain, or risk. Both the empirical and theoretical literatures relevant to this issue are reviewed. The methodology and results from fifty-nine studies in which animals are required to choose between foraging options differing in the variances in the rate of gain available are tabulated. We found that when risk is generated by variability in the amount of reward, animals are most frequently risk-averse and sometimes indifferent to risk, although in some studies preference depends on energy budget. In contrast, when variability is in delay to reward, animals are universally risk-prone. A range of functional, descriptive and mechanistic accounts for these findings is described, none of which alone is capable of accommodating all aspects of the data. Risk-sensitive foraging theory provides the only currently available explanation for why energy budget should affect preference. An information-processing model that incorporates Weber's law provides the only general explanation for why animals should be risk-averse with variability in amount and risk-prone with delay. A theory based on the mechanisms of associative learning explains quantitative aspects of risk-proneness for delay; specifically why the delay between choice and reward should have a stronger impact on preference than delays between the reward and subsequent choice. It also explains why animals should appear to commit the ``fallacy of the average,'' maximising the expected ratio of amount of reward over delay to reward when computing rates rather than the ratio of expected amount over expected delay. We conclude that only a fusion of functional and mechanistic thinking will lead to progress in the understanding of animal decision making.},
  journal = {Integrative and Comparative Biology},
  number = {4}
}

@article{Kachergis_continuoustime_2014,
  title = {A Continuous-Time Neural Model for Sequential Action},
  author = {Kachergis, George and Wyatte, Dean and O'Reilly, Randall C. and {de Kleijn}, Roy and Hommel, Bernhard},
  year = {2014},
  month = nov,
  volume = {369},
  pages = {20130623},
  publisher = {{Royal Soc}},
  address = {{London}},
  issn = {0962-8436},
  doi = {10.1098/rstb.2013.0623},
  abstract = {Action selection, planning and execution are continuous processes that evolve over time, responding to perceptual feedback as well as evolving top-down constraints. Existing models of routine sequential action (e.g. coffee- or pancake-making) generally fall into one of two classes: hierarchical models that include hand-built task representations, or heterarchical models that must learn to represent hierarchy via temporal context, but thus far lack goal-orientedness. We present a biologically motivated model of the latter class that, because it is situated in the Leabra neural architecture, affords an opportunity to include both unsupervised and goal-directed learning mechanisms. Moreover, we embed this neurocomputational model in the theoretical framework of the theory of event coding (TEC), which posits that actions and perceptions share a common representation with bidirectional associations between the two. Thus, in this view, not only does perception select actions (along with task context), but actions are also used to generate perceptions (i.e. intended effects). We propose a neural model that implements TEC to carry out sequential action control in hierarchically structured tasks such as coffee-making. Unlike traditional feedforward discrete-time neural network models, which use static percepts to generate static outputs, our biological model accepts continuous-time inputs and likewise generates non-stationary outputs, making short-timescale dynamic predictions.},
  annotation = {WOS:000342882400011},
  journal = {Philosophical Transactions of the Royal Society B-Biological Sciences},
  keywords = {behavior,everyday action,neural model,perception,sequential action control,tec},
  language = {English},
  number = {1655}
}

@article{Kahneman_Prospect_1979,
  title = {Prospect {{Theory}}: {{An Analysis}} of {{Decision}} under {{Risk}}},
  shorttitle = {Prospect {{Theory}}},
  author = {Kahneman, Daniel and Tversky, Amos},
  year = {1979},
  volume = {47},
  pages = {263--291},
  issn = {0012-9682},
  doi = {10.2307/1914185},
  abstract = {This paper presents a critique of expected utility theory as a descriptive model of decision making under risk, and develops an alternative model, called prospect theory. Choices among risky prospects exhibit several pervasive effects that are inconsistent with the basic tenets of utility theory. In particular, people underweight outcomes that are merely probable in comparison with outcomes that are obtained with certainty. This tendency, called the certainty effect, contributes to risk aversion in choices involving sure gains and to risk seeking in choices involving sure losses. In addition, people generally discard components that are shared by all prospects under consideration. This tendency, called the isolation effect, leads to inconsistent preferences when the same choice is presented in different forms. An alternative theory of choice is developed, in which value is assigned to gains and losses rather than to final assets and in which probabilities are replaced by decision weights. The value function is normally concave for gains, commonly convex for losses, and is generally steeper for losses than for gains. Decision weights are generally lower than the corresponding probabilities, except in the range of low probabilities. Overweighting of low probabilities may contribute to the attractiveness of both insurance and gambling.},
  journal = {Econometrica},
  keywords = {effort},
  number = {2}
}

@article{Kahnt_Disentangling_2014,
  title = {Disentangling Neural Representations of Value and Salience in the Human Brain},
  author = {Kahnt, Thorsten and Park, Soyoung Q. and Haynes, John-Dylan and Tobler, Philippe N.},
  year = {2014},
  month = apr,
  volume = {111},
  pages = {5000--5005},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1320189111},
  abstract = {A large body of evidence has implicated the posterior parietal and orbitofrontal cortex in the processing of value. However, value correlates perfectly with salience when appetitive stimuli are investigated in isolation. Accordingly, considerable uncertainty has remained about the precise nature of the previously identified signals. In particular, recent evidence suggests that neurons in the primate parietal cortex signal salience instead of value. To investigate neural signatures of value and salience, here we apply multivariate (pattern-based) analyses to human functional MRI data acquired during a noninstrumental outcome-prediction task involving appetitive and aversive outcomes. Reaction time data indicated additive and independent effects of value and salience. Critically, we show that multivoxel ensemble activity in the posterior parietal cortex encodes predicted value and salience in superior and inferior compartments, respectively. These findings reinforce the earlier reports of parietal value signals and reconcile them with the recent salience report. Moreover, we find that multivoxel patterns in the orbitofrontal cortex correlate with value. Importantly, the patterns coding for the predicted value of appetitive and aversive outcomes are similar, indicating a common neural scale for appetite and aversive values in the orbitofrontal cortex. Thus orbitofrontal activity patterns satisfy a basic requirement for a neural value signal.},
  journal = {Proceedings of the National Academy of Sciences},
  keywords = {Attention,decision-making,MVPA,punishment,Reward},
  language = {en},
  number = {13},
  pmid = {24639493}
}

@article{Kang_Hypothetical_2011,
  title = {Hypothetical and {{Real Choice Differentially Activate Common Valuation Areas}}},
  author = {Kang, Min Jeong and Rangel, Antonio and Camus, Mickael and Camerer, Colin F.},
  year = {2011},
  month = jan,
  volume = {31},
  pages = {461--468},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.1583-10.2011},
  abstract = {Hypothetical reports of intended behavior are commonly used to draw conclusions about real choices. A fundamental question in decision neuroscience is whether the same type of valuation and choice computations are performed in hypothetical and real decisions. We investigated this question using functional magnetic resonance imaging while human subjects made real and hypothetical choices about purchases of consumer goods. We found that activity in common areas of the orbitofrontal cortex and the ventral striatum correlated with behavioral measures of the stimulus value of the goods in both types of decision. Furthermore, we found that activity in these regions was stronger in response to the stimulus value signals in the real choice condition. The findings suggest that the difference between real and hypothetical choice is primarily attributable to variations in the value computations of the medial orbitofrontal cortex and the ventral striatum, and not attributable to the use of different valuation systems, or to the computation of stronger stimulus value signals in the hypothetical condition.},
  copyright = {Copyright \textcopyright{} 2011 the authors 0270-6474/11/310461-08\$15.00/0},
  journal = {Journal of Neuroscience},
  language = {en},
  number = {2},
  pmid = {21228156}
}

@article{Kaplan_Planning_2018,
  title = {Planning and Navigation as Active Inference},
  author = {Kaplan, Raphael and Friston, Karl J.},
  year = {2018},
  month = aug,
  volume = {112},
  pages = {323--343},
  issn = {1432-0770},
  doi = {10.1007/s00422-018-0753-2},
  abstract = {This paper introduces an active inference formulation of planning and navigation. It illustrates how the exploitation\textendash exploration dilemma is dissolved by acting to minimise uncertainty (i.e. expected surprise or free energy). We use simulations of a maze problem to illustrate how agents can solve quite complicated problems using context sensitive prior preferences to form subgoals. Our focus is on how epistemic behaviour\textemdash driven by novelty and the imperative to reduce uncertainty about the world\textemdash contextualises pragmatic or goal-directed behaviour. Using simulations, we illustrate the underlying process theory with synthetic behavioural and electrophysiological responses during exploration of a maze and subsequent navigation to a target location. An interesting phenomenon that emerged from the simulations was a putative distinction between `place cells'\textemdash that fire when a subgoal is reached\textemdash and `path cells'\textemdash that fire until a subgoal is reached.},
  journal = {Biological Cybernetics},
  language = {en},
  number = {4}
}

@article{Kass_Bayes_1995,
  title = {Bayes {{Factors}}},
  author = {Kass, Robert E. and Raftery, Adrian E.},
  year = {1995},
  month = jun,
  volume = {90},
  pages = {773--795},
  issn = {0162-1459},
  doi = {10.1080/01621459.1995.10476572},
  abstract = {In a 1935 paper and in his book Theory of Probability, Jeffreys developed a methodology for quantifying the evidence in favor of a scientific theory. The centerpiece was a number, now called the Bayes factor, which is the posterior odds of the null hypothesis when the prior probability on the null is one-half. Although there has been much discussion of Bayesian hypothesis testing in the context of criticism of P-values, less attention has been given to the Bayes factor as a practical tool of applied statistics. In this article we review and discuss the uses of Bayes factors in the context of five scientific applications in genetics, sports, ecology, sociology, and psychology. We emphasize the following points: \textbullet From Jeffreys' Bayesian viewpoint, the purpose of hypothesis testing is to evaluate the evidence in favor of a scientific theory.\textbullet Bayes factors offer a way of evaluating evidence in favor of a null hypothesis.\textbullet Bayes factors provide a way of incorporating external information into the evaluation of evidence about a hypothesis.\textbullet Bayes factors are very general and do not require alternative models to be nested.\textbullet Several techniques are available for computing Bayes factors, including asymptotic approximations that are easy to compute using the output from standard packages that maximize likelihoods.\textbullet In ``nonstandard'' statistical models that do not satisfy common regularity conditions, it can be technically simpler to calculate Bayes factors than to derive non-Bayesian significance tests.\textbullet The Schwarz criterion (or BIC) gives a rough approximation to the logarithm of the Bayes factor, which is easy to use and does not require evaluation of prior distributions.\textbullet When one is interested in estimation or prediction, Bayes factors may be converted to weights to be attached to various models so that a composite estimate or prediction may be obtained that takes account of structural or model uncertainty.\textbullet Algorithms have been proposed that allow model uncertainty to be taken into account when the class of models initially considered is very large.\textbullet Bayes factors are useful for guiding an evolutionary model-building process.\textbullet It is important, and feasible, to assess the sensitivity of conclusions to the prior distributions used.},
  journal = {Journal of the American Statistical Association},
  number = {430}
}

@article{Kazama_Origins_2009,
  title = {Origins of Correlated Activity in an Olfactory Circuit},
  author = {Kazama, Hokto and Wilson, Rachel I.},
  year = {2009},
  month = sep,
  volume = {12},
  pages = {1136--1144},
  issn = {1097-6256},
  doi = {10.1038/nn.2376},
  abstract = {Multineuronal recordings often reveal synchronized spikes in different neurons. How correlated spike timing affects neural codes depends on the statistics of correlations, which in turn reflects the connectivity that gives rise to correlations. However, determining the connectivity of neurons recorded in vivo can be difficult. Here, we investigate the origins of correlated activity in genetically-labeled neurons of the Drosophila antennal lobe. Dual recordings show synchronized spontaneous spikes in projection neurons (PNs) postsynaptic to the same type of olfactory receptor neuron (ORN). Odors increase these correlations. The primary origin of correlations lies in the divergence of each ORN onto every PN in its glomerulus. Reciprocal PN-PN connections make a smaller contribution to correlations, and PN spike trains in different glomeruli are only weakly correlated. PN axons from the same glomerulus reconverge in the lateral horn, where pooling redundant signals may allow lateral horn neurons to average out noise that arises independently in these PNs.},
  journal = {Nature neuroscience},
  number = {9},
  pmcid = {PMC2751859},
  pmid = {19684589}
}

@article{Kellen_How_2016,
  title = {How (in)Variant Are Subjective Representations of Described and Experienced Risk and Rewards?},
  author = {Kellen, David and Pachur, Thorsten and Hertwig, Ralph},
  year = {2016},
  month = dec,
  volume = {157},
  pages = {126--138},
  issn = {0010-0277},
  doi = {10.1016/j.cognition.2016.08.020},
  abstract = {Decisions under risk have been shown to differ depending on whether information on outcomes and probabilities is gleaned from symbolic descriptions or gathered through experience. To some extent, this description\textendash experience gap is due to sampling error in experience-based choice. Analyses with cumulative prospect theory (CPT), investigating to what extent the gap is also driven by differences in people's subjective representations of outcome and probability information (taking into account sampling error), have produced mixed results. We improve on previous analyses of description-based and experience-based choices by taking advantage of both a within-subjects design and a hierarchical Bayesian implementation of CPT. This approach allows us to capture both the differences and the within-person stability of individuals' subjective representations across the two modes of learning about choice options. Relative to decisions from description, decisions from experience showed reduced sensitivity to probabilities and increased sensitivity to outcomes. For some CPT parameters, individual differences were relatively stable across modes of learning. Our results suggest that outcome and probability information translate into systematically different subjective representations in description- versus experience-based choice. At the same time, both types of decisions seem to tap into the same individual-level regularities.},
  journal = {Cognition},
  keywords = {Cumulative prospect theory,Decisions from experience,Hierarchical Bayesian modeling,Risky choice}
}

@article{Kepecs_Neural_2008,
  title = {Neural Correlates, Computation and Behavioural Impact of Decision Confidence},
  author = {Kepecs, Adam and Uchida, Naoshige and Zariwala, Hatim A. and Mainen, Zachary F.},
  year = {2008},
  month = sep,
  volume = {455},
  pages = {227--231},
  issn = {0028-0836},
  doi = {10.1038/nature07200},
  abstract = {Humans and other animals must often make decisions on the basis of imperfect evidence. Statisticians use measures such as P values to assign degrees of confidence to propositions, but little is known about how the brain computes confidence estimates about decisions. We explored this issue using behavioural analysis and neural recordings in rats in combination with computational modelling. Subjects were trained to perform an odour categorization task that allowed decision confidence to be manipulated by varying the distance of the test stimulus to the category boundary. To understand how confidence could be computed along with the choice itself, using standard models of decision-making, we defined a simple measure that quantified the quality of the evidence contributing to a particular decision. Here we show that the firing rates of many single neurons in the orbitofrontal cortex match closely to the predictions of confidence models and cannot be readily explained by alternative mechanisms, such as learning stimulus\textendash outcome associations. Moreover, when tested using a delayed reward version of the task, we found that rats' willingness to wait for rewards increased with confidence, as predicted by the theoretical model. These results indicate that confidence estimates, previously suggested to require `metacognition' and conscious awareness, are available even in the rodent brain, can be computed with relatively simple operations, and can drive adaptive behaviour. We suggest that confidence estimation may be a fundamental and ubiquitous component of decision-making.},
  copyright = {\textcopyright{} 2008 Nature Publishing Group},
  journal = {Nature},
  language = {en},
  number = {7210}
}

@article{Keramati_Adaptive_2016,
  title = {Adaptive Integration of Habits into Depth-Limited Planning Defines a Habitual-Goal\textendash Directed Spectrum},
  author = {Keramati, Mehdi and Smittenaar, Peter and Dolan, Raymond J. and Dayan, Peter},
  year = {2016},
  month = nov,
  volume = {113},
  pages = {12868--12873},
  issn = {0027-8424},
  doi = {10.1073/pnas.1609094113},
  abstract = {Solving complex tasks often requires estimates of the future consequences of current actions. Estimates could be learned from past experience, but they then risk being out of date, or they could be calculated by a form of planning into the future, a process that is computationally taxing. We show that humans integrate learned estimates into their planning calculations, saving mental effort and time. We also show that increasing time pressure leads to reliance on learned estimates after fewer steps of planning. We suggest a normative rationale for this effect using a computational model. Our results provide a perspective on how the brain combines different decision processes collaboratively to exploit their comparative computational advantages., Behavioral and neural evidence reveal a prospective goal-directed decision process that relies on mental simulation of the environment, and a retrospective habitual process that caches returns previously garnered from available choices. Artificial systems combine the two by simulating the environment up to some depth and then exploiting habitual values as proxies for consequences that may arise in the further future. Using a three-step task, we provide evidence that human subjects use such a normative plan-until-habit strategy, implying a spectrum of approaches that interpolates between habitual and goal-directed responding. We found that increasing time pressure led to shallower goal-directed planning, suggesting that a speed-accuracy tradeoff controls the depth of planning with deeper search leading to more accurate evaluation, at the cost of slower decision-making. We conclude that subjects integrate habit-based cached values directly into goal-directed evaluations in a normative manner.},
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  number = {45},
  pmcid = {PMC5111694},
  pmid = {27791110}
}

@article{Kiebel_Free_2011,
  title = {Free Energy and Dendritic Self-Organization},
  author = {Kiebel, Stefan J. and Friston, Karl J.},
  year = {2011},
  volume = {5},
  pages = {80},
  doi = {10.3389/fnsys.2011.00080},
  abstract = {In this paper, we pursue recent observations that, through selective dendritic filtering, single neurons respond to specific sequences of presynaptic inputs. We try to provide a principled and mechanistic account of this selectivity by applying a recent free-energy principle to a dendrite that is immersed in its neuropil or environment. We assume that neurons self-organize to minimize a variational free-energy bound on the self-information or surprise of presynaptic inputs that are sampled. We model this as a selective pruning of dendritic spines that are expressed on a dendritic branch. This pruning occurs when postsynaptic gain falls below a threshold. Crucially, postsynaptic gain is itself optimized with respect to free energy. Pruning suppresses free energy as the dendrite selects presynaptic signals that conform to its expectations, specified by a generative model implicit in its intracellular kinetics. Not only does this provide a principled account of how neurons organize and selectively sample the myriad of potential presynaptic inputs they are exposed to, but it also connects the optimization of elemental neuronal (dendritic) processing to generic (surprise or evidence-based) schemes in statistics and machine learning, such as Bayesian model selection and automatic relevance determination.},
  journal = {Frontiers in Systems Neuroscience},
  keywords = {Bayesian inference,dendrite,dendritic computation,Free energy,multi-scale,non-linear dynamical system,single neuron,synaptic reconfiguration}
}

@article{Kiebel_Hierarchy_2008,
  title = {A {{Hierarchy}} of {{Time}}-{{Scales}} and the {{Brain}}},
  author = {Kiebel, Stefan J. and Daunizeau, Jean and Friston, Karl J.},
  year = {2008},
  month = nov,
  volume = {4},
  pages = {e1000209},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1000209},
  abstract = {In this paper, we suggest that cortical anatomy recapitulates the temporal hierarchy that is inherent in the dynamics of environmental states. Many aspects of brain function can be understood in terms of a hierarchy of temporal scales at which representations of the environment evolve. The lowest level of this hierarchy corresponds to fast fluctuations associated with sensory processing, whereas the highest levels encode slow contextual changes in the environment, under which faster representations unfold. First, we describe a mathematical model that exploits the temporal structure of fast sensory input to track the slower trajectories of their underlying causes. This model of sensory encoding or perceptual inference establishes a proof of concept that slowly changing neuronal states can encode the paths or trajectories of faster sensory states. We then review empirical evidence that suggests that a temporal hierarchy is recapitulated in the macroscopic organization of the cortex. This anatomic-temporal hierarchy provides a comprehensive framework for understanding cortical function: the specific time-scale that engages a cortical area can be inferred by its location along a rostro-caudal gradient, which reflects the anatomical distance from primary sensory areas. This is most evident in the prefrontal cortex, where complex functions can be explained as operations on representations of the environment that change slowly. The framework provides predictions about, and principled constraints on, cortical structure\textendash function relationships, which can be tested by manipulating the time-scales of sensory input.},
  journal = {PLOS Computational Biology},
  keywords = {Agent-based modeling,Behavior,Bird song,Birds,Brain,Dynamical systems,Nonlinear dynamics,Sensory perception},
  language = {en},
  number = {11}
}

@article{Kiebel_Perception_2009,
  title = {Perception and Hierarchical Dynamics},
  author = {Kiebel, Stefan J. and Daunizeau, Jean and Friston, Karl J.},
  year = {2009},
  volume = {3},
  pages = {20},
  doi = {10.3389/neuro.11.020.2009},
  abstract = {In this paper, we suggest that perception could be modeled by assuming that sensory input is generated by a hierarchy of attractors in a dynamic system. We describe a mathematical model which exploits the temporal structure of rapid sensory dynamics to track the slower trajectories of their underlying causes. This model establishes a proof of concept that slowly changing neuronal states can encode the trajectories of faster sensory signals. We link this hierarchical account to recent developments in the perception of human action; in particular artificial speech recognition. We argue that these hierarchical models of dynamical systems are a plausible starting point to develop robust recognition schemes, because they capture critical temporal dependencies induced by deep hierarchical structure. We conclude by suggesting that a fruitful computational neuroscience approach may emerge from modeling perception as non-autonomous recognition dynamics enslaved by autonomous hierarchical dynamics in the sensorium.},
  journal = {Frontiers in Neuroinformatics},
  keywords = {Bayesian inversion,biological movement,birdsong,dynamic systems theory,environment,Perception,recognition,speech}
}

@article{Kiebel_Recognizing_2009,
  title = {Recognizing Sequences of Sequences},
  author = {Kiebel, Stefan},
  year = {2009},
  abstract = {The brain's decoding of fast sensory streams is currently impossible to emulate, even approximately, with artificial agents. For example, robust speech recognition is relatively easy for humans but exceptionally difficult for artificial speech recognition systems. In this paper, we propose that recognition can be simplified with an internal model of how sensory input is generated, when formulated in a Bayesian framework. We show that a plausible candidate for an internal or generative model is a hierarchy of `stable heteroclinic channels'. This model describes continuous dynamics in the environment as a hierarchy of sequences, where slower sequences cause faster sequences. Under this model, online recognition corresponds to the dynamic decoding of causal sequences, giving a representation of the environment with predictive power on several timescales. We illustrate the ensuing decoding or recognition scheme using synthetic sequences of syllables, where syllables are sequences of phonemes and phonemes are sequences of sound-wave modulations. By presenting anomalous stimuli, we find that the resulting recognition dynamics disclose inference at multiple time scales and are reminiscent of neuronal dynamics seen in the real brain.},
  keywords = {bird songs,Sequential Dynamics}
}

@article{Kiebel_Recognizing_2009a,
  title = {Recognizing {{Sequences}} of {{Sequences}}},
  author = {Kiebel, Stefan J. and {von Kriegstein}, Katharina and Daunizeau, Jean and Friston, Karl J.},
  year = {2009},
  month = aug,
  volume = {5},
  pages = {e1000464},
  doi = {10.1371/journal.pcbi.1000464},
  abstract = {Author Summary Despite tremendous advances in neuroscience, we cannot yet build machines that recognize the world as effortlessly as we do. One reason might be that there are computational approaches to recognition that have not yet been exploited. Here, we demonstrate that the ability to recognize temporal sequences might play an important part. We show that an artificial decoding device can extract natural speech sounds from sound waves if speech is generated as dynamic and transient sequences of sequences. In principle, this means that artificial recognition can be implemented robustly and online using dynamic systems theory and Bayesian inference.},
  journal = {PLoS Comput Biol},
  number = {8}
}

@article{Kiesel_Control_2010,
  title = {Control and Interference in Task Switching--a Review},
  author = {Kiesel, Andrea and Steinhauser, Marco and Wendt, Mike and Falkenstein, Michael and Jost, Kerstin and Philipp, Andrea M. and Koch, Iring},
  year = {2010},
  month = sep,
  volume = {136},
  pages = {849--874},
  issn = {1939-1455},
  doi = {10.1037/a0019842},
  abstract = {The task-switching paradigm offers enormous possibilities to study cognitive control as well as task interference. The current review provides an overview of recent research on both topics. First, we review different experimental approaches to task switching, such as comparing mixed-task blocks with single-task blocks, predictable task-switching and task-cuing paradigms, intermittent instructions, and voluntary task selection. In the 2nd part, we discuss findings on preparatory control mechanisms in task switching and theoretical accounts of task preparation. We consider preparation processes in two-stage models, consider preparation as an all-or-none process, address the question of whether preparation is switch-specific, reflect on preparation as interaction of cue encoding and memory retrieval, and discuss the impact of verbal mediation on preparation. In the 3rd part, we turn to interference phenomena in task switching. We consider proactive interference of tasks and inhibition of recently performed tasks indicated by asymmetrical switch costs and n-2 task-repetition costs. We discuss stimulus-based interference as a result of stimulus-based response activation and stimulus-based task activation, and response-based interference because of applying bivalent rather than univalent responses, response repetition effects, and carryover of response selection and execution. In the 4th and final part, we mention possible future research fields.},
  journal = {Psychological Bulletin},
  keywords = {cognition,Cues,Humans,Inhibition (Psychology),Internal-External Control,memory,Task Performance and Analysis},
  language = {eng},
  number = {5},
  pmid = {20804238}
}

@article{Kim_functional_2011,
  title = {A Functional Dissociation of Conflict Processing within Anterior Cingulate Cortex},
  author = {Kim, Chobok and Kroger, James K. and Kim, Jeounghoon},
  year = {2011},
  month = feb,
  volume = {32},
  pages = {304--312},
  issn = {1097-0193},
  doi = {10.1002/hbm.21020},
  abstract = {Goal-directed behavior requires cognitive control to regulate the occurrence of conflict. The dorsal anterior cingulate cortex (dACC) has been suggested in detecting response conflict during various conflict tasks. Recent findings, however, have indicated not only that two distinct subregions of dACC are involved in conflict processing but also that the conflict occurs at both perceptual and response levels. In this study, we sought to examine whether perceptual and response conflicts are functionally dissociated in dACC. Thirteen healthy subjects performed a version of the Stroop task during functional magnetic resonance imaging (fMRI) scanning. We identified a functional dissociation of the caudal dACC (cdACC) and the rostral dACC (rdACC) in their responses to different sources of conflict. The cdACC was selectively engaged in perceptual conflict whereas the rdACC was more active in response conflict. Further, the dorsolateral prefrontal cortex (DLPFC) was coactivated not with cdACC but with rdACC. We suggest that cdACC plays an important role in regulative processing of perceptual conflict whereas rdACC is involved in detecting response conflict. Hum Brain Mapp, 2011. \textcopyright{} 2010 Wiley-Liss, Inc.},
  copyright = {Copyright \textcopyright{} 2010 Wiley-Liss, Inc.},
  journal = {Human Brain Mapping},
  keywords = {Anterior cingulate cortex,Cognitive control,conflict monitoring,dorsolateral prefrontal cortex,functional MRI,perceptual conflict,Response conflict},
  language = {en},
  number = {2}
}

@article{Kirby_Delaydiscounting_1996,
  title = {Delay-Discounting Probabilistic Rewards: {{Rates}} Decrease as Amounts Increase},
  shorttitle = {Delay-Discounting Probabilistic Rewards},
  author = {Kirby, Kris N. and Marakovi{\'C}, Nino N.},
  year = {1996},
  month = mar,
  volume = {3},
  pages = {100--104},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/BF03210748},
  abstract = {The independence of delay-discounting rate and monetary reward size was tested by offering subjects (N = 621) a series of choices between immediate rewards and larger, delayed rewards. In contrast to previous studies, in which hypothetical rewards have typically been employed, subjects in the present study were entered into a lottery in which they had a chance of actually receiving one of their choices. The delayed rewards were grouped into small (\$30\textendash\$35), medium (\$55\textendash\$65), and large amounts (\$70\textendash\$85). Using a novel parameter estimation procedure, we estimated discounting rates for all three reward sizes for each subject on the basis of his/her pattern of choices. The data indicated that the discounting rate is a decreasing function of the size of the delayed reward (p {$<$} .0001), whether hyperbolic or exponential discounting functions are assumed. In addition, a reliable gender difference was found (p = .005), with males discounting at higher rates than females, on average.},
  journal = {Psychonomic Bulletin \& Review},
  keywords = {Cognitive Psychology},
  language = {en},
  number = {1}
}

@article{Kirby_Oneyear_2009,
  title = {One-Year Temporal Stability of Delay-Discount Rates},
  author = {Kirby, Kris N.},
  year = {2009},
  month = jun,
  volume = {16},
  pages = {457--462},
  issn = {1531-5320},
  doi = {10.3758/PBR.16.3.457},
  abstract = {The temporal stability of delay-discount rates for monetary rewards was assessed using a monetary choice questionnaire (Kirby \& Marakovic, 1996). Of 100 undergraduate participants who completed the questionnaire at the initial session, 81 returned 5 weeks later and 46 returned 57 weeks later for subsequent sessions. The 5-week test\textemdash retest stability of discount rates was .77 (95\% confidence interval 5 .67\textemdash.85), the 1-year stability was .71 (.50\textendash.84), and the 57-week stability was .63 (.41\textemdash.77). Thus, at least when similar testing situations are reinstated, discount rates as individual differences have 1-year stabilities in the range that is typically obtained for personality traits. Discount rates index an attribute of the person that is relatively stable over time but that is moderated by aspects of the situation, such as reward type and deprivational state.},
  journal = {Psychonomic Bulletin \& Review},
  language = {en},
  number = {3}
}

@article{Kivetz_Effects_2003,
  title = {The {{Effects}} of {{Effort}} and {{Intrinsic Motivation}} on {{Risky Choice}}},
  author = {Kivetz, Ran},
  year = {2003},
  month = oct,
  volume = {22},
  pages = {477--502},
  issn = {1526-548X},
  doi = {10.1287/mksc.22.4.477.24911},
  abstract = {People often need to trade off between the probability and magnitude of the rewards that they could earn for investing effort. The present paper proposes that the conjunction of two simple assumptions (relating effort-induced reward expectations to prospect theory's value function) provides a parsimonious theory that predicts that the nature of the required effort will have a systematic effect on such trade-offs. Using the case of frequency (or loyalty) programs, a series of five studies involving both real and hypothetical choices demonstrated that (a) the presence (as opposed to absence) of effort requirements enhances the preference for sure-small rewards over large-uncertain rewards; (b) the preference for reward certainty is attenuated when the effort activity is intrinsically motivating; and (c) continuously increasing the effort level leads to an inverted-U effect on the preference for sure-small over largeuncertain rewards. The studies also employ process measures and examine the mechanisms underlying the impact of the effort stream on the trade-off between the certainty and magnitude of rewards. The final section discusses the theoretical implications of this research as well as the practical implications with respect to frequency programs and other types of incentive systems.},
  journal = {Marketing Science},
  keywords = {Decisions under uncertainty,Effort and reward,Frequency/loyalty/reward programs,Incentive systems,Intrinsic motivation,Psychology of rewards,Risky choice},
  number = {4}
}

@article{Klein-Flugge_Behavioral_2015,
  title = {Behavioral {{Modeling}} of {{Human Choices Reveals Dissociable Effects}} of {{Physical Effort}} and {{Temporal Delay}} on {{Reward Devaluation}}},
  author = {{Klein-Fl{\"u}gge}, Miriam C. and Kennerley, Steven W. and Saraiva, Ana C. and Penny, Will D. and Bestmann, Sven},
  year = {2015},
  month = mar,
  volume = {11},
  pages = {e1004116},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1004116},
  abstract = {There has been considerable interest from the fields of biology, economics, psychology, and ecology about how decision costs decrease the value of rewarding outcomes. For example, formal descriptions of how reward value changes with increasing temporal delays allow for quantifying individual decision preferences, as in animal species populating different habitats, or normal and clinical human populations. Strikingly, it remains largely unclear how humans evaluate rewards when these are tied to energetic costs, despite the surge of interest in the neural basis of effort-guided decision-making and the prevalence of disorders showing a diminished willingness to exert effort (e.g., depression). One common assumption is that effort discounts reward in a similar way to delay. Here we challenge this assumption by formally comparing competing hypotheses about effort and delay discounting. We used a design specifically optimized to compare discounting behavior for both effort and delay over a wide range of decision costs (Experiment 1). We then additionally characterized the profile of effort discounting free of model assumptions (Experiment 2). Contrary to previous reports, in both experiments effort costs devalued reward in a manner opposite to delay, with small devaluations for lower efforts, and progressively larger devaluations for higher effort-levels (concave shape). Bayesian model comparison confirmed that delay-choices were best predicted by a hyperbolic model, with the largest reward devaluations occurring at shorter delays. In contrast, an altogether different relationship was observed for effort-choices, which were best described by a model of inverse sigmoidal shape that is initially concave. Our results provide a novel characterization of human effort discounting behavior and its first dissociation from delay discounting. This enables accurate modelling of cost-benefit decisions, a prerequisite for the investigation of the neural underpinnings of effort-guided choice and for understanding the deficits in clinical disorders characterized by behavioral inactivity.},
  journal = {PLOS Computational Biology},
  keywords = {Behavior,Behavioral disorders,Behavioral ecology,Classical mechanics,Decision making,Depression,Impulsivity,Thermometers},
  language = {en},
  number = {3}
}

@article{Klein-Flugge_Neural_2016,
  title = {Neural {{Signatures}} of {{Value Comparison}} in {{Human Cingulate Cortex}} during {{Decisions Requiring}} an {{Effort}}-{{Reward Trade}}-Off},
  author = {{Klein-Fl{\"u}gge}, Miriam C. and Kennerley, Steven W. and Friston, Karl and Bestmann, Sven},
  year = {2016},
  month = sep,
  volume = {36},
  pages = {10002--10015},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.0292-16.2016},
  abstract = {Integrating costs and benefits is crucial for optimal decision-making. Although much is known about decisions that involve outcome-related costs (e.g., delay, risk), many of our choices are attached to actions and require an evaluation of the associated motor costs. Yet how the brain incorporates motor costs into choices remains largely unclear. We used human fMRI during choices involving monetary reward and physical effort to identify brain regions that serve as a choice comparator for effort-reward trade-offs. By independently varying both options' effort and reward levels, we were able to identify the neural signature of a comparator mechanism. A network involving supplementary motor area and the caudal portion of dorsal anterior cingulate cortex encoded the difference in reward (positively) and effort levels (negatively) between chosen and unchosen choice options. We next modeled effort-discounted subjective values using a novel behavioral model. This revealed that the same network of regions involving dorsal anterior cingulate cortex and supplementary motor area encoded the difference between the chosen and unchosen options' subjective values, and that activity was best described using a concave model of effort-discounting. In addition, this signal reflected how precisely value determined participants' choices. By contrast, separate signals in supplementary motor area and ventromedial prefrontal cortex correlated with participants' tendency to avoid effort and seek reward, respectively. This suggests that the critical neural signature of decision-making for choices involving motor costs is found in human cingulate cortex and not ventromedial prefrontal cortex as typically reported for outcome-based choice. Furthermore, distinct frontal circuits seem to drive behavior toward reward maximization and effort minimization. SIGNIFICANCE STATEMENT The neural processes that govern the trade-off between expected benefits and motor costs remain largely unknown. This is striking because energetic requirements play an integral role in our day-to-day choices and instrumental behavior, and a diminished willingness to exert effort is a characteristic feature of a range of neurological disorders. We use a new behavioral characterization of how humans trade off reward maximization with effort minimization to examine the neural signatures that underpin such choices, using BOLD MRI neuroimaging data. We find the critical neural signature of decision-making, a signal that reflects the comparison of value between choice options, in human cingulate cortex, whereas two distinct brain circuits drive behavior toward reward maximization or effort minimization.},
  copyright = {Copyright \textcopyright{} 2016 Klein-Fl\"ugge et al.. This article is freely available online through the J Neurosci Author Open Choice option.},
  journal = {Journal of Neuroscience},
  keywords = {cingulate cortex,cost-benefit decision making,fMRI,motor cost,physical effort,value comparison},
  language = {en},
  number = {39},
  pmid = {27683898}
}

@article{Knill_Bayesian_2004,
  title = {The {{Bayesian}} Brain: The Role of Uncertainty in Neural Coding and Computation},
  shorttitle = {The {{Bayesian}} Brain},
  author = {Knill, David C. and Pouget, Alexandre},
  year = {2004},
  month = dec,
  volume = {27},
  pages = {712--719},
  issn = {0166-2236},
  doi = {10.1016/j.tins.2004.10.007},
  abstract = {To use sensory information efficiently to make judgments and guide action in the world, the brain must represent and use information about uncertainty in its computations for perception and action. Bayesian methods have proven successful in building computational theories for perception and sensorimotor control, and psychophysics is providing a growing body of evidence that human perceptual computations are `Bayes' optimal'. This leads to the `Bayesian coding hypothesis': that the brain represents sensory information probabilistically, in the form of probability distributions. Several computational schemes have recently been proposed for how this might be achieved in populations of neurons. Neurophysiological data on the hypothesis, however, is almost non-existent. A major challenge for neuroscientists is to test these ideas experimentally, and so determine whether and how neurons code information about sensory uncertainty.},
  journal = {Trends in Neurosciences},
  number = {12}
}

@article{Knowlton_Neostriatal_1996,
  title = {A {{Neostriatal Habit Learning System}} in {{Humans}}},
  author = {Knowlton, Barbara J. and Mangels, Jennifer A. and Squire, Larry R.},
  year = {1996},
  month = sep,
  volume = {273},
  pages = {1399--1402},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.273.5280.1399},
  abstract = {Amnesic patients and nondemented patients with Parkinson's disease were given a probabilistic classification task in which they learned which of two outcomes would occur on each trial, given the particular combination of cues that appeared. Amnesic patients exhibited normal learning of the task but had severely impaired declarative memory for the training episode. In contrast, patients with Parkinson's disease failed to learn the probabilistic classification task, despite having intact memory for the training episode. This double dissociation shows that the limbic-diencephalic regions damaged in amnesia and the neostriatum damaged in Parkinson's disease support separate and parallel learning systems. In humans, the neostriatum (caudate nucleus and putamen) is essential for the gradual, incremental learning of associations that is characteristic of habit learning. The neostriatum is important not just for motor behavior and motor learning but also for acquiring nonmotor dispositions and tendencies that depend on new associations.},
  copyright = {\textcopyright{} 1996 American Association for the Advancement of Science},
  journal = {Science},
  language = {en},
  number = {5280},
  pmid = {8703077}
}

@article{Knusel_Decoding_2004,
  title = {Decoding a {{Temporal Population Code}}},
  author = {Kn{\"u}sel, Philipp and Wyss, Reto and K{\"o}nig, Peter and Verschure, Paul F.M.J.},
  year = {2004},
  month = oct,
  volume = {16},
  pages = {2079--2100},
  issn = {0899-7667},
  doi = {10.1162/0899766041732459},
  abstract = {Encoding of sensory events in internal states of the brain requires that this information can be decoded by other neural structures. The encoding of sensory events can involve both the spatial organization of neuronal activityanditstemporaldynamics. Here we investigate the issue of decoding in the context of a recently proposed encoding scheme: the temporal population code. In this code, the geometric properties of visual stimuli become encoded into the temporal response characteristics of the summed activities of a population of cortical neurons. For its decoding, we evaluate a model based on the structure and dynamics of cortical microcircuits that is proposed for computations on continuous temporal streams: the liquid state machine. Employing the original proposal of the decoding network results in a moderate performance. Our analysis shows that the temporal mixing of subsequent stimuli results in a joint representation that compromises their classification. To overcome this problem, we investigate a number of initialization strategies. Whereas we observe that a deterministically initialized network results in the best performance, we find that in case the network is never reset, that is, it continuously processes the sequence of stimuli, the classification performance is greatly hampered by the mixing of information from past and present stimuli. We conclude that this problem of the mixing of temporally segregated information is not specific to this particular decoding model but relates to a general problem that any circuit that processes continuous streams of temporal information needs to solve. Furthermore, as both the encoding and decoding components of our network have been independently proposed as models of the cerebral cortex, our results suggest that the brain could solve the problem of temporal mixing by applying reset signals at stimulus onset, leading to a temporal segmentation of a continuous input stream.},
  journal = {Neural Computation},
  number = {10}
}

@article{Koch_Cognitive_2018,
  title = {Cognitive Structure, Flexibility, and Plasticity in Human Multitasking-{{An}} Integrative Review of Dual-Task and Task-Switching Research},
  author = {Koch, Iring and Poljac, Edita and M{\"u}ller, Hermann and Kiesel, Andrea},
  year = {2018},
  month = jun,
  volume = {144},
  pages = {557--583},
  issn = {1939-1455},
  doi = {10.1037/bul0000144},
  abstract = {Numerous studies showed decreased performance in situations that require multiple tasks or actions relative to appropriate control conditions. Because humans often engage in such multitasking activities, it is important to understand how multitasking affects performance. In the present article, we argue that research on dual-task interference and sequential task switching has proceeded largely separately using different experimental paradigms and methodology. In our article we aim at organizing this complex set of research in terms of three complementary research perspectives on human multitasking. One perspective refers to structural accounts in terms of cognitive bottlenecks (i.e., critical processing stages). A second perspective refers to cognitive flexibility in terms of the underlying cognitive control processes. A third perspective emphasizes cognitive plasticity in terms of the influence of practice on human multitasking abilities. With our review article we aimed at highlighting the value of an integrative position that goes beyond isolated consideration of a single theoretical research perspective and that broadens the focus from single experimental paradigms (dual task and task switching) to favor instead a view that emphasizes the fundamental similarity of the underlying cognitive mechanisms across multitasking paradigms. (PsycINFO Database Record},
  journal = {Psychological Bulletin},
  keywords = {Adaptation; Physiological,Aged,Attention,Child,Cognition,Humans,Models; Theoretical,Multitasking Behavior,Task Performance and Analysis,Young Adult},
  language = {eng},
  number = {6},
  pmid = {29517261}
}

@article{Koch_role_2010,
  title = {The Role of Inhibition in Task Switching: A Review},
  shorttitle = {The Role of Inhibition in Task Switching},
  author = {Koch, Iring and Gade, Miriam and Schuch, Stefanie and Philipp, Andrea M.},
  year = {2010},
  month = feb,
  volume = {17},
  pages = {1--14},
  issn = {1531-5320},
  doi = {10.3758/PBR.17.1.1},
  abstract = {The concept of inhibition plays a major role in cognitive psychology. In the present article, we review the evidence for the inhibition of task sets. In the first part, we critically discuss empirical findings of task inhibition from studies that applied variants of the task-switching methodology and argue that most of these findings-such as switch cost asymmetries-are ambiguous. In the second part, we focus on n-2 task-repetition costs, which currently constitute the most convincing evidence for inhibition of task sets. n-2 repetition costs refer to the performance impairment in sequences of the ABA type relative to CBA, which can be interpreted in terms of persisting inhibition of previously abandoned tasks. The available evidence suggests that inhibition is primarily triggered by conflict at selection of stimulus attributes and at the response level.},
  journal = {Psychonomic Bulletin \& Review},
  keywords = {Attention,Conflict; Psychological,Cues,Humans,Inhibition; Psychological,Psychomotor Performance,Reaction Time,Task Performance and Analysis},
  language = {eng},
  number = {1},
  pmid = {20081154}
}

@article{Koechlin_Architecture_2003,
  title = {The {{Architecture}} of {{Cognitive Control}} in the {{Human Prefrontal Cortex}}},
  author = {Koechlin, Etienne and Ody, Chryst{\`e}le and Kouneiher, Fr{\'e}d{\'e}rique},
  year = {2003},
  month = nov,
  volume = {302},
  pages = {1181--1185},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1088545},
  abstract = {The prefrontal cortex (PFC) subserves cognitive control: the ability to coordinate thoughts or actions in relation with internal goals. Its functional architecture, however, remains poorly understood. Using brain imaging in humans, we showed that the lateral PFC is organized as a cascade of executive processes from premotor to anterior PFC regions that control behavior according to stimuli, the present perceptual context, and the temporal episode in which stimuli occur, respectively. The results support an unified modular model of cognitive control that describes the overall functional organization of the human lateral PFC and has basic methodological and theoretical implications.},
  journal = {Science},
  language = {en},
  number = {5648},
  pmid = {14615530}
}

@article{Kojima_Memory_2004,
  title = {Memory of {{Learning Facilitates Saccadic Adaptation}} in the {{Monkey}}},
  author = {Kojima, Yoshiko and Iwamoto, Yoshiki and Yoshida, Kaoru},
  year = {2004},
  month = aug,
  volume = {24},
  pages = {7531--7539},
  issn = {0270-6474},
  doi = {10.1523/JNEUROSCI.1741-04.2004},
  abstract = {A motor learning mechanism called saccadic adaptation ensures accuracy of saccades throughout life despite growth, aging, and some pathologies of the oculomotor plant or nervous system. The present study investigates effects of preceding adaptation on the speed of subsequent adaptation during single experiments. Adaptive changes in gain (movement size divided by target eccentricity) were induced by intrasaccadic step (ISS) of the target. After the gain was altered (control block), we reversed the direction of ISS to bring the gain back to {$\sim$}1.0 (recovery). We then reversed ISS direction again to induce another adaptation (test block). Analyses revealed that the gain changed at a higher rate in the early part of test adaptation than in the corresponding part of control. After {$\sim$}100-300 saccades in the test block, adaptation slowed down. The gain value at which adaptation slowed was correlated with the gain achieved in the control. We further examined effects of a 30 min intervention inserted between recovery and test blocks. When zero-visual-error trials ({$\sim$}700 saccades) were repeated during this period, the rate of test adaptation was similar to that of control. In contrast, when the animal was deprived of visual inputs during this period, test adaptation was still influenced by preceding learning. We conclude that a memory of previous learning remains during recovery to facilitate subsequent adaptation and that such a memory does not disappear merely with time but is erased actively by repeated zero-error movements. Our results, which cannot be explained by a single mechanism, suggest that the saccadic system is equipped with more than one plasticity process.},
  journal = {The Journal of Neuroscience},
  number = {34},
  pmcid = {PMC6729647},
  pmid = {15329400}
}

@article{Kolling_Multiple_2014,
  title = {Multiple {{Neural Mechanisms}} of {{Decision Making}} and {{Their Competition}} under {{Changing Risk Pressure}}},
  author = {Kolling, Nils and Wittmann, Marco and Rushworth, Matthew F. S.},
  year = {2014},
  month = mar,
  volume = {81},
  pages = {1190--1202},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2014.01.033},
  abstract = {Summary Sometimes when a choice is made, the outcome is not guaranteed and there is only a probability of its occurrence. Each individual's attitude to probability, sometimes called risk proneness or aversion, has been assumed to be static. Behavioral ecological studies, however, suggest such attitudes are dynamically modulated by the context an organism finds itself in; in some cases, it may be optimal to pursue actions with a low probability of success but which are associated with potentially large gains. We show that human subjects rapidly adapt their use of probability as a function of current resources, goals, and opportunities for further foraging. We demonstrate that dorsal anterior cingulate cortex (dACC) carries signals indexing the pressure to pursue unlikely choices and signals related to the taking of such choices. We show that dACC exerts this control over behavior when it, rather than ventromedial prefrontal cortex, interacts with posterior cingulate cortex.},
  journal = {Neuron},
  keywords = {Printed},
  number = {5}
}

@article{Kolling_Neural_2012,
  title = {Neural {{Mechanisms}} of {{Foraging}}},
  author = {Kolling, Nils and Behrens, Timothy E. J. and Mars, Rogier B. and Rushworth, Matthew F. S.},
  year = {2012},
  month = apr,
  volume = {336},
  pages = {95--98},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1216930},
  abstract = {Behavioral economic studies involving limited numbers of choices have provided key insights into neural decision-making mechanisms. By contrast, animals' foraging choices arise in the context of sequences of encounters with prey or food. On each encounter, the animal chooses whether to engage or, if the environment is sufficiently rich, to search elsewhere. The cost of foraging is also critical. We demonstrate that humans can alternate between two modes of choice, comparative decision-making and foraging, depending on distinct neural mechanisms in ventromedial prefrontal cortex (vmPFC) and anterior cingulate cortex (ACC) using distinct reference frames; in ACC, choice variables are represented in invariant reference to foraging or searching for alternatives. Whereas vmPFC encodes values of specific well-defined options, ACC encodes the average value of the foraging environment and cost of foraging.},
  journal = {Science},
  keywords = {Printed},
  language = {en},
  number = {6077},
  pmid = {22491854}
}

@article{Komarov_Sequentially_2009,
  title = {Sequentially Activated Groups in Neural Networks},
  author = {Komarov, M. A. and Osipov, G. V. and Suykens, J. a. K.},
  year = {2009},
  month = jun,
  volume = {86},
  pages = {60006},
  issn = {0295-5075},
  doi = {10.1209/0295-5075/86/60006},
  abstract = {The internal neuronal dynamics, network configurations and coupling are influencing the output of neuronal networks through different external actions. One possible output form is sequential neuronal activity. This activity typically comprises many subsequent components generated by neuronal networks with a different action and spatial location. A stimulus-dependent formation of certain spatio-temporal structures takes place with sequences of groups of neurons that have a switching activity in time. We obtain spatio-temporal structures of activity in networks of randomly synaptically coupled neurons modeled as a Hodgkin-Huxley system. Necessary conditions for appearance of functional structures are presented. It is found that the asymptotic information capacity of the neuronal network exhibits a power law dependency. Its exponent can be very large and depends on the number of groups and the number of neurons per group.},
  journal = {EPL (Europhysics Letters)},
  language = {en},
  number = {6}
}

@article{Konig_Integrator_1996,
  title = {Integrator or Coincidence Detector? {{The}} Role of the Cortical Neuron Revisited},
  shorttitle = {Integrator or Coincidence Detector?},
  author = {Konig, P. and Engel, A. K. and Singer, W.},
  year = {1996},
  month = apr,
  volume = {19},
  pages = {130--137},
  issn = {0166-2236},
  doi = {10.1016/S0166-2236(96)80019-1},
  abstract = {Neurons can operate in two distinct ways, depending on the duration of the interval over which they effectively summate incoming synaptic potentials. If this interval is of the order of the mean interspike interval or longer, neurons act effectively as temporal integrators and transmit temporal patterns with only low reliability. If, by contrast, the integration interval is short compared to the interspike interval, neurons act essentially as coincidence detectors, relay preferentially synchronized input, and the temporal structure of their output is a direct function of the input pattern. Recently, interest in this distinction has been revived because experimental and theoretical results suggest that synchronous firing of neurons might play an important role for information processing in the cortex. Here, we argue that coincidence detection, rather than temporal integration, might be a prevalent operation mode of cortical neurons. We base our arguments on established biophysical properties of cortical neurons and on particular features of cortical dynamics.},
  annotation = {WOS:A1996UA95600004},
  journal = {Trends in Neurosciences},
  keywords = {cat visual-cortex,channels,information,oscillatory responses,synchronization},
  language = {English},
  number = {4}
}

@article{Konishi_Contribution_1999,
  title = {Contribution of {{Working Memory}} to {{Transient Activation}} in {{Human Inferior Prefrontal Cortex}} during {{Performance}} of the {{Wisconsin Card Sorting Test}}},
  author = {Konishi, S. and Kawazu, M. and Uchida, I. and Kikyo, H. and Asakura, I. and Miyashita, Y.},
  year = {1999},
  month = oct,
  volume = {9},
  pages = {745--753},
  issn = {1047-3211, 1460-2199},
  doi = {10.1093/cercor/9.7.745},
  abstract = {The Wisconsin Card Sorting Test (WCST) is the standard task paradigm to detect human frontal lobe dysfunction. In this test, subjects sort card stimuli with respect to one of three possible dimensions (color, form and number). These dimensions are changed intermittently, whereupon subjects are required to identify by trial and error a new correct dimension and flexibly shift cognitive set. We decomposed the cognitive requirements at the time of the dimensional changes of the WCST, using functional magnetic resonance imaging (fMRI). By explicitly informing subjects of a new correct dimension, the working memory load for the trial-and-error identification of the new dimension was removed. Event-related fMRI still revealed transient activation time-locked to the dimensional changes in areas in the posterior part of the inferior frontal sulci. However, the activation was significantly smaller than in the original WCST in which subjects had to use working memory to identify the new dimension by trial and error. Furthermore, these areas were found to spatially overlap the areas activated by a working memory task. These results suggest that working memory and set-shifting act cooperatively in the same areas of prefrontal cortex to adapt us to changing environments.},
  journal = {Cerebral Cortex},
  language = {en},
  number = {7},
  pmid = {10554997}
}

@article{Konishi_Hemispheric_2002,
  title = {Hemispheric Asymmetry in Human Lateral Prefrontal Cortex during Cognitive Set Shifting},
  author = {Konishi, Seiki and Hayashi, Toshihiro and Uchida, Idai and Kikyo, Hideyuki and Takahashi, Emi and Miyashita, Yasushi},
  year = {2002},
  month = may,
  volume = {99},
  pages = {7803--7808},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.122644899},
  abstract = {Functional organization of human cerebral hemispheres is asymmetrically specialized, most typically along a verbal/nonverbal axis. In this event-related functional MRI study, we report another example of the asymmetrical specialization. Set-shifting paradigms derived from the Wisconsin card sorting test were used, where subjects update one behavior to another on the basis of environmental feedback. The cognitive requirements constituting the paradigms were decomposed into two components according to temporal stages of task events. Double dissociation of the component brain activity was found in the three bilateral pairs of regions in the lateral frontal cortex, the right regions being activated during exposure to negative feedback and the corresponding left regions being activated during updating of behavior, to suggest that both hemispheres contribute to cognitive set shifting but in different ways. The asymmetrical hemispheric specialization within the same paradigms further implies an interhemispheric interaction of these task components that achieve a common goal.},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {11},
  pmid = {12032364}
}

@article{Konishi_Transient_1998,
  title = {Transient Activation of Inferior Prefrontal Cortex during Cognitive Set Shifting},
  author = {Konishi, Seiki and Nakajima, Kyoichi and Uchida, Idai and Kameyama, Masashi and Nakahara, Kiyoshi and Sekihara, Kensuke and Miyashita, Yasushi},
  year = {1998},
  month = may,
  volume = {1},
  pages = {80--84},
  issn = {1097-6256},
  doi = {10.1038/283},
  abstract = {The Wisconsin Card Sorting Test, which probes the ability to shift attention from one category of stimulus attributes to another (shifting cognitive sets), is the most common paradigm used to detect human frontal lobe pathology. However, the exact relationship of this card test to prefrontal function and the precise anatomical localization of the cognitive shifts involved are controversial. By isolating shift-related signals using the temporal resolution of functional magnetic resonance imaging, we reproducibly found transient activation of the posterior part of the bilateral inferior frontal sulci. This activation was larger as the number of dimensions (relevant stimulus attributes that had to be recognized) were increased. These results suggest that the inferior frontal areas play an essential role in the flexible shifting of cognitive sets.},
  copyright = {\textcopyright{} 1998 Nature Publishing Group},
  journal = {Nature Neuroscience},
  language = {en},
  number = {1}
}

@article{Konovalov_Gaze_2016,
  title = {Gaze Data Reveal Distinct Choice Processes Underlying Model-Based and Model-Free Reinforcement Learning},
  author = {Konovalov, Arkady and Krajbich, Ian},
  year = {2016},
  month = aug,
  volume = {7},
  issn = {2041-1723},
  doi = {10.1038/ncomms12438},
  abstract = {Organisms appear to learn and make decisions using different strategies known as model-free and model-based learning; the former is mere reinforcement of previously rewarded actions and the latter is a forward-looking strategy that involves evaluation of action-state transition probabilities. Prior work has used neural data to argue that both model-based and model-free learners implement a value comparison process at trial onset, but model-based learners assign more weight to forward-looking computations. Here using eye-tracking, we report evidence for a different interpretation of prior results: model-based subjects make their choices prior to trial onset. In contrast, model-free subjects tend to ignore model-based aspects of the task and instead seem to treat the decision problem as a simple comparison process between two differentially valued items, consistent with previous work on sequential-sampling models of decision making. These findings illustrate a problem with assuming that experimental subjects make their decisions at the same prescribed time.,  Learning occurs when previously rewarded actions are reinforced or when predictions are made about future consequences. Here Konovalov and Krajbich show that people who learn through reinforcement treat decisions as a comparison while those who learn by making predictions make their choices before deciding.},
  journal = {Nature Communications},
  keywords = {eye tracking,model-based},
  pmcid = {PMC4987535},
  pmid = {27511383}
}

@article{Kool_Decision_2010,
  title = {Decision {{Making}} and the {{Avoidance}} of {{Cognitive Demand}}},
  author = {Kool, Wouter and McGuire, Joseph T. and Rosen, Zev B. and Botvinick, Matthew M.},
  year = {2010},
  month = nov,
  volume = {139},
  pages = {665--682},
  issn = {0096-3445},
  doi = {10.1037/a0020198},
  abstract = {Behavioral and economic theories have long maintained that actions are chosen so as to minimize demands for exertion or work, a principle sometimes referred to as the ``law of less work.'' The data supporting this idea pertain almost entirely to demands for physical effort. However, the same minimization principle has often been assumed also to apply to cognitive demand. We set out to evaluate the validity of this assumption. In six behavioral experiments, participants chose freely between courses of action associated with different levels of demand for controlled information processing. Together, the results of these experiments revealed a bias in favor of the less demanding course of action. The bias was obtained across a range of choice settings and demand manipulations, and was not wholly attributable to strategic avoidance of errors, minimization of time on task, or maximization of the rate of goal achievement. Remarkably, the effect also did not depend on awareness of the demand manipulation. Consistent with a motivational account, avoidance of demand displayed sensitivity to task incentives and co-varied with individual differences in the efficacy of executive control. The findings reported, together with convergent neuroscientific evidence, lend support to the idea that anticipated cognitive demand plays a significant role in behavioral decision-making.},
  journal = {Journal of experimental psychology. General},
  number = {4},
  pmcid = {PMC2970648},
  pmid = {20853993}
}

@article{Kool_intrinsic_2013,
  title = {The Intrinsic Cost of Cognitive Control},
  author = {Kool, Wouter and Botvinick, Matthew},
  year = {2013},
  month = dec,
  volume = {36},
  pages = {697--698},
  issn = {0140-525X, 1469-1825},
  doi = {10.1017/S0140525X1300109X},
  abstract = {Kurzban and colleagues carry forward an important contemporary movement in cognitive control research, tending away from resource-based models and toward a framework focusing on motivation or value. However, their specific proposal, centering on opportunity costs, appears problematic. We favor a simpler view, according to which the exertion of cognitive control carries intrinsic subjective costs.},
  journal = {Behavioral and Brain Sciences},
  language = {en},
  number = {6}
}

@article{Kool_Planning_2018,
  title = {Planning {{Complexity Registers}} as a {{Cost}} in {{Metacontrol}}},
  author = {Kool, Wouter and Gershman, Samuel J. and Cushman, Fiery A.},
  year = {2018},
  month = apr,
  volume = {30},
  pages = {1391--1404},
  issn = {0898-929X},
  doi = {10.1162/jocn_a_01263},
  abstract = {Decision-making algorithms face a basic tradeoff between accuracy and effort (i.e., computational demands). It is widely agreed that humans can choose between multiple decision-making processes that embody different solutions to this tradeoff: Some are computationally cheap but inaccurate, whereas others are computationally expensive but accurate. Recent progress in understanding this tradeoff has been catalyzed by formalizing it in terms of model-free (i.e., habitual) versus model-based (i.e., planning) approaches to reinforcement learning. Intuitively, if two tasks offer the same rewards for accuracy but one of them is much more demanding, we might expect people to rely on habit more in the difficult task: Devoting significant computation to achieve slight marginal accuracy gains would not be ``worth it.'' We test and verify this prediction in a sequential reinforcement learning task. Because our paradigm is amenable to formal analysis, it contributes to the development of a computational model of how people balance the costs and benefits of different decision-making processes in a task-specific manner; in other words, how we decide when hard thinking is worth it.},
  journal = {Journal of Cognitive Neuroscience},
  number = {10}
}

@article{Kool_When_2016,
  title = {When {{Does Model}}-{{Based Control Pay Off}}?},
  author = {Kool, Wouter and Cushman, Fiery A. and Gershman, Samuel J.},
  year = {2016},
  month = aug,
  volume = {12},
  pages = {e1005090},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1005090},
  abstract = {Author Summary When you make a choice about what groceries to get for dinner, you can rely on two different strategies. You can make your choice by relying on habit, simply buying the items you need to make a meal that is second nature to you. However, you can also plan your actions in a more deliberative way, realizing that the friend who will join you is a vegetarian, and therefore you should not make the burgers that have become a staple in your cooking. These two strategies differ in how computationally demanding and accurate they are. While the habitual strategy is less computationally demanding (costs less effort and time), the deliberative strategy is more accurate. Scientists have been able to study the distinction between these strategies using a task that allows them to measure how much people rely on habit and planning strategies. Interestingly, we have discovered that in this task, the deliberative strategy does not increase performance accuracy, and hence does not induce a trade-off between accuracy and demand. We describe why this happens, and improve the task so that it embodies an accuracy-demand trade-off, providing evidence for theories of cost-based arbitration between cognitive strategies.},
  journal = {PLOS Computational Biology},
  keywords = {Agent-based modeling,Decision Making,Human learning,Learning,Planets,Probability distribution,Random walk,Simulation and modeling},
  number = {8}
}

@article{Kording_loss_2004,
  title = {The Loss Function of Sensorimotor Learning},
  author = {K{\"o}rding, Konrad Paul and Wolpert, Daniel M.},
  year = {2004},
  month = jun,
  volume = {101},
  pages = {9839--9842},
  publisher = {{National Academy of Sciences}},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.0308394101},
  abstract = {Motor learning can be defined as changing performance so as to optimize some function of the task, such as accuracy. The measure of accuracy that is optimized is called a loss function and specifies how the CNS rates the relative success or cost of a particular movement outcome. Models of pointing in sensorimotor control and learning usually assume a quadratic loss function in which the mean squared error is minimized. Here we develop a technique for measuring the loss associated with errors. Subjects were required to perform a task while we experimentally controlled the skewness of the distribution of errors they experienced. Based on the change in the subjects' average performance, we infer the loss function. We show that people use a loss function in which the cost increases approximately quadratically with error for small errors and significantly less than quadratically for large errors. The system is thus robust to outliers. This suggests that models of sensorimotor control and learning that have assumed minimizing squared error are a good approximation but tend to penalize large errors excessively.},
  chapter = {Biological Sciences},
  copyright = {Copyright \textcopyright{} 2004, The National Academy of Sciences},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {26},
  pmid = {15210973}
}

@article{Korn_Heuristic_2018,
  title = {Heuristic and Optimal Policy Computations in the Human Brain during Sequential Decision-Making},
  author = {Korn, Christoph W. and Bach, Dominik R.},
  year = {2018},
  month = jan,
  volume = {9},
  pages = {1--15},
  issn = {2041-1723},
  doi = {10.1038/s41467-017-02750-3},
  abstract = {Alhough humans often make a series of related decisions, it is unknown whether this is done by relying on optimal or heuristic strategies. Here, the\&nbsp;authors show that humans rely on both\&nbsp;the best heuristic and the optimal policy, and that these strategies are controlled by parts of the medial prefrontal cortex.},
  copyright = {2018 The Author(s)},
  journal = {Nature Communications},
  language = {en},
  number = {1}
}

@article{Kuipers_Spatial_2000,
  title = {The {{Spatial Semantic Hierarchy}}},
  author = {Kuipers, Benjamin},
  year = {2000},
  month = may,
  volume = {119},
  pages = {191--233},
  issn = {0004-3702},
  doi = {10.1016/S0004-3702(00)00017-5},
  abstract = {The Spatial Semantic Hierarchy is a model of knowledge of large-scale space consisting of multiple interacting representations, both qualitative and quantitative. The SSH is inspired by the properties of the human cognitive map, and is intended to serve both as a model of the human cognitive map and as a method for robot exploration and map-building. The multiple levels of the SSH express states of partial knowledge, and thus enable the human or robotic agent to deal robustly with uncertainty during both learning and problem-solving. The control level represents useful patterns of sensorimotor interaction with the world in the form of trajectory-following and hill-climbing control laws leading to locally distinctive states. Local geometric maps in local frames of reference can be constructed at the control level to serve as observers for control laws in particular neighborhoods. The causal level abstracts continuous behavior among distinctive states into a discrete model consisting of states linked by actions. The topological level introduces the external ontology of places, paths and regions by abduction to explain the observed pattern of states and actions at the causal level. Quantitative knowledge at the control, causal and topological levels supports a ``patchwork map'' of local geometric frames of reference linked by causal and topological connections. The patchwork map can be merged into a single global frame of reference at the metrical level when sufficient information and computational resources are available. We describe the assumptions and guarantees behind the generality of the SSH across environments and sensorimotor systems. Evidence is presented from several partial implementations of the SSH on simulated and physical robots.},
  journal = {Artificial Intelligence},
  keywords = {Cognitive map,Map learning,Qualitative reasoning,Robot exploration,Spatial reasoning},
  number = {1\textendash 2}
}

@article{Kurzban_opportunity_2013,
  title = {An Opportunity Cost Model of Subjective Effort and Task Performance},
  author = {Kurzban, Robert and Duckworth, Angela and Kable, Joseph W. and Myers, Justus},
  year = {2013},
  month = dec,
  volume = {36},
  pages = {661--679},
  issn = {0140-525X, 1469-1825},
  doi = {10.1017/S0140525X12003196},
  abstract = {Why does performing certain tasks cause the aversive experience of mental effort and concomitant deterioration in task performance? One explanation posits a physical resource that is depleted over time. We propose an alternative explanation that centers on mental representations of the costs and benefits associated with task performance. Specifically, certain computational mechanisms, especially those associated with executive function, can be deployed for only a limited number of simultaneous tasks at any given moment. Consequently, the deployment of these computational mechanisms carries an opportunity cost~\textendash ~that is, the next-best use to which these systems might be put. We argue that the phenomenology of effort can be understood as the felt output of these cost/benefit computations. In turn, the subjective experience of effort motivates reduced deployment of these computational mechanisms in the service of the present task. These opportunity cost representations, then, together with other cost/benefit calculations, determine effort expended and, everything else equal, result in performance reductions. In making our case for this position, we review alternative explanations for both the phenomenology of effort associated with these tasks and for performance reductions over time. Likewise, we review the broad range of relevant empirical results from across sub-disciplines, especially psychology and neuroscience. We hope that our proposal will help to build links among the diverse fields that have been addressing similar questions from different perspectives, and we emphasize ways in which alternative models might be empirically distinguished.},
  journal = {Behavioral and Brain Sciences},
  keywords = {evolutionary psychology,mental effort,neuroeconomics,phenomenology,self-control},
  language = {en},
  number = {6}
}

@article{Lak_Orbitofrontal_2014,
  title = {Orbitofrontal {{Cortex Is Required}} for {{Optimal Waiting Based}} on {{Decision Confidence}}},
  author = {Lak, Armin and Costa, Gil M. and Romberg, Erin and Koulakov, Alexei A. and Mainen, Zachary F. and Kepecs, Adam},
  year = {2014},
  month = oct,
  volume = {84},
  pages = {190--201},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2014.08.039},
  abstract = {Summary Confidence judgments are a central example of metacognition\textemdash knowledge about one's own cognitive processes. According to this metacognitive view, confidence reports are generated by a second-order monitoring process based on the quality of internal representations about beliefs. Although neural correlates of decision confidence have been recently identified in humans and other animals, it is not well understood whether there are brain areas specifically important for confidence monitoring. To address this issue, we designed a postdecision temporal wagering task in which rats expressed choice confidence by the amount of time they were willing to wait for reward. We found that orbitofrontal cortex inactivation disrupts waiting-based confidence reports without affecting decision accuracy. Furthermore, we show that a normative model can quantitatively account for waiting times based on the computation of decision confidence. These results establish an anatomical locus for a metacognitive report, confidence judgment, distinct from the processes required for perceptual decisions.},
  journal = {Neuron},
  number = {1}
}

@article{Lally_How_2010,
  title = {How Are Habits Formed: {{Modelling}} Habit Formation in the Real World},
  shorttitle = {How Are Habits Formed},
  author = {Lally, Phillippa and van Jaarsveld, Cornelia H. M. and Potts, Henry W. W. and Wardle, Jane},
  year = {2010},
  volume = {40},
  pages = {998--1009},
  issn = {1099-0992},
  doi = {10.1002/ejsp.674},
  abstract = {To investigate the process of habit formation in everyday life, 96 volunteers chose an eating, drinking or activity behaviour to carry out daily in the same context (for example `after breakfast') for 12 weeks. They completed the self-report habit index (SRHI) each day and recorded whether they carried out the behaviour. The majority (82) of participants provided sufficient data for analysis, and increases in automaticity (calculated with a sub-set of SRHI items) were examined over the study period. Nonlinear regressions fitted an asymptotic curve to each individual's automaticity scores over the 84 days. The model fitted for 62 individuals, of whom 39 showed a good fit. Performing the behaviour more consistently was associated with better model fit. The time it took participants to reach 95\% of their asymptote of automaticity ranged from 18 to 254 days; indicating considerable variation in how long it takes people to reach their limit of automaticity and highlighting that it can take a very long time. Missing one opportunity to perform the behaviour did not materially affect the habit formation process. With repetition of a behaviour in a consistent context, automaticity increases following an asymptotic curve which can be modelled at the individual level. Copyright \textcopyright{} 2009 John Wiley \& Sons, Ltd.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/ejsp.674},
  copyright = {Copyright \textcopyright{} 2009 John Wiley \& Sons, Ltd.},
  journal = {European Journal of Social Psychology},
  keywords = {habits,modeling,unread},
  language = {en},
  number = {6}
}

@article{Lally_Neural_2017,
  title = {The {{Neural Basis}} of {{Aversive Pavlovian Guidance}} during {{Planning}}},
  author = {Lally, N{\'i}all and Huys, Quentin J. M. and Eshel, Neir and Faulkner, Paul and Dayan, Peter and Roiser, Jonathan P.},
  year = {2017},
  month = oct,
  volume = {37},
  pages = {10215--10229},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.0085-17.2017},
  abstract = {Important real-world decisions are often arduous as they frequently involve sequences of choices, with initial selections affecting future options. Evaluating every possible combination of choices is computationally intractable, particularly for longer multistep decisions. Therefore, humans frequently use heuristics to reduce the complexity of decisions. We recently used a goal-directed planning task to demonstrate the profound behavioral influence and ubiquity of one such shortcut, namely aversive pruning, a reflexive Pavlovian process that involves neglecting parts of the decision space residing beyond salient negative outcomes. However, how the brain implements this important decision heuristic and what underlies individual differences have hitherto remained unanswered. Therefore, we administered an adapted version of the same planning task to healthy male and female volunteers undergoing functional magnetic resonance imaging (fMRI) to determine the neural basis of aversive pruning. Through both computational and standard categorical fMRI analyses, we show that when planning was influenced by aversive pruning, the subgenual cingulate cortex was robustly recruited. This neural signature was distinct from those associated with general planning and valuation, two fundamental cognitive components elicited by our task but which are complementary to aversive pruning. Furthermore, we found that individual variation in levels of aversive pruning was associated with the responses of insula and dorsolateral prefrontal cortices to the receipt of large monetary losses, and also with subclinical levels of anxiety. In summary, our data reveal the neural signatures of an important reflexive Pavlovian process that shapes goal-directed evaluations and thereby determines the outcome of high-level sequential cognitive processes. SIGNIFICANCE STATEMENT Multistep decisions are complex because initial choices constrain future options. Evaluating every path for long decision sequences is often impractical; thus, cognitive shortcuts are often essential. One pervasive and powerful heuristic is aversive pruning, in which potential decision-making avenues are curtailed at immediate negative outcomes. We used neuroimaging to examine how humans implement such pruning. We found it to be associated with activity in the subgenual cingulate cortex, with neural signatures that were distinguishable from those covarying with planning and valuation. Individual variations in aversive pruning levels related to subclinical anxiety levels and insular cortex activation. These findings reveal the neural mechanisms by which basic negative Pavlovian influences guide decision-making during planning, with implications for disrupted decision-making in psychiatric disorders.},
  copyright = {Copyright \textcopyright{} 2017 the authors 0270-6474/17/3710216-15\$15.00/0},
  journal = {Journal of Neuroscience},
  keywords = {aversive pruning,decision-making,fMRI,punishment,reward,subgenual cingulate cortex},
  language = {en},
  number = {42},
  pmid = {28924006}
}

@article{Langdon_Modelbased_2018,
  title = {Model-Based Predictions for Dopamine},
  author = {Langdon, Angela J and Sharpe, Melissa J and Schoenbaum, Geoffrey and Niv, Yael},
  year = {2018},
  month = apr,
  volume = {49},
  pages = {1--7},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2017.10.006},
  abstract = {Phasic dopamine responses are thought to encode a prediction-error signal consistent with model-free reinforcement learning theories. However, a number of recent findings highlight the influence of model-based computations on dopamine responses, and suggest that dopamine prediction errors reflect more dimensions of an expected outcome than scalar reward value. Here, we review a selection of these recent results and discuss the implications and complications of model-based predictions for computational theories of dopamine and learning.},
  journal = {Current Opinion in Neurobiology},
  series = {Neurobiology of {{Behavior}}}
}

@article{Langdon_Modelbased_2018a,
  title = {Model-Based Predictions for Dopamine},
  author = {Langdon, Angela J and Sharpe, Melissa J and Schoenbaum, Geoffrey and Niv, Yael},
  year = {2018},
  month = apr,
  volume = {49},
  pages = {1--7},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2017.10.006},
  abstract = {Phasic dopamine responses are thought to encode a prediction-error signal consistent with model-free reinforcement learning theories. However, a number of recent findings highlight the influence of model-based computations on dopamine responses, and suggest that dopamine prediction errors reflect more dimensions of an expected outcome than scalar reward value. Here, we review a selection of these recent results and discuss the implications and complications of model-based predictions for computational theories of dopamine and learning.},
  journal = {Current Opinion in Neurobiology},
  series = {Neurobiology of {{Behavior}}}
}

@article{Laurent_Dynamical_1996,
  title = {Dynamical Representation of Odors by Oscillating and Evolving Neural Assemblies},
  author = {Laurent, Gilles},
  year = {1996},
  month = nov,
  volume = {19},
  pages = {489--496},
  issn = {0166-2236},
  doi = {10.1016/S0166-2236(96)10054-0},
  abstract = {Although smells are some of the most evocative and emotionally charged sensory inputs known to us, we still understand relatively little about olfactory processing and odor representation in the brain. This review summarizes physiological results obtained from an insect olfactory system and presents a functional scheme for odor coding that is compatible with data from other animals, including mammals. This coding scheme consists of three main and concurrent odor-induced phenomena: 20\textendash 30 Hz oscillatory mass activity; patterned and odor-specific neuronal responses; and transient, dynamic synchronization of odor-specific neural assemblies. When these phenomena are considered together, odors appear to be represented combinatorially by dynamical neural assemblies, defined partly by the transient but stimulus-specific synchronization of their neuronal components. Trends Neurosci. (1996) 19, 489\textendash 496},
  journal = {Trends in Neurosciences},
  number = {11}
}

@article{Laurent_Encoding_1994,
  title = {Encoding of Olfactory Information with Oscillating Neural Assemblies},
  author = {Laurent, G and Davidowitz, H},
  year = {1994},
  month = sep,
  volume = {265},
  pages = {1872--1875},
  issn = {0036-8075},
  doi = {10.1126/science.265.5180.1872},
  abstract = {In the brain, fast oscillations of local field potentials, which are thought to arise from the coherent and rhythmic activity of large numbers of neurons, were observed first in the olfactory system and have since been described in many neocortical areas. The importance of these oscillations in information coding, however, is controversial. Here, local field potential and intracellular recordings were obtained from the antennal lobe and mushroom body of the locust Schistocerca americana. Different odors evoked coherent oscillations in different, but usually overlapping, ensembles of neurons. The phase of firing of individual neurons relative to the population was not dependent on the odor. The components of a coherently oscillating ensemble of neurons changed over the duration of a single exposure to an odor. It is thus proposed that odors are encoded by specific but dynamic assemblies of coherently oscillating neurons. Such distributed and temporal representation of complex sensory signals may facilitate combinatorial coding and associative learning in these, and possibly other, sensory networks.},
  journal = {Science (New York, N.Y.)},
  language = {eng},
  number = {5180},
  pmid = {17797226}
}

@article{Laurent_Odor_2001,
  title = {Odor Encoding as an Active, Dynamical Process: Experiments, Computation, and Theory},
  shorttitle = {Odor Encoding as an Active, Dynamical Process},
  author = {Laurent, G and Stopfer, M and Friedrich, R W and Rabinovich, M I and Volkovskii, A and Abarbanel, H D},
  year = {2001},
  volume = {24},
  pages = {263--297},
  issn = {0147-006X},
  doi = {10.1146/annurev.neuro.24.1.263},
  abstract = {We examine early olfactory processing in the vertebrate and insect olfactory systems, using a computational perspective. What transformations occur between the first and second olfactory processing stages? What are the causes and consequences of these transformations? To answer these questions, we focus on the functions of olfactory circuit structure and on the role of time in odor-evoked integrative processes. We argue that early olfactory relays are active and dynamical networks, whose actions change the format of odor-related information in very specific ways, so as to refine stimulus identification. Finally, we introduce a new theoretical framework ("winnerless competition") for the interpretation of these data.},
  journal = {Annual review of neuroscience},
  keywords = {Animals,Humans,Models; Neurological,Odors,Olfactory Bulb,Olfactory Pathways,Smell},
  language = {eng},
  pmid = {11283312}
}

@article{Laurent_Odorantinduced_1994,
  title = {Odorant-Induced Oscillations in the Mushroom Bodies of the Locust},
  author = {Laurent, G and Naraghi, M},
  year = {1994},
  month = may,
  volume = {14},
  pages = {2993--3004},
  issn = {0270-6474},
  abstract = {Kenyon cells are the intrinsic interneurons of the mushroom bodies in the insect brain, a center for olfactory and multimodal processing and associative learning. These neurons are small (3-8 microns soma diameter) and numerous (340,000 and 400,000 in the bee and cockroach brains, respectively). In Drosophila, Kenyon cells are the dominant site of expression of the dunce, DC0, and rutabaga gene products, enzymes in the cAMP cascade whose absence leads to specific defects in olfactory learning. In honeybees, the volume of the mushroom body neurophils may depend on the age or social status of the individual. Although the anatomy of these neurons has been known for nearly a century, their physiological properties and the principles of information processing in the circuits that they form are totally unknown. This article provides a first such characterization. The activity of Kenyon cells was recorded in vivo from locust brains with intracellular and local field potential electrodes during olfactory processing. Kenyon cells had a high input impedance (approximately 1 G omega at the soma). They produced action potentials upon depolarization, and consistently showed spike adaptation during long depolarizing current pulses. They generally displayed a low resting level of spike activity in the absence of sensory stimulation, despite a large background of spontaneous synaptic activity, and showed no intrinsic bursting behavior. Presentation of an airborne odor, but not air alone, to an antenna evoked spatially coherent field potential oscillations in the ipsilateral mushroom body, with a frequency of approximately 20 Hz. The frequency of these oscillations was independent of the nature of the odorant. Short bouts of oscillations sometimes occurred spontaneously, that is, in the absence of odorant stimulation. Autocorrelograms of the local field potentials in the absence of olfactory stimulation revealed small peaks at +/- 50 msec, suggesting an intrinsic tendency of the mushroom body networks to oscillate at 20 Hz. Such oscillatory behavior could not be seen from local field potential recordings in the antennal lobes, and may thus be generated in the mushroom body, or via feedback interactions with downstream neurons in the protocerebrum. During the odor-induced oscillations, the membrane potential of Kenyon cells oscillated around the resting level, under the influence of excitatory inputs phase-locked to the field activity. Each phasic wave of depolarization in a Kenyon cell could be amplified by intrinsic excitable properties of the dendritic membrane, and sometimes led to one action potential, whose timing was phase-locked to the population oscillations.(ABSTRACT TRUNCATED AT 400 WORDS)},
  journal = {The Journal of neuroscience: the official journal of the Society for Neuroscience},
  keywords = {Animals,Brain,Electrophysiology,Female,Grasshoppers,Interneurons,Male,Nerve Net,Odors,Olfactory Pathways,Oscillometry,Physical Stimulation,Sense Organs},
  language = {eng},
  number = {5 Pt 2},
  pmid = {8182454}
}

@article{Laurent_Odorantinduced_1994a,
  title = {Odorant-Induced Oscillations in the Mushroom Bodies of the Locust},
  author = {Laurent, G. and Naraghi, M.},
  year = {1994},
  month = may,
  volume = {14},
  pages = {2993--3004},
  issn = {0270-6474, 1529-2401},
  journal = {The Journal of Neuroscience},
  language = {en},
  number = {5},
  pmid = {8182454}
}

@article{Laurent_Spatiotemporal_1998,
  title = {Spatiotemporal Structure of Olfactory Inputs to the Mushroom Bodies},
  author = {Laurent, G. and MacLeod, K. and Stopfer, M. and Wehr, M.},
  year = {1998},
  month = may,
  volume = {5},
  pages = {124--132},
  issn = {1072-0502},
  annotation = {WOS:000078894100009},
  journal = {Learning \& Memory},
  number = {1-2}
}

@article{Lavie_Load_2004,
  title = {Load Theory of Selective Attention and Cognitive Control},
  author = {Lavie, Nilli and Hirst, Aleksandra and {de Fockert}, Jan W. and Viding, Essi},
  year = {2004},
  month = sep,
  volume = {133},
  pages = {339--354},
  issn = {0096-3445},
  doi = {10.1037/0096-3445.133.3.339},
  abstract = {A load theory of attention in which distractor rejection depends on the level and type of load involved in current processing was tested. A series of experiments demonstrates that whereas high perceptual load reduces distractor interference, working memory load or dual-task coordination load increases distractor interference. These findings suggest 2 selective attention mechanisms: a perceptual selection mechanism serving to reduce distractor perception in situations of high perceptual load that exhaust perceptual capacity in processing relevant stimuli and a cognitive control mechanism that reduces interference from perceived distractors as long as cognitive control functions are available to maintain current priorities (low cognitive load). This theory resolves the long-standing early versus late selection debate and clarifies the role of cognitive control in selective attention.},
  journal = {Journal of Experimental Psychology. General},
  keywords = {Analysis of Variance,Attention,cognition,Great Britain,Humans,Memory; Short-Term,Models; Psychological,Visual Perception},
  language = {eng},
  number = {3},
  pmid = {15355143}
}

@article{Lebreton_Automatic_2015,
  title = {Automatic Integration of Confidence in the Brain Valuation Signal},
  author = {Lebreton, Ma{\"e}l and Abitbol, Rapha{\"e}lle and Daunizeau, Jean and Pessiglione, Mathias},
  year = {2015},
  month = aug,
  volume = {18},
  pages = {1159--1167},
  issn = {1097-6256},
  doi = {10.1038/nn.4064},
  abstract = {A key process in decision-making is estimating the value of possible outcomes. Growing evidence suggests that different types of values are automatically encoded in the ventromedial prefrontal cortex (VMPFC). Here we extend this idea by suggesting that any overt judgment is accompanied by a second-order valuation (a confidence estimate), which is also automatically incorporated in VMPFC activity. In accordance with the predictions of our normative model of rating tasks, two behavioral experiments showed that confidence levels were quadratically related to first-order judgments (age, value or probability ratings). The analysis of three functional magnetic resonance imaging data sets using similar rating tasks confirmed that the quadratic extension of first-order ratings (our proxy for confidence) was encoded in VMPFC activity, even if no confidence judgment was required of the participants. Such an automatic aggregation of value and confidence in a same brain region might provide insight into many distortions of judgment and choice.},
  copyright = {\textcopyright{} 2015 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  journal = {Nature Neuroscience},
  language = {en},
  number = {8}
}

@article{Lee_Avoiding_2003,
  title = {Avoiding the Dangers of Averaging across Subjects When Using Multidimensional Scaling},
  author = {Lee, Michael D. and Pope, Kenneth J.},
  year = {2003},
  month = feb,
  volume = {47},
  pages = {32--46},
  issn = {0022-2496},
  doi = {10.1016/S0022-2496(02)00019-6},
  abstract = {Ashby, Maddox and Lee (Psychological Science, 5 (3) 144) argue that it can be inappropriate to fit multidimensional scaling (MDS) models to similarity or dissimilarity data that have been averaged across subjects. They demonstrate that the averaging process tends to make dissimilarity data more amenable to metric representations, and conduct a simulation study showing that noisy data generated using one distance metric, when averaged, may be better fit using a different distance metric. This paper argues that a Bayesian measure of MDS models has the potential to address these difficulties, because it takes into account data-fit, the number of dimensions used by an MDS representation, and the precision of the data. A method of analysis based on the Bayesian measure is demonstrated through two simulation studies with accompanying theoretical analysis. In the first study, it is shown that the Bayesian analysis rejects those MDS models showing better fit to averaged data using the incorrect distance metric, while accepting those that use the correct metric. In the second study, different groups of simulated `subjects' are assumed to use different underlying configurations. In this case, the Bayesian analysis rejects MDS representations where a significant proportion of subjects use different configurations, or when their dissimilarity judgments contain significant amounts of noise. It is concluded that the Bayesian analysis provides a simple and principled means for systematically accepting and rejecting MDS models derived from averaged data.},
  journal = {Journal of Mathematical Psychology},
  number = {1}
}

@article{Lee_Decision_2013,
  title = {Decision {{Making}}: {{From Neuroscience}} to {{Psychiatry}}},
  shorttitle = {Decision {{Making}}},
  author = {Lee, Daeyeol},
  year = {2013},
  month = apr,
  volume = {78},
  pages = {233--248},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2013.04.008},
  journal = {Neuron},
  language = {English},
  number = {2},
  pmid = {23622061}
}

@article{Lee_Decision_2013a,
  title = {Decision {{Making}}: From {{Neuroscience}} to {{Psychiatry}}},
  shorttitle = {Decision {{Making}}},
  author = {Lee, Daeyeol},
  year = {2013},
  month = apr,
  volume = {78},
  pages = {233--248},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2013.04.008},
  abstract = {Adaptive behaviors increase the likelihood of survival and reproduction and improve the quality of life. However, it is often difficult to identify optimal behaviors in real life due to the complexity of the decision maker's environment and social dynamics. As a result, although many different brain areas and circuits are involved in decision making, evolutionary and learning solutions adopted by individual decision makers sometimes produce suboptimal outcomes. Although these problems are exacerbated in numerous neurological and psychiatric disorders, their underlying neurobiological causes remain incompletely understood. In this review, theoretical frameworks in economics and machine learning and their applications in recent behavioral and neurobiological studies are summarized. Examples of such applications in clinical domains are also discussed for substance abuse, Parkinson's disease, attention-deficit/hyperactivity disorder, schizophrenia, mood disorders, and autism. Findings from these studies have begun to lay the foundations necessary to improve diagnostics and treatment for various neurological and psychiatric disorders.},
  journal = {Neuron},
  number = {2},
  pmcid = {PMC3670825},
  pmid = {23622061}
}

@article{Lee_Dual_2009,
  title = {Dual {{Adaptation Supports}} a {{Parallel Architecture}} of {{Motor Memory}}},
  author = {Lee, Jeong-Yoon and Schweighofer, Nicolas},
  year = {2009},
  month = aug,
  volume = {29},
  pages = {10396--10404},
  publisher = {{Society for Neuroscience}},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.1294-09.2009},
  abstract = {Although our understanding of the mechanisms underlying motor adaptation has greatly benefited from previous computational models, the architecture of motor memory is still uncertain. On one hand, two-state models that contain both a fast-learning\textendash fast-forgetting process and a slow-learning\textendash slow-forgetting process explain a wide range of data on motor adaptation, but cannot differentiate whether the fast and slow processes are arranged serially or in parallel and cannot account for learning multiple tasks simultaneously. On the other hand, multiple parallel-state models learn multiple tasks simultaneously but cannot account for a number of motor adaptation data. Here, we investigated the architecture of human motor memory by systematically testing possible architectures via a combination of simulations and a dual visuomotor adaptation experimental paradigm. We found that only one parsimonious model can account for both previous motor adaptation data and our dual-task adaptation data: a fast process that contains a single state is arranged in parallel with a slow process that contains multiple states switched via contextual cues. Our result suggests that during motor adaptation, fast and slow processes are updated simultaneously from the same motor learning errors.},
  chapter = {Articles},
  copyright = {Copyright \textcopyright{} 2009 Society for Neuroscience 0270-6474/09/2910396-09\$15.00/0},
  journal = {Journal of Neuroscience},
  language = {en},
  number = {33},
  pmid = {19692614}
}

@article{Lee_Neural_2012,
  title = {Neural {{Basis}} of {{Reinforcement Learning}} and {{Decision Making}}},
  author = {Lee, Daeyeol and Seo, Hyojung and Jung, Min Whan},
  year = {2012},
  volume = {35},
  pages = {287--308},
  doi = {10.1146/annurev-neuro-062111-150512},
  abstract = {Reinforcement learning is an adaptive process in which an animal utilizes its previous experience to improve the outcomes of future choices. Computational theories of reinforcement learning play a central role in the newly emerging areas of neuroeconomics and decision neuroscience. In this framework, actions are chosen according to their value functions, which describe how much future reward is expected from each action. Value functions can be adjusted not only through reward and penalty, but also by the animal's knowledge of its current environment. Studies have revealed that a large proportion of the brain is involved in representing and updating value functions and using them to choose an action. However, how the nature of a behavioral task affects the neural mechanisms of reinforcement learning remains incompletely understood. Future studies should uncover the principles by which different computational elements of reinforcement learning are dynamically coordinated across the entire brain.},
  annotation = {\_eprint: https://doi.org/10.1146/annurev-neuro-062111-150512},
  journal = {Annual Review of Neuroscience},
  number = {1},
  pmid = {22462543}
}

@article{Lee_Neural_2014,
  title = {Neural {{Computations Underlying Arbitration}} between {{Model}}-{{Based}} and {{Model}}-Free {{Learning}}},
  author = {Lee, Sang Wan and Shimojo, Shinsuke and O'Doherty, John P.},
  year = {2014},
  month = may,
  volume = {81},
  pages = {687--699},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2013.11.028},
  abstract = {There is accumulating neural evidence to support the existence of two distinct systems for guiding action selection, a deliberative ``model-based'' and a reflexive ``model-free'' system. However, little is known about how the brain determines which of these systems controls behavior at one moment in time. We provide evidence for an arbitration mechanism that allocates the degree of control over behavior by model-based and model-free systems as a function of the reliability of their respective predictions. We show that the inferior lateral prefrontal and frontopolar cortex encode both reliability signals and the output of a comparison between those signals, implicating these regions in the arbitration process. Moreover, connectivity between these regions and model-free valuation areas is negatively modulated by the degree of model-based control in the arbitrator, suggesting that arbitration may work through modulation of the model-free valuation system when the arbitrator deems that the model-based system should drive behavior.},
  journal = {Neuron},
  keywords = {arbitration,computational model,decision-making,model-based,Printed},
  language = {English},
  number = {3},
  pmid = {24507199}
}

@article{Legenstein_Ensembles_2014,
  title = {Ensembles of Spiking Neurons with Noise Support Optimal Probabilistic Inference in a Dynamically Changing Environment.},
  author = {Legenstein, Robert and Maass, Wolfgang},
  year = {2014},
  month = oct,
  volume = {10},
  pages = {e1003859},
  doi = {10.1371/journal.pcbi.1003859},
  abstract = {It has recently been shown that networks of spiking neurons with noise can emulate simple forms of probabilistic inference through "neural sampling", i.e., by treating spikes as samples from a probability distribution of network states that is encoded in the network. Deficiencies of the existing model are its reliance on single neurons for sampling from each random variable, and the resulting limitation in representing quickly varying probabilistic information. We show that both deficiencies can be overcome by moving to a biologically more realistic encoding of each salient random variable through the stochastic firing activity of an ensemble of neurons. The resulting model demonstrates that networks of spiking neurons with noise can easily track and carry out basic computational operations on rapidly varying probability distributions, such as the odds of getting rewarded for a specific behavior. We demonstrate the viability of this new approach towards neural coding and computation, which makes use of the inherent parallelism of generic neural circuits, by showing that this model can explain experimentally observed firing activity of cortical neurons for a variety of tasks that require rapid temporal integration of sensory information.},
  journal = {PLoS Comput Biol},
  language = {eng},
  number = {10},
  pmid = {25340749}
}

@article{Leitch_GABAergic_1996,
  title = {{{GABAergic}} Synapses in the Antennal Lobe and Mushroom Body of the Locust Olfactory System},
  author = {Leitch, B and Laurent, G},
  year = {1996},
  month = sep,
  volume = {372},
  pages = {487--514},
  issn = {0021-9967},
  doi = {10.1002/(SICI)1096-9861(19960902)372:4&lt;487::AID-CNE1&gt;3.0.CO;2-0},
  abstract = {To help elucidate the role of inhibitory feedback in the genesis of odour-evoked synchronization of neural activity, we investigated the distribution of gamma-aminobutyric acid (GABA)ergic synaptic terminals in the antennal lobes (AL) and mushroom bodies (MB) of the locust olfactory system. Electron-microscopy, intracellular horseradish peroxidase labelling, and immunocytochemistry were combined to assess the distribution of GABAergic synapses, using established methods (Leitch and Laurent [1993] J. Comp. Neurol. 337:461-470). In the AL, GABA-immunoreactive presynaptic terminals contacted both immunoreactive and immunonegative profiles. Conversely, GABA-immunoreactive profiles received direct input from both reactive and negative terminals. The tract containing the axons of the projection neurons that run from the AL to the MB contained about 830 axons of fairly uniform size, none of which was immunoreactive for GABA. In the calyx of the MB, large immunoreactive terminals contacted very-small-diameter profiles thought to belong to the Kenyon cells (KCs). This was confirmed by combining immunocytochemistry with intracellular HRP-labelling of KCs. KCs were not immunoreactive for GABA. Although some GABAergic contacts were made onto the spiny profiles of KCs, others were made onto their dendritic shafts. Large GABA-immunoreactive profiles were also found to contact large negative profiles that were presynaptic to KC terminals. This suggests that KC dendrites can be both pre- and post-synaptically inhibited in the calyx. The MB pedunculus contained ca. 50,000 tightly packed KC axons, showing conspicuous en passant and often reciprocal synaptic contacts between neighbouring axons. KC axons were immunonegative, but received direct input from, and contacted directly, large immunoreactive profiles running across or along the KC axons. In the alpha- and beta-lobes of the MB, connections similar to those in the pedunculus were seen with two main differences: (1) The density of synaptic profiles was higher, giving on occasion numerous serially connected profiles in a single section; (2) large immunonegative profiles with dense-core vesicles were abundant and were frequently presynaptic to GABAergic processes and to very-small-diameter profiles which possibly belong to KCs. These results are discussed in the context of the known physiological data on olfactory processing in these complex circuits.},
  journal = {The Journal of comparative neurology},
  keywords = {Animals,Biological Clocks,gamma-Aminobutyric Acid,Grasshoppers,Nerve Endings,Olfactory Pathways,Sense Organs,Synapses},
  language = {eng},
  number = {4},
  pmid = {8876449}
}

@article{Lerner_Topographic_2011,
  title = {Topographic {{Mapping}} of a {{Hierarchy}} of {{Temporal Receptive Windows Using}} a {{Narrated Story}}},
  author = {Lerner, Yulia and Honey, Christopher J. and Silbert, Lauren J. and Hasson, Uri},
  year = {2011},
  month = feb,
  volume = {31},
  pages = {2906--2915},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.3684-10.2011},
  abstract = {Real-life activities, such as watching a movie or engaging in conversation, unfold over many minutes. In the course of such activities, the brain has to integrate information over multiple time scales. We recently proposed that the brain uses similar strategies for integrating information across space and over time. Drawing a parallel with spatial receptive fields, we defined the temporal receptive window (TRW) of a cortical microcircuit as the length of time before a response during which sensory information may affect that response. Our previous findings in the visual system are consistent with the hypothesis that TRWs become larger when moving from low-level sensory to high-level perceptual and cognitive areas. In this study, we mapped TRWs in auditory and language areas by measuring fMRI activity in subjects listening to a real-life story scrambled at the time scales of words, sentences, and paragraphs. Our results revealed a hierarchical topography of TRWs. In early auditory cortices (A1+), brain responses were driven mainly by the momentary incoming input and were similarly reliable across all scrambling conditions. In areas with an intermediate TRW, coherent information at the sentence time scale or longer was necessary to evoke reliable responses. At the apex of the TRW hierarchy, we found parietal and frontal areas that responded reliably only when intact paragraphs were heard in a meaningful sequence. These results suggest that the time scale of processing is a functional property that may provide a general organizing principle for the human cerebral cortex.},
  copyright = {Copyright \textcopyright{} 2011 the authors 0270-6474/11/312906-10\$15.00/0},
  journal = {Journal of Neuroscience},
  language = {en},
  number = {8},
  pmid = {21414912}
}

@article{Lestienne_Functionality_2002,
  title = {Functionality of Divergence and Convergence in a Model of the Insect Olfactory System},
  author = {Lestienne, R{\'e}my and Quenet, Brigitte and Bouret, S{\'e}bastien and Parodi, Olivier},
  year = {2002},
  month = sep,
  volume = {87},
  pages = {220--229},
  issn = {0340-1200, 1432-0770},
  doi = {10.1007/s00422-002-0329-y},
  abstract = {Recent studies have shown that the insect olfactory system uses a spatio-temporal encoding of odours in the population of projection neurons in the antennal lobe, and suggest that the information thus coded is spread across a large population of Kenyon cells in the mushroom bodies. At this stage, the temporal part of the code might be transformed into a spatial code, especially via the temporally sensitive mechanisms of paired\textendash pulse facilitation and feedback inhibition with its possible associated rebound. We explore here a simple model of the olfactory system using a three\textendash layer network of formal neurons, comprising a fixed number (three) of projection and inhibitory neurons, but a variable number of Kenyon cells. We show how enlarging the divergence of the network (i.e. the ratio between the number of Kenyon cells to the number of input \textendash{} projection \textendash{} neurons) alters the number of different output spatial states in response to a fixed set of spatio-temporal inputs, and may therefore improve its effectiveness in discriminating between these inputs. Such enlarged divergence also reduces the variation of this effectiveness among random realisations of the network connectivity. Our model shows that the discriminative effectiveness first increases with the divergence, and then plateaus for a divergence factor of {$\sim$}20. The maximal average number of different outputs was 470.2, which was computed from some simulations with random realisations of connectivity and with a set of 512 possible inputs. The discriminative effectiveness of the network is sensitive to paired-pulse facilitation, and especially to inhibition with rebound.},
  journal = {Biological Cybernetics},
  language = {en},
  number = {3}
}

@article{Li_Transformation_2013,
  title = {Transformation of Odor Selectivity from Projection Neurons to Single Mushroom Body Neurons Mapped with Dual-Color Calcium Imaging},
  author = {Li, Hao and Li, Yiming and Lei, Zhengchang and Wang, Kaiyu and Guo, Aike},
  year = {2013},
  month = jul,
  volume = {110},
  pages = {12084--12089},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1305857110},
  abstract = {Although the response properties of most neurons are, to a large extent, determined by the presynaptic inputs that they receive, comprehensive functional characterization of the presynaptic inputs of a single neuron remains elusive. Toward this goal, we introduce a dual-color calcium imaging approach that simultaneously monitors the responses of a single postsynaptic neuron together with its presynaptic axon terminal inputs in vivo. As a model system, we applied the strategy to the feed-forward connections from the projection neurons (PNs) to the Kenyon cells (KCs) in the mushroom body of Drosophila and functionally mapped essentially all PN inputs for some of the KCs. We found that the output of single KCs could be well predicted by a linear summation of the PN input signals, indicating that excitatory PN inputs play the major role in generating odor-selective responses in KCs. When odors failed to activate KC output, local calcium transients restricted to individual postsynaptic sites could be observed in the KC dendrites. The response amplitudes of the local transients often correlated linearly with the presynaptic response amplitudes, allowing direct assay of the strength of single synaptic sites. Furthermore, we found a scaling relationship between the total number of PN terminals that a single KC received and the average synaptic strength of these PN-KC synapses. Our strategy provides a unique perspective on the process of information transmission and integration in a model neural circuit and may be broadly applicable for the study of the origin of neuronal response properties.},
  journal = {Proceedings of the National Academy of Sciences},
  keywords = {EM reconstruction,functional connectome,G-CaMP,inputome mapping,R-GECO},
  language = {en},
  number = {29},
  pmid = {23818618}
}

@article{Liang_GABAergic_2013,
  title = {{{GABAergic Projection Neurons Route Selective Olfactory Inputs}} to {{Specific Higher Order Neurons}}},
  author = {Liang, Liang and Li, Yulong and Potter, Christopher J. and Yizhar, Ofer and Deisseroth, Karl and Tsien, Richard W. and Luo, Liqun},
  year = {2013},
  month = sep,
  volume = {79},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2013.06.014},
  abstract = {We characterize an inhibitory circuit motif in the Drosophila olfactory system, parallel inhibition, which differs from feed-forward or feedback inhibition. Excitatory and GABAergic inhibitory projection neurons (ePNs and iPNs) each receive input from antennal lobe glomeruli and send parallel output to the lateral horn, a higher center implicated in regulating innate olfactory behavior. Ca2+ imaging of specific lateral horn neurons as an olfactory readout revealed that iPNs selectively suppress food-related odorant responses, but spared signal transmission from pheromone channels. Co-applying food odorant did not affect pheromone signal transmission, suggesting that the differential effects likely result from connection specificity of iPNs, rather than a generalized inhibitory tone. Ca2+ responses in the ePN axon terminals show no detectable suppression by iPNs, arguing against presynaptic inhibition as a primary mechanism. The parallel inhibition motif may provide specificity in inhibition to funnel specific olfactory information, such as food and pheromone, into distinct downstream circuits.},
  journal = {Neuron},
  number = {5},
  pmcid = {PMC3838762},
  pmid = {24012005}
}

@article{Limongi_Temporal_2015,
  title = {Temporal Prediction Errors Modulate Task-Switching Performance},
  author = {Limongi, Roberto and Silva, Ang{\'e}lica M. and {G{\'o}ngora-Costa}, Bego{\~n}a},
  year = {2015},
  month = aug,
  volume = {6},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2015.01185},
  abstract = {We have previously shown that temporal prediction errors (PEs, the differences between the expected and the actual stimulus' onset times) modulate the effective connectivity between the anterior cingulate cortex and the right anterior insular cortex (rAI), causing the activity of the rAI to decrease. The activity of the rAI is associated with efficient performance under uncertainty (e.g., changing a prepared behavior when a change demand is not expected), which leads to hypothesize that temporal PEs might disrupt behavior-change performance under uncertainty. This hypothesis has not been tested at a behavioral level. In this work, we evaluated this hypothesis within the context of task switching and concurrent temporal predictions. Our participants performed temporal predictions while observing one moving ball striking a stationary ball which bounced off with a variable temporal gap. Simultaneously, they performed a simple color comparison task. In some trials, a change signal made the participants change their behaviors. Performance accuracy decreased as a function of both the temporal PE and the delay. Explaining these results without appealing to ad hoc concepts such as ``executive control'' is a challenge for cognitive neuroscience. We provide a predictive coding explanation. We hypothesize that exteroceptive and proprioceptive minimization of PEs would converge in a fronto-basal ganglia network which would include the rAI. Both temporal gaps (or uncertainty) and temporal PEs would drive and modulate this network respectively. Whereas the temporal gaps would drive the activity of the rAI, the temporal PEs would modulate the endogenous excitatory connections of the fronto-striatal network. We conclude that in the context of perceptual uncertainty, the system is not able to minimize perceptual PE, causing the ongoing behavior to finalize and, in consequence, disrupting task switching.},
  journal = {Frontiers in Psychology},
  pmcid = {PMC4548091},
  pmid = {26379568}
}

@article{Little_Learning_2013,
  title = {Learning and Exploration in Action-Perception Loops},
  author = {Little, Daniel Ying-Jeh and Sommer, Friedrich Tobias},
  year = {2013},
  volume = {7},
  pages = {37},
  doi = {10.3389/fncir.2013.00037},
  abstract = {Discovering the structure underlying observed data is a recurring problem in machine learning with important applications in neuroscience. It is also a primary function of the brain. When data can be actively collected in the context of a closed action-perception loop, behavior becomes a critical determinant of learning efficiency. Psychologists studying exploration and curiosity in humans and animals have long argued that learning itself is a primary motivator of behavior. However, the theoretical basis of learning-driven behavior is not well understood. Previous computational studies of behavior have largely focused on the control problem of maximizing acquisition of rewards and have treated learning the structure of data as a secondary objective. Here, we study exploration in the absence of external reward feedback. Instead, we take the quality of an agent's learned internal model to be the primary objective. In a simple probabilistic framework, we derive a Bayesian estimate for the amount of information about the environment an agent can expect to receive by taking an action, a measure we term the predicted information gain (PIG). We develop exploration strategies that approximately maximize PIG. One strategy based on value-iteration consistently learns faster than previously developed reward-free exploration strategies across a diverse range of environments. Psychologists believe the evolutionary advantage of learning-driven exploration lies in the generalized utility of an accurate internal model. Consistent with this hypothesis, we demonstrate that agents which learn more efficiently during exploration are later better able to accomplish a range of goal-directed tasks. We will conclude by discussing how our work elucidates the explorative behaviors of animals and humans, its relationship to other computational models of behavior, and its potential application to experimental design, such as in closed-loop neurophysiology studies.},
  journal = {Frontiers in Neural Circuits},
  keywords = {behavioral psychology,Computational neuroscience,control theory,Information theory,knowledge acquisition,machine learning}
}

@article{Liu_Common_2011,
  title = {Common and Distinct Networks Underlying Reward Valence and Processing Stages: {{A}} Meta-Analysis of Functional Neuroimaging Studies},
  shorttitle = {Common and Distinct Networks Underlying Reward Valence and Processing Stages},
  author = {Liu, Xun and Hairston, Jacqueline and Schrier, Madeleine and Fan, Jin},
  year = {2011},
  month = apr,
  volume = {35},
  pages = {1219--1236},
  issn = {0149-7634},
  doi = {10.1016/j.neubiorev.2010.12.012},
  abstract = {To better understand the reward circuitry in human brain, we conducted activation likelihood estimation (ALE) and parametric voxel-based meta-analyses (PVM) on 142 neuroimaging studies that examined brain activation in reward-related tasks in healthy adults. We observed several core brain areas that participated in reward-related decision making, including the nucleus accumbens (NAcc), caudate, putamen, thalamus, orbitofrontal cortex (OFC), bilateral anterior insula, anterior cingulate cortex (ACC) and posterior cingulate cortex (PCC), as well as cognitive control regions in the inferior parietal lobule and prefrontal cortex (PFC). The NAcc was commonly activated by both positive and negative rewards across various stages of reward processing (e.g., anticipation, outcome, and evaluation). In addition, the medial OFC and PCC preferentially responded to positive rewards, whereas the ACC, bilateral anterior insula, and lateral PFC selectively responded to negative rewards. Reward anticipation activated the ACC, bilateral anterior insula, and brain stem, whereas reward outcome more significantly activated the NAcc, medial OFC, and amygdala. Neurobiological theories of reward-related decision making should therefore take distributed and interrelated representations of reward valuation and valence assessment into account.},
  journal = {Neuroscience \& Biobehavioral Reviews},
  keywords = {Anterior cingulate cortex,Anterior insula,Meta-analysis,Nucleus accumbens,Orbitofrontal cortex,Reward},
  number = {5}
}

@article{Liu_Human_2019,
  title = {Human {{Replay Spontaneously Reorganizes Experience}}},
  author = {Liu, Yunzhe and Dolan, Raymond J. and {Kurth-Nelson}, Zeb and Behrens, Timothy E. J.},
  year = {2019},
  month = jul,
  volume = {178},
  pages = {640-652.e14},
  issn = {1097-4172},
  doi = {10.1016/j.cell.2019.06.012},
  abstract = {Knowledge abstracted from previous experiences can be transferred to aid new learning. Here, we asked whether such abstract knowledge immediately guides the replay of new experiences. We first trained participants on a rule defining an ordering of objects and then presented a novel set of objects in a scrambled order. Across two studies, we observed that representations of these novel objects were reactivated during a subsequent rest. As in rodents, human "replay" events occurred in sequences accelerated in time, compared to actual experience, and reversed their direction after a reward. Notably, replay did not simply recapitulate visual experience, but followed instead a sequence implied by learned abstract knowledge. Furthermore, each replay contained more than sensory representations of the relevant objects. A sensory code of object representations was preceded 50~ms by a~code factorized into sequence position and sequence identity. We argue that this factorized representation facilitates the generalization of a previously learned structure to new objects.},
  journal = {Cell},
  keywords = {Action Potentials,Adult,factorized representation,Female,generalization,grid cells,hippocampus,Hippocampus,Humans,inference,Learning,Magnetoencephalography,Male,MEG,Memory,Photic Stimulation,place cells,preplay,replay,Reward,transfer learning,Young Adult},
  language = {eng},
  number = {3},
  pmcid = {PMC6657653},
  pmid = {31280961}
}

@article{Lloyd_Least_1982,
  title = {Least Squares Quantization in {{PCM}}},
  author = {Lloyd, S.},
  year = {1982},
  month = mar,
  volume = {28},
  pages = {129--137},
  issn = {0018-9448},
  doi = {10.1109/TIT.1982.1056489},
  abstract = {It has long been realized that in pulse-code modulation (PCM), with a given ensemble of signals to handle, the quantum values should be spaced more closely in the voltage regions where the signal amplitude is more likely to fall. It has been shown by Panter and Dite that, in the limit as the number of quanta becomes infinite, the asymptotic fractional density of quanta per unit voltage should vary as the one-third power of the probability density per unit voltage of signal amplitudes. In this paper the corresponding result for any finite number of quanta is derived; that is, necessary conditions are found that the quanta and associated quantization intervals of an optimum finite quantization scheme must satisfy. The optimization criterion used is that the average quantization noise power be a minimum. It is shown that the result obtained here goes over into the Panter and Dite result as the number of quanta become large. The optimum quautization schemes for2\^bquanta,b=1,2, cdots, 7, are given numerically for Gaussian and for Laplacian distribution of signal amplitudes.},
  journal = {IEEE Transactions on Information Theory},
  keywords = {Least-squares approximation,PCM communication,Quantization (signal),Signal quantization},
  number = {2}
}

@article{Locey_Real_2011,
  title = {Real and Hypothetical Rewards},
  author = {Locey, Matthew L. and Jones, Bryan A. and Rachlin, Howard},
  year = {2011},
  month = aug,
  volume = {6},
  pages = {552--564},
  issn = {1930-2975},
  abstract = {Laboratory studies of choice and decision making among real monetary rewards typically use smaller real rewards than those common in real life. When laboratory rewards are large, they are almost always hypothetical. In applying laboratory results meaningfully to real-life situations, it is important to know the extent to which choices among hypothetical rewards correspond to choices among real rewards and whether variation of the magnitude of hypothetical rewards affects behavior in meaningful ways. The present study compared real and hypothetical monetary rewards in two experiments. In Experiment 1, participants played a temporal discounting game that incorporates the logic of a repeated prisoner's-dilemma (PD) type game versus tit-for-tat; choice of one alternative (``defection'' in PD terminology) resulted in a small-immediate reward; choice of the other alternative (``cooperation'' in PD terminology) resulted in a larger reward delayed until the following trial. The larger-delayed reward was greater for half of the groups than for the other half. Rewards also differed in type across groups: multiples of real nickels, hypothetical nickels or hypothetical hundred-dollar bills. All groups significantly increased choice of the larger delayed reward over the 40 trials of the experiment. Over the last 10 trials, cooperation was significantly higher when the difference between larger and smaller hypothetical rewards was greater. Reward type (real or hypothetical) made no significant difference in cooperation. In Experiment 2, real and hypothetical rewards were compared in social discounting \textendash{} the decrease in value to the giver of a reward as social distance increases to the receiver of the reward. Social discount rates were well described by a hyperbolic function. Discounting rates for real and hypothetical rewards did not significantly differ. These results add to the evidence that results of experiments with hypothetical rewards validly apply in everyday life.},
  journal = {Judgment and decision making},
  number = {6},
  pmcid = {PMC3348706},
  pmid = {22582110}
}

@article{Loomes_Modelling_2005,
  title = {Modelling the {{Stochastic Component}} of {{Behaviour}} in {{Experiments}}: {{Some Issues}} for the {{Interpretation}} of {{Data}}},
  shorttitle = {Modelling the {{Stochastic Component}} of {{Behaviour}} in {{Experiments}}},
  author = {Loomes, Graham},
  year = {2005},
  month = dec,
  volume = {8},
  pages = {301--323},
  issn = {1386-4157, 1573-6938},
  doi = {10.1007/s10683-005-5372-9},
  abstract = {This paper considers some of the questions raised by the fact that people's behaviour\textemdash including their behaviour in experimental environments\textemdash has a stochastic component. The nature of this component may be crucial to the interpretation of the patterns of data we observe and the choice of statistical criteria for favouring one hypothesis at the expense of others. However, it is arguable that insufficient consideration has been given to the way(s) in which the stochastic element is modelled. The paper aims to explore some of the issues involved.},
  journal = {Experimental Economics},
  language = {en},
  number = {4}
}

@article{Luo_Generating_2010,
  title = {Generating Sparse and Selective Third-Order Responses in the Olfactory System of the Fly},
  author = {Luo, Sean X. and Axel, Richard and Abbott, L. F.},
  year = {2010},
  month = jun,
  volume = {107},
  pages = {10713--10718},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1005635107},
  abstract = {In the antennal lobe of Drosophila, information about odors is transferred from olfactory receptor neurons (ORNs) to projection neurons (PNs), which then send axons to neurons in the lateral horn of the protocerebrum (LHNs) and to Kenyon cells (KCs) in the mushroom body. The transformation from ORN to PN responses can be described by a normalization model similar to what has been used in modeling visually responsive neurons. We study the implications of this transformation for the generation of LHN and KC responses under the hypothesis that LHN responses are highly selective and therefore suitable for driving innate behaviors, whereas KCs provide a more general sparse representation of odors suitable for forming learned behavioral associations. Our results indicate that the transformation from ORN to PN firing rates in the antennal lobe equalizes the magnitudes of and decorrelates responses to different odors through feedforward nonlinearities and lateral suppression within the circuitry of the antennal lobe, and we study how these two components affect LHN and KC responses.},
  journal = {Proceedings of the National Academy of Sciences},
  keywords = {antennal lobe,decorrelation,lateral horn,normalization,olfaction},
  language = {en},
  number = {23},
  pmid = {20498080}
}

@article{Luo_Generating_2010a,
  title = {Generating Sparse and Selective Third-Order Responses in the Olfactory System of the Fly},
  author = {Luo, Sean X. and Axel, Richard and Abbott, L. F.},
  year = {2010},
  month = jun,
  volume = {107},
  pages = {10713--10718},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1005635107},
  abstract = {In the antennal lobe of Drosophila, information about odors is transferred from olfactory receptor neurons (ORNs) to projection neurons (PNs), which then send axons to neurons in the lateral horn of the protocerebrum (LHNs) and to Kenyon cells (KCs) in the mushroom body. The transformation from ORN to PN responses can be described by a normalization model similar to what has been used in modeling visually responsive neurons. We study the implications of this transformation for the generation of LHN and KC responses under the hypothesis that LHN responses are highly selective and therefore suitable for driving innate behaviors, whereas KCs provide a more general sparse representation of odors suitable for forming learned behavioral associations. Our results indicate that the transformation from ORN to PN firing rates in the antennal lobe equalizes the magnitudes of and decorrelates responses to different odors through feedforward nonlinearities and lateral suppression within the circuitry of the antennal lobe, and we study how these two components affect LHN and KC responses.},
  journal = {Proceedings of the National Academy of Sciences},
  keywords = {antennal lobe,decorrelation,lateral horn,normalization,olfaction},
  language = {en},
  number = {23},
  pmid = {20498080}
}

@article{Lupien_effects_2007,
  title = {The Effects of Stress and Stress Hormones on Human Cognition: {{Implications}} for the Field of Brain and Cognition},
  shorttitle = {The Effects of Stress and Stress Hormones on Human Cognition},
  author = {Lupien, S. J. and Maheu, F. and Tu, M. and Fiocco, A. and Schramek, T. E.},
  year = {2007},
  month = dec,
  volume = {65},
  pages = {209--237},
  issn = {0278-2626},
  doi = {10.1016/j.bandc.2007.02.007},
  abstract = {In this review, we report on studies that have assessed the effects of exogenous and endogenous increases in stress hormones on human cognitive performance. We first describe the history of the studies on the effects of using exogenous stress hormones such as glucocorticoids as anti-inflammatory medications on human cognition and mental health. Here, we summarize the cases that led to the diagnosis of glucocorticoid-induced `steroid psychosis' in human populations and which demonstrated that these stress hormones could thus cross the blood\textendash brain barrier and access the brain where they could influence cognition and mental health. We then summarize studies that assessed the effects of the exogenous administration of glucocorticoids on cognitive performance supported by the hippocampus, the frontal lobes and amygdala. In the second section of the paper, we summarize the effects of the endogenous release of glucocorticoids induced by exposure to a stressful situation on human cognition and we further dissociate the effects of emotion from those of stress on human learning and memory. Finally, in the last section of the paper, we discuss the potential impact that the environmental context to which we expose participants when assessing their memory could have on their reactivity to stress and subsequent cognitive performance. In order to make our point, we discuss the field of memory and aging and we suggest that some of the `age-related memory impairments' observed in the literature could be partly due to increased stress reactivity in older adults to the environmental context of testing. We also discuss the inverse negative correlations reported between hippocampal volume and memory for young and older adults and suggest that these inverse correlations could be partly due to the effects of contextual stress in young and older adults, as a function of age-related differences in hippocampal volume.},
  journal = {Brain and Cognition},
  keywords = {Aging,Catecholamines,Glucocorticoids,Hippocampus,Memory,Stress,unread},
  number = {3}
}

@article{Lutz_Sleep_2018,
  title = {Sleep {{Strengthens Predictive Sequence Coding}}},
  author = {Lutz, Nicolas D. and Wolf, Ines and H{\"u}bner, Stefanie and Born, Jan and Rauss, Karsten},
  year = {2018},
  month = oct,
  volume = {38},
  pages = {8989--9000},
  publisher = {{Society for Neuroscience}},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.1352-18.2018},
  abstract = {Predictive-coding theories assume that perception and action are based on internal models derived from previous experience. Such internal models require selection and consolidation to be stored over time. Sleep is known to support memory consolidation. We hypothesized that sleep supports both consolidation and abstraction of an internal task model that is subsequently used to predict upcoming stimuli. Human subjects (of either sex) were trained on deterministic visual sequences and tested with interleaved deviant stimuli after retention intervals of sleep or wakefulness. Adopting a predictive-coding approach, we found increased prediction strength after sleep, as expressed by increased error rates to deviant stimuli, but fewer errors for the immediately following standard stimuli. Sleep likewise enhanced the formation of an abstract sequence model, independent of the temporal context during training. Moreover, sleep increased confidence for sequence knowledge, reflecting enhanced metacognitive access to the model. Our results suggest that sleep supports the formation of internal models which can be used to predict upcoming events in different contexts. SIGNIFICANCE STATEMENT To efficiently interact with the ever-changing world, we predict upcoming events based on similar previous experiences. Sleep is known to benefit memory consolidation. However, it is not clear whether sleep specifically supports the transformation of past experience into predictions of future events. Here, we find that, when human subjects sleep after learning a sequence of predictable visual events, they make better predictions about upcoming events compared with subjects who stayed awake for an equivalent period of time. In addition, sleep supports the transfer of such knowledge between different temporal contexts (i.e., when sequences unfold at different speeds). Thus, sleep supports perception and action by enhancing the predictive utility of previous experiences.},
  chapter = {Research Articles},
  copyright = {Copyright \textcopyright{} 2018 the authors 0270-6474/18/388989-12\$15.00/0},
  journal = {Journal of Neuroscience},
  keywords = {abstraction,consolidation,predictive coding,sequence learning,sleep},
  language = {en},
  number = {42},
  pmid = {30185464}
}

@article{Ma_Bayesian_2006,
  title = {Bayesian Inference with Probabilistic Population Codes},
  author = {Ma, Wei Ji and Beck, Jeffrey M. and Latham, Peter E. and Pouget, Alexandre},
  year = {2006},
  month = nov,
  volume = {9},
  pages = {1432--1438},
  issn = {1097-6256},
  doi = {10.1038/nn1790},
  abstract = {Recent psychophysical experiments indicate that humans perform near-optimal Bayesian inference in a wide variety of tasks, ranging from cue integration to decision making to motor control. This implies that neurons both represent probability distributions and combine those distributions according to a close approximation to Bayes' rule. At first sight, it would seem that the high variability in the responses of cortical neurons would make it difficult to implement such optimal statistical inference in cortical circuits. We argue that, in fact, this variability implies that populations of neurons automatically represent probability distributions over the stimulus, a type of code we call probabilistic population codes. Moreover, we demonstrate that the Poisson-like variability observed in cortex reduces a broad class of Bayesian inference to simple linear combinations of populations of neural activity. These results hold for arbitrary probability distributions over the stimulus, for tuning curves of arbitrary shape and for realistic neuronal variability.},
  copyright = {\textcopyright{} 2006 Nature Publishing Group},
  journal = {Nature Neuroscience},
  language = {en},
  number = {11}
}

@article{Ma_Bayesian_2006a,
  title = {Bayesian Inference with Probabilistic Population Codes.},
  author = {Ma, Wei Ji and Beck, Jeffrey M. and Latham, Peter E. and Pouget, Alexandre},
  year = {2006},
  month = nov,
  volume = {9},
  pages = {1432--1438},
  doi = {10.1038/nn1790},
  abstract = {Recent psychophysical experiments indicate that humans perform near-optimal Bayesian inference in a wide variety of tasks, ranging from cue integration to decision making to motor control. This implies that neurons both represent probability distributions and combine those distributions according to a close approximation to Bayes' rule. At first sight, it would seem that the high variability in the responses of cortical neurons would make it difficult to implement such optimal statistical inference in cortical circuits. We argue that, in fact, this variability implies that populations of neurons automatically represent probability distributions over the stimulus, a type of code we call probabilistic population codes. Moreover, we demonstrate that the Poisson-like variability observed in cortex reduces a broad class of Bayesian inference to simple linear combinations of populations of neural activity. These results hold for arbitrary probability distributions over the stimulus, for tuning curves of arbitrary shape and for realistic neuronal variability.},
  journal = {Nat Neurosci},
  keywords = {Algorithms,Bayes Theorem,Cerebral Cortex,cytology/physiology,Humans,Models,Nerve Net,Neurological,Normal Distribution,physiology,Poisson Distribution,Statistical},
  language = {eng},
  number = {11},
  pmid = {17057707}
}

@article{MacDonald_Dissociating_2000,
  title = {Dissociating the {{Role}} of the {{Dorsolateral Prefrontal}} and {{Anterior Cingulate Cortex}} in {{Cognitive Control}}},
  author = {MacDonald, Angus W. and Cohen, Jonathan D. and Stenger, V. Andrew and Carter, Cameron S.},
  year = {2000},
  month = jun,
  volume = {288},
  pages = {1835--1838},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.288.5472.1835},
  abstract = {Theories of the regulation of cognition suggest a system with two necessary components: one to implement control and another to monitor performance and signal when adjustments in control are needed. Event-related functional magnetic resonance imaging and a task-switching version of the Stroop task were used to examine whether these components of cognitive control have distinct neural bases in the human brain. A double dissociation was found. During task preparation, the left dorsolateral prefrontal cortex (Brodmann's area 9) was more active for color naming than for word reading, consistent with a role in the implementation of control. In contrast, the anterior cingulate cortex (Brodmann's areas 24 and 32) was more active when responding to incongruent stimuli, consistent with a role in performance monitoring.},
  journal = {Science},
  language = {en},
  number = {5472},
  pmid = {10846167}
}

@article{MacLeod_Distinct_1996,
  title = {Distinct Mechanisms for Synchronization and Temporal Patterning of Odor-Encoding Neural Assemblies},
  author = {MacLeod, K. and Laurent, G.},
  year = {1996},
  month = nov,
  volume = {274},
  pages = {976--979},
  issn = {0036-8075},
  abstract = {Stimulus-evoked oscillatory synchronization of neural assemblies and temporal patterns of neuronal activity have been observed in many sensory systems, such as the visual and auditory cortices of mammals or the olfactory system of insects. In the locust olfactory system, single odor puffs cause the immediate formation of odor-specific neural assemblies, defined both by their transient synchronized firing and their progressive transformation over the course of a response. The application of an antagonist of ionotropic gamma-aminobutyric acid (GABA) receptors to the first olfactory relay neuropil selectively blocked the fast inhibitory synapse between local and projection neurons. This manipulation abolished the synchronization of the odor-coding neural ensembles but did not affect each neuron's temporal response patterns to odors, even when these patterns contained periods of inhibition. Fast GABA-mediated inhibition, therefore, appears to underlie neuronal synchronization but not response tuning in this olfactory system. The selective desynchronization of stimulus-evoked oscillating neural assemblies in vivo is now possible, enabling direct functional tests of their significance for sensation and perception.},
  journal = {Science (New York, N.Y.)},
  keywords = {Animals,Female,GABA Antagonists,gamma-Aminobutyric Acid,Grasshoppers,Male,Membrane Potentials,Neurons; Afferent,Odors,Olfactory Pathways,Picrotoxin,Receptors; GABA,Sense Organs,Sensory Receptor Cells,Synaptic Transmission},
  language = {eng},
  number = {5289},
  pmid = {8875938}
}

@article{MacLeod_Who_1998,
  title = {Who Reads Temporal Information Contained across Synchronized and Oscillatory Spike Trains?},
  author = {MacLeod, Katrina and B{\"a}cker, Alex and Laurent, Gilles},
  year = {1998},
  month = oct,
  volume = {395},
  pages = {693--698},
  issn = {0028-0836},
  doi = {10.1038/27201},
  abstract = {Our inferences about brain mechanisms underlying perception rely on whether it is possible for the brain to 'reconstruct' a stimulus from the information contained in the spike trains from many neurons. How the brain actually accomplishes this reconstruction remains largely unknown. Oscillatory and synchronized activities in the brain of mammals have been correlated with distinct behavioural states or the execution of complex cognitive tasks and are proposed to participate in the 'binding' of individual features into more complex percepts,. But if synchronization is indeed relevant, what senses it? In insects, oscillatory synchronized activity in the early olfactory system seems to be necessary for fine odour discrimination and enables the encoding of information about a stimulus in spike times relative to the oscillatory 'clock'. Here we study the decoding of these coherent oscillatory signals. We identify a population of neurons downstream from the odour-activated, synchronized neuronal assemblies. These downstream neurons show odour responses whose specificity is degraded when their inputs are desynchronized. This degradation of selectivity consists of the appearance of responses to new odours and a loss ofdiscrimination of spike trains evoked by different odours. Suchloss of information is never observed in the upstream neurons whose activity is desynchronized. These results indicate that information encoded in time across ensembles of neurons converges onto single neurons downstream in the pathway.},
  copyright = {\textcopyright{} 1998 Nature Publishing Group},
  journal = {Nature},
  language = {en},
  number = {6703}
}

@article{Maddox_Depressive_2012,
  title = {Depressive Symptoms Enhance Loss-Minimization, but Attenuate Gain-Maximization in History-Dependent Decision-Making},
  author = {Maddox, W. Todd and Gorlick, Marissa A. and Worthy, Darrell A. and Beevers, Christopher G.},
  year = {2012},
  month = oct,
  volume = {125},
  pages = {118--124},
  issn = {0010-0277},
  doi = {10.1016/j.cognition.2012.06.011},
  abstract = {Individuals with depressive symptoms typically show deficits in decision-making. However, most work has emphasized decision-making under gain-maximization conditions. A gain-maximization framework may undermine decision-making when depressive symptoms are present because depressives are generally more sensitive to losses than gains. The present study examined decision making in a non-clinical sample of depressive and non-depressive individuals under gain-maximization or loss-minimization conditions using a task for which the currently available rewards depend upon participants' previous history of choices. As predicted, we found a cross over interaction whereby depressive individuals were superior to non-depressive individuals under loss-minimization conditions, but were inferior to non-depressive individuals under gain-maximization conditions. In addition, we found that loss-minimization performance was superior to gain-maximization performance for depressive individuals, but that gain-maximization performance was superior to loss-minimization performance for non-depressive individuals. These results suggest that decision making deficits observed when depressive symptoms are present may be attenuated when decisions involve minimizing losses rather than maximizing gains.},
  journal = {Cognition},
  keywords = {Choice,Decision Making,Depressive symptoms,Gains,Losses,punishment,Reward},
  number = {1}
}

@inproceedings{Marco_Automatic_2016,
  title = {Automatic {{LQR}} Tuning Based on {{Gaussian}} Process Global Optimization},
  booktitle = {2016 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Marco, Alonso and Hennig, Philipp and Bohg, Jeannette and Schaal, Stefan and Trimpe, Sebastian},
  year = {2016},
  month = may,
  pages = {270--277},
  doi = {10.1109/ICRA.2016.7487144},
  abstract = {This paper proposes an automatic controller tuning framework based on linear optimal control combined with Bayesian optimization. With this framework, an initial set of controller gains is automatically improved according to a pre-defined performance objective evaluated from experimental data. The underlying Bayesian optimization algorithm is Entropy Search, which represents the latent objective as a Gaussian process and constructs an explicit belief over the location of the objective minimum. This is used to maximize the information gain from each experimental evaluation. Thus, this framework shall yield improved controllers with fewer evaluations compared to alternative approaches. A seven-degree-of-freedom robot arm balancing an inverted pole is used as the experimental demonstrator. Results of two- and four-dimensional tuning problems highlight the method's potential for automatic controller tuning on robotic platforms.},
  keywords = {automatic controller tuning,automatic LQR tuning,Bayes methods,Bayesian optimization,Computational modeling,controller gains,Cost function,entropy,entropy search,four-dimensional tuning problems,Gaussian process,Gaussian processes,global optimization,information gain,inverted pole,linear optimal control,linear quadratic control,linear quadratic regulator,optimisation,robotic platforms,Robots,search problems,seven-degree-of-freedom robot arm,Tuning,two-dimensional tuning problems}
}

@article{Maren_contextual_2013,
  title = {The Contextual Brain: Implications for Fear Conditioning, Extinction and Psychopathology},
  shorttitle = {The Contextual Brain},
  author = {Maren, Stephen and Phan, K. Luan and Liberzon, Israel},
  year = {2013},
  month = jun,
  volume = {14},
  pages = {417--428},
  issn = {1471-003X},
  doi = {10.1038/nrn3492},
  abstract = {Contexts surround and imbue meaning to events; they are essential for recollecting the past, interpreting the present and anticipating the future. Indeed, the brain's capacity to contextualize information permits enormous cognitive and behavioural flexibility. Studies of Pavlovian fear conditioning and extinction in rodents and humans suggest that a neural circuit including the hippocampus, amygdala and medial prefrontal cortex is involved in the learning and memory processes that enable context-dependent behaviour. Dysfunction in this network may be involved in several forms of psychopathology, including post-traumatic stress disorder, schizophrenia and substance abuse disorders.},
  journal = {Nature reviews. Neuroscience},
  number = {6},
  pmcid = {PMC5072129},
  pmid = {23635870}
}

@article{Markovic_Comparative_2016,
  title = {Comparative {{Analysis}} of {{Behavioral Models}} for {{Adaptive Learning}} in {{Changing Environments}}},
  author = {Markovi{\'c}, Dimitrije and Kiebel, Stefan J.},
  year = {2016},
  volume = {10},
  issn = {1662-5188},
  doi = {10.3389/fncom.2016.00033},
  abstract = {Probabilistic models of decision making under various forms of uncertainty have been applied in recent years to numerous behavioral and model-based fMRI studies. These studies were highly successful in enabling a better understanding of behavior and delineating the functional properties of brain areas involved in decision making under uncertainty. However, as different studies considered different models of decision making under uncertainty, it is unclear which of these computational models provides the best account of the observed behavioral and neuroimaging data. This is an important issue, as not performing model comparison may tempt researchers to over-interpret results based on a single model. Here we describe how in practice one can compare different behavioral models and test the accuracy of model comparison and parameter estimation of Bayesian and maximum-likelihood based methods. We focus our analysis on two well-established hierarchical probabilistic models that aim at capturing the evolution of beliefs in changing environments: Hierarchical Gaussian Filters and Change Point Models. To our knowledge, these two, well-established models have never been compared on the same data. We demonstrate, using simulated behavioral experiments, that one can accurately disambiguate between these two models, and accurately infer free model parameters and hidden belief trajectories (e.g. posterior expectations, posterior uncertainties, and prediction errors) even when using noisy and highly correlated behavioral measurements. Importantly, we found several advantages of Bayesian inference and Bayesian model comparison compared to often-used Maximum-Likelihood schemes combined with the Bayesian Information Criterion. These results stress the relevance of Bayesian data analysis for model-based neuroimaging studies that investigate human decision making under uncertainty.},
  journal = {Frontiers in Computational Neuroscience},
  keywords = {Bayesian inference,Bayesian model comparison,Chair,Change point models,Changing environments,Decision Making,Hierarchical Gaussian Filters,maximum-likelihood estimate},
  language = {English}
}

@article{Markovic_Predicting_2019,
  title = {Predicting Change: {{Approximate}} Inference under Explicit Representation of Temporal Structure in Changing Environments},
  shorttitle = {Predicting Change},
  author = {Markovi{\'c}, Dimitrije and Reiter, Andrea M. F. and Kiebel, Stefan J.},
  year = {2019},
  month = jan,
  volume = {15},
  pages = {e1006707},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1006707},
  abstract = {In our daily lives timing of our actions plays an essential role when we navigate the complex everyday environment. It is an open question though how the representations of the temporal structure of the world influence our behavior. Here we propose a probabilistic model with an explicit representation of state durations which may provide novel insights in how the brain predicts upcoming changes. We illustrate several properties of the behavioral model using a standard reversal learning design and compare its task performance to standard reinforcement learning models. Furthermore, using experimental data, we demonstrate how the model can be applied to identify participants' beliefs about the latent temporal task structure. We found that roughly one quarter of participants seem to have learned the latent temporal structure and used it to anticipate changes, whereas the remaining participants' behavior did not show signs of anticipatory responses, suggesting a lack of precise temporal expectations. We expect that the introduced behavioral model will allow, in future studies, for a systematic investigation of how participants learn the underlying temporal structure of task environments and how these representations shape behavior.},
  journal = {PLOS Computational Biology},
  keywords = {Behavior,Decision making,Experimental design,Forecasting,Free energy,Hidden Markov models,Human learning,Learning},
  language = {en},
  number = {1}
}

@article{Martignon_Fast_2002,
  title = {Fast, Frugal, and Fit: {{Simple}} Heuristics for Paired Comparison},
  shorttitle = {Fast, Frugal, and Fit},
  author = {Martignon, Laura and Hoffrage, Ulrich},
  year = {2002},
  month = feb,
  volume = {52},
  pages = {29--71},
  issn = {0040-5833, 1573-7187},
  doi = {10.1023/A:1015516217425},
  abstract = {This article provides an overview of recent results on lexicographic, linear, and Bayesian models for paired comparison from a cognitive psychology perspective. Within each class, we distinguish subclasses according to the computational complexity required for parameter setting. We identify the optimal model in each class, where optimality is defined with respect to performance when fitting known data. Although not optimal when fitting data, simple models can be astonishingly accurate when generalizing to new data. A simple heuristic belonging to the class of lexicographic models is Take The Best (Gigerenzer \& Goldstein (1996) Psychol. Rev. 102: 684). It is more robust than other lexicographic strategies which use complex procedures to establish a cue hierarchy. In fact, it is robust due to its simplicity, not despite it. Similarly, Take The Best looks up only a fraction of the information that linear and Bayesian models require; yet it achieves performance comparable to that of models which integrate information. Due to its simplicity, frugality, and accuracy, Take The Best is a plausible candidate for a psychological model in the tradition of bounded rationality. We review empirical evidence showing the descriptive validity of fast and frugal heuristics.},
  journal = {Theory and Decision},
  language = {en},
  number = {1}
}

@article{Masuda-Nakagawa_single_2014,
  title = {A Single {{GABAergic}} Neuron Mediates Feedback of Odor-Evoked Signals in the Mushroom Body of Larval {{Drosophila}}},
  author = {{Masuda-Nakagawa}, Liria Monica and Ito, Kei and Awasaki, Takeshi and O'Kane, Cahir Joseph},
  year = {2014},
  volume = {8},
  pages = {35},
  doi = {10.3389/fncir.2014.00035},
  abstract = {Inhibition has a central role in defining the selectivity of the responses of higher order neurons to sensory stimuli. However, the circuit mechanisms of regulation of these responses by inhibitory neurons are still unclear. In Drosophila, the mushroom bodies (MBs) are necessary for olfactory memory, and by implication for the selectivity of learned responses to specific odors. To understand the circuitry of inhibition in the calyx (the input dendritic region) of the MBs, and its relationship with MB excitatory activity, we used the simple anatomy of the Drosophila larval olfactory system to identify any inhibitory inputs that could contribute to the selectivity of MB odor responses. We found that a single neuron accounts for all detectable GABA innervation in the calyx of the MBs, and that this neuron has pre-synaptic terminals in the calyx and post-synaptic branches in the MB lobes (output axonal area). We call this neuron the larval anterior paired lateral (APL) neuron, because of its similarity to the previously described adult APL neuron. Reconstitution of GFP partners (GRASP) suggests that the larval APL makes extensive contacts with the MB intrinsic neurons, Kenyon Cells (KCs), but few contacts with incoming projection neurons (PNs). Using calcium imaging of neuronal activity in live larvae, we show that the larval APL responds to odors, in a mannner that requires output from KCs. Our data suggest that the larval APL is the sole GABAergic neuron that innervates the MB input region and carries inhibitory feedback from the MB output region, consistent with a role in modulating the olfactory selectivity of MB neurons.},
  journal = {Frontiers in Neural Circuits},
  keywords = {APL neuron,inhibition,mushroom body calyx,odor discrimination,olfaction}
}

@article{Mather_Remembering_2003,
  title = {Remembering Chosen and Assigned Options},
  author = {Mather, Mara and Shafir, Eldar and Johnson, Marcia K.},
  year = {2003},
  month = apr,
  volume = {31},
  pages = {422--433},
  issn = {0090-502X, 1532-5946},
  doi = {10.3758/BF03194400},
  abstract = {Recent studies have shown systematic choice-supportive memory for past choices, wherein people tend to overattribute positive features to options they chose and negative features to unchosen options (Mather \& Johnson, 2000; Mather, Shafir, \& Johnson, 2000). In contrast, the present experiments showed no choice-supportive memory bias for assigned options. Rather than having a general motivation to recall the chosen or the assigned option in a more positive light, people appear to be influenced by heuristics that vary with context: In recalling past choices, people expect the chosen option to contain more positive and fewer negative features than do its competitors. In recalling past assignments, in contrast, people expect the assigned option to be remembered better than the unassigned alternatives. This vividness heuristic leads to systematic misattribution of new features to unassigned alternatives, but not in a manner supportive of the assigned option. Some implications of these findings are discussed.},
  journal = {Memory \& Cognition},
  language = {en},
  number = {3}
}

@article{Mather_Risk_2012,
  title = {Risk Preferences and Aging: The "Certainty Effect" in Older Adults' Decision Making},
  shorttitle = {Risk Preferences and Aging},
  author = {Mather, Mara and Mazar, Nina and Gorlick, Marissa A. and Lighthall, Nichole R. and Burgeno, Jessica and Schoeke, Andrej and Ariely, Dan},
  year = {2012},
  month = dec,
  volume = {27},
  pages = {801--816},
  issn = {1939-1498},
  doi = {10.1037/a0030174},
  abstract = {A prevalent stereotype is that people become less risk taking and more cautious as they get older. However, in laboratory studies, findings are mixed and often reveal no age differences. In the current series of experiments, we examined whether age differences in risk seeking are more likely to emerge when choices include a certain option (a sure gain or a sure loss). In four experiments, we found that age differences in risk preferences only emerged when participants were offered a choice between a risky and a certain gamble but not when offered two risky gambles. In particular, Experiments 1 and 2 included only gambles about potential gains. Here, compared with younger adults, older adults preferred a certain gain over a chance to win a larger gain and thus, exhibited more risk aversion in the domain of gains. But in Experiments 3 and 4, when offered the chance to take a small sure loss rather than risking a larger loss, older adults exhibited more risk seeking in the domain of losses than younger adults. Both their greater preference for sure gains and greater avoidance of sure losses suggest that older adults weigh certainty more heavily than younger adults. Experiment 4 also indicates that older adults focus more on positive emotions than younger adults do when considering their options, and that this emotional shift can at least partially account for age differences in how much people are swayed by certainty in their choices.},
  journal = {Psychology and Aging},
  keywords = {Adolescent,Adult,Affect,Age Factors,Aged,Aged; 80 and over,Aging,Choice Behavior,Decision Making,Female,Humans,Male,Risk-Taking,Stress; Psychological,Uncertainty,Young Adult},
  language = {eng},
  number = {4},
  pmcid = {PMC3565580},
  pmid = {23066800}
}

@article{Mathys_Bayesian_2011,
  title = {A {{Bayesian}} Foundation for Individual Learning under Uncertainty},
  author = {Mathys, Christoph and Daunizeau, Jean and Friston, Karl J. and Stephan, Klaas Enno},
  year = {2011},
  volume = {5},
  pages = {39},
  doi = {10.3389/fnhum.2011.00039},
  abstract = {Computational learning models are critical for understanding mechanisms of adaptive behavior. However, the two major current frameworks, reinforcement learning (RL) and Bayesian learning, both have certain limitations. For example, many Bayesian models are agnostic of inter-individual variability and involve complicated integrals, making online learning difficult. Here, we introduce a generic hierarchical Bayesian framework for individual learning under multiple forms of uncertainty (e.g., environmental volatility and perceptual uncertainty). The model assumes Gaussian random walks of states at all but the first level, with the step size determined by the next highest level. The coupling between levels is controlled by parameters that shape the influence of uncertainty on learning in a subject-specific fashion. Using variational Bayes under a mean-field approximation and a novel approximation to the posterior energy function, we derive trial-by-trial update equations which (i) are analytical and extremely efficient, enabling real-time learning, (ii) have a natural interpretation in terms of RL, and (iii) contain parameters representing processes which play a key role in current theories of learning, e.g., precision-weighting of prediction error. These parameters allow for the expression of individual differences in learning and may relate to specific neuromodulatory mechanisms in the brain. Our model is very general: it can deal with both discrete and continuous states and equally accounts for deterministic and probabilistic relations between environmental events and perceptual states (i.e., situations with and without perceptual uncertainty). These properties are illustrated by simulations and analyses of empirical time series. Overall, our framework provides a novel foundation for understanding normal and pathological learning that contextualizes RL within a generic Bayesian scheme and thus connects it to principles of optimality from probability theory.},
  journal = {Frontiers in Human Neuroscience},
  keywords = {acetylcholine,decision-making,Dopamine,hierarchical models,neuromodulation,serotonin,Variational Bayes,volatility}
}

@article{Mathys_Uncertainty_2014,
  title = {Uncertainty in Perception and the {{Hierarchical Gaussian Filter}}},
  author = {Mathys, Christoph D. and Lomakina, Ekaterina I. and Daunizeau, Jean and Iglesias, Sandra and Brodersen, Kay H. and Friston, Karl J. and Stephan, Klaas E.},
  year = {2014},
  volume = {8},
  pages = {825},
  doi = {10.3389/fnhum.2014.00825},
  abstract = {In its full sense, perception rests on an agent's model of how its sensory input comes about and the inferences it draws based on this model. These inferences are necessarily uncertain. Here, we illustrate how the Hierarchical Gaussian Filter (HGF) offers a principled and generic way to deal with the several forms that uncertainty in perception takes. The HGF is a recent derivation of one-step update equations from Bayesian principles that rests on a hierarchical generative model of the environment and its (in)stability. It is computationally highly efficient, allows for online estimates of hidden states, and has found numerous applications to experimental data from human subjects. In this paper, we generalize previous descriptions of the HGF and its account of perceptual uncertainty. First, we explicitly formulate the extension of the HGF's hierarchy to any number of levels; second, we discuss how various forms of uncertainty are accommodated by the minimization of variational free energy as encoded in the update equations; third, we combine the HGF with decision models and demonstrate the inversion of this combination; finally, we report a simulation study that compared four optimization methods for inverting the HGF/decision model combination at different noise levels. These four methods (Nelder\textendash Mead simplex algorithm, Gaussian process-based global optimization, variational Bayes and Markov chain Monte Carlo sampling) all performed well even under considerable noise, with variational Bayes offering the best combination of efficiency and informativeness of inference. Our results demonstrate that the HGF provides a principled, flexible, and efficient\textemdash but at the same time intuitive\textemdash framework for the resolution of perceptual uncertainty in behaving agents.},
  journal = {Frontiers in Human Neuroscience},
  keywords = {Bayesian inference,decision-making,filtering,Free energy,hierarchical modeling,Learning,uncertainty,volatility}
}

@article{Mayseless_Generating_2015,
  title = {Generating Original Ideas: {{The}} Neural Underpinning of Originality},
  shorttitle = {Generating Original Ideas},
  author = {Mayseless, Naama and Eran, Ayelet and {Shamay-Tsoory}, Simone G.},
  year = {2015},
  month = aug,
  volume = {116},
  pages = {232--239},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2015.05.030},
  abstract = {One of the key aspects of creativity is the ability to produce original ideas. Originality is defined in terms of the novelty and rarity of an idea and is measured by the infrequency of the idea compared to other ideas. In the current study we focused on divergent thinking (DT) \textendash{} the ability to produce many alternate ideas \textendash{} and assessed the neural pathways associated with originality. Considering that generation of original ideas involves both the ability to generate new associations and the ability to overcome automatic common responses, we hypothesized that originality would be associated with activations in regions related to associative thinking, including areas of the default mode network (DMN) such as medial prefrontal areas, as well as with areas involved in cognitive control and inhibition. Thirty participants were scanned while performing a DT task that required the generation of original uses for common objects. The results indicate that the ability to produce original ideas is mediated by activity in several regions that are part of the DMN including the medial prefrontal cortex (mPFC) and the posterior cingulate cortex (PCC). Furthermore, individuals who are more original exhibited enhanced activation in the ventral anterior cingulate cortex (vACC), which was also positively coupled with activity in the left occipital\textendash temporal area. These results are in line with the dual model of creativity, according to which original ideas are a product of the interaction between a system that generates ideas and a control system that evaluates these ideas.},
  journal = {NeuroImage},
  keywords = {Anterior cingulate cortex,Creativity,fMRI,Originality,Prefrontal cortex}
}

@article{Mazor_Transient_2005,
  title = {Transient {{Dynamics}} versus {{Fixed Points}} in {{Odor Representations}} by {{Locust Antennal Lobe Projection Neurons}}},
  author = {Mazor, Ofer and Laurent, Gilles},
  year = {2005},
  month = nov,
  volume = {48},
  pages = {661--673},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2005.09.032},
  abstract = {Summary Projection neurons (PNs) in the locust antennal lobe exhibit odor-specific dynamic responses. We studied a PN population, stimulated with five odorants and pulse durations between 0.3 and 10 s. Odor representations were characterized as time series of vectors of PN activity, constructed from the firing rates of all PNs in successive 50 ms time bins. Odor representations by the PN population can be described as trajectories in PN state space with three main phases: an on transient, lasting 1\textendash 2 s; a fixed point, stable for at least 8 s; and an off transient, lasting a few seconds as activity returns to baseline. Whereas all three phases are odor specific, optimal stimulus separation occurred during the transients rather than the fixed points. In addition, the PNs' own target neurons respond least when their PN-population input stabilized at a fixed point. Steady-state measures of activity thus seem inappropriate to understand the neural code in this system.},
  journal = {Neuron},
  number = {4}
}

@article{Mazzotta_Decision_1995,
  title = {Decision {{Making When Choices Are Complex}}: {{A Test}} of {{Heiner}}'s {{Hypothesis}}},
  shorttitle = {Decision {{Making When Choices Are Complex}}},
  author = {Mazzotta, Marisa J. and Opaluch, James J.},
  year = {1995},
  volume = {71},
  pages = {500--515},
  issn = {0023-7639},
  doi = {10.2307/3146714},
  abstract = {This paper explores Heiner's hypothesis concerning a gap between the cognitive ability of decision makers and the difficulty of decisions (the C-D gap). We discuss the implications of decision heuristics for coefficient estimates when uncertainty is faced by decision makers, where the level of uncertainty varies with complexity. Statistical analysis strongly supports the presence of a C-D gap and provides evidence supporting the use of decision heuristics. The results of both direct and indirect methods suggest that mixed decision strategies may be used. We also find that complexity effects can have important implications for welfare analysis.},
  journal = {Land Economics},
  number = {4}
}

@article{McClure_dualsystems_2014,
  title = {A Dual-Systems Perspective on Addiction: Contributions from Neuroimaging and Cognitive Training},
  shorttitle = {A Dual-Systems Perspective on Addiction},
  author = {McClure, Samuel M. and Bickel, Warren K.},
  year = {2014},
  month = oct,
  volume = {1327},
  pages = {62--78},
  issn = {0077-8923},
  doi = {10.1111/nyas.12561},
  abstract = {Dual-systems theories explain lapses in self-control in terms of a conflict between automatic and deliberative modes of behavioral control. Numerous studies have now tested whether the brain areas that control behavior are organized in a manner consistent with dual-systems models. Brain regions directly associated with the mesolimbic dopamine system, the nucleus accumbens (NAcc) and ventromedial prefrontal cortex (vmPFC) in particular, capture some of the features assumed by automatic processing. Regions in the lateral prefrontal cortex (lPFC) are more closely linked to deliberative processing and the exertion of self-control in the suppression of impulses. While identifying these regions crudely supports dual-system theories, important modifications to what constitutes automatic and deliberative behavioral control are also suggested. Experiments have identified various means by which automatic processes may be sculpted. Additional work decomposes deliberative processes into component functions such as generalized working memory, reappraisal of emotional stimuli, and prospection. The importance of deconstructing dual-systems models into specific cognitive processes is clear for understanding and treating addiction. We discuss intervention possibilities suggested by recent research, and focus in particular on cognitive training approaches to bolster deliberative control processes that may aid quit attempts.},
  journal = {Annals of the New York Academy of Sciences},
  pmcid = {PMC4285342},
  pmid = {25336389}
}

@article{McDannaldMichaelA._Model_2012,
  title = {Model-based Learning and the Contribution of the Orbitofrontal Cortex to the Model-free World},
  author = {{McDannald Michael A.} and {Takahashi Yuji K.} and {Lopatina Nina} and {Pietras Brad W.} and {Jones Josh L.} and {Schoenbaum Geoffrey}},
  year = {2012},
  month = apr,
  volume = {35},
  pages = {991--996},
  issn = {0953-816X},
  doi = {10.1111/j.1460-9568.2011.07982.x},
  abstract = {Abstract Learning is proposed to occur when there is a discrepancy between reward prediction and reward receipt. At least two separate systems are thought to exist: one in which predictions are proposed to be based on model?free or cached values; and another in which predictions are model?based. A basic neural circuit for model?free reinforcement learning has already been described. In the model?free circuit the ventral striatum (VS) is thought to supply a common?currency reward prediction to midbrain dopamine neurons that compute prediction errors and drive learning. In a model?based system, predictions can include more information about an expected reward, such as its sensory attributes or current, unique value. This detailed prediction allows for both behavioral flexibility and learning driven by changes in sensory features of rewards alone. Recent evidence from animal learning and human imaging suggests that, in addition to model?free information, the VS also signals model?based information. Further, there is evidence that the orbitofrontal cortex (OFC) signals model?based information. Here we review these data and suggest that the OFC provides model?based information to this traditional model?free circuitry and offer possibilities as to how this interaction might occur.},
  journal = {European Journal of Neuroscience},
  keywords = {modelbased,modelfree,orbitofrontal cortex,Pavlovian,striatum},
  number = {7}
}

@article{McKerchar_Delay_2012,
  title = {Delay and Probability Discounting in Humans: {{An}} Overview},
  shorttitle = {Delay and Probability Discounting in Humans},
  author = {McKerchar, Todd L. and Renda, C. Renee},
  year = {2012},
  volume = {62},
  pages = {817--834},
  issn = {2163-3452(Electronic),0033-2933(Print)},
  abstract = {[Correction Notice: An Erratum for this article was reported in Vol 63(3) of The Psychological Record (see record 2013-27342-004). In the original article, the x-axis of Figure 2 was labeled incorrectly. The correct figure is present in the erratum.] The purpose of this review is to introduce the reader to the concepts of delay and probability discounting as well as the major empirical findings to emerge from research with humans on these concepts. First, we review a seminal discounting study by Rachlin, Raineri, and Cross (1991) as well as an influential extension of this study by Madden, Petry, Badger, and Bickel (1997). In doing so, we describe the general procedure used for assessing discounting and the resulting form of the obtained discounting functions. With this as background, we review additional empirical findings that have emerged over the last 20 years, by addressing issues such as time consistency and preference reversals, magnitude effects, and the gain\textendash loss asymmetry. Finally, we conclude with a discussion of more recent developments and their implications for the future of this growing area. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  journal = {The Psychological Record},
  keywords = {Concepts,Delay Discounting,Probability},
  number = {4}
}

@article{McNamara_Risksensitive_1992,
  title = {Risk-Sensitive Foraging: {{A}} Review of the Theory},
  shorttitle = {Risk-Sensitive Foraging},
  author = {McNamara, John M. and Houston, Alasdair I.},
  year = {1992},
  month = jan,
  volume = {54},
  pages = {355--378},
  issn = {0092-8240},
  doi = {10.1016/S0092-8240(05)80031-X},
  journal = {Bulletin of Mathematical Biology},
  number = {2}
}

@article{Meister_dimensionality_2015,
  title = {On the Dimensionality of Odor Space},
  author = {Meister, Markus},
  year = {2015},
  month = jul,
  volume = {4},
  pages = {e07865},
  issn = {2050-084X},
  doi = {10.7554/eLife.07865},
  abstract = {There is great interest in understanding human olfactory experience from a principled and quantitative standpoint. The comparison is often made to color vision, where a solid framework with a three-dimensional perceptual space enabled a rigorous search for the underlying neural pathways, and the technological development of lifelike color display devices. A recent, highly publicized report claims that humans can discriminate at least 1 trillion odors, which exceeds by many orders of magnitude the known capabilities of color discrimination. This claim is wrong. I show that the failure lies in the mathematical method used to infer the size of odor space from a limited experimental sample. Further analysis focuses on establishing how many dimensions the perceptual odor space has. I explore the dimensionality of physical, neural, and perceptual spaces, drawing on results from bacteria to humans, and propose some experimental approaches to better estimate the number of discriminable odors.DOI: http://dx.doi.org/10.7554/eLife.07865.001View Full TextTo Top There is great interest in understanding human olfactory experience from a principled and quantitative standpoint. The comparison is often made to color vision, where a solid framework with a three-dimensional perceptual space enabled a rigorous search for the underlying neural pathways, and the technological development of lifelike color display devices. A recent, highly publicized report claims that humans can discriminate at least 1 trillion odors, which exceeds by many orders of magnitude the known capabilities of color discrimination. This claim is wrong. I show that the failure lies in the mathematical method used to infer the size of odor space from a limited experimental sample. Further analysis focuses on establishing how many dimensions the perceptual odor space has. I explore the dimensionality of physical, neural, and perceptual spaces, drawing on results from bacteria to humans, and propose some experimental approaches to better estimate the number of discriminable odors. DOI: http://dx.doi.org/10.7554/eLife.07865.001 Scientists are interested in the number of colors, sounds and smells we can distinguish because this information can shed light onto how our brains process these senses both in health and disease. It is relatively straightforward to determine how many colors we can see or sounds we can hear because these stimuli are well defined by physical properties such as wavelength. We know the range of wavelengths that the eye can see or the ear can hear, and we can also understand how two such stimuli (e.g., red and blue) are arranged perceptually (think of a color wheel). It is harder, however, to do the same for smell because most `olfactory stimuli' consist of mixtures of different odor molecules. Moreover, we understand much less about how olfactory stimuli are arranged perceptually. In 2014 researchers at Rockefeller University reported that humans can distinguish more than one trillion smells from one another. To calculate this number the researchers tested the ability of human subjects to discriminate between mixtures of different odor molecules. Each mixture consisted of 10, 20 or 30 molecules selected from a chemical library of 128 different odor molecules. Since each mixture of 10 molecules could contain any 10 of the 128 molecules, more than 200 trillion combinations were possible; the number of possible combinations for the 20- and 30-molecule mixtures were even higher. The aim of the experiment was to identify\textemdash by sampling from this very large number of combinations\textemdash the number of molecules that two mixtures could have in common and still be distinguishable to the typical person. The Rockefeller team used this number and a geometrical analogy to conclude that humans could discriminate at least 1.72 trillion odors, which was much higher than expected from previous reports and anecdotes. Now Meister reports that the claims made in the Rockefeller study are unsupported because of flaws in the design and analysis of the experiment. In particular, there are flaws in the mathematical methods used to infer the potential number of all smells that humans can discriminate from the numbers of experimental samples tested. Meister also applies the Rockefeller approach to a well-understood sensory system\textemdash the vision system\textemdash and finds that it predicts that humans should be able to discriminate an infinite number of colors: however, it is widely agreed that humans can only discriminate several million colors. In a separate paper Gerkin and Castro also report that the 1.72 trillion smells claim is unjustified. DOI: http://dx.doi.org/10.7554/eLife.07865.002},
  copyright = {\textcopyright{} 2015, Meister. This article is distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use and redistribution provided that the original author and source are credited.},
  journal = {eLife},
  language = {en}
}

@article{Mellet_Neural_2000,
  title = {Neural {{Correlates}} of {{Topographic Mental Exploration}}: {{The Impact}} of {{Route}} versus {{Survey Perspective Learning}}},
  shorttitle = {Neural {{Correlates}} of {{Topographic Mental Exploration}}},
  author = {Mellet, E. and Bricogne, S. and {Tzourio-Mazoyer}, N. and Gha{\"e}m, O. and Petit, L. and Zago, L. and Etard, O. and Berthoz, A. and Mazoyer, B. and Denis, M.},
  year = {2000},
  month = nov,
  volume = {12},
  pages = {588--600},
  issn = {1053-8119},
  doi = {10.1006/nimg.2000.0648},
  abstract = {There are two major sources of information to build a topographic representation of an environment, namely actual navigation within the environment (route perspective) and map learning (survey perspective). The aim of the present work was to use positron emission tomography (PET) to compare the neural substrate of the topographic representation built from these two modes. One group of subjects performed a mental exploration task in an environment learned from actual navigation (mental navigation task). Another group of subjects performed exploration in the same environment learned from a map (mental map task). A right hippocampal activation common to both mental navigation and mental map tasks was evidenced and may correspond the neural substrate of a ``dual-perspective'' representation. The parahippocampal gyrus was additionally activated bilaterally during mental navigation only. These results suggest that the right hippocampus involvement would be sufficient when the representation incorporates essentially survey information while the bilateral parahippocampal gyrus would be involved when the environment incorporates route information and includes ``object'' landmarks. The activation of a parietofrontal network composed of the intraparietal sulcus, the superior frontal sulcus, the middle frontal gyrus, and the pre-SMA was observed in common for both mental navigation and mental map and is likely to reflect the spatial mental imagery components of the tasks.},
  journal = {NeuroImage},
  keywords = {hippocampus,parahippocampus,parieto-frontal network,positron emission tomography,route perspective,spatial mental imagery,survey perspective},
  number = {5}
}

@article{Mendl_Performing_1999,
  title = {Performing under Pressure: Stress and Cognitive Function},
  shorttitle = {Performing under Pressure},
  author = {Mendl, Michael},
  year = {1999},
  month = dec,
  volume = {65},
  pages = {221--244},
  issn = {0168-1591},
  doi = {10.1016/S0168-1591(99)00088-X},
  abstract = {The way in which cognitive functioning is affected by stressors is an important area of research for applied ethologists because stress caused by captive conditions may disrupt cognitive processes and lead to welfare and husbandry problems. Such problems may be minimised through an understanding of the links between stress and cognition. The effects of stress on cognitive function have been studied in disciplines ranging from human perceptual psychology to animal neuroscience. The aim of this paper is to provide an introduction to this research, focusing on the effects of stressors on attention, memory formation and memory recall. Findings from such a diverse literature with little apparent inter-disciplinary communication are inevitably complex and often contradictory. Nevertheless, some generalities do emerge. The idea that an inverted U-shaped relationship exists between an individual's state of stress or arousal and its ability to perform a cognitive task effectively, the so-called Yerkes\textendash Dodson law, is commonly encountered. The law has limited explanatory value because it is unlikely that different stressors act on cognitive function via the same intervening, non-specific state. Furthermore, the law only provides a very general description of the relationship between stress and cognitive function. Empirical research on attention and memory processes reveals more specific findings. Stressors appear to cause shifts, lapses and narrowing of attention, and can also influence decision speed. These processes may be viewed as serving an adaptive role helping the animal to search for and scrutinise a source of danger. There is conflicting evidence as to whether hormones involved in the hypothalamic\textendash pituitary\textendash adrenal stress response play a part in these processes. These hormones and those involved in the sympathetic-adrenomedullary stress response do appear to play an important role in memory formation. Low or moderate concentrations of circulating glucocorticoids and catecholamines can enhance memory formation, while excessively high or prolonged elevations of these hormones can lead to memory disruption. The effects of stressors on memory recall are less clear. There is evidence for disruptive effects, and for facilitatory effects indicating state-dependent memory recall; events experienced under conditions of high arousal may be best recalled under similar conditions. Applied ethologists have the opportunity to extend work in this area, which often involves studies of single stressors/stress hormones acting in isolation and limited measures of cognitive function, by focusing on real-life husbandry stressors encountered by captive animals. This will yield fundamental information which also has direct relevance to animal welfare and management issues.},
  journal = {Applied Animal Behaviour Science},
  keywords = {Attention,Cognition,Learning,Memory,Stress,Welfare},
  number = {3}
}

@article{Meyerowitz_effect_1987,
  title = {The Effect of Message Framing on Breast Self-Examination Attitudes, Intentions, and Behavior},
  author = {Meyerowitz, B. E. and Chaiken, S.},
  year = {1987},
  month = mar,
  volume = {52},
  pages = {500--510},
  issn = {0022-3514},
  doi = {10.1037//0022-3514.52.3.500},
  abstract = {In this study we tested the framing hypothesis that a pamphlet stressing the negative consequences of not performing breast self-examination (BSE) would be more persuasive than a pamphlet emphasizing BSE's positive consequences. College-aged female subjects were exposed to a loss-frame pamphlet, a gain-frame pamphlet, or a no-arguments pamphlet, or they received no pamphlet describing the importance of and the techniques for performing BSE. Attitudes toward BSE and intentions to perform BSE were assessed immediately after this intervention and again 4 months later. The follow-up also assessed subjects' postexperimental BSE behavior. Consistent with predictions, subjects who read a pamphlet with arguments framed in loss language manifested more positive BSE attitudes, intentions, and behaviors than did subjects in the other three conditions. The greater impact of the loss pamphlet could not be attributed to greater fear arousal, better memory for pamphlet content, greater perceived susceptibility to breast cancer, or stronger beliefs in BSE's efficacy on the part of the loss subjects. Only measures of perceived self-efficacy in performing BSE were differentially affected by the framing manipulation, with loss subjects reporting the greatest levels of self-confidence. The results are discussed in terms of prospect theory's framing postulate and a simpler negativity-bias conceptualization, and underlying mechanisms such as differential salience and vividness are considered. Clinical implications of the findings are also explored.},
  journal = {Journal of Personality and Social Psychology},
  keywords = {Attitude to Health,Breast,Emotions,Female,Follow-Up Studies,Health Education,Humans,Mental Recall,Motivation,Palpation,Persuasive Communication,Risk,Self Care},
  language = {eng},
  number = {3},
  pmid = {3572721}
}

@article{Meyniel_Confidence_2015,
  title = {Confidence as {{Bayesian Probability}}: {{From Neural Origins}} to {{Behavior}}},
  shorttitle = {Confidence as {{Bayesian Probability}}},
  author = {Meyniel, Florent and Sigman, Mariano and Mainen, Zachary F.},
  year = {2015},
  month = oct,
  volume = {88},
  pages = {78--92},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2015.09.039},
  abstract = {Research on confidence spreads across several sub-fields of psychology and neuroscience. Here, we explore how a definition of confidence as Bayesian probability can unify these viewpoints. This computational view entails that there are distinct forms in which confidence is represented and used in the brain, including distributional confidence, pertaining to neural representations of probability distributions, and summary confidence, pertaining to scalar summaries of those distributions. Summary confidence is, normatively, derived or ``read out'' from distributional confidence. Neural implementations of readout will trade off optimality versus flexibility of routing across brain systems, allowing confidence to serve diverse cognitive functions.},
  journal = {Neuron},
  language = {English},
  number = {1}
}

@article{Meyniel_Confidence_2015a,
  title = {Confidence as {{Bayesian Probability}}: {{From Neural Origins}} to {{Behavior}}},
  shorttitle = {Confidence as {{Bayesian Probability}}},
  author = {Meyniel, Florent and Sigman, Mariano and Mainen, Zachary F.},
  year = {2015},
  month = oct,
  volume = {88},
  pages = {78--92},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2015.09.039},
  journal = {Neuron},
  language = {English},
  number = {1}
}

@article{Meyniel_Sense_2015,
  title = {The {{Sense}} of {{Confidence}} during {{Probabilistic Learning}}: {{A Normative Account}}},
  shorttitle = {The {{Sense}} of {{Confidence}} during {{Probabilistic Learning}}},
  author = {Meyniel, Florent and Schlunegger, Daniel and Dehaene, Stanislas},
  year = {2015},
  month = jun,
  volume = {11},
  pages = {e1004305},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1004305},
  abstract = {Author Summary Learning is often accompanied by a ``feeling of knowing'', a growing sense of confidence in having acquired the relevant information. Here, we formalize this introspective ability, and we evaluate its accuracy and its flexibility in the face of environmental changes that impose a revision of one's mental model. We evaluate the hypothesis that the brain acts as a statistician that accurately tracks not only the most likely state of the environment, but also the uncertainty associated with its own inferences. We show that subjective confidence ratings varied across successive observations in tight parallel with a mathematical model of an ideal observer performing the optimal inference. Our results suggest that, during learning, the brain constantly keeps track of its own uncertainty, and that subjective confidence may derive from the learning process itself. Our results therefore suggest that subjective confidence, although currently under-explored, could provide key data to better understand learning.},
  journal = {PLOS Computational Biology},
  keywords = {Algorithms,Data visualization,Entropy,Human learning,Learning,Probability distribution,Regression analysis,Sequence analysis},
  number = {6}
}

@article{Miller_Habits_2019,
  title = {Habits without Values},
  author = {Miller, Kevin J. and Shenhav, Amitai and Ludvig, Elliot A.},
  year = {2019},
  month = mar,
  volume = {126},
  pages = {292--311},
  issn = {1939-1471},
  doi = {10.1037/rev0000120},
  abstract = {Habits form a crucial component of behavior. In recent years, key computational models have conceptualized habits as arising from model-free reinforcement learning mechanisms, which typically select between available actions based on the future value expected to result from each. Traditionally, however, habits have been understood as behaviors that can be triggered directly by a stimulus, without requiring the animal to evaluate expected outcomes. Here, we develop a computational model instantiating this traditional view, in which habits develop through the direct strengthening of recently taken actions rather than through the encoding of outcomes. We demonstrate that this model accounts for key behavioral manifestations of habits, including insensitivity to outcome devaluation and contingency degradation, as well as the effects of reinforcement schedule on the rate of habit formation. The model also explains the prevalent observation of perseveration in repeated-choice tasks as an additional behavioral manifestation of the habit system. We suggest that mapping habitual behaviors onto value-free mechanisms provides a parsimonious account of existing behavioral and neural data. This mapping may provide a new foundation for building robust and comprehensive models of the interaction of habits with other, more goal-directed types of behaviors and help to better guide research into the neural mechanisms underlying control of instrumental behavior more generally. (PsycINFO Database Record (c) 2019 APA, all rights reserved).},
  journal = {Psychological Review},
  keywords = {Animals,Behavior; Animal,Decision Making,Goals,Habits,Humans,Models; Psychological,Prefrontal Cortex,Reinforcement; Psychology},
  language = {eng},
  number = {2},
  pmcid = {PMC6548181},
  pmid = {30676040}
}

@article{Miller_Integrative_2001,
  title = {An {{Integrative Theory}} of {{Prefrontal Cortex Function}}},
  author = {Miller, Earl K. and Cohen, Jonathan D.},
  year = {2001},
  volume = {24},
  pages = {167--202},
  doi = {10.1146/annurev.neuro.24.1.167},
  abstract = {The prefrontal cortex has long been suspected to play an important role in cognitive control, in the ability to orchestrate thought and action in accordance with internal goals. Its neural basis, however, has remained a mystery. Here, we propose that cognitive control stems from the active maintenance of patterns of activity in the prefrontal cortex that represent goals and the means to achieve them. They provide bias signals to other brain structures whose net effect is to guide the flow of activity along neural pathways that establish the proper mappings between inputs, internal states, and outputs needed to perform a given task. We review neurophysiological, neurobiological, neuroimaging, and computational studies that support this theory and discuss its implications as well as further issues to be addressed},
  journal = {Annual Review of Neuroscience},
  keywords = {Attention,cognition,executive control,frontal lobes,working memory},
  number = {1},
  pmid = {11283309}
}

@article{Miller_prefontral_2000,
  title = {The Prefontral Cortex and Cognitive Control},
  author = {Miller, Earl K.},
  year = {2000},
  month = oct,
  volume = {1},
  pages = {59--65},
  issn = {1471-003X},
  doi = {10.1038/35036228},
  abstract = {One of the enduring mysteries of brain function concerns the process of cognitive control. How does complex and seemingly wilful behaviour emerge from interactions between millions of neurons? This has long been suspected to depend on the prefrontal cortex \textemdash{} the neocortex at the anterior end of the brain \textemdash{} but now we are beginning to uncover its neural basis. Nearly all intended behaviour is learned and so depends on a cognitive system that can acquire and implement the 'rules of the game' needed to achieve a given goal in a given situation. Studies indicate that the prefrontal cortex is central in this process. It provides an infrastructure for synthesizing a diverse range of information that lays the foundation for the complex forms of behaviour observed in primates.},
  copyright = {\textcopyright{} 2000 Nature Publishing Group},
  journal = {Nature Reviews Neuroscience},
  language = {en},
  number = {1}
}

@article{Miller_Stochastic_2010,
  title = {Stochastic {{Transitions}} between {{Neural States}} in {{Taste Processing}} and {{Decision}}-{{Making}}},
  author = {Miller, Paul and Katz, Donald B.},
  year = {2010},
  month = feb,
  volume = {30},
  pages = {2559--2570},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.3047-09.2010},
  abstract = {Noise, which is ubiquitous in the nervous system, causes trial-to-trial variability in the neural responses to stimuli. This neural variability is in turn a likely source of behavioral variability. Using Hidden Markov modeling, a method of analysis that can make use of such trial-to-trial response variability, we have uncovered sequences of discrete states of neural activity in gustatory cortex during taste processing. Here, we advance our understanding of these patterns in two ways. First, we reproduce the experimental findings in a formal model, describing a network that evinces sharp transitions between discrete states that are deterministically stable given sufficient noise in the network; as in the empirical data, the transitions occur at variable times across trials, but the stimulus-specific sequence is itself reliable. Second, we demonstrate that such noise-induced transitions between discrete states can be computationally advantageous in a reduced, decision-making network. The reduced network produces binary outputs, which represent classification of ingested substances as palatable or nonpalatable, and the corresponding behavioral responses of ``spit'' or ``swallow''. We evaluate the performance of the network by measuring how reliably its outputs follow small biases in the strengths of its inputs. We compare two modes of operation: deterministic integration (``ramping'') versus stochastic decision-making (``jumping''), the latter of which relies on state-to-state transitions. We find that the stochastic mode of operation can be optimal under typical levels of internal noise and that, within this mode, addition of random noise to each input can improve optimal performance when decisions must be made in limited time.},
  journal = {The Journal of Neuroscience},
  language = {en},
  number = {7},
  pmid = {20164341}
}

@article{Milligan_examination_1985,
  title = {An Examination of Procedures for Determining the Number of Clusters in a Data Set},
  author = {Milligan, Glenn W. and Cooper, Martha C.},
  year = {1985},
  month = jun,
  volume = {50},
  pages = {159--179},
  issn = {0033-3123, 1860-0980},
  doi = {10.1007/BF02294245},
  abstract = {A Monte Carlo evaluation of 30 procedures for determining the number of clusters was conducted on artificial data sets which contained either 2, 3, 4, or 5 distinct nonoverlapping clusters. To provide a variety of clustering solutions, the data sets were analyzed by four hierarchical clustering methods. External criterion measures indicated excellent recovery of the true cluster structure by the methods at the correct hierarchy level. Thus, the clustering present in the data was quite strong. The simulation results for the stopping rules revealed a wide range in their ability to determine the correct number of clusters in the data. Several procedures worked fairly well, whereas others performed rather poorly. Thus, the latter group of rules would appear to have little validity, particularly for data sets containing distinct clusters. Applied researchers are urged to select one or more of the better criteria. However, users are cautioned that the performance of some of the criteria may be data dependent.},
  journal = {Psychometrika},
  language = {en},
  number = {2}
}

@article{Milligan_examination_1985a,
  title = {An Examination of Procedures for Determining the Number of Clusters in a Data Set},
  author = {Milligan, Glenn W. and Cooper, Martha C.},
  year = {1985},
  month = jun,
  volume = {50},
  pages = {159--179},
  issn = {0033-3123, 1860-0980},
  doi = {10.1007/BF02294245},
  abstract = {A Monte Carlo evaluation of 30 procedures for determining the number of clusters was conducted on artificial data sets which contained either 2, 3, 4, or 5 distinct nonoverlapping clusters. To provide a variety of clustering solutions, the data sets were analyzed by four hierarchical clustering methods. External criterion measures indicated excellent recovery of the true cluster structure by the methods at the correct hierarchy level. Thus, the clustering present in the data was quite strong. The simulation results for the stopping rules revealed a wide range in their ability to determine the correct number of clusters in the data. Several procedures worked fairly well, whereas others performed rather poorly. Thus, the latter group of rules would appear to have little validity, particularly for data sets containing distinct clusters. Applied researchers are urged to select one or more of the better criteria. However, users are cautioned that the performance of some of the criteria may be data dependent.},
  journal = {Psychometrika},
  language = {en},
  number = {2}
}

@article{Mirpour_Been_2009,
  title = {Been {{There}}, {{Seen That}}: {{A Neural Mechanism}} for {{Performing Efficient Visual Search}}},
  shorttitle = {Been {{There}}, {{Seen That}}},
  author = {Mirpour, Koorosh and Arcizet, Fabrice and Ong, Wei Song and Bisley, James W.},
  year = {2009},
  month = dec,
  volume = {102},
  pages = {3481--3491},
  issn = {0022-3077, 1522-1598},
  doi = {10.1152/jn.00688.2009},
  abstract = {In everyday life, we efficiently find objects in the world by moving our gaze from one location to another. The efficiency of this process is brought about by ignoring items that are dissimilar to the target and remembering which target-like items have already been examined. We trained two animals on a visual foraging task in which they had to find a reward-loaded target among five task-irrelevant distractors and five potential targets. We found that both animals performed the task efficiently, ignoring the distractors and rarely examining a particular target twice. We recorded the single unit activity of 54 neurons in the lateral intraparietal area (LIP) while the animals performed the task. The responses of the neurons differentiated between targets and distractors throughout the trial. Further, the responses marked off targets that had been fixated by a reduction in activity. This reduction acted like inhibition of return in saliency map models; items that had been fixated would no longer be represented by high enough activity to draw an eye movement. This reduction could also be seen as a correlate of reward expectancy; after a target had been identified as not containing the reward the activity was reduced. Within a trial, responses to the remaining targets did not increase as they became more likely to yield a result, suggesting that only activity related to an event is updated on a moment-by-moment bases. Together, our data show that all the neural activity required to guide efficient search is present in LIP. Because LIP activity is known to correlate with saccade goal selection, we propose that LIP plays a significant role in the guidance of efficient visual search.},
  copyright = {Copyright \textcopyright{} 2009 the American Physiological Society},
  journal = {Journal of Neurophysiology},
  language = {en},
  number = {6},
  pmid = {19812286}
}

@article{Mirza_Scene_2016,
  title = {Scene {{Construction}}, {{Visual Foraging}}, and {{Active Inference}}},
  author = {Mirza, M. Berk and Adams, Rick A. and Mathys, Christoph D. and Friston, Karl J.},
  year = {2016},
  pages = {56},
  doi = {10.3389/fncom.2016.00056},
  abstract = {This paper describes an active inference scheme for visual searches and the perceptual synthesis entailed by scene construction. Active inference assumes that perception and action minimize variational free energy, where actions are selected to minimize the free energy expected in the future. This assumption generalizes risk-sensitive control and expected utility theory to include epistemic value; namely, the value (or salience) of information inherent in resolving uncertainty about the causes of ambiguous cues or outcomes. Here, we apply active inference to saccadic searches of a visual scene. We consider the (difficult) problem of categorizing a scene, based on the spatial relationship among visual objects where, crucially, visual cues are sampled myopically through a sequence of saccadic eye movements. This means that evidence for competing hypotheses about the scene has to be accumulated sequentially, calling upon both prediction (planning) and postdiction (memory). Our aim is to highlight some simple but fundamental aspects of the requisite functional anatomy; namely, the link between approximate Bayesian inference under mean field assumptions and functional segregation in the visual cortex. This link rests upon the (neurobiologically plausible) process theory that accompanies the normative formulation of active inference for Markov decision processes. In future work, we hope to use this scheme to model empirical saccadic searches and identify the prior beliefs that underwrite intersubject variability in the way people forage for information in visual scenes (e.g., in schizophrenia).},
  journal = {Frontiers in Computational Neuroscience},
  keywords = {active inference,Bayesian inference,epistemic value,Free energy,information gain,salience,scene construction,visual search}
}

@article{Miura_Odor_2012,
  title = {Odor {{Representations}} in {{Olfactory Cortex}}: {{Distributed Rate Coding}} and {{Decorrelated Population Activity}}},
  shorttitle = {Odor {{Representations}} in {{Olfactory Cortex}}},
  author = {Miura, Keiji and Mainen, Zachary F. and Uchida, Naoshige},
  year = {2012},
  month = jun,
  volume = {74},
  pages = {1087--1098},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2012.04.021},
  abstract = {Summary How information encoded in neuronal spike trains is used to guide sensory decisions is a fundamental question. In olfaction, a single sniff is sufficient for fine odor discrimination but the neural representations on which olfactory decisions are based are unclear. Here, we recorded neural ensemble activity in the anterior piriform cortex (aPC) of rats performing an odor mixture categorization task. We show that odors evoke transient bursts locked to sniff onset and that odor identity can be better decoded using burst spike counts than by spike latencies or temporal patterns. Surprisingly, aPC ensembles also exhibited near-zero noise correlations during odor stimulation. Consequently, fewer than 100 aPC neurons provided sufficient information to account for behavioral speed and accuracy, suggesting that behavioral performance limits arise downstream of aPC. These findings demonstrate profound transformations in the dynamics of odor representations from the olfactory bulb to cortex and reveal likely substrates for odor-guided decisions. Video Abstract},
  journal = {Neuron},
  number = {6}
}

@article{Mobbs_Foraging_2013,
  title = {Foraging under {{Competition}}: {{The Neural Basis}} of {{Input}}-{{Matching}} in {{Humans}}},
  shorttitle = {Foraging under {{Competition}}},
  author = {Mobbs, Dean and Hassabis, Demis and Yu, Rongjun and Chu, Carlton and Rushworth, Matthew and Boorman, Erie and Dalgleish, Tim},
  year = {2013},
  month = jun,
  volume = {33},
  pages = {9866--9872},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.2238-12.2013},
  abstract = {Input-matching is a key mechanism by which animals optimally distribute themselves across habitats to maximize net gains based on the changing input values of food supply rate and competition. To examine the neural systems that underlie this rule in humans, we created a continuous-input foraging task where subjects had to decide to stay or switch between two habitats presented on the left and right of the screen. The subject's decision to stay or switch was based on changing input values of reward-token supply rate and competition density. High density of competition or low-reward token rate was associated with decreased chance of winning. Therefore, subjects attempted to maximize their gains by switching to habitats that possessed low competition density and higher token rate. When it was increasingly disadvantageous to be in a habitat, we observed increased activity in brain regions that underlie preparatory motor actions, including the dorsal anterior cingulate cortex and the supplementary motor area, as well as the insula, which we speculate may be involved in the conscious urge to switch habitats. Conversely, being in an advantageous habitat is associated with activity in the reward systems, namely the striatum and medial prefrontal cortex. Moreover, amygdala and dorsal putamen activity steered interindividual preferences in competition avoidance and pursuing reward. Our results suggest that input-matching decisions are made as a net function of activity in a distributed set of neural systems. Furthermore, we speculate that switching behaviors are related to individual differences in competition avoidance and reward drive.},
  journal = {The Journal of Neuroscience},
  language = {en},
  number = {23},
  pmid = {23739983}
}

@article{Momennejad_successor_2017,
  title = {The Successor Representation in Human Reinforcement Learning},
  author = {Momennejad, Ida and Russek, Evan M. and Cheong, Jin H. and Botvinick, Matthew M. and Daw, Nathaniel and Gershman, Samuel J.},
  year = {2017},
  month = jul,
  pages = {083824},
  doi = {10.1101/083824},
  abstract = {Theories of reward learning in neuroscience have focused on two families of algorithms, thought to capture deliberative vs. habitual choice. Model-based algorithms compute the value of candidate actions from scratch, whereas model-free algorithms make choice more efficient but less flexible by storing pre-computed action values. We examine an intermediate algorithmic family, the successor representation (SR), which balances flexibility and efficiency by storing partially computed action values: predictions about future events. These pre-computation strategies differ in how they update their choices following changes in a task. SR's reliance on stored predictions about future states predicts a unique signature of insensitivity to changes in the task's sequence of events, but flexible adjustment following changes to rewards. We provide evidence for such differential sensitivity in two behavioral studies with humans. These results suggest that the SR is a computational substrate for semi-flexible choice in humans, introducing a subtler, more cognitive notion of habit.},
  copyright = {\textcopyright{} 2017, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NoDerivs 4.0 International), CC BY-ND 4.0, as described at http://creativecommons.org/licenses/by-nd/4.0/},
  journal = {bioRxiv},
  language = {en}
}

@article{Monsell_Task_2003,
  title = {Task Switching},
  author = {Monsell, Stephen},
  year = {2003},
  month = mar,
  volume = {7},
  pages = {134--140},
  issn = {1364-6613},
  doi = {10.1016/S1364-6613(03)00028-7},
  abstract = {Everyday life requires frequent shifts between cognitive tasks. Research reviewed in this article probes the control processes that reconfigure mental resources for a change of task by requiring subjects to switch frequently among a small set of simple tasks. Subjects' responses are substantially slower and, usually, more error-prone immediately after a task switch. This `switch cost' is reduced, but not eliminated, by an opportunity for preparation. It seems to result from both transient and long-term carry-over of `task-set' activation and inhibition as well as time consumed by task-set reconfiguration processes. Neuroimaging studies of task switching have revealed extra activation in numerous brain regions when subjects prepare to change tasks and when they perform a changed task, but we cannot yet separate `controlling' from `controlled' regions.},
  journal = {Trends in Cognitive Sciences},
  number = {3}
}

@article{Monsell_Task_2003a,
  title = {Task Switching},
  author = {Monsell, Stephen},
  year = {2003},
  month = mar,
  volume = {7},
  pages = {134--140},
  issn = {1364-6613},
  doi = {10.1016/S1364-6613(03)00028-7},
  abstract = {Everyday life requires frequent shifts between cognitive tasks. Research reviewed in this article probes the control processes that reconfigure mental resources for a change of task by requiring subjects to switch frequently among a small set of simple tasks. Subjects' responses are substantially slower and, usually, more error-prone immediately after a task switch. This `switch cost' is reduced, but not eliminated, by an opportunity for preparation. It seems to result from both transient and long-term carry-over of `task-set' activation and inhibition as well as time consumed by task-set reconfiguration processes. Neuroimaging studies of task switching have revealed extra activation in numerous brain regions when subjects prepare to change tasks and when they perform a changed task, but we cannot yet separate `controlling' from `controlled' regions.},
  journal = {Trends in Cognitive Sciences},
  language = {en},
  number = {3}
}

@article{Montague_framework_1996,
  title = {A Framework for Mesencephalic Dopamine Systems Based on Predictive {{Hebbian}} Learning},
  author = {Montague, P. R. and Dayan, P. and Sejnowski, T. J.},
  year = {1996},
  month = mar,
  volume = {16},
  pages = {1936--1947},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.16-05-01936.1996},
  abstract = {We develop a theoretical framework that shows how mesencephalic dopamine systems could distribute to their targets a signal that represents information about future expectations. In particular, we show how activity in the cerebral cortex can make predictions about future receipt of reward and how fluctuations in the activity levels of neurons in diffuse dopamine systems above and below baseline levels would represent errors in these predictions that are delivered to cortical and subcortical targets. We present a model for how such errors could be constructed in a real brain that is consistent with physiological results for a subset of dopaminergic neurons located in the ventral tegmental area and surrounding dopaminergic neurons. The theory also makes testable predictions about human choice behavior on a simple decision-making task. Furthermore, we show that, through a simple influence on synaptic plasticity, fluctuations in dopamine release can act to change the predictions in an appropriate manner.},
  copyright = {\textcopyright{} 1996 by Society for Neuroscience},
  journal = {Journal of Neuroscience},
  language = {en},
  number = {5},
  pmid = {8774460}
}

@article{Moran_Neural_2013,
  title = {Neural Masses and Fields in Dynamic Causal Modeling},
  author = {Moran, Rosalyn and Pinotsis, Dimitris A. and Friston, Karl},
  year = {2013},
  month = may,
  volume = {7},
  issn = {1662-5188},
  doi = {10.3389/fncom.2013.00057},
  abstract = {Dynamic causal modeling (DCM) provides a framework for the analysis of effective connectivity among neuronal subpopulations that subtend invasive (electrocorticograms and local field potentials) and non-invasive (electroencephalography and magnetoencephalography) electrophysiological responses. This paper reviews the suite of neuronal population models including neural masses, fields and conductance-based models that are used in DCM. These models are expressed in terms of sets of differential equations that allow one to model the synaptic underpinnings of connectivity. We describe early developments using neural mass models, where convolution-based dynamics are used to generate responses in laminar-specific populations of excitatory and inhibitory cells. We show that these models, though resting on only two simple transforms, can recapitulate the characteristics of both evoked and spectral responses observed empirically. Using an identical neuronal architecture, we show that a set of conductance based models\textemdash that consider the dynamics of specific ion-channels\textemdash present a richer space of responses; owing to non-linear interactions between conductances and membrane potentials. We propose that conductance-based models may be more appropriate when spectra present with multiple resonances. Finally, we outline a third class of models, where each neuronal subpopulation is treated as a field; in other words, as a manifold on the cortical surface. By explicitly accounting for the spatial propagation of cortical activity through partial differential equations (PDEs), we show that the topology of connectivity\textemdash through local lateral interactions among cortical layers\textemdash may be inferred, even in the absence of spatially resolved data. We also show that these models allow for a detailed analysis of structure\textendash function relationships in the cortex. Our review highlights the relationship among these models and how the hypothesis asked of empirical data suggests an appropriate model class.},
  journal = {Frontiers in Computational Neuroscience},
  pmcid = {PMC3664834},
  pmid = {23755005}
}

@article{Muezzinoglu_ChemosensorDriven_2008,
  title = {Chemosensor-{{Driven Artificial Antennal Lobe Transient Dynamics Enable Fast Recognition}} and {{Working Memory}}},
  author = {Muezzinoglu, Mehmet K. and Huerta, Ramon and Abarbanel, Henry D. I. and Ryan, Margaret A. and Rabinovich, Mikhail I.},
  year = {2008},
  month = nov,
  volume = {21},
  pages = {1018--1037},
  issn = {0899-7667},
  doi = {10.1162/neco.2008.05-08-780},
  abstract = {The speed and accuracy of odor recognition in insects can hardly be resolved by the raw descriptors provided by olfactory receptors alone due to their slow time constant and high variability. The animal overcomes these barriers by means of the antennal lobe (AL) dynamics, which consolidates the classificatory information in receptor signal with a spatiotemporal code that is enriched in odor sensitivity, particularly in its transient. Inspired by this fact, we propose an easily implementable AL-like network and show that it significantly expedites and enhances the identification of odors from slow and noisy artificial polymer sensor responses. The device owes its efficiency to two intrinsic mechanisms: inhibition (which triggers a competition) and integration (due to the dynamical nature of the network). The former functions as a sharpening filter extracting the features of receptor signal that favor odor separation, whereas the latter implements a working memory by accumulating the extracted features in trajectories. This cooperation boosts the odor specificity during the receptor transient, which is essential for fast odor recognition.},
  journal = {Neural Computation},
  number = {4}
}

@article{Muraven_Mechanisms_2003,
  title = {Mechanisms of {{Self}}-{{Control Failure}}: {{Motivation}} and {{Limited Resources}}                                                    ,                                                             {{Mechanisms}} of {{Self}}-{{Control Failure}}: {{Motivation}} and {{Limited Resources}}},
  shorttitle = {Mechanisms of {{Self}}-{{Control Failure}}},
  author = {Muraven, Mark and Slessareva, Elisaveta},
  year = {2003},
  month = jul,
  volume = {29},
  pages = {894--906},
  issn = {0146-1672},
  doi = {10.1177/0146167203029007008},
  abstract = {Research has found that individuals who are lower in self-control strength because of previous self-control exertions perform more poorly on subsequent tests of self-control. The present studies suggest that this effect may be moderated by motivation. In particular, depletion and motivation jointly determine self-control performance. Individuals who were depleted and believed that the task would help others (Experiment 1) or believed that their efforts could benefit them (Experiment 2) performed better on a subsequent test of self-control than individuals who were depleted and lower in motivation. The results of Experiment 3 replicated these findings and suggested that depletion only affects performance on tasks that require self-control; tasks that are difficult but do not require self-control are immune to the effects of depletion. Hence, depleted individuals may compensate for their lack of self-control resources when sufficiently motivated. The results may help explain the nature of self-control strength., Research has found that individuals who are lower in self-control strength because of previous self-control exertions perform more poorly on subsequent tests of self-control. The present studies suggest that this effect may be moderated by motivation. In particular, depletion and motivation jointly determine self-control performance. Individuals who were depleted and believed that the task would help others (Experiment 1) or believed that their efforts could benefit them (Experiment 2) performed better on a subsequent test of self-control than individuals who were depleted and lower in motivation. The results of Experiment 3 replicated these findings and suggested that depletion only affects performance on tasks that require self-control; tasks that are difficult but do not require self-control are immune to the effects of depletion. Hence, depleted individuals may compensate for their lack of self-control resources when sufficiently motivated. The results may help explain the nature of self-control strength.},
  journal = {Personality and Social Psychology Bulletin},
  language = {en},
  number = {7}
}

@article{Murlis_Odor_1992,
  title = {Odor {{Plumes}} and {{How Insects Use Them}}},
  author = {Murlis, J and Elkinton, J S and Card{\'e}, R T},
  year = {1992},
  volume = {37},
  pages = {505--532},
  doi = {10.1146/annurev.en.37.010192.002445},
  journal = {Annual Review of Entomology},
  number = {1}
}

@book{Murphy_Machine_2012,
  title = {Machine {{Learning}}: {{A Probabilistic Perspective}}},
  author = {Murphy, Kevin P.},
  year = {2012},
  publisher = {{MIT Press}},
  abstract = {My book (MLaPP) is similar to Bishop's Pattern recognition and machine learning, Hastie et al's The Elements of Statistical Learning, and to Wasserman's All of statistics, with the following key differences: MLaPP is more accessible to undergrads. It pre-supposes a background in probability, linear algebra, calculus, and programming; however, the mathematical level ramps up slowly, with more difficult sections clearly denoted as such. This makes the book suitable for both undergrads and grads. Summaries of the relevant mathematical background, on topics such as linear algebra, optimization and classical statistics make the book self-contained. MLaPP is more practically-oriented. In particular, it comes with Matlab software to reproduce almost every figure, and to implement almost every algorithm, discussed in the book. It includes many worked examples of the methods applied to real data, with readable source code online. MLaPP covers various important topics that are not discussed in these other books, such as conditional random fields, deep learning, etc. MLaPP is "more Bayesian" than the Hastie or Wasserman books, but "more frequentist" than the Bishop book. In particular, in MLaPP, we make extensive use of MAP estimation, which we regard as "poor man's Bayes". We prefer this to the regularization interpretation of MAP, because then all the methods in the book (except cross validation...) can be viewed as probabilistic inference, or some approximation thereof. The MAP interpretation also allows for an easy "upgrade path" to more accurate methods of approximate Bayesian inference, such as empirical Bayes, variational Bayes, MCMC, SMC, etc. The emphasis is on simple parametric models (linear and logistic regression, discriminant analysis/ naive Bayes, mixture models, factor analysis, graphical models, etc.), which are the ones most often used in practice. However, we also briefly discuss non-parametric models, such as Gaussian processes, Dirichlet processes, SVMs, RVMs, etc.},
  series = {Adaptive {{Computation}} and {{Machine Learning}}}
}

@article{Murray_hierarchy_2014,
  title = {A Hierarchy of Intrinsic Timescales across Primate Cortex},
  author = {Murray, John D. and Bernacchia, Alberto and Freedman, David J. and Romo, Ranulfo and Wallis, Jonathan D. and Cai, Xinying and {Padoa-Schioppa}, Camillo and Pasternak, Tatiana and Seo, Hyojung and Lee, Daeyeol and Wang, Xiao-Jing},
  year = {2014},
  month = dec,
  volume = {17},
  pages = {1661--1663},
  issn = {1546-1726},
  doi = {10.1038/nn.3862},
  abstract = {Primate cortex can be organized with specialization and hierarchical principles, but presently there is little evidence for how it is organized temporally. Across six separate datasets, the authors find a hierarchical ordering of intrinsic fluctuation of spiking activity, with timescales that increase from sensory to prefrontal areas.},
  copyright = {2014 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  journal = {Nature Neuroscience},
  language = {en},
  number = {12}
}

@article{Myerson_Area_2001,
  title = {Area under the Curve as a Measure of Discounting.},
  author = {Myerson, J and Green, L and Warusawitharana, M},
  year = {2001},
  month = sep,
  volume = {76},
  pages = {235--243},
  issn = {0022-5002},
  doi = {10.1901/jeab.2001.76-235},
  abstract = {We describe a novel approach to the measurement of discounting based on calculating the area under the empirical discounting function. This approach avoids some of the problems associated with measures based on estimates of the parameters of theoretical discounting functions. The area measure may be easily calculated for both individual and group data collected using any of a variety of current delay and probability discounting procedures. The present approach is not intended as a substitute for theoretical discounting models. It is useful, however, to have a simple, univariate measure of discounting that is not tied to any specific theoretical framework.},
  journal = {Journal of the Experimental Analysis of Behavior},
  number = {2},
  pmcid = {PMC1284836},
  pmid = {11599641}
}

@article{Myerson_Discounting_2003,
  title = {Discounting Delayed and Probabilistic Rewards: {{Processes}} and Traits},
  shorttitle = {Discounting Delayed and Probabilistic Rewards},
  author = {Myerson, Joel and Green, Leonard and Scott Hanson, J and Holt, Daniel D and Estle, Sara J},
  year = {2003},
  month = oct,
  volume = {24},
  pages = {619--635},
  issn = {0167-4870},
  doi = {10.1016/S0167-4870(03)00005-9},
  abstract = {Discounting of delayed and probabilistic rewards was examined in two relatively large samples (Ns\&gt;100). For both types of rewards, a hyperbola-like discounting function provided good fits to individual data. Amount of reward had opposite effects on temporal and probability discounting: Smaller delayed rewards were discounted more steeply than larger delayed rewards, whereas larger probabilistic rewards were discounted more steeply than smaller probabilistic rewards. The nonlinear scaling parameter of the hyperbola-like function was larger for larger probabilistic rewards, but did not vary with the amount of delayed reward. Taken together, these findings suggest that despite the similar form of the temporal and probability discounting functions, separate processes may underlie the discounting of delayed and probabilistic rewards. Finally, weak to moderate positive correlations were observed between the discounting of delayed and probabilistic rewards. This finding is inconsistent with the notion of an ``impulsiveness'' trait that links an inability to delay gratification with a tendency to gamble and take risks.},
  journal = {Journal of Economic Psychology},
  keywords = {Choice Behavior,Delay of gratification,Discounting,effort,Impulsiveness,Risky choice},
  number = {5},
  series = {The Behavior Analysis of Consumer Choice}
}

@article{Nakahara_Dopamine_2004,
  title = {Dopamine {{Neurons Can Represent Context}}-{{Dependent Prediction Error}}},
  author = {Nakahara, H. and Itoh, H. and Kawagoe, R. and Takikawa, Y. and Hikosaka, O.},
  year = {2004},
  volume = {41},
  pages = {269--280},
  doi = {10.1016/S0896-6273(03)00869-9},
  abstract = {Midbrain dopamine (DA) neurons are thought to encode reward prediction error. Reward prediction can be improved if any relevant context is taken into account. We found that monkey DA neurons can encode a context-dependent prediction error. In the first noncontextual task, a light stimulus was randomly followed by reward, with a fixed equal probability. The response of DA neurons was positively correlated with the number of preceding unrewarded trials and could be simulated by a conventional temporal difference (TD) model. In the second contextual task, a reward-indicating light stimulus was presented with the probability that, while fixed overall, was incremented as a function of the number of preceding unrewarded trials. The DA neuronal response then was negatively correlated with this number. This history effect corresponded to the prediction error based on the conditional probability of reward and could be simulated only by implementing the relevant context into the TD model.},
  journal = {Neuron},
  number = {2}
}

@article{Nakahara_Dopamine_2004a,
  title = {Dopamine {{Neurons Can Represent Context}}-{{Dependent Prediction Error}}},
  author = {Nakahara, Hiroyuki and Itoh, Hideaki and Kawagoe, Reiko and Takikawa, Yoriko and Hikosaka, Okihide},
  year = {2004},
  month = jan,
  volume = {41},
  pages = {269--280},
  issn = {0896-6273},
  doi = {10.1016/S0896-6273(03)00869-9},
  abstract = {Midbrain dopamine (DA) neurons are thought to encode reward prediction error. Reward prediction can be improved if any relevant context is taken into account. We found that monkey DA neurons can encode a context-dependent prediction error. In the first noncontextual task, a light stimulus was randomly followed by reward, with a fixed equal probability. The response of DA neurons was positively correlated with the number of preceding unrewarded trials and could be simulated by a conventional temporal difference (TD) model. In the second contextual task, a reward-indicating light stimulus was presented with the probability that, while fixed overall, was incremented as a function of the number of preceding unrewarded trials. The DA neuronal response then was negatively correlated with this number. This history effect corresponded to the prediction error based on the conditional probability of reward and could be simulated only by implementing the relevant context into the TD model.},
  journal = {Neuron},
  number = {2}
}

@article{Nakahara_Learning_2012,
  title = {Learning to Represent Reward Structure: {{A}} Key to Adapting to Complex Environments},
  shorttitle = {Learning to Represent Reward Structure},
  author = {Nakahara, Hiroyuki and Hikosaka, Okihide},
  year = {2012},
  month = dec,
  volume = {74},
  pages = {177--183},
  issn = {0168-0102},
  doi = {10.1016/j.neures.2012.09.007},
  abstract = {Predicting outcomes is a critical ability of humans and animals. The dopamine reward prediction error hypothesis, the driving force behind the recent progress in neural ``value-based'' decision making, states that dopamine activity encodes the signals for learning in order to predict a reward, that is, the difference between the actual and predicted reward, called the reward prediction error. However, this hypothesis and its underlying assumptions limit the prediction and its error as reactively triggered by momentary environmental events. Reviewing the assumptions and some of the latest findings, we suggest that the internal state representation is learned to reflect the environmental reward structure, and we propose a new hypothesis \textendash{} the dopamine reward structural learning hypothesis \textendash{} in which dopamine activity encodes multiplex signals for learning in order to represent reward structure in the internal state, leading to better reward prediction.},
  journal = {Neuroscience Research},
  keywords = {Decision,Dopamine,Reinforcement learning,Reward,Salience,Structure,unread,Value},
  number = {3}
}

@article{Nakao_Distinction_2012,
  title = {Distinction between Externally vs. Internally Guided Decision-Making: Operational Differences, Meta-Analytical Comparisons and Their Theoretical Implications},
  shorttitle = {Distinction between Externally vs. Internally Guided Decision-Making},
  author = {Nakao, Takashi and Ohira, Hideki and Northoff, Georg},
  year = {2012},
  volume = {6},
  pages = {31},
  doi = {10.3389/fnins.2012.00031},
  abstract = {Most experimental studies of decision-making have specifically examined situations in which a single less-predictable correct answer exists (externally guided decision-making under uncertainty). Along with such externally guided decision-making, there are instances of decision-making in which no correct answer based on external circumstances is available for the subject (internally guided decision-making). Such decisions are usually made in the context of moral decision-making as well as in preference judgment, where the answer depends on the subject's own, i.e., internal, preferences rather than on external, i.e., circumstantial, criteria. The neuronal and psychological mechanisms that allow guidance of decisions based on more internally oriented criteria in the absence of external ones remain unclear. This study was undertaken to compare decision-making of these two kinds empirically and theoretically. First, we reviewed studies of decision-making to clarify experimental\textendash operational differences between externally guided and internally guided decision-making. Second, using multi-level kernel density analysis, a whole-brain-based quantitative meta-analysis of neuroimaging studies was performed. Our meta-analysis revealed that the neural network used predominantly for internally guided decision-making differs from that for externally guided decision-making under uncertainty. This result suggests that studying only externally guided decision-making under uncertainty is insufficient to account for decision-making processes in the brain. Finally, based on the review and results of the meta-analysis, we discuss the differences and relations between decision-making of these two types in terms of their operational, neuronal, and theoretical characteristics.},
  journal = {Decision Neuroscience},
  keywords = {Conflict,default-mode network,fMRI,medial prefrontal cortex,moral judgment,preference,resting state,social situation}
}

@article{Nasiry_Advance_2012,
  title = {Advance {{Selling When Consumers Regret}}},
  author = {Nasiry, Javad and Popescu, Ioana},
  year = {2012},
  month = feb,
  volume = {58},
  pages = {1160--1177},
  publisher = {{INFORMS}},
  issn = {0025-1909},
  doi = {10.1287/mnsc.1110.1473},
  abstract = {We characterize the effect of anticipated regret on consumer decisions and on firm profits and policies in an advance selling context where buyers have uncertain valuations. Advance purchases trigger action regret if valuations turn out to be lower than the price paid, whereas delaying purchase may cause inaction regret from missing a discount or facing a stockout. Consumers whom we describe as emotionally rational act strategically in response to the firm's policies and in anticipation of regret. In this context, regret explains two types of behavioral patterns: inertia (delayed purchase) and frenzies (buying early at negative surplus). We show how firms should optimally respond to consumer regret and also characterize a normative regret threshold above which they should not advance sell. Action regret reduces profits as well as the value of advance selling and booking limit policies for price-setting firms; inaction regret has the opposite effects. These effects are diminished by capacity constraints and are reversed for firms facing price pressure in the advance period (owing, e.g., to competition or market heterogeneity). Regret heterogeneity explains premium advance selling for the capacity-constrained firm, which may benefit from larger shares of regretful buyers. Finally, we show how the negative effects of regret on profits can be mitigated by regret-priming marketing campaigns and by offering refunds or options or allowing resales. Our results highlight the importance of assessing the relative strength of regret within and across market segments and of accounting for these factors in pricing and marketing policies.This paper was accepted by Christian Terwiesch, operations management.},
  journal = {Management Science},
  number = {6}
}

@article{Nassar_Approximately_2010,
  title = {An {{Approximately Bayesian Delta}}-{{Rule Model Explains}} the {{Dynamics}} of {{Belief Updating}} in a {{Changing Environment}}},
  author = {Nassar, Matthew R. and Wilson, Robert C. and Heasly, Benjamin and Gold, Joshua I.},
  year = {2010},
  month = sep,
  volume = {30},
  pages = {12366--12378},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.0822-10.2010},
  abstract = {Maintaining appropriate beliefs about variables needed for effective decision making can be difficult in a dynamic environment. One key issue is the amount of influence that unexpected outcomes should have on existing beliefs. In general, outcomes that are unexpected because of a fundamental change in the environment should carry more influence than outcomes that are unexpected because of persistent environmental stochasticity. Here we use a novel task to characterize how well human subjects follow these principles under a range of conditions. We show that the influence of an outcome depends on both the error made in predicting that outcome and the number of similar outcomes experienced previously. We also show that the exact nature of these tendencies varies considerably across subjects. Finally, we show that these patterns of behavior are consistent with a computationally simple reduction of an ideal-observer model. The model adjusts the influence of newly experienced outcomes according to ongoing estimates of uncertainty and the probability of a fundamental change in the process by which outcomes are generated. A prior that quantifies the expected frequency of such environmental changes accounts for individual variability, including a positive relationship between subjective certainty and the degree to which new information influences existing beliefs. The results suggest that the brain adaptively regulates the influence of decision outcomes on existing beliefs using straightforward updating rules that take into account both recent outcomes and prior expectations about higher-order environmental structure.},
  journal = {The Journal of Neuroscience},
  keywords = {change-point},
  language = {en},
  number = {37},
  pmid = {20844132}
}

@article{Natarajan_Encoding_2008,
  title = {Encoding and {{Decoding Spikes}} for {{Dynamic Stimuli}}},
  author = {Natarajan, Rama and Huys, Quentin J. M. and Dayan, Peter and Zemel, Richard S.},
  year = {2008},
  volume = {20},
  pages = {2325--2360},
  doi = {10.1162/neco.2008.01-07-436},
  abstract = {Naturally occurring sensory stimuli are dynamic. In this letter, we consider how spiking neural populations might transmit information about continuous dynamic stimulus variables. The combination of simple encoders and temporal stimulus correlations leads to a code in which information is not readily available to downstream neurons. Here, we explore a complex encoder that is paired with a simple decoder that allows representation and manipulation of the dynamic information in neural systems. The encoder we present takes the form of a biologically plausible recurrent spiking neural network where the output population recodes its inputs to produce spikes that are independently decodeable. We show that this network can be learned in a supervised manner by a simple local learning rule.},
  journal = {Neural Computation},
  number = {9}
}

@article{Nawrot_Dynamics_2012,
  title = {Dynamics of Sensory Processing in the Dual Olfactory Pathway of the Honeybee},
  author = {Nawrot, Martin Paul},
  year = {2012},
  month = may,
  volume = {43},
  pages = {269--291},
  issn = {0044-8435, 1297-9678},
  doi = {10.1007/s13592-012-0131-3},
  abstract = {Insects identify and evaluate behaviorally relevant odorants in complex natural scenes where odor concentrations and mixture composition can change rapidly. This requires fast and reliable information processing in the olfactory system. Here, we review recent experimental findings and theoretical hypotheses on olfactory processing in the honeybee with a focus on its temporal dynamics. Specifically we address odor response characteristics of antennal lobe interneurons and projection neurons, local processing of elemental odors and odor blends, the functional role of the dual olfactory pathway in the honeybee, population coding in uniglomerular projection neurons, and a novel model for sparse and reliable coding in projection neurons and mushroom body Kenyon cells. It is concluded that the olfactory system of the honeybee implements a fast and reliable coding scheme optimized for processing dynamic input within the behaviorally relevant temporal range.},
  journal = {Apidologie},
  keywords = {antennal lobe,Entomology,latency code,Life Sciences; general,odor trace,olfaction,sparse code},
  language = {en},
  number = {3}
}

@article{Nessler_Bayesian_2013,
  title = {Bayesian {{Computation Emerges}} in {{Generic Cortical Microcircuits}} through {{Spike}}-{{Timing}}-{{Dependent Plasticity}}},
  author = {Nessler, Bernhard and Pfeiffer, Michael and Buesing, Lars and Maass, Wolfgang},
  year = {2013},
  month = apr,
  volume = {9},
  pages = {e1003037},
  doi = {10.1371/journal.pcbi.1003037},
  abstract = {Abstract The principles by which networks of neurons compute, and how spike-timing dependent plasticity (STDP) of synaptic weights generates and maintains their computational function, are unknown. Preceding work has shown that soft winner-take-all (WTA) circuits, where pyramidal neurons inhibit each other via interneurons, are a common motif of cortical microcircuits. We show through theoretical analysis and computer simulations that Bayesian computation is induced in these network motifs through STDP in combination with activity-dependent changes in the excitability of neurons. The fundamental components of this emergent Bayesian computation are priors that result from adaptation of neuronal excitability and implicit generative models for hidden causes that are created in the synaptic weights through STDP. In fact, a surprising result is that STDP is able to approximate a powerful principle for fitting such implicit generative models to high-dimensional spike inputs: Expectation Maximization. Our results suggest that the experimentally observed spontaneous activity and trial-to-trial variability of cortical neurons are essential features of their information processing capability, since their functional role is to represent probability distributions rather than static neural codes. Furthermore it suggests networks of Bayesian computation modules as a new model for distributed information processing in the cortex. Author Summary How do neurons learn to extract information from their inputs, and perform meaningful computations? Neurons receive inputs as continuous streams of action potentials or "spikes" that arrive at thousands of synapses. The strength of these synapses - the synaptic weight - undergoes constant modification. It has been demonstrated in numerous experiments that this modification depends on the temporal order of spikes in the pre- and postsynaptic neuron, a rule known as STDP, but it has remained unclear, how this contributes to higher level functions in neural network architectures. In this paper we show that STDP induces in a commonly found connectivity motif in the cortex - a winner-take-all (WTA) network - autonomous, self-organized learning of probabilistic models of the input. The resulting function of the neural circuit is Bayesian computation on the input spike trains. Such unsupervised learning has previously been studied extensively on an abstract, algorithmical level. We show that STDP approximates one of the most powerful learning methods in machine learning, Expectation-Maximization (EM). In a series of computer simulations we demonstrate that this enables STDP in WTA circuits to solve complex learning tasks, reaching a performance level that surpasses previous uses of spiking neural networks.},
  journal = {PLoS Comput Biol},
  number = {4}
}

@article{NguyenTrong_Associating_2013,
  title = {Associating Spontaneous with Evoked Activity in a Neural Mass Model of Visual Cortex},
  author = {Nguyen Trong, Manh and Bojak, Ingo and Kn{\"o}sche, Thomas R.},
  year = {2013},
  month = feb,
  volume = {66},
  pages = {80--87},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2012.10.024},
  abstract = {Spontaneous activity of the brain at rest frequently has been considered a mere backdrop to the salient activity evoked by external stimuli or tasks. However, the resting state of the brain consumes most of its energy budget, which suggests a far more important role. An intriguing hint comes from experimental observations of spontaneous activity patterns, which closely resemble those evoked by visual stimulation with oriented gratings, except that cortex appeared to cycle between different orientation maps. Moreover, patterns similar to those evoked by the behaviorally most relevant horizontal and vertical orientations occurred more often than those corresponding to oblique angles. We hypothesize that this kind of spontaneous activity develops at least to some degree autonomously, providing a dynamical reservoir of cortical states, which are then associated with visual stimuli through learning. To test this hypothesis, we use a biologically inspired neural mass model to simulate a patch of cat visual cortex. Spontaneous transitions between orientation states were induced by modest modifications of the neural connectivity, establishing a stable heteroclinic channel. Significantly, the experimentally observed greater frequency of states representing the behaviorally important horizontal and vertical orientations emerged spontaneously from these simulations. We then applied bar-shaped inputs to the model cortex and used Hebbian learning rules to modify the corresponding synaptic strengths. After unsupervised learning, different bar inputs reliably and exclusively evoked their associated orientation state; whereas in the absence of input, the model cortex resumed its spontaneous cycling. We conclude that the experimentally observed similarities between spontaneous and evoked activity in visual cortex can be explained as the outcome of a learning process that associates external stimuli with a preexisting reservoir of autonomous neural activity states. Our findings hence demonstrate how cortical connectivity can link the maintenance of spontaneous activity in the brain mechanistically to its core cognitive functions.},
  journal = {NeuroImage},
  keywords = {Learning,Neural mass,Spontaneous activity,Stable heteroclinic channels}
}

@article{Nigbur_Theta_2011,
  title = {Theta Power as a Marker for Cognitive Interference},
  author = {Nigbur, Roland and Ivanova, Galina and St{\"u}rmer, Birgit},
  year = {2011},
  month = nov,
  volume = {122},
  pages = {2185--2194},
  issn = {1388-2457},
  doi = {10.1016/j.clinph.2011.03.030},
  abstract = {Objective The present study aimed at investigating whether theta activity within medio-frontal cortex (MFC) serves as a marker for increased cognitive control demands such as performance monitoring. Methods We confronted participants with at least two incompatible sources of information in a Simon task, a flanker task, and a NoGo task to assess whether changes in EEG theta activity correspond to executive control demands across different sources of cognitive interference. Results Overall, increases of theta power were to a different extent observed in all interference situations: (1) differences in theta power were largest between successful response inhibition in NoGo events compared to Go responses, (2) incongruent and congruent events in the flanker task differed to a lesser extent, and (3) differences in theta power were smallest comparing incompatible and compatible Simon events. Scalp-topographies and dipole modeling of theta activity pointed to different sources across interference conditions that encompassed various MFC areas within anterior cingulate cortex and (pre-) supplementary motor areas. Conclusions Our results indicate that theta power amplitude is sensitive to the recruitment of executive control in interference situations, whereas the MFC sources of theta power varied across different interference situations. Significance This study shows for the first time theta power enhancement related to the recruitment of cognitive control across different types of conflicts in the stream of information processing.},
  journal = {Clinical Neurophysiology},
  keywords = {Cognitive control,Conflict,Error-related negativity,Event-related potentials,Medial frontal cortex,N200,Theta},
  number = {11}
}

@article{Niv_Learning_2019,
  title = {Learning Task-State Representations},
  author = {Niv, Yael},
  year = {2019},
  month = oct,
  volume = {22},
  pages = {1544--1553},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-019-0470-8},
  abstract = {When crossing the street, you can ignore the color of oncoming cars, but for hailing a taxi color is important. How do we learn what to represent neurally for each task? Here, Niv summarizes a decade of work on representation learning in the brain.},
  copyright = {2019 The Author(s), under exclusive licence to Springer Nature America, Inc.},
  journal = {Nature Neuroscience},
  language = {en},
  number = {10}
}

@article{OBrien_Differential_2020,
  title = {Differential Focus on Probability and Losses between Young and Older Adults in Risky Decision-Making},
  author = {O'Brien, Erica L. and Hess, Thomas M.},
  year = {2020},
  month = jul,
  volume = {27},
  pages = {532--552},
  publisher = {{Routledge}},
  issn = {1382-5585},
  doi = {10.1080/13825585.2019.1642442},
  abstract = {We examined young and older adults' use of descriptive information about risk (i.e., probability and expected value) in financial decision-making. In Experiment 1, participants chose between lotteries in pairs of bets that offered either two risky gains or one risky gain and one sure gain. Whereas they showed a strong and indiscriminate preference for high-probability gambles in risky-risky pairs, they selected sure options at high rates and risky options at low rates in risky-sure pairs, with slightly stronger effects in older relative to young adults due to age differences in ability. Experiment 2 involved the same task but in terms of losses. Participants, especially older adults, preferred low-probability gambles not accounted for by age differences in ability. Results suggest minimal consideration of expected value and a strong focus on probabilities in decision-making. They also suggest that cognitive ability and chronic goals differentially influence age effects depending on risk context.},
  annotation = {\_eprint: https://doi.org/10.1080/13825585.2019.1642442},
  journal = {Aging, Neuropsychology, and Cognition},
  keywords = {Aging,certainty,expected value,loss aversion,probability},
  number = {4},
  pmid = {31355695}
}

@article{ODoherty_Dissociable_2004,
  title = {Dissociable {{Roles}} of {{Ventral}} and {{Dorsal Striatum}} in {{Instrumental Conditioning}}},
  author = {O'Doherty, John and Dayan, Peter and Schultz, Johannes and Deichmann, Ralf and Friston, Karl and Dolan, Raymond J.},
  year = {2004},
  month = apr,
  volume = {304},
  pages = {452--454},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1094285},
  abstract = {Instrumental conditioning studies how animals and humans choose actions appropriate to the affective structure of an environment. According to recent reinforcement learning models, two distinct components are involved: a ``critic,'' which learns to predict future reward, and an ``actor,'' which maintains information about the rewarding outcomes of actions to enable better ones to be chosen more frequently. We scanned human participants with functional magnetic resonance imaging while they engaged in instrumental conditioning. Our results suggest partly dissociable contributions of the ventral and dorsal striatum, with the former corresponding to the critic and the latter corresponding to the actor. The human brain region that associates an action with a particular reward outcome differs from the one that modifies the behavior in accord with expectation. The human brain region that associates an action with a particular reward outcome differs from the one that modifies the behavior in accord with expectation.},
  copyright = {American Association for the Advancement of Science},
  journal = {Science},
  language = {en},
  number = {5669},
  pmid = {15087550}
}

@article{ODonoghue_Doing_1999,
  title = {Doing {{It Now}} or {{Later}}},
  author = {O'Donoghue, Ted and Rabin, Matthew},
  year = {1999},
  month = mar,
  volume = {89},
  pages = {103--124},
  issn = {0002-8282},
  doi = {10.1257/aer.89.1.103},
  abstract = {The authors examine self-control problems--modeled as time-inconsistent, present-biased preferences--in a model where a person must do an activity exactly once. They emphasize two distinctions: do activities involve immediate costs or immediate rewards, and are people sophisticated or naive about future self-control problems? Naive people procrastinate immediate-cost activities and preproperate--do too soon--immediate-reward activities. Sophistication mitigates procrastination but exacerbates preproperation. Moreover, with immediate costs, a small present bias can severely harm only naive people, whereas with immediate rewards it can severely harm only sophisticated people. Lessons for savings, addiction, and elsewhere are discussed.},
  journal = {American Economic Review},
  keywords = {Intertemporal Consumer Choice,Life Cycle Models and Saving; Consumer Economics: Theory},
  language = {en},
  number = {1}
}

@article{Olsen_Divisive_2010,
  title = {Divisive {{Normalization}} in {{Olfactory Population Codes}}},
  author = {Olsen, Shawn R. and Bhandawat, Vikas and Wilson, Rachel I.},
  year = {2010},
  month = apr,
  volume = {66},
  pages = {287--299},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2010.04.009},
  abstract = {Summary In many regions of the visual system, the activity of a neuron is normalized by the activity of other neurons in the same region. Here we show that a similar normalization occurs during olfactory processing in the Drosophila antennal lobe. We exploit the orderly anatomy of this circuit to independently manipulate feedforward and lateral input to second-order projection neurons (PNs). Lateral inhibition increases the level of feedforward input needed to drive PNs to saturation, and this normalization scales with the total activity of the olfactory receptor neuron (ORN) population. Increasing total ORN activity also makes PN responses more transient. Strikingly, a model with just two variables (feedforward and total ORN activity) accurately predicts PN odor responses. Finally, we show that discrimination by a linear decoder is facilitated by two complementary transformations: the saturating transformation intrinsic to each processing channel boosts weak signals, while normalization helps equalize responses to different stimuli. Video Abstract},
  journal = {Neuron},
  keywords = {SIGNALING,SYSBIO,SYSNEURO},
  number = {2}
}

@article{Olsen_Excitatory_2007,
  title = {Excitatory {{Interactions Between Olfactory Processing Channels}} in the {{Drosophila Antennal Lobe}}},
  author = {Olsen, Shawn R. and Bhandawat, Vikas and Wilson, Rachel I.},
  year = {2007},
  month = apr,
  volume = {54},
  pages = {89--103},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2007.03.010},
  abstract = {Each odorant receptor gene defines a unique type of olfactory receptor neuron (ORN) and a corresponding type of second-order neuron. Because each odor can activate multiple ORN types, information must ultimately be integrated across these processing channels to form a unified percept. Here we show that, in Drosophila, integration begins at the level of second-order projection neurons (PNs). We genetically silence all the ORNs that normally express a particular odorant receptor, and find that PNs postsynaptic to the silent glomerulus receive substantial lateral excitatory input from other glomeruli. Genetically confining odor-evoked ORN input to just one glomerulus reveals that most PNs postsynaptic to other glomeruli receive indirect excitatory input from the single ORN type that is active. Lateral connections between identified glomeruli vary in strength, and this pattern of connections is stereotyped across flies. Thus, a dense network of lateral connections distributes odor-evoked excitation between channels in the first brain region of the olfactory processing stream.},
  journal = {Neuron},
  number = {1},
  pmcid = {PMC2048819},
  pmid = {17408580}
}

@article{Olszanowski_conflict_2015,
  title = {A Conflict Monitoring Account of the Control Mechanisms Involved in Dual-Tasking},
  author = {Olszanowski, Michal and Bajo, Maria Teresa and Szmalec, Arnaud},
  year = {2015},
  month = aug,
  volume = {27},
  pages = {704--714},
  issn = {2044-5911},
  doi = {10.1080/20445911.2015.1022553},
  abstract = {The present study investigates the cognitive mechanism underlying the control of interference during dual-task coordination. Partially inspired by the conflict monitoring hypothesis, we test the assumption that dual-task interference is resolved by a top-down adaptation mechanism that is responsible for behavioural adjustments in the prioritisation of the coordinated tasks. In a series of two experiments, we measured conflict adaptation to the so-called Gratton effect\textemdash the decrease in dual-task interference following incompatible trials. In Experiment 1 the primary task was a low demand choice discrimination task, whereas in Experiment 2 the primary task was an updating task that imposes a continuous load on working memory. The secondary task was a tone discrimination task. Both experiments consistently showed that the response conflict of previous trial triggers top-down behavioural adjustments that reduce interference. We conclude that dual-task interference shows strong similarities to Stroop-like types of cognitive interference, namely in the way that suboptimal performance is dealt with by the cognitive system.},
  journal = {Journal of Cognitive Psychology},
  number = {6}
}

@article{Oppenheimer_Not_2003,
  title = {Not so Fast! (And Not so Frugal!): Rethinking the Recognition Heuristic},
  shorttitle = {Not so Fast! (And Not so Frugal!)},
  author = {Oppenheimer, Daniel M},
  year = {2003},
  month = nov,
  volume = {90},
  pages = {B1-B9},
  issn = {0010-0277},
  doi = {10.1016/S0010-0277(03)00141-0},
  abstract = {The `fast and frugal' approach to reasoning (Gigerenzer, G., \& Todd, P. M. (1999). Simple heuristics that make us smart. New York: Oxford University Press) claims that individuals use non-compensatory strategies in judgment \textendash{} the idea that only one cue is taken into account in reasoning. The simplest and most important of these heuristics postulates that judgment sometimes relies solely on recognition. However, the studies that have investigated usage of the recognition heuristic have confounded recognition with other cues that could also lead to similar judgments. This paper tests whether mere recognition is actually driving the findings in support of the recognition heuristic. Two studies provide evidence that judgments do not conform to the recognition heuristic when these confounds are accounted for. Implications for the study of simple heuristics are discussed.},
  journal = {Cognition},
  keywords = {Fast \& Frugal,Heuristics,Judgment,Recognition heuristic},
  number = {1}
}

@article{Ostaszewski_Effects_1998,
  title = {Effects of Inflation on the Subjective Value of Delayed and Probabilistic Rewards},
  author = {Ostaszewski, Pawel and Green, Leonard and Myerson, Joel},
  year = {1998},
  month = jun,
  volume = {5},
  pages = {324--333},
  issn = {1531-5320},
  doi = {10.3758/BF03212959},
  abstract = {In the years prior to 1994, there were very high rates of inflation in Poland, and the zloty depreciated relative to the U.S. dollar. However, the new zloty, introduced in 1995, was associated with greatly decreased rates of inflation and provided a more stable currency. We report a series of three experiments that take advantage of these changes to examine the effects of inflation on the subjective value of delayed and probabilistic rewards. Subjects were Polish citizens familiar with both zlotys and dollars. The first two experiments, conducted in 1994, used dollars and old zlotys, and the third experiment, conducted in 1996, used dollars and new zlotys. In all three experiments, the dollar and zloty rewards were of equivalent worth, according to the then current exchange rates. In Experiment 1, subjects chose between immediate and delayed rewards and, in Experiment 2, chose between certain and probabilistic rewards. The subjective value of a delayed reward was greater when its amount was specified in dollars than when it was specified in old zlotys. In contrast, the currency in which a reward was specified had no effect on the subjective value of probabilistic rewards. The results of these two experiments suggest a selective effect of inflation on decisions involving delayed rewards. This was verified in the third experiment, in which, using new zlotys, no differences in discounting were observed between the two currencies with either probabilistic or delayed rewards. Importantly, in all three experiments, the discounting of both delayed and probabilistic rewards was well described by the same simple mathematical model, suggesting that similar decision-making processes underlie both phenomena. However, the present results argue against a single-process theory in which the discounting of probabilistic rewards is derived from the discounting of delayed rewards.},
  journal = {Psychonomic Bulletin \& Review},
  keywords = {Discount Function,Future Reward,Inflation Rate,Probabilistic Reward,Temporal Discount},
  language = {en},
  number = {2}
}

@article{Otto_Cognitive_2014,
  title = {Cognitive {{Control Predicts Use}} of {{Model}}-Based {{Reinforcement Learning}}},
  author = {Otto, A. Ross and Skatova, Anya and {Madlon-Kay}, Seth and Daw, Nathaniel D.},
  year = {2014},
  month = aug,
  volume = {27},
  pages = {319--333},
  issn = {0898-929X},
  doi = {10.1162/jocn_a_00709},
  abstract = {Accounts of decision-making and its neural substrates have long posited the operation of separate, competing valuation systems in the control of choice behavior. Recent theoretical and experimental work suggest that this classic distinction between behaviorally and neurally dissociable systems for habitual and goal-directed (or more generally, automatic and controlled) choice may arise from two computational strategies for reinforcement learning (RL), called model-free and model-based RL, but the cognitive or computational processes by which one system may dominate over the other in the control of behavior is a matter of ongoing investigation. To elucidate this question, we leverage the theoretical framework of cognitive control, demonstrating that individual differences in utilization of goal-related contextual information\textemdash in the service of overcoming habitual, stimulus-driven responses\textemdash in established cognitive control paradigms predict model-based behavior in a separate, sequential choice task. The behavioral correspondence between cognitive control and model-based RL compellingly suggests that a common set of processes may underpin the two behaviors. In particular, computational mechanisms originally proposed to underlie controlled behavior may be applicable to understanding the interactions between model-based and model-free choice behavior.},
  journal = {Journal of Cognitive Neuroscience},
  number = {2}
}

@article{Otto_Curse_2013,
  title = {The {{Curse}} of {{Planning}}: {{Dissecting Multiple Reinforcement}}-{{Learning Systems}} by {{Taxing}} the {{Central Executive}}},
  shorttitle = {The {{Curse}} of {{Planning}}},
  author = {Otto, A. Ross and Gershman, Samuel J. and Markman, Arthur B. and Daw, Nathaniel D.},
  year = {2013},
  month = may,
  volume = {24},
  pages = {751--761},
  issn = {0956-7976},
  doi = {10.1177/0956797612463080},
  abstract = {A number of accounts of human and animal behavior posit the operation of parallel and competing valuation systems in the control of choice behavior. In these accounts, a flexible but computationally expensive model-based reinforcement-learning system has been contrasted with a less flexible but more efficient model-free reinforcement-learning system. The factors governing which system controls behavior\textemdash and under what circumstances\textemdash are still unclear. Following the hypothesis that model-based reinforcement learning requires cognitive resources, we demonstrated that having human decision makers perform a demanding secondary task engenders increased reliance on a model-free reinforcement-learning strategy. Further, we showed that, across trials, people negotiate the trade-off between the two systems dynamically as a function of concurrent executive-function demands, and people's choice latencies reflect the computational expenses of the strategy they employ. These results demonstrate that competition between multiple learning systems can be controlled on a trial-by-trial basis by modulating the availability of cognitive resources.},
  journal = {Psychological Science},
  language = {en},
  number = {5}
}

@article{Page_Continuous_1954,
  title = {Continuous {{Inspection Schemes}}},
  author = {Page, E. S.},
  year = {1954},
  volume = {41},
  pages = {100--115},
  issn = {0006-3444},
  doi = {10.2307/2333009},
  journal = {Biometrika},
  number = {1/2}
}

@article{Paine_How_2005,
  title = {How {{Hierarchical Control Self}}-Organizes in {{Artificial Adaptive Systems}}},
  author = {Paine, Rainer W. and Tani, Jun},
  year = {2005},
  month = sep,
  volume = {13},
  pages = {211--225},
  publisher = {{SAGE Publications Ltd STM}},
  issn = {1059-7123},
  doi = {10.1177/105971230501300303},
  abstract = {Diverse, complex, and adaptive animal behaviors are achieved by organizing hierarchically structured controllers in motor systems. The levels of control progress from simple spinal reflexes and central pattern generators through to executive cognitive control in the frontal cortex. Various types of hierarchical control structures have been introduced and shown to be effective in past artificial agent models, but few studies have shown how such structures can self-organize. This study describes how such hierarchical control may evolve in a simple recurrent neural network model implemented in a mobile robot. Topological constraints on information flow are found to improve system performance by decreasing interference between different parts of the network. One part becomes responsible for generating lower behavior primitives while another part evolves top-down sequencing of the primitives for achieving global goals. Fast and slow neuronal response dynamics are automatically generated in specific neurons of the lower and the higher levels, respectively. A hierarchical neural network is shown to outperform a comparable single-level network in controlling a mobile robot.},
  journal = {Adaptive Behavior},
  language = {en},
  number = {3}
}

@article{Pang_SelfControl_2015,
  title = {Self-{{Control Moderates Decision}}-{{Making Behavior When Minimizing Losses}} versus {{Maximizing Gains}}},
  author = {Pang, Bo and Otto, A. Ross and Worthy, Darrell A.},
  year = {2015},
  month = apr,
  volume = {28},
  pages = {176--187},
  issn = {1099-0771},
  doi = {10.1002/bdm.1830},
  abstract = {We examined (1) whether people would be more responsive to the delayed consequences of their decisions when attempting to minimize losses than when attempting to maximize gains in a history-dependent decision-making task and (2) how trait self-control would moderate such an effect. In two experiments, participants performed a dynamic decision-making task where they chose one of two options on each trial. The increasing option always gave a smaller immediate reward but caused future rewards for both options to increase. The decreasing option always gave a larger immediate reward but caused future rewards for both options to decrease. In Experiment 1 where the two options had equivalent expected value in the long run, participants were more prone to select the increasing option, which yielded larger benefits on future trials, in the loss-minimization condition than in the gain-maximization condition. Trait self-control moderated the effect of losses by enhancing the effect for low self-control participants while attenuating it for high self-control participants. In Experiment 2 where selecting the increasing option was suboptimal, low self-control participants still attempted to reduce losses on future trials by selecting the increasing option more often than high self-control participants. These results suggest that decision makers value delayed consequences of their actions more in a losses domain relative to a gains domain and low self-control individuals are more susceptible to such an effect. Copyright \textcopyright{} 2014 John Wiley \& Sons, Ltd.},
  copyright = {Copyright \textcopyright{} 2014 John Wiley \& Sons, Ltd.},
  journal = {Journal of Behavioral Decision Making},
  keywords = {Decision Making,experience-based,Gains,loss aversion,Losses,Self-control},
  language = {en},
  number = {2}
}

@article{Papadopoulou_Normalization_2011,
  title = {Normalization for {{Sparse Encoding}} of {{Odors}} by a {{Wide}}-{{Field Interneuron}}},
  author = {Papadopoulou, Maria and Cassenaer, Stijn and Nowotny, Thomas and Laurent, Gilles},
  year = {2011},
  month = may,
  volume = {332},
  pages = {721--725},
  doi = {10.1126/science.1201835},
  abstract = {Sparse coding presents practical advantages for sensory representations and memory storage. In the insect olfactory system, the representation of general odors is dense in the antennal lobes but sparse in the mushroom bodies, only one synapse downstream. In locusts, this transformation relies on the oscillatory structure of antennal lobe output, feed-forward inhibitory circuits, intrinsic properties of mushroom body neurons, and connectivity between antennal lobe and mushroom bodies. Here we show the existence of a normalizing negative-feedback loop within the mushroom body to maintain sparse output over a wide range of input conditions. This loop consists of an identifiable ``giant'' nonspiking inhibitory interneuron with ubiquitous connectivity and graded release properties.},
  journal = {Science},
  number = {6030}
}

@article{Parr_Neuronal_2019,
  title = {Neuronal Message Passing Using {{Mean}}-Field, {{Bethe}}, and {{Marginal}} Approximations},
  author = {Parr, Thomas and Markovic, Dimitrije and Kiebel, Stefan J. and Friston, Karl J.},
  year = {2019},
  month = feb,
  volume = {9},
  pages = {1889},
  issn = {2045-2322},
  doi = {10.1038/s41598-018-38246-3},
  abstract = {Neuronal computations rely upon local interactions across synapses. For a neuronal network to perform inference, it must integrate information from locally computed messages that are propagated among elements of that network. We review the form of two popular (Bayesian) message passing schemes and consider their plausibility as descriptions of inference in biological networks. These are variational message passing and belief propagation \textendash{} each of which is derived from a free energy functional that relies upon different approximations (mean-field and Bethe respectively). We begin with an overview of these schemes and illustrate the form of the messages required to perform inference using Hidden Markov Models as generative models. Throughout, we use factor graphs to show the form of the generative models and of the messages they entail. We consider how these messages might manifest neuronally and simulate the inferences they perform. While variational message passing offers a simple and neuronally plausible architecture, it falls short of the inferential performance of belief propagation. In contrast, belief propagation allows exact computation of marginal posteriors at the expense of the architectural simplicity of variational message passing. As a compromise between these two extremes, we offer a third approach \textendash{} marginal message passing \textendash{} that features a simple architecture, while approximating the performance of belief propagation. Finally, we link formal considerations to accounts of neurological and psychiatric syndromes in terms of aberrant message passing.},
  copyright = {2019 The Author(s)},
  journal = {Scientific Reports},
  language = {En},
  number = {1}
}

@article{Payzan-LeNestour_Risk_2011,
  title = {Risk, {{Unexpected Uncertainty}}, and {{Estimation Uncertainty}}: {{Bayesian Learning}} in {{Unstable Settings}}},
  shorttitle = {Risk, {{Unexpected Uncertainty}}, and {{Estimation Uncertainty}}},
  author = {{Payzan-LeNestour}, Elise and Bossaerts, Peter},
  year = {2011},
  month = jan,
  volume = {7},
  pages = {e1001048},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1001048},
  abstract = {Author Summary The ability of humans to learn changing reward contingencies implies that they perceive, at a minimum, three levels of uncertainty: risk, which reflects imperfect foresight even after everything is learned; (parameter) estimation uncertainty, i.e., uncertainty about outcome probabilities; and unexpected uncertainty, or sudden changes in the probabilities. We describe how these levels of uncertainty evolve in a natural sampling task in which human choices reliably reflect optimal (Bayesian) learning, and how their evolution changes the learning rate. We then zoom in on estimation uncertainty. The ability to sense estimation uncertainty (also known as ambiguity) is a virtue because, besides allowing one to learn optimally, it may guide more effective exploration; but aversion to estimation uncertainty may be maladaptive. Here, we show that participant choices reflected aversion to estimation uncertainty. We discuss how past imaging studies foreshadowed the ability of humans to distinguish the different notions of uncertainty. Also, we document that the ability of participants to do such distinction relies on sufficient revelation of the payoff-generating model. When we induced structural uncertainty, participants did not gain awareness of the jumps in our task, and fell back to model-free reinforcement learning.},
  journal = {PLOS Comput Biol},
  keywords = {Algorithms,Behavior,Decision Making,Economics,Entropy,Human learning,Learning,Probability distribution},
  number = {1}
}

@article{Pearl_Search_1987,
  title = {Search {{Techniques}}},
  author = {Pearl, Judea and Korf, Richard E.},
  year = {1987},
  volume = {2},
  pages = {451--467},
  doi = {10.1146/annurev.cs.02.060187.002315},
  journal = {Annual Review of Computer Science},
  keywords = {ai,machine learning},
  number = {1}
}

@article{Pearson_Decision_2014,
  title = {Decision {{Making}}: {{The Neuroethological Turn}}},
  shorttitle = {Decision {{Making}}},
  author = {Pearson, John M. and Watson, Karli K. and Platt, Michael L.},
  year = {2014},
  month = jun,
  volume = {82},
  pages = {950--965},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2014.04.037},
  abstract = {Neuroeconomics applies models from economics and psychology to inform neurobiological studies of choice. This approach has revealed neural signatures of concepts like value, risk, and ambiguity, which are known to influence decision making. Such observations have led theorists to hypothesize a single, unified decision process that mediates choice behavior via a common neural currency for outcomes like food, money, or social praise. In parallel, recent neuroethological studies of decision making have focused on natural behaviors like foraging, mate choice, and social interactions. These decisions strongly impact evolutionary fitness and thus are likely to have played a key role in shaping the neural circuits that mediate decision making. This approach has revealed a suite of computational motifs that appear to be shared across a wide variety of organisms. We argue that the existence of deep homologies in the neural circuits mediating choice may have profound implications for understanding human decision making in health and disease.},
  journal = {Neuron},
  number = {5}
}

@article{Pedersen_drift_2017,
  title = {The Drift Diffusion Model as the Choice Rule in Reinforcement Learning},
  author = {Pedersen, Mads Lund and Frank, Michael J. and Biele, Guido},
  year = {2017},
  month = aug,
  volume = {24},
  pages = {1234--1251},
  issn = {1531-5320},
  doi = {10.3758/s13423-016-1199-y},
  abstract = {Current reinforcement-learning models often assume simplified decision processes that do not fully reflect the dynamic complexities of choice processes. Conversely, sequential-sampling models of decision making account for both choice accuracy and response time, but assume that decisions are based on static decision values. To combine these two computational models of decision making and learning, we implemented reinforcement-learning models in which the drift diffusion model describes the choice process, thereby capturing both within- and across-trial dynamics. To exemplify the utility of this approach, we quantitatively fit data from a common reinforcement-learning paradigm using hierarchical Bayesian parameter estimation, and compared model variants to determine whether they could capture the effects of stimulant medication in adult patients with attention-deficit hyperactivity disorder (ADHD). The model with the best relative fit provided a good description of the learning process, choices, and response times. A parameter recovery experiment showed that the hierarchical Bayesian modeling approach enabled accurate estimation of the model parameters. The model approach described here, using simultaneous estimation of reinforcement-learning and drift diffusion model parameters, shows promise for revealing new insights into the cognitive and neural mechanisms of learning and decision making, as well as the alteration of such processes in clinical groups.},
  journal = {Psychonomic Bulletin \& Review},
  language = {en},
  number = {4}
}

@article{Perez-Orive_Intrinsic_2004,
  title = {Intrinsic and {{Circuit Properties Favor Coincidence Detection}} for {{Decoding Oscillatory Input}}},
  author = {{Perez-Orive}, Javier and Bazhenov, Maxim and Laurent, Gilles},
  year = {2004},
  month = jun,
  volume = {24},
  pages = {6037--6047},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.1084-04.2004},
  abstract = {In the insect olfactory system the antennal lobe generates oscillatory synchronization of its output as a framework for coincidence detection by its target, the mushroom body (MB). The intrinsic neurons of the MB (Kenyon cells, KCs) are thus a good model system in which to investigate the functional relevance of oscillations and neural synchronization. We combine electrophysiological and modeling approaches to examine how intrinsic and circuit properties might contribute to the preference of KCs for coincident input and how their decoding of olfactory information is affected by the absence of oscillatory synchronization in their input. We show that voltage-dependent subthreshold properties of KCs bring about a supralinear summation of their inputs, favoring responses to coincident EPSPs. Abolishing oscillatory synchronization weakens the preference of KCs for coincident input and causes a large reduction in their odor specificity. Finally, we find that a decoding strategy that is based on coincidence detection enhances both noise tolerance and input discriminability by KCs.},
  journal = {The Journal of Neuroscience},
  keywords = {coding,coincidence detection,Kenyon cell,mushroom body,oscillations,synchrony},
  language = {en},
  number = {26},
  pmid = {15229251}
}

@article{Perez-Orive_Oscillations_2002,
  title = {Oscillations and Sparsening of Odor Representations in the Mushroom Body},
  author = {{Perez-Orive}, Javier and Mazor, Ofer and Turner, Glenn C and Cassenaer, Stijn and Wilson, Rachel I and Laurent, Gilles},
  year = {2002},
  month = jul,
  volume = {297},
  pages = {359--365},
  issn = {1095-9203},
  doi = {10.1126/science.1070502},
  abstract = {In the insect olfactory system, oscillatory synchronization is functionally relevant and reflects the coherent activation of dynamic neural assemblies. We examined the role of such oscillatory synchronization in information transfer between networks in this system. The antennal lobe is the obligatory relay for olfactory afferent signals and generates oscillatory output. The mushroom body is responsible for formation and retrieval of olfactory and other memories. The format of odor representations differs significantly across these structures. Whereas representations are dense, dynamic, and seemingly redundant in the antennal lobe, they are sparse and carried by more selective neurons in the mushroom body. This transformation relies on a combination of oscillatory dynamics and intrinsic and circuit properties that act together to selectively filter and synthesize the output from the antennal lobe. These results provide direct support for the functional relevance of correlation codes and shed some light on the role of oscillatory synchronization in sensory networks.},
  journal = {Science (New York, N.Y.)},
  keywords = {Action Potentials,Animals,Electric Stimulation,Electrodes,Evoked Potentials,Excitatory Postsynaptic Potentials,Female,gamma-Aminobutyric Acid,Grasshoppers,Interneurons,Male,Mushroom Bodies,Nerve Net,Neural Inhibition,Neurons,Odors,Patch-Clamp Techniques,Picrotoxin,Smell,Synaptic Transmission,Time Factors},
  language = {eng},
  number = {5580},
  pmid = {12130775}
}

@article{PerezDArpino_Fast_2015,
  title = {Fast Target Prediction of Human Reaching Motion for Cooperative Human-Robot Manipulation Tasks Using Time Series Classification},
  author = {Perez D'Arpino, Claudia and Shah, Julie A.},
  year = {2015},
  month = jul,
  publisher = {{Institute of Electrical and Electronics Engineers (IEEE)}},
  issn = {1050-4729},
  abstract = {Interest in human-robot coexistence, in which humans and robots share a common work volume, is increasing in manufacturing environments. Efficient work coordination requires both awareness of the human pose and a plan of action for both human and robot agents in order to compute robot motion trajectories that synchronize naturally with human motion. In this paper, we present a data-driven approach that synthesizes anticipatory knowledge of both human motions and subsequent action steps in order to predict in real-time the intended target of a human performing a reaching motion. Motion-level anticipatory models are constructed using multiple demonstrations of human reaching motions. We produce a library of motions from human demonstrations, based on a statistical representation of the degrees of freedom of the human arm, using time series analysis, wherein each time step is encoded as a multivariate Gaussian distribution. We demonstrate the benefits of this approach through offline statistical analysis of human motion data. The results indicate a considerable improvement over prior techniques in early prediction, achieving 70\% or higher correct classification on average for the first third of the trajectory ({$<$}; 500msec). We also indicate proof-of-concept through the demonstration of a human-robot cooperative manipulation task performed with a PR2 robot. Finally, we analyze the quality of task-level anticipatory knowledge required to improve prediction performance early in the human motion trajectory.},
  annotation = {Accepted: 2017-01-27T17:20:37Z},
  copyright = {Creative Commons Attribution-Noncommercial-Share Alike},
  isbn = {9781479969234},
  journal = {Other repository},
  language = {en\_US}
}

@article{Pessiglione_Why_2018,
  title = {Why Not Try Harder? {{Computational}} Approach to Motivation Deficits in Neuro-Psychiatric Diseases},
  shorttitle = {Why Not Try Harder?},
  author = {Pessiglione, Mathias and Vinckier, Fabien and Bouret, S{\'e}bastien and Daunizeau, Jean and Le Bouc, Rapha{\"e}l},
  year = {2018},
  month = mar,
  volume = {141},
  pages = {629--650},
  issn = {0006-8950},
  doi = {10.1093/brain/awx278},
  abstract = {Motivational deficits are pervasive in psychiatric and neurological disorders but their assessment and treatment remain inadequate. Pessiglione et al. present a},
  journal = {Brain},
  language = {en},
  number = {3}
}

@article{Pessoa_relationship_2008,
  title = {On the Relationship between Emotion and Cognition},
  author = {Pessoa, Luiz},
  year = {2008},
  month = feb,
  volume = {9},
  pages = {148--158},
  issn = {1471-003X},
  doi = {10.1038/nrn2317},
  abstract = {The current view of brain organization supports the notion that there is a considerable degree of functional specialization and that many regions can be conceptualized as either 'affective' or 'cognitive'. Popular examples are the amygdala in the domain of emotion and the lateral prefrontal cortex in the case of cognition. This prevalent view is problematic for a number of reasons. Here, I will argue that complex cognitive\textendash emotional behaviours have their basis in dynamic coalitions of networks of brain areas, none of which should be conceptualized as specifically affective or cognitive. Central to cognitive\textendash emotional interactions are brain areas with a high degree of connectivity, called hubs, which are critical for regulating the flow and integration of information between regions.},
  copyright = {\textcopyright{} 2008 Nature Publishing Group},
  journal = {Nature Reviews Neuroscience},
  language = {en},
  number = {2}
}

@article{Pezzulo_Active_2015,
  title = {Active {{Inference}}, Homeostatic Regulation and Adaptive Behavioural Control},
  author = {Pezzulo, Giovanni and Rigoli, Francesco and Friston, Karl},
  year = {2015},
  month = nov,
  volume = {134},
  pages = {17--35},
  issn = {0301-0082},
  doi = {10.1016/j.pneurobio.2015.09.001},
  abstract = {We review a theory of homeostatic regulation and adaptive behavioural control within the Active Inference framework. Our aim is to connect two research streams that are usually considered independently; namely, Active Inference and associative learning theories of animal behaviour. The former uses a probabilistic (Bayesian) formulation of perception and action, while the latter calls on multiple (Pavlovian, habitual, goal-directed) processes for homeostatic and behavioural control. We offer a synthesis these classical processes and cast them as successive hierarchical contextualisations of sensorimotor constructs, using the generative models that underpin Active Inference. This dissolves any apparent mechanistic distinction between the optimization processes that mediate classical control or learning. Furthermore, we generalize the scope of Active Inference by emphasizing interoceptive inference and homeostatic regulation. The ensuing homeostatic (or allostatic) perspective provides an intuitive explanation for how priors act as drives or goals to enslave action, and emphasises the embodied nature of inference.},
  journal = {Progress in Neurobiology},
  keywords = {active inference,Adaptive control,Homeostatic regulation,Model-based control,Model-free control,Pavlovian control}
}

@article{Pezzulo_Active_2016,
  title = {Active {{Inference}}, Epistemic Value, and Vicarious Trial and Error},
  author = {Pezzulo, Giovanni and Cartoni, Emilio and Rigoli, Francesco and {Pio-Lopez}, L{\'e}o and Friston, Karl},
  year = {2016},
  month = jul,
  volume = {23},
  pages = {322--338},
  issn = {1072-0502, 1549-5485},
  doi = {10.1101/lm.041780.116},
  abstract = {Balancing habitual and deliberate forms of choice entails a comparison of their respective merits\textemdash the former being faster but inflexible, and the latter slower but more versatile. Here, we show that arbitration between these two forms of control can be derived from first principles within an Active Inference scheme. We illustrate our arguments with simulations that reproduce rodent spatial decisions in T-mazes. In this context, deliberation has been associated with vicarious trial and error (VTE) behavior (i.e., the fact that rodents sometimes stop at decision points as if deliberating between choice alternatives), whose neurophysiological correlates are ``forward sweeps'' of hippocampal place cells in the arms of the maze under consideration. Crucially, forward sweeps arise early in learning and disappear shortly after, marking a transition from deliberative to habitual choice. Our simulations show that this transition emerges as the optimal solution to the trade-off between policies that maximize reward or extrinsic value (habitual policies) and those that also consider the epistemic value of exploratory behavior (deliberative or epistemic policies)\textemdash the latter requiring VTE and the retrieval of episodic information via forward sweeps. We thus offer a novel perspective on the optimality principles that engender forward sweeps and VTE, and on their role on deliberate choice.},
  journal = {Learning \& Memory},
  language = {en},
  number = {7},
  pmid = {27317193}
}

@article{Phillips_Calculating_2007,
  title = {Calculating Utility: Preclinical Evidence for Cost\textendash Benefit Analysis by Mesolimbic Dopamine},
  shorttitle = {Calculating Utility},
  author = {Phillips, Paul E. M. and Walton, Mark E. and Jhou, Thomas C.},
  year = {2007},
  month = apr,
  volume = {191},
  pages = {483--495},
  issn = {1432-2072},
  doi = {10.1007/s00213-006-0626-6},
  abstract = {RationaleThroughout our lives we constantly assess the costs and benefits of the possible future outcomes of our actions and use this information to guide behavior. There is accumulating evidence that dopamine contributes to a fundamental component of this computation\textemdash how rewards are compared with the costs incurred when obtaining them.ObjectiveWe review the evidence for dopamine's role in cost\textendash benefit decision making and outline a simple mathematical framework in which to represent the interactions between rewards, costs, behavioral state and dopamine.ConclusionsDopamine's effects on cost\textendash benefit decision making can be modeled using simple utility\textendash function curves. This approach provides a useful framework for modeling existing data and generating experimental hypotheses that can be objectively and quantitatively tested by observing choice behavior without the necessity to account for subjective psychological states such as pleasure or desire. We suggest that dopamine plays a key role in overcoming response costs and enabling high-effort behaviors. A particularly important anatomical site of this action is the core of the nucleus accumbens. Here, dopamine is able to modulate activity originating from the frontal cortical systems that also assess costs and rewards. Internal deprivation states (e.g., hunger and thirst) also help to energize goal-seeking behaviors, probably in part by their rich influence on dopamine, which can in turn modify decision making policies.},
  journal = {Psychopharmacology},
  keywords = {Accumbens,Decision,Dopamine,Neuroeconomics,Prefrontal cortex,VTA},
  language = {en},
  number = {3}
}

@article{Pietras_Risksensitive_2001,
  title = {Risk-Sensitive Choice in Humans as a Function of an Earnings Budget.},
  author = {Pietras, C J and Hackenberc, T D},
  year = {2001},
  month = jul,
  volume = {76},
  pages = {1--19},
  issn = {0022-5002},
  doi = {10.1901/jeab.2001.76-1},
  abstract = {Risky choice in 3 adult humans was investigated across procedural manipulations designed to model energy-budget manipulations conducted with nonhumans. Subjects were presented with repeated choices between a fixed and a variable number of points. An energy budget was simulated by use of an earnings budget, defined as the number of points needed within a block of trials for points to be exchanged for money. During positive earnings-budget conditions, exclusive preference for the fixed option met the earnings requirement. During negative earnings-budget conditions, exclusive preference for the certain option did not meet the earnings requirement, but choice for the variable option met the requirement probabilistically. Choice was generally risk averse (the fixed option was preferred) when the earnings budget was positive and risk prone (the variable option was preferred) when the earnings budget was negative. Furthermore, choice was most risk prone during negative earnings-budget conditions in which the earnings requirement was most stringent. Local choice patterns were also frequently consistent with the predictions of a dynamic optimization model, indicating that choice was simultaneously sensitive to short-term choice contingencies, current point earnings, and the earnings requirement. Overall, these results show that the patterns of risky choice generated by energy-budget variables can also be produced by choice contingencies that do not involve immediate survival, and that risky choice in humans may be similar to that shown in nonhumans when choice is studied under analogous experimental conditions.},
  journal = {Journal of the Experimental Analysis of Behavior},
  number = {1},
  pmcid = {PMC1285017},
  pmid = {11516113}
}

@article{Pio-Lopez_Active_2016,
  title = {Active Inference and Robot Control: A Case Study},
  shorttitle = {Active Inference and Robot Control},
  author = {{Pio-Lopez}, L{\'e}o and Nizard, Ange and Friston, Karl and Pezzulo, Giovanni},
  year = {2016},
  month = sep,
  volume = {13},
  pages = {20160616},
  issn = {1742-5689, 1742-5662},
  doi = {10.1098/rsif.2016.0616},
  abstract = {Active inference is a general framework for perception and action that is gaining prominence in computational and systems neuroscience but is less known outside these fields. Here, we discuss a proof-of-principle implementation of the active inference scheme for the control or the 7-DoF arm of a (simulated) PR2 robot. By manipulating visual and proprioceptive noise levels, we show under which conditions robot control under the active inference scheme is accurate. Besides accurate control, our analysis of the internal system dynamics (e.g. the dynamics of the hidden states that are inferred during the inference) sheds light on key aspects of the framework such as the quintessentially multimodal nature of control and the differential roles of proprioception and vision. In the discussion, we consider the potential importance of being able to implement active inference in robots. In particular, we briefly review the opportunities for modelling psychophysiological phenomena such as sensory attenuation and related failures of gain control, of the sort seen in Parkinson's disease. We also consider the fundamental difference between active inference and optimal control formulations, showing that in the former the heavy lifting shifts from solving a dynamical inverse problem to creating deep forward or generative models with dynamics, whose attracting sets prescribe desired behaviours.},
  copyright = {\textcopyright{} 2016 The Authors.. Published by the Royal Society under the terms of the Creative Commons Attribution License http://creativecommons.org/licenses/by/4.0/, which permits unrestricted use, provided the original author and source are credited.},
  journal = {Journal of The Royal Society Interface},
  language = {en},
  number = {122},
  pmid = {27683002}
}

@article{Platt_Risky_2008,
  title = {Risky Business: The Neuroeconomics of Decision Making under Uncertainty},
  shorttitle = {Risky Business},
  author = {Platt, Michael L. and Huettel, Scott A.},
  year = {2008},
  month = apr,
  volume = {11},
  pages = {398--403},
  issn = {1097-6256},
  doi = {10.1038/nn2062},
  abstract = {Many decisions involve uncertainty, or imperfect knowledge about how choices lead to outcomes. Colloquial notions of uncertainty, particularly when describing a decision as 'risky', often carry connotations of potential danger as well. Gambling on a long shot, whether a horse at the racetrack or a foreign oil company in a hedge fund, can have negative consequences, but the impact of uncertainty on decision making extends beyond gambling. Indeed, uncertainty in some form pervades nearly all our choices in daily life. Stepping into traffic to hail a cab, braving an ice storm to be the first at work, or dating the boss's son or daughter also offer potentially great windfalls, at the expense of surety. We continually face trade-offs between options that promise safety and others that offer an uncertain potential for jackpot or bust. When mechanisms for dealing with uncertain outcomes fail, as in mental disorders such as problem gambling or addiction, the results can be disastrous. Thus, understanding decision making\textemdash indeed, understanding behavior itself\textemdash requires knowing how the brain responds to and uses information about uncertainty.},
  copyright = {\textcopyright{} 2008 Nature Publishing Group},
  journal = {Nature Neuroscience},
  language = {en},
  number = {4}
}

@article{Ponzi_Sequentially_2010,
  title = {Sequentially {{Switching Cell Assemblies}} in {{Random Inhibitory Networks}} of {{Spiking Neurons}} in the {{Striatum}}},
  author = {Ponzi, Adam and Wickens, Jeff},
  year = {2010},
  month = apr,
  volume = {30},
  pages = {5894--5911},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.5540-09.2010},
  abstract = {The striatum is composed of GABAergic medium spiny neurons with inhibitory collaterals forming a sparse random asymmetric network and receiving an excitatory glutamatergic cortical projection. Because the inhibitory collaterals are sparse and weak, their role in striatal network dynamics is puzzling. However, here we show by simulation of a striatal inhibitory network model composed of spiking neurons that cells form assemblies that fire in sequential coherent episodes and display complex identity\textendash temporal spiking patterns even when cortical excitation is simply constant or fluctuating noisily. Strongly correlated large-scale firing rate fluctuations on slow behaviorally relevant timescales of hundreds of milliseconds are shown by members of the same assembly whereas members of different assemblies show strong negative correlation, and we show how randomly connected spiking networks can generate this activity. Cells display highly irregular spiking with high coefficients of variation, broadly distributed low firing rates, and interspike interval distributions that are consistent with exponentially tailed power laws. Although firing rates vary coherently on slow timescales, precise spiking synchronization is absent in general. Our model only requires the minimal but striatally realistic assumptions of sparse to intermediate random connectivity, weak inhibitory synapses, and sufficient cortical excitation so that some cells are depolarized above the firing threshold during up states. Our results are in good qualitative agreement with experimental studies, consistent with recently determined striatal anatomy and physiology, and support a new view of endogenously generated metastable state switching dynamics of the striatal network underlying its information processing operations.},
  journal = {The Journal of Neuroscience},
  language = {en},
  number = {17},
  pmid = {20427650}
}

@article{Pouget_Inference_2003,
  title = {Inference and Computation with Population Codes.},
  author = {Pouget, Alexandre and Dayan, Peter and Zemel, Richard S.},
  year = {2003},
  volume = {26},
  pages = {381--410},
  doi = {10.1146/annurev.neuro.26.041002.131112},
  abstract = {In the vertebrate nervous system, sensory stimuli are typically encoded through the concerted activity of large populations of neurons. Classically, these patterns of activity have been treated as encoding the value of the stimulus (e.g., the orientation of a contour), and computation has been formalized in terms of function approximation. More recently, there have been several suggestions that neural computation is akin to a Bayesian inference process, with population activity patterns representing uncertainty about stimuli in the form of probability distributions (e.g., the probability density function over the orientation of a contour). This paper reviews both approaches, with a particular emphasis on the latter, which we see as a very promising framework for future modeling and experimental work.},
  journal = {Annu Rev Neurosci},
  keywords = {Animals,Bayes Theorem,classification/physiology,Humans,Models,Motivation,Nerve Net,Nervous System Physiological Phenomena,Neural Networks (Computer),Neurological,Neurons,Orientation,Psychophysics},
  language = {eng},
  pmid = {12704222}
}

@article{Pouget_Probabilistic_2013,
  title = {Probabilistic Brains: Knowns and Unknowns},
  shorttitle = {Probabilistic Brains},
  author = {Pouget, Alexandre and Beck, Jeffrey M. and Ma, Wei Ji and Latham, Peter E.},
  year = {2013},
  month = sep,
  volume = {16},
  pages = {1170--1178},
  issn = {1097-6256},
  doi = {10.1038/nn.3495},
  abstract = {There is strong behavioral and physiological evidence that the brain both represents probability distributions and performs probabilistic inference. Computational neuroscientists have started to shed light on how these probabilistic representations and computations might be implemented in neural circuits. One particularly appealing aspect of these theories is their generality: they can be used to model a wide range of tasks, from sensory processing to high-level cognition. To date, however, these theories have only been applied to very simple tasks. Here we discuss the challenges that will emerge as researchers start focusing their efforts on real-life computations, with a focus on probabilistic learning, structural learning and approximate inference.},
  copyright = {\textcopyright{} 2013 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  journal = {Nature Neuroscience},
  language = {en},
  number = {9}
}

@article{Premack_Does_1978,
  title = {Does the Chimpanzee Have a Theory of Mind?},
  author = {Premack, David and Woodruff, Guy},
  year = {1978},
  month = dec,
  volume = {1},
  pages = {515--526},
  publisher = {{Cambridge University Press}},
  issn = {1469-1825, 0140-525X},
  doi = {10.1017/S0140525X00076512},
  abstract = {An individual has a theory of mind if he imputes mental states to himself and others. A system of inferences of this kind is properly viewed as a theory because such states are not directly observable, and the system can be used to make predictions about the behavior of others. As to the mental states the chimpanzee may infer, consider those inferred by our own species, for example, purpose or intention, as well as knowledge, belief, thinking, doubt, guessing, pretending, liking, and so forth. To determine whether or not the chimpanzee infers states of this kind, we showed an adult chimpanzee a series of videotaped scenes of a human actor struggling with a variety of problems. Some problems were simple, involving inaccessible food \textendash{} bananas vertically or horizontally out of reach, behind a box, and so forth \textendash{} as in the original Kohler problems; others were more complex, involving an actor unable to extricate himself from a locked cage, shivering because of a malfunctioning heater, or unable to play a phonograph because it was unplugged. With each videotape the chimpanzee was given several photographs, one a solution to the problem, such as a stick for the inaccessible bananas, a key for the locked up actor, a lit wick for the malfunctioning heater. The chimpanzee's consistent choice of the correct photographs can be understood by assuming that the animal recognized the videotape as representing a problem, understood the actor's purpose, and chose alternatives compatible with that purpose.},
  journal = {Behavioral and Brain Sciences},
  keywords = {chimpanzee communication,cognition,consciousness,intentionality,language,mind,primate intelligence.,theory of mind},
  language = {en},
  number = {4}
}

@misc{Press_Reinforcement_,
  title = {Reinforcement {{Learning}}, {{Second Edition}} | {{The MIT Press}}},
  author = {Press, The MIT},
  publisher = {{The MIT Press}},
  abstract = {The significantly expanded and updated new edition of a widely used text on reinforcement learning, one of the most active research areas in artificial intelligence.                 Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms. This second edition has been significantly expanded and updated, presenting new topics and updating coverage of other topics.Like the first edition, this second edition focuses on core online learning algorithms, with the more mathematical material set off in shaded boxes. Part I covers as much of reinforcement learning as possible without going beyond the tabular case for which exact solutions can be found. Many algorithms presented in this part are new to the second edition, including UCB, Expected Sarsa, and Double Learning. Part II extends these ideas to function approximation, with new sections on such topics as artificial neural networks and the Fourier basis, and offers expanded treatment of off-policy learning and policy-gradient methods. Part III has new chapters on reinforcement learning's relationships to psychology and neuroscience, as well as an updated case-studies chapter including AlphaGo and AlphaGo Zero, Atari game playing, and IBM Watson's wagering strategy. The final chapter discusses the future societal impacts of reinforcement learning.},
  howpublished = {https://mitpress.mit.edu/books/reinforcement-learning-second-edition},
  keywords = {reinforcement learning},
  language = {en}
}

@article{Prevost_Separate_2010,
  title = {Separate {{Valuation Subsystems}} for {{Delay}} and {{Effort Decision Costs}}},
  author = {Pr{\'e}vost, Charlotte and Pessiglione, Mathias and M{\'e}t{\'e}reau, Elise and {Cl{\'e}ry-Melin}, Marie-Laure and Dreher, Jean-Claude},
  year = {2010},
  month = oct,
  volume = {30},
  pages = {14080--14090},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.2752-10.2010},
  abstract = {Decision making consists of choosing among available options on the basis of a valuation of their potential costs and benefits. Most theoretical models of decision making in behavioral economics, psychology, and computer science propose that the desirability of outcomes expected from alternative options can be quantified by utility functions. These utility functions allow a decision maker to assign subjective values to each option under consideration by weighting the likely benefits and costs resulting from an action and to select the one with the highest subjective value. Here, we used model-based neuroimaging to test whether the human brain uses separate valuation systems for rewards (erotic stimuli) associated with different types of costs, namely, delay and effort. We show that humans devalue rewards associated with physical effort in a strikingly similar fashion to those they devalue that are associated with delays, and that a single computational model derived from economics theory can account for the behavior observed in both delay discounting and effort discounting. However, our neuroimaging data reveal that the human brain uses distinct valuation subsystems for different types of costs, reflecting in opposite fashion delayed reward and future energetic expenses. The ventral striatum and the ventromedial prefrontal cortex represent the increasing subjective value of delayed rewards, whereas a distinct network, composed of the anterior cingulate cortex and the anterior insula, represent the decreasing value of the effortful option, coding the expected expense of energy. Together, these data demonstrate that the valuation processes underlying different types of costs can be fractionated at the cerebral level.},
  copyright = {Copyright \textcopyright{} 2010 the authors 0270-6474/10/3014080-11\$15.00/0},
  journal = {Journal of Neuroscience},
  language = {en},
  number = {42},
  pmid = {20962229}
}

@article{Puig_Role_2012,
  title = {The {{Role}} of {{Prefrontal Dopamine D1 Receptors}} in the {{Neural Mechanisms}} of {{Associative Learning}}},
  author = {Puig, M. Victoria and Miller, Earl K.},
  year = {2012},
  month = jun,
  volume = {74},
  pages = {874--886},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2012.04.018},
  abstract = {Summary Dopamine is thought to play a major role in learning. However, while dopamine D1 receptors (D1Rs) in the prefrontal cortex (PFC) have been shown to modulate working memory-related neural activity, their role in the cellular basis of learning is unknown. We recorded activity from multiple electrodes while injecting the D1R antagonist SCH23390 in the lateral PFC as monkeys learned visuomotor associations. Blocking D1Rs impaired learning of novel associations and decreased cognitive flexibility but spared performance of already familiar associations. This suggests a greater role for prefrontal D1Rs in learning new, rather than performing familiar, associations. There was a corresponding greater decrease in neural selectivity and increase in alpha and beta oscillations in local field potentials for novel than for familiar associations. Our results suggest that weak stimulation of D1Rs observed in aging and psychiatric disorders may impair learning and PFC function by reducing neural selectivity and exacerbating neural oscillations associated with inattention and cognitive deficits.},
  journal = {Neuron},
  number = {5}
}

@article{Rabinovich_Dynamical_2001,
  title = {Dynamical {{Encoding}} by {{Networks}} of {{Competing Neuron Groups}}: {{Winnerless Competition}}},
  shorttitle = {Dynamical {{Encoding}} by {{Networks}} of {{Competing Neuron Groups}}},
  author = {Rabinovich, M. and Volkovskii, A. and Lecanda, P. and Huerta, R. and Abarbanel, H. D. I. and Laurent, G.},
  year = {2001},
  month = jul,
  volume = {87},
  pages = {068102},
  doi = {10.1103/PhysRevLett.87.068102},
  abstract = {Following studies of olfactory processing in insects and fish, we investigate neural networks whose dynamics in phase space is represented by orbits near the heteroclinic connections between saddle regions (fixed points or limit cycles). These networks encode input information as trajectories along the heteroclinic connections. If there are N neurons in the network, the capacity is approximately e(N-1)!, i.e., much larger than that of most traditional network structures. We show that a small winnerless competition network composed of FitzHugh-Nagumo spiking neurons efficiently transforms input information into a spatiotemporal output.},
  journal = {Physical Review Letters},
  number = {6}
}

@article{Rabinovich_Dynamics_2006,
  title = {Dynamics of {{Sequential Decision Making}}},
  author = {Rabinovich, Mikhail I. and Huerta, Ram{\'o}n and Afraimovich, Valentin},
  year = {2006},
  month = nov,
  volume = {97},
  pages = {188103},
  doi = {10.1103/PhysRevLett.97.188103},
  abstract = {We suggest a new paradigm for intelligent decision-making suitable for dynamical sequential activity of animals or artificial autonomous devices that depends on the characteristics of the internal and external world. To do it we introduce a new class of dynamical models that are described by ordinary differential equations with a finite number of possibilities at the decision points, and also include rules solving this uncertainty. Our approach is based on the competition between possible cognitive states using their stable transient dynamics. The model controls the order of choosing successive steps of a sequential activity according to the environment and decision-making criteria. Two strategies (high-risk and risk-aversion conditions) that move the system out of an erratic environment are analyzed.},
  journal = {Physical Review Letters},
  number = {18}
}

@article{Rabinovich_Robust_2011,
  title = {Robust Transient Dynamics and Brain Functions},
  author = {Rabinovich, Mikhail I. and Varona, Pablo},
  year = {2011},
  volume = {5},
  pages = {24},
  doi = {10.3389/fncom.2011.00024},
  abstract = {In the last few decades several concepts of dynamical systems theory (DST) have guided psychologists, cognitive scientists, and neuroscientists to rethink about sensory motor behavior and embodied cognition. A critical step in the progress of DST application to the brain (supported by modern methods of brain imaging and multi-electrode recording techniques) has been the transfer of its initial success in motor behavior to mental function, i.e., perception, emotion, and cognition. Open questions from research in genetics, ecology, brain sciences, etc., have changed DST itself and lead to the discovery of a new dynamical phenomenon, i.e., reproducible and robust transients that are at the same time sensitive to informational signals. The goal of this review is to describe a new mathematical framework \textendash{} heteroclinic sequential dynamics \textendash{} to understand self-organized activity in the brain that can explain certain aspects of robust itinerant behavior. Specifically, we discuss a hierarchy of coarse-grain models of mental dynamics in the form of kinetic equations of modes. These modes compete for resources at three levels: (i) within the same modality, (ii) among different modalities from the same family (like perception), and (iii) among modalities from different families (like emotion and cognition). The analysis of the conditions for robustness, i.e., the structural stability of transient (sequential) dynamics, give us the possibility to explain phenomena like the finite capacity of our sequential working memory \textendash{} a vital cognitive function \textendash, and to find specific dynamical signatures \textendash{} different kinds of instabilities \textendash{} of several brain functions and mental diseases.},
  journal = {Frontiers in Computational Neuroscience},
  keywords = {binding,low frequency oscillations,mental disorders,mental modes,stable heteroclinic channel,transient neural dynamics,winnerless competition,working memory}
}

@article{Rachlin_Subjective_1991,
  title = {Subjective Probability and Delay.},
  author = {Rachlin, H and Raineri, A and Cross, D},
  year = {1991},
  month = mar,
  volume = {55},
  pages = {233--244},
  issn = {0022-5002},
  doi = {10.1901/jeab.1991.55-233},
  abstract = {Human subjects indicated their preference between a hypothetical \$1,000 reward available with various probabilities or delays and a certain reward of variable amount available immediately. The function relating the amount of the certain-immediate reward subjectively equivalent to the delayed \$1,000 reward had the same general shape (hyperbolic) as the function found by Mazur (1987) to describe pigeons' delay discounting. The function relating the certain-immediate amount of money subjectively equivalent to the probabilistic \$1,000 reward was also hyperbolic, provided that the stated probability was transformed to odds against winning. In a second experiment, when human subjects chose between a delayed \$1,000 reward and a probabilistic \$1,000 reward, delay was proportional to the same odds-against transformation of the probability to which it was subjectively equivalent.},
  journal = {Journal of the Experimental Analysis of Behavior},
  keywords = {effort},
  number = {2},
  pmcid = {PMC1323057},
  pmid = {2037827}
}

@article{Rachlin_Subjective_1991a,
  title = {Subjective Probability and Delay.},
  author = {Rachlin, H and Raineri, A and Cross, D},
  year = {1991},
  month = mar,
  volume = {55},
  pages = {233--244},
  issn = {0022-5002},
  doi = {10.1901/jeab.1991.55-233},
  abstract = {Human subjects indicated their preference between a hypothetical \$1,000 reward available with various probabilities or delays and a certain reward of variable amount available immediately. The function relating the amount of the certain-immediate reward subjectively equivalent to the delayed \$1,000 reward had the same general shape (hyperbolic) as the function found by Mazur (1987) to describe pigeons' delay discounting. The function relating the certain-immediate amount of money subjectively equivalent to the probabilistic \$1,000 reward was also hyperbolic, provided that the stated probability was transformed to odds against winning. In a second experiment, when human subjects chose between a delayed \$1,000 reward and a probabilistic \$1,000 reward, delay was proportional to the same odds-against transformation of the probability to which it was subjectively equivalent.},
  journal = {Journal of the Experimental Analysis of Behavior},
  number = {2},
  pmcid = {PMC1323057},
  pmid = {2037827}
}

@incollection{Radulescu_Mental_2015,
  title = {Mental {{Effort}}: {{Brain}} and {{Autonomic Correlates}} in {{Health}} and {{Disease}}},
  shorttitle = {Mental {{Effort}}},
  booktitle = {Handbook of {{Biobehavioral Approaches}} to {{Self}}-{{Regulation}}},
  author = {Radulescu, Eugenia and Nagai, Yoko and Critchley, Hugo},
  editor = {Gendolla, Guido H.E. and Tops, Mattie and Koole, Sander L.},
  year = {2015},
  pages = {237--253},
  publisher = {{Springer}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4939-1236-0_16},
  abstract = {Mental effort is an embodied process for the short-term deployment of attentional, cognitive and affective resources. The engagement of mental effort involves whole brain shifts in the activation and functional connectivity of sensory and integrative brain regions. Concurrent changes in bodily internal physiology are mediated by cortically driven modulation of subcortical and brainstem homeostatic centres. Within the brain, there is typically engagement of components of the salience network including (sympathetic visceromotor) dorsal anterior cingulate cortex and (viscerosensory) bilateral insula cortex. There is also commonly a disengagement of the default mode network (`antisympathetic' ventromedial prefrontal cortex and posterior cingulate/precuneus) regions. The bidirectional impact of these changes on bodily states of preparedness is mediated neurally via midbrain and brainstem centres. The accompanying state of autonomic arousal is proposed to facilitate goal-directed cognitive processes and underpin feelings of perceived difficulty, control and achievement. Mental effort also elicits more task-specific involvement of executive frontoparietal centres and sensory cortices, while the achievability and control of sustained effort feeds back into affective circuitry. Clinical disorders of effort accompany inflammation-induced stereotyped sickness responses and span developmental, `functional' and degenerative psychiatric diagnostic boundaries. Fatigue states, inattentiveness and diminished motivational drive suggest discrete dimensions through which effort is compromised. Mental effort is ultimately tied to top-down predictions and the value associated with active more precise inferences about future behavioural outcomes.},
  isbn = {978-1-4939-1236-0},
  keywords = {Arousal,Attention-deficit hyperactivity disorder,Autonomic control,Brain imaging,Emotion,Interoception,Predictive coding,Schizophrenia},
  language = {en}
}

@article{Ranti_Parallel_2015,
  title = {Parallel Temporal Dynamics in Hierarchical Cognitive Control},
  author = {Ranti, Carolyn and Chatham, Christopher H. and Badre, David},
  year = {2015},
  month = sep,
  volume = {142},
  pages = {205--229},
  issn = {0010-0277},
  doi = {10.1016/j.cognition.2015.05.003},
  abstract = {Cognitive control allows us to follow abstract rules in order to choose appropriate responses given our desired outcomes. Cognitive control is often conceptualized as a hierarchical decision process, wherein decisions made at higher, more abstract levels of control asymmetrically influence lower-level decisions. These influences could evolve sequentially across multiple levels of a hierarchical decision, consistent with much prior evidence for central bottlenecks and seriality in decision-making processes. However, here, we show that multiple levels of hierarchical cognitive control are processed primarily in parallel. Human participants selected responses to stimuli using a complex, multiply contingent (third order) rule structure. A response deadline procedure allowed assessment of the accuracy and timing of decisions made at each level of the hierarchy. In contrast to a serial decision process, error rates across levels of the decision mostly declined simultaneously and at identical rates, with only a slight tendency to complete the highest level decision first. Simulations with a biologically plausible neural network model demonstrate how such parallel processing could emerge from a previously developed hierarchically nested frontostriatal architecture. Our results support a parallel processing model of cognitive control, in which uncertainty on multiple levels of a decision is reduced simultaneously.},
  journal = {Cognition},
  keywords = {basal ganglia,Computational model,Executive function,Prefrontal cortex,Serial vs. parallel}
}

@article{Rao_Bayesian_2004,
  title = {Bayesian Computation in Recurrent Neural Circuits.},
  author = {Rao, Rajesh P. N.},
  year = {2004},
  month = jan,
  volume = {16},
  pages = {1--38},
  doi = {10.1162/08997660460733976},
  abstract = {A large number of human psychophysical results have been successfully explained in recent years using Bayesian models. However, the neural implementation of such models remains largely unclear. In this article, we show that a network architecture commonly used to model the cerebral cortex can implement Bayesian inference for an arbitrary hidden Markov model. We illustrate the approach using an orientation discrimination task and a visual motion detection task. In the case of orientation discrimination, we show that the model network can infer the posterior distribution over orientations and correctly estimate stimulus orientation in the presence of significant noise. In the case of motion detection, we show that the resulting model network exhibits direction selectivity and correctly computes the posterior probabilities over motion direction and position. When used to solve the well-known random dots motion discrimination task, the model generates responses that mimic the activities of evidence-accumulating neurons in cortical areas LIP and FEF. The framework we introduce posits a new interpretation of cortical activities in terms of log posterior probabilities of stimuli occurring in the natural world.},
  journal = {Neural Comput},
  keywords = {Action Potentials,Animals,Artifacts,Bayes Theorem,Cerebral Cortex,Discrimination Learning,Humans,Markov Chains,Motion Perception,Nerve Net,Neural Networks (Computer),Neural Pathways,Neurons,Orientation,Pattern Recognition,Photic Stimulation,physiology,Reaction Time,Synaptic Transmission,Visual,Visual Fields},
  language = {eng},
  number = {1},
  pmid = {15006021}
}

@article{Rao_Dynamic_1997,
  title = {Dynamic Model of Visual Recognition Predicts Neural Response Properties in the Visual Cortex.},
  author = {Rao, R. P. and Ballard, D. H.},
  year = {1997},
  month = may,
  volume = {9},
  pages = {721--763},
  abstract = {The responses of visual cortical neurons during fixation tasks can be significantly modulated by stimuli from beyond the classical receptive field. Modulatory effects in neural responses have also been recently reported in a task where a monkey freely views a natural scene. In this article, we describe a hierarchical network model of visual recognition that explains these experimental observations by using a form of the extended Kalman filter as given by the minimum description length (MDL) principle. The model dynamically combines input-driven bottom-up signals with expectation-driven top-down signals to predict current recognition state. Synaptic weights in the model are adapted in a Hebbian manner according to a learning rule also derived from the MDL principle. The resulting prediction-learning scheme can be viewed as implementing a form of expectation-maximization (EM) algorithm. The architecture of the model posits an active computational role of the reciprocal connections between adjoining visual cortical areas in determining neural response properties. In particular, the model demonstrates the possible role of feedback from higher cortical areas in mediating neurophysiological effects due to stimuli from beyond the classical receptive field. Simulations of the model are provided that help explain the experimental observations regarding neural responses in both free viewing and fixation conditions.},
  journal = {Neural Comput},
  keywords = {Animals,Artificial Intelligence,cytology/physiology,Fixation,Haplorhini,Humans,Models,Neural Networks (Computer),Neurological,Neurons,Ocular,physiology,Synapses,Visual Cortex,Visual Perception},
  language = {eng},
  number = {4},
  pmid = {9161021}
}

@incollection{Rao_Hierarchical_2005,
  title = {Hierarchical {{Bayesian Inference}} in {{Networks}} of {{Spiking Neurons}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 17},
  author = {Rao, Rajesh P. N.},
  editor = {Saul, Lawrence K. and Weiss, Yair and Bottou, L{\'e}on},
  year = {2005},
  pages = {1113--1120},
  publisher = {{MIT Press}},
  address = {{Cambridge, MA}},
  abstract = {There is growing evidence from psychophysical and neurophysiological studies that the brain utilizes Bayesian principles for inference and decision making. An important open question is how Bayesian inference for arbitrary graphical models can be implemented in networks of spiking neurons. In this paper, we show that recurrent networks of noisy integrate-and-fire neurons can perform approximate Bayesian inference for dynamic and hierarchical graphical models. The membrane potential dynamics of neurons is used to implement belief propagation in the log domain. The spiking probability of a neuron is shown to approximate the posterior probability of the preferred state encoded by the neuron, given past inputs. We illustrate the model using two examples: (1) a motion detection network in which the spiking probability of a direction-selective neuron becomes proportional to the posterior probability of motion in a preferred direction, and (2) a two-level hierarchical network that produces attentional effects similar to those observed in visual cortical areas V2 and V4. The hierarchical model offers a new Bayesian interpretation of attentional modulation in V2 and V4.}
}

@article{Rao_Predictive_1999,
  title = {Predictive Coding in the Visual Cortex: A Functional Interpretation of Some Extra-Classical Receptive-Field Effects},
  shorttitle = {Predictive Coding in the Visual Cortex},
  author = {Rao, Rajesh P. N. and Ballard, Dana H.},
  year = {1999},
  month = jan,
  volume = {2},
  pages = {79--87},
  issn = {1097-6256},
  doi = {10.1038/4580},
  abstract = {We describe a model of visual processing in which feedback connections from a higher- to a lower-order visual cortical area carry predictions of lower-level neural activities, whereas the feedforward connections carry the residual errors between the predictions and the actual lower-level activities. When exposed to natural images, a hierarchical network of model neurons implementing such a model developed simple-cell-like receptive fields. A subset of neurons responsible for carrying the residual errors showed endstopping and other extra-classical receptive-field effects. These results suggest that rather than being exclusively feedforward phenomena, nonclassical surround effects in the visual cortex may also result from cortico-cortical feedback as a consequence of the visual system using an efficient hierarchical strategy for encoding natural images.},
  copyright = {\textcopyright{} 1999 Nature Publishing Group},
  journal = {Nature Neuroscience},
  language = {en},
  number = {1}
}

@article{Ratcliff_diffusion_2008,
  title = {The Diffusion Decision Model: {{Theory}} and Data for Two-Choice Decision Tasks},
  shorttitle = {The Diffusion Decision Model},
  author = {Ratcliff, Roger and McKoon, Gail},
  year = {2008},
  month = apr,
  volume = {20},
  pages = {873--922},
  publisher = {{Mit Press}},
  address = {{Cambridge}},
  issn = {0899-7667},
  doi = {10.1162/neco.2008.12-06-420},
  abstract = {The diffusion decision model allows detailed explanations of behavior in two-choice discrimination tasks. In this article, the model is reviewed to show how it translates behavioral data-accuracy, mean response times, and response time distributions-into components of cognitive processing. Three experiments are used to illustrate experimental manipulations of three components: stimulus difficulty affects the quality of information on which a decision is based; instructions emphasizing either speed or accuracy affect the criterial amounts of information that a subject requires before initiating a response; and the relative proportions of the two stimuli affect biases in drift rate and starting point. The experiments also illustrate the strong constraints that ensure the model is empirically testable and potentially falsifiable. The broad range of applications of the model is also reviewed, including research in the domains of aging and neurophysiology.},
  annotation = {WOS:000253808800001},
  journal = {Neural Computation},
  keywords = {account,accuracy,choice,field-theory,perceptual decision,reaction-time,response-time,speed,superior colliculus,visual-motion},
  language = {English},
  number = {4}
}

@article{Redheffer_new_1989,
  title = {A New Class of {{Volterra}} Differential Equations for Which the Solutions Are Globally Asymptotically Stable},
  author = {Redheffer, Ray},
  year = {1989},
  month = dec,
  volume = {82},
  pages = {251--268},
  issn = {0022-0396},
  doi = {10.1016/0022-0396(89)90133-2},
  journal = {Journal of Differential Equations},
  number = {2}
}

@article{Reynolds_Delay_2005,
  title = {Delay of {{Gratification}} and {{Delay Discounting}}: {{A Unifying Feedback Model}} of {{Delay}}-{{Related Impulsive Behavior}}},
  shorttitle = {Delay of {{Gratification}} and {{Delay Discounting}}},
  author = {Reynolds, Brady and Schiffbauer, Ryan},
  year = {2005},
  month = sep,
  volume = {55},
  journal = {The Psychological Record},
  number = {3}
}

@article{Ridderinkhof_Neurocognitive_2004,
  title = {Neurocognitive Mechanisms of Cognitive Control: {{The}} Role of Prefrontal Cortex in Action Selection, Response Inhibition, Performance Monitoring, and Reward-Based Learning},
  shorttitle = {Neurocognitive Mechanisms of Cognitive Control},
  author = {Ridderinkhof, K. Richard and {van den Wildenberg}, Wery P. M. and Segalowitz, Sidney J. and Carter, Cameron S.},
  year = {2004},
  month = nov,
  volume = {56},
  pages = {129--140},
  issn = {0278-2626},
  doi = {10.1016/j.bandc.2004.09.016},
  abstract = {Convergent evidence highlights the differential contributions of various regions of the prefrontal cortex in the service of cognitive control, but little is understood about how the brain determines and communicates the need to recruit cognitive control, and how such signals instigate the implementation of appropriate performance adjustments. Here we review recent progress from cognitive neuroscience in examining some of the main constituent processes of cognitive control as involved in dynamic decision making: goal-directed action selection, response activation and inhibition, performance monitoring, and reward-based learning. Medial frontal cortex is found to be involved in performance monitoring: evaluating outcome vis-\`a-vis expectancy, and detecting performance errors or conflicting response tendencies. Lateral and orbitofrontal divisions of prefrontal cortex are involved in subsequently implementing appropriate adjustments.},
  journal = {Brain and Cognition},
  keywords = {Action selection,Cognitive control,Medial frontal cortex,Orbitofrontal cortex,Performance adjustment,Performance monitoring,Prefrontal cortex,Response inhibition,Reward-based learning},
  number = {2},
  series = {Neurocognitive Mechanisms of Performance Monitoring and Inhibitory Control}
}

@article{Ridderinkhof_Role_2004,
  title = {The {{Role}} of the {{Medial Frontal Cortex}} in {{Cognitive Control}}},
  author = {Ridderinkhof, K. Richard and Ullsperger, Markus and Crone, Eveline A. and Nieuwenhuis, Sander},
  year = {2004},
  month = oct,
  volume = {306},
  pages = {443--447},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1100301},
  abstract = {Adaptive goal-directed behavior involves monitoring of ongoing actions and performance outcomes, and subsequent adjustments of behavior and learning. We evaluate new findings in cognitive neuroscience concerning cortical interactions that subserve the recruitment and implementation of such cognitive control. A review of primate and human studies, along with a meta-analysis of the human functional neuroimaging literature, suggest that the detection of unfavorable outcomes, response errors, response conflict, and decision uncertainty elicits largely overlapping clusters of activation foci in an extensive part of the posterior medial frontal cortex (pMFC). A direct link is delineated between activity in this area and subsequent adjustments in performance. Emerging evidence points to functional interactions between the pMFC and the lateral prefrontal cortex (LPFC), so that monitoring-related pMFC activity serves as a signal that engages regulatory processes in the LPFC to implement performance adjustments.},
  journal = {Science},
  language = {en},
  number = {5695},
  pmid = {15486290}
}

@article{Rieskamp_probabilistic_2008,
  title = {The Probabilistic Nature of Preferential Choice},
  author = {Rieskamp, J{\"o}rg},
  year = {2008},
  month = nov,
  volume = {34},
  pages = {1446--1465},
  issn = {0278-7393},
  doi = {10.1037/a0013646},
  abstract = {Previous research has developed a variety of theories explaining when and why people's decisions under risk deviate from the standard economic view of expected utility maximization. These theories are limited in their predictive accuracy in that they do not explain the probabilistic nature of preferential choice, that is, why an individual makes different choices in nearly identical situations, or why the magnitude of these inconsistencies varies in different situations. To illustrate the advantage of probabilistic theories, three probabilistic theories of decision making under risk are compared with their deterministic counterparts. The probabilistic theories are (a) a probabilistic version of a simple choice heuristic, (b) a probabilistic version of cumulative prospect theory, and (c) decision field theory. By testing the theories with the data from three experimental studies, the superiority of the probabilistic models over their deterministic counterparts in predicting people's decisions under risk become evident. When testing the probabilistic theories against each other, decision field theory provides the best account of the observed behavior.},
  journal = {Journal of Experimental Psychology. Learning, Memory, and Cognition},
  keywords = {Adult,Choice Behavior,Decision Theory,Female,Gambling,Humans,Male,Models; Statistical,Motivation,Probability Learning,Risk-Taking},
  language = {eng},
  number = {6},
  pmid = {18980407}
}

@article{Rinberg_Speedaccuracy_2006,
  title = {Speed-Accuracy Tradeoff in Olfaction},
  author = {Rinberg, Dmitry},
  year = {2006},
  abstract = {The basic psychophysical principle of speed-accuracy tradeoff (SAT) has been used to understand key as- pects of neuronal information processing in vision and audition, but the principle of SAT is still debated in olfaction. In this study we present the direct obser- vation of SAT in olfaction. We developed a behavioral paradigm for mice in which both the duration of odor- ant sampling and the difficulty of the odor discrimi- nation task were controlled by the experimenter. We observed that the accuracy of odor discrimination increases with the duration of imposed odorant sam- pling, and that the rate of this increase is slower for harder tasks. We also present a unifying picture of two previous, seemingly disparate experiments on tim- ing of odorant sampling in odor discrimination tasks. The presence of SAT in olfaction provides strong evidence for temporal integration in olfaction and puts a constraint on models of olfactory processing.}
}

@article{Robbins_Dissociating_1996,
  title = {Dissociating {{Executive Functions}} of the {{Prefrontal Cortex}} [and {{Discussion}}]},
  author = {Robbins, T. W. and Weinberger, D. and Taylor, J. G. and Morris, R. G.},
  year = {1996},
  month = oct,
  volume = {351},
  pages = {1463--1471},
  issn = {0962-8436, 1471-2970},
  doi = {10.1098/rstb.1996.0131},
  abstract = {An analysis is provided of three distinct paradigms that have been used to study executive functions of the prefrontal cortex involving planning, self-ordered memory or attentional set-shifting. Psychological and anatomical dissociations are sought from the perspective of studies of patients with frontal lobe lesions, functional neuroimaging, psychometric studies in normal volunteers and experimental studies in non-human primates. Particular attention is paid to attempts to dissociate mnemonic from other executive capacities. Thus, patients with frontal damage are shown to have deficits in their (1) use of strategies to improve performance in a spatial working memory task and (2) capacity to make an extra-dimensional shift due to a high-order failure of inhibition in an attentional set-shifting paradigm. These results are discussed in terms of anatomical and neuropharmacological dissociations of different aspects of executive function within the prefrontal cortex shown in monkeys.},
  journal = {Philosophical Transactions of the Royal Society of London B: Biological Sciences},
  language = {en},
  number = {1346},
  pmid = {8941958}
}

@article{Robertson_Dorsal_2015,
  title = {Dorsal Striatum Mediates Cognitive Control, Not Cognitive Effort per Se, in Decision-Making: {{An}} Event-Related {{fMRI}} Study},
  shorttitle = {Dorsal Striatum Mediates Cognitive Control, Not Cognitive Effort per Se, in Decision-Making},
  author = {Robertson, Brian D. and Hiebert, Nole M. and Seergobin, Ken N. and Owen, Adrian M. and MacDonald, Penny A.},
  year = {2015},
  month = jul,
  volume = {114},
  pages = {170--184},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2015.03.082},
  abstract = {Objective Whether the dorsal striatum (DS) mediates cognitive control or cognitive effort per se in decision-making is unclear given that these effects are highly correlated. As the cognitive control requirements of a neuropsychological task intensify, cognitive effort increases proportionately. We implemented a task that disentangled cognitive control and cognitive effort to specify the particular function DS mediates in decision-making. Methods Sixteen healthy young adults completed a number Stroop task with simultaneous blood-oxygenation-level-dependent response (BOLD) measurement using functional magnetic resonance imaging. Participants selected the physically larger number of a pair of single-digit integers. Discriminating smaller versus larger physical size differences between a number pair requires greater cognitive effort, but does not require greater cognitive control. We also investigated the effect of conflict between the physical and numerical dimensions of targets (e.g., 2 6). Selections in this incongruent case are more cognitively effortful and require greater cognitive control to suppress responding to the irrelevant dimension. Enhancing cognitive effort or cognitive control demands increases errors and response times. Despite similar behavioural profiles, our aim was to determine whether DS mediates cognitive control or simply indexes cognitive effort, using the same data set. Results As expected, behavioural interference effects occurred for both enhanced cognitive control and/or cognitive effort conditions. Despite similar degrees of behavioural interference, DS BOLD signal only correlated with interference arising due to increased cognitive control demands in the incongruent case. DS was not preferentially activated for discriminations of smaller relative to larger physical size differences between number pairs, even when using liberal statistical criteria. However, our incongruent and physical size effects conjointly activated regions related to effortful processing (e.g., anterior cingulate cortex). Interpretation We interpret these findings as support for the increasingly accepted notion that DS mediates cognitive control specifically and does not simply index cognitive effort per se.},
  journal = {NeuroImage},
  keywords = {Cognitive control,Cognitive effort,fMRI,Striatum,Stroop}
}

@article{Rode_When_1999,
  title = {When and Why Do People Avoid Unknown Probabilities in Decisions under Uncertainty? {{Testing}} Some Predictions from Optimal Foraging Theory},
  shorttitle = {When and Why Do People Avoid Unknown Probabilities in Decisions under Uncertainty?},
  author = {Rode, Catrin and Cosmides, Leda and Hell, Wolfgang and Tooby, John},
  year = {1999},
  month = oct,
  volume = {72},
  pages = {269--304},
  issn = {00100277},
  doi = {10.1016/S0010-0277(99)00041-4},
  journal = {Cognition},
  language = {en},
  number = {3}
}

@article{Rode_When_1999a,
  title = {When and Why Do People Avoid Unknown Probabilities in Decisions under Uncertainty? {{Testing}} Some Predictions from Optimal Foraging Theory},
  shorttitle = {When and Why Do People Avoid Unknown Probabilities in Decisions under Uncertainty?},
  author = {Rode, Catrin and Cosmides, Leda and Hell, Wolfgang and Tooby, John},
  year = {1999},
  month = oct,
  volume = {72},
  pages = {269--304},
  issn = {0010-0277},
  doi = {10.1016/S0010-0277(99)00041-4},
  abstract = {When given a choice between two otherwise equivalent options \textemdash{} one in which the probability information is stated and another in which it is missing \textemdash{} most people avoid the option with missing probability information (Camerer \& Weber, 1992). This robust, frequently replicated tendency is known as the ambiguity effect. It is unclear, however, why the ambiguity effect occurs. Experiments 1 and 2, which separated effects of the comparison process from those related to missing probability information, demonstrate that the ambiguity effect is elicited by missing probabilities rather than by comparison of options. Experiments 3 and 4 test predictions drawn from the literature on behavioral ecology. It is suggested that choices between two options should reflect three parameters: (1) the need of the organism, (2) the mean expected outcome of each option; and (3) the variance associated with each option's outcome. It is hypothesized that unknown probabilities are avoided because they co-occur with high outcome variability. In Experiment 3 it was found that subjects systematically avoid options with high outcome variability regardless of whether probabilities are explicitly stated or not. In Experiment 4, we reversed the ambiguity effect: when participants' need was greater than the known option's expected mean outcome, subjects preferred the ambiguous (high variance) option. From these experiments we conclude that people do not generally avoid ambiguous options. Instead, they take into account expected outcome, outcome variability, and their need in order to arrive at a decision that is most likely to satisfy this need.},
  journal = {Cognition},
  keywords = {Ambiguity effect,Decision Making,Optomal foraging theory,risky behavior},
  number = {3}
}

@article{Russek_Predictive_2017,
  title = {Predictive Representations Can Link Model-Based Reinforcement Learning to Model-Free Mechanisms},
  author = {Russek, Evan M. and Momennejad, Ida and Botvinick, Matthew M. and Gershman, Samuel J. and Daw, Nathaniel D.},
  year = {2017},
  month = sep,
  volume = {13},
  pages = {e1005768},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1005768},
  abstract = {Humans and animals are capable of evaluating actions by considering their long-run future rewards through a process described using model-based reinforcement learning (RL) algorithms. The mechanisms by which neural circuits perform the computations prescribed by model-based RL remain largely unknown; however, multiple lines of evidence suggest that neural circuits supporting model-based behavior are structurally homologous to and overlapping with those thought to carry out model-free temporal difference (TD) learning. Here, we lay out a family of approaches by which model-based computation may be built upon a core of TD learning. The foundation of this framework is the successor representation, a predictive state representation that, when combined with TD learning of value predictions, can produce a subset of the behaviors associated with model-based learning, while requiring less decision-time computation than dynamic programming. Using simulations, we delineate the precise behavioral capabilities enabled by evaluating actions using this approach, and compare them to those demonstrated by biological organisms. We then introduce two new algorithms that build upon the successor representation while progressively mitigating its limitations. Because this framework can account for the full range of observed putatively model-based behaviors while still utilizing a core TD framework, we suggest that it represents a neurally plausible family of mechanisms for model-based evaluation.},
  journal = {PLOS Computational Biology},
  keywords = {Algorithms,Animal behavior,Behavior,Decision making,Dopamine,Dopaminergics,Learning,Neostriatum},
  language = {en},
  number = {9}
}

@article{Ruter_Paradoxical_2012,
  title = {Paradoxical {{Evidence Integration}} in {{Rapid Decision Processes}}},
  author = {R{\"u}ter, Johannes and Marcille, Nicolas and Sprekeler, Henning and Gerstner, Wulfram and Herzog, Michael H.},
  year = {2012},
  month = feb,
  volume = {8},
  pages = {e1002382},
  doi = {10.1371/journal.pcbi.1002382},
  abstract = {Author Summary In models of decision making, evidence is accumulated until it crosses a threshold. The amount of evidence is directly related to the strength of the sensory input for the decision alternatives. Such one-stage models predict that if two stimulus alternatives are presented in succession, the stimulus alternative presented first dominates the decision, as the accumulated evidence will reach the threshold for this alternative first. Here, we show that for short stimulus durations decision making is not dominated by the first, but by the second stimulus. This result cannot be explained by classical one-stage decision models. We present a two-stage model where sensory input is first integrated before its outcome is fed into a classical decision process.},
  journal = {PLoS Comput Biol},
  number = {2}
}

@article{Salamone_Mysterious_2012,
  title = {The {{Mysterious Motivational Functions}} of {{Mesolimbic Dopamine}}},
  author = {Salamone, John D. and Correa, Merc{\`e}},
  year = {2012},
  month = nov,
  volume = {76},
  pages = {470--485},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2012.10.021},
  abstract = {Nucleus accumbens dopamine is known to play a role in motivational processes, and dysfunctions of mesolimbic dopamine may contribute to motivational symptoms of depression and other disorders, as well as features of substance abuse. Although it has become traditional to label dopamine neurons as ``reward'' neurons, this is an overgeneralization, and it is important to distinguish between aspects of motivation that are differentially affected by dopaminergic manipulations. For example, accumbens dopamine does not mediate primary food motivation or appetite, but is involved in appetitive and aversive motivational processes including behavioral activation, exertion of effort, approach behavior, sustained task engagement, Pavlovian processes, and instrumental learning. In this review, we discuss the complex roles of dopamine in behavioral functions related to motivation.},
  journal = {Neuron},
  number = {3}
}

@article{Salvatier_Probabilistic_2016,
  title = {Probabilistic Programming in {{Python}} Using {{PyMC3}}},
  author = {Salvatier, John and Wiecki, Thomas V. and Fonnesbeck, Christopher},
  year = {2016},
  month = apr,
  volume = {2},
  pages = {e55},
  issn = {2376-5992},
  doi = {10.7717/peerj-cs.55},
  abstract = {Probabilistic programming allows for automatic Bayesian inference on user-defined probabilistic models. Recent advances in Markov chain Monte Carlo (MCMC) sampling allow inference on increasingly complex models. This class of MCMC, known as Hamiltonian Monte Carlo, requires gradient information which is often not readily available. PyMC3 is a new open source probabilistic programming framework written in Python that uses Theano to compute gradients via automatic differentiation as well as compile probabilistic programs on-the-fly to C for increased speed. Contrary to other probabilistic programming languages, PyMC3 allows model specification directly in Python code. The lack of a domain specific language allows for great flexibility and direct interaction with the model. This paper is a tutorial-style introduction to this software package.},
  journal = {PeerJ Computer Science},
  language = {en}
}

@article{Sayali_Neural_2019,
  title = {Neural Systems of Cognitive Demand Avoidance},
  author = {Sayal{\i}, Ceyda and Badre, David},
  year = {2019},
  month = feb,
  volume = {123},
  pages = {41--54},
  issn = {0028-3932},
  doi = {10.1016/j.neuropsychologia.2018.06.016},
  abstract = {Cognitive effort is typically aversive, evident in people's tendency to avoid cognitively demanding tasks. The `cost of control' hypothesis suggests that engagement of cognitive control systems of the brain makes a task costly and the currency of that cost is a reduction in anticipated rewards. However, prior studies have relied on binary hard versus easy task subtractions to manipulate cognitive effort and so have not tested this hypothesis in ``dose-response'' fashion. In a sample of 50 participants, we parametrically manipulated the level of effort during fMRI scanning by systematically increasing cognitive control demands during a demand-selection paradigm over six levels. As expected, frontoparietal control network (FPN) activity increased, and reward network activity decreased, as control demands increased across tasks. However, avoidance behavior was not attributable to the change in FPN activity, lending only partial support to the cost of control hypothesis. By contrast, we unexpectedly observed that the de-activation of a task-negative brain network corresponding to the Default Mode Network (DMN) across levels of the cognitive control manipulation predicted the change in avoidance. In summary, we find partial support for the cost of control hypothesis, while highlighting the role of task-negative brain networks in modulating effort avoidance behavior.},
  journal = {Neuropsychologia},
  keywords = {Cognitive control,Cognitive effort,Effort avoidance,Effort cost,Reward},
  series = {Cognitive {{Effort}}}
}

@article{Scheidt_Learning_2001,
  title = {Learning to {{Move Amid Uncertainty}}},
  author = {Scheidt, Robert A. and Dingwell, Jonathan B. and {Mussa-Ivaldi}, Ferdinando A.},
  year = {2001},
  month = aug,
  volume = {86},
  pages = {971--985},
  publisher = {{American Physiological Society}},
  issn = {0022-3077},
  doi = {10.1152/jn.2001.86.2.971},
  abstract = {We studied how subjects learned to make movements against unpredictable perturbations. Twelve healthy human subjects made goal-directed reaching movements in the horizontal plane while holding the handle of a two-joint robotic manipulator. The robot generated viscous force fields that perturbed the limb perpendicular to the desired direction of movement. The amplitude (but not the direction) of the viscous field varied randomly from trial to trial. Systems identification techniques were employed to characterize how subjects adapted to these random perturbations. Subject performance was quantified primarily using the peak deviation from a straight-line hand path. Subjects adapted their arm movements to the sequence of random force-field amplitudes. This adaptive response compensated for the approximate mean from the random sequence of perturbations and did not depend on the statistical distribution of that sequence. Subjects did not adapt by directly counteracting the mean field strength itself on each trial but rather by using information about perturbations and movement errors from a limited number of previous trials to adjust motor commands on subsequent trials. This strategy permitted subjects to achieve near-optimal performance (defined as minimizing movement errors in a least-squares sense) while maintaining computational efficiency. A simple model using information about movement errors and perturbation amplitudes from a single previous trial predicted subject performance in stochastic environments with a high degree of fidelity and further predicted key performance features observed in nonstochastic environments. This suggests that the neural structures modified during motor adaptation require only short-term memory. Explicit representations regarding movements made more than a few trials in the past are not used in generating optimal motor responses on any given trial.},
  journal = {Journal of Neurophysiology},
  number = {2}
}

@article{Schiffer_role_2015,
  title = {The Role of Prediction and Outcomes in Adaptive Cognitive Control},
  author = {Schiffer, Anne-Marike and Waszak, Florian and Yeung, Nick},
  year = {2015},
  month = feb,
  volume = {109},
  pages = {38--52},
  issn = {0928-4257},
  doi = {10.1016/j.jphysparis.2015.02.001},
  abstract = {Humans adaptively perform actions to achieve their goals. This flexible behaviour requires two core abilities: the ability to anticipate the outcomes of candidate actions and the ability to select and implement actions in a goal-directed manner. The ability to predict outcomes has been extensively researched in reinforcement learning paradigms, but this work has often focused on simple actions that are not embedded in hierarchical and sequential structures that are characteristic of goal-directed human behaviour. On the other hand, the ability to select actions in accordance with high-level task goals, particularly in the presence of alternative responses and salient distractors, has been widely researched in cognitive control paradigms. Cognitive control research, however, has often paid less attention to the role of action outcomes. The present review attempts to bridge these accounts by proposing an outcome-guided mechanism for selection of extended actions. Our proposal builds on constructs from the hierarchical reinforcement learning literature, which emphasises the concept of reaching and evaluating informative states, i.e., states that constitute subgoals in complex actions. We develop an account of the neural mechanisms that allow outcome-guided action selection to be achieved in a network that relies on projections from cortical areas to the basal ganglia and back-projections from the basal ganglia to the cortex. These cortico-basal ganglia-thalamo-cortical `loops' allow convergence \textendash{} and thus integration \textendash{} of information from non-adjacent cortical areas (for example between sensory and motor representations). This integration is essential in action sequences, for which achieving an anticipated sensory state signals the successful completion of an action. We further describe how projection pathways within the basal ganglia allow selection between representations, which may pertain to movements, actions, or extended action plans. The model lastly envisages a role for hierarchical projections from the striatum to dopaminergic midbrain areas that enable more rostral frontal areas to bias the selection of inputs from more posterior frontal areas via their respective representations in the basal ganglia.},
  journal = {Journal of Physiology-Paris},
  keywords = {Action selection,basal ganglia,Cognitive control,Dopamine,Hierarchical reinforcement learning,Ideomotor principle,Prediction,Prefrontal cortex,Reinforcement learning,Striatum},
  number = {1\textendash 3},
  series = {Neural {{Basis}} of {{Adaptive Control}}}
}

@article{Schiffer_role_2015a,
  title = {The Role of Prediction and Outcomes in Adaptive Cognitive Control},
  author = {Schiffer, Anne-Marike and Waszak, Florian and Yeung, Nick},
  year = {2015},
  month = feb,
  volume = {109},
  pages = {38--52},
  issn = {0928-4257},
  doi = {10.1016/j.jphysparis.2015.02.001},
  abstract = {Humans adaptively perform actions to achieve their goals. This flexible behaviour requires two core abilities: the ability to anticipate the outcomes of candidate actions and the ability to select and implement actions in a goal-directed manner. The ability to predict outcomes has been extensively researched in reinforcement learning paradigms, but this work has often focused on simple actions that are not embedded in hierarchical and sequential structures that are characteristic of goal-directed human behaviour. On the other hand, the ability to select actions in accordance with high-level task goals, particularly in the presence of alternative responses and salient distractors, has been widely researched in cognitive control paradigms. Cognitive control research, however, has often paid less attention to the role of action outcomes. The present review attempts to bridge these accounts by proposing an outcome-guided mechanism for selection of extended actions. Our proposal builds on constructs from the hierarchical reinforcement learning literature, which emphasises the concept of reaching and evaluating informative states, i.e., states that constitute subgoals in complex actions. We develop an account of the neural mechanisms that allow outcome-guided action selection to be achieved in a network that relies on projections from cortical areas to the basal ganglia and back-projections from the basal ganglia to the cortex. These cortico-basal ganglia-thalamo-cortical `loops' allow convergence \textendash{} and thus integration \textendash{} of information from non-adjacent cortical areas (for example between sensory and motor representations). This integration is essential in action sequences, for which achieving an anticipated sensory state signals the successful completion of an action. We further describe how projection pathways within the basal ganglia allow selection between representations, which may pertain to movements, actions, or extended action plans. The model lastly envisages a role for hierarchical projections from the striatum to dopaminergic midbrain areas that enable more rostral frontal areas to bias the selection of inputs from more posterior frontal areas via their respective representations in the basal ganglia.},
  journal = {Journal of Physiology-Paris},
  keywords = {Action selection,basal ganglia,Cognitive control,Dopamine,Hierarchical reinforcement learning,Ideomotor principle,Prediction,Prefrontal cortex,Reinforcement learning,Striatum},
  number = {1\textendash 3},
  series = {Neural {{Basis}} of {{Adaptive Control}}}
}

@article{Schiller_Shortterm_1976,
  title = {Short-Term Response Variability of Monkey Striate Neurons},
  author = {Schiller, Peter H. and Finlay, Barbara L. and Volman, Susan F.},
  year = {1976},
  month = mar,
  volume = {105},
  pages = {347--349},
  issn = {0006-8993},
  doi = {10.1016/0006-8993(76)90432-7},
  journal = {Brain Research},
  number = {2}
}

@article{Schmidt_Disconnecting_2008,
  title = {Disconnecting Force from Money: Effects of Basal Ganglia Damage on Incentive Motivation},
  shorttitle = {Disconnecting Force from Money},
  author = {Schmidt, Liane and {d'Arc}, Baudouin Forgeot and Lafargue, Gilles and Galanaud, Damien and Czernecki, Virginie and Grabli, David and Sch{\"u}pbach, Michael and Hartmann, Andreas and L{\'e}vy, Richard and Dubois, Bruno and Pessiglione, Mathias},
  year = {2008},
  month = may,
  volume = {131},
  pages = {1303--1310},
  issn = {0006-8950},
  doi = {10.1093/brain/awn045},
  abstract = {Abstract.  Bilateral basal ganglia lesions have been reported to induce a particular form of apathy, termed auto-activation deficit (AAD), principally defined a},
  journal = {Brain},
  language = {en},
  number = {5}
}

@article{Schmidt_Neural_2012,
  title = {Neural {{Mechanisms Underlying Motivation}} of {{Mental Versus Physical Effort}}},
  author = {Schmidt, Liane and Lebreton, Ma{\"e}l and {Cl{\'e}ry-Melin}, Marie-Laure and Daunizeau, Jean and Pessiglione, Mathias},
  year = {2012},
  month = feb,
  volume = {10},
  pages = {e1001266},
  issn = {1545-7885},
  doi = {10.1371/journal.pbio.1001266},
  abstract = {Mental and physical efforts, such as paying attention and lifting weights, have been shown to involve different brain systems. These cognitive and motor systems, respectively, include cortical networks (prefronto-parietal and precentral regions) as well as subregions of the dorsal basal ganglia (caudate and putamen). Both systems appeared sensitive to incentive motivation: their activity increases when we work for higher rewards. Another brain system, including the ventral prefrontal cortex and the ventral basal ganglia, has been implicated in encoding expected rewards. How this motivational system drives the cognitive and motor systems remains poorly understood. More specifically, it is unclear whether cognitive and motor systems can be driven by a common motivational center or if they are driven by distinct, dedicated motivational modules. To address this issue, we used functional MRI to scan healthy participants while performing a task in which incentive motivation, cognitive, and motor demands were varied independently. We reasoned that a common motivational node should (1) represent the reward expected from effort exertion, (2) correlate with the performance attained, and (3) switch effective connectivity between cognitive and motor regions depending on task demand. The ventral striatum fulfilled all three criteria and therefore qualified as a common motivational node capable of driving both cognitive and motor regions of the dorsal striatum. Thus, we suggest that the interaction between a common motivational system and the different task-specific systems underpinning behavioral performance might occur within the basal ganglia.},
  journal = {PLOS Biology},
  keywords = {Basal ganglia,Behavior,Delta functions,Functional magnetic resonance imaging,Human performance,Motivation,Neostriatum,Prefrontal cortex},
  language = {en},
  number = {2}
}

@article{Schmitter-Edgecombe_Costs_2006,
  title = {Costs of a {{Predictable Switch Between Simple Cognitive Tasks}}                     {{Following Severe Closed}}-{{Head Injury}}},
  author = {{Schmitter-Edgecombe}, Maureen and Langill, Michelle},
  year = {2006},
  month = nov,
  volume = {20},
  pages = {675--684},
  issn = {0894-4105},
  doi = {10.1037/0894-4105.20.6.675},
  abstract = {The authors used a predictable, externally cued task-switching paradigm                     to investigate executive control in a severe closed-head injury (CHI)                     population. Eighteen individuals with severe CHI and 18 controls switched                     between classifying whether a digit was odd or even and whether a letter was a                     consonant or vowel on every 4th trial. The target stimuli appeared in a circle                     divided into 8 equivalent parts. Presentation of the stimuli rotated clockwise.                     Participants performed the switching task at both a short (200 ms) and a long                     (1,000 ms) preparatory interval. Although the participants with CHI exhibited                     slower response times and greater switch costs, similar to controls, additional                     preparatory time reduced the switch costs, and the switch costs were limited to                     the 1st trial in the run. These findings indicate that participants with severe                     CHI were able to take advantage of time to prepare for the task switch, and the                     executive control processes involved in the switch costs were completed before                     the 1st trial of the run ended.},
  journal = {Neuropsychology},
  number = {6},
  pmcid = {PMC1779821},
  pmid = {17100512}
}

@article{Scholz_uncontrolled_1999,
  title = {The Uncontrolled Manifold Concept: Identifying Control Variables for a Functional Task},
  shorttitle = {The Uncontrolled Manifold Concept},
  author = {Scholz, J. P. and Sch{\"o}ner, Gregor},
  year = {1999},
  month = may,
  volume = {126},
  pages = {289--306},
  issn = {1432-1106},
  doi = {10.1007/s002210050738},
  abstract = {The degrees of freedom problem is often posed by asking which of the many possible degrees of freedom does the nervous system control? By implication, other degrees of freedom are not controlled. We give an operational meaning to ''controlled'' and ''uncontrolled'' and describe a method of analysis through which hypotheses about controlled and uncontrolled degrees of freedom can be tested. In this conception, control refers to stabilization, so that lack of control implies reduced stability. The method was used to analyze an experiment on the sit-to-stand transition. By testing different hypotheses about the controlled variables, we systematically approximated the structure of control in joint space. We found that, for the task of sit-to-stand, the position of the center of mass in the sagittal plane was controlled. The horizontal head position and the position of the hand were controlled less stably, while vertical head position appears to be no more controlled than joint motions.},
  journal = {Experimental Brain Research},
  language = {en},
  number = {3}
}

@article{Schubert_banana_2014,
  title = {The Banana Code--Natural Blend Processing in the Olfactory Circuitry of {{Drosophila}} Melanogaster},
  author = {Schubert, Marco and Hansson, Bill S. and Sachse, Silke},
  year = {2014},
  month = feb,
  volume = {5},
  issn = {1664-042X},
  doi = {10.3389/fphys.2014.00059},
  abstract = {Odor information is predominantly perceived as complex odor blends. For Drosophila melanogaster one of the most attractive blends is emitted by an over-ripe banana. To analyze how the fly's olfactory system processes natural blends we combined the experimental advantages of gas chromatography and functional imaging (GC-I). In this way, natural banana compounds were presented successively to the fly antenna in close to natural occurring concentrations. This technique allowed us to identify the active odor components, use these compounds as stimuli and measure odor-induced Ca2+ signals in input and output neurons of the Drosophila antennal lobe (AL), the first olfactory neuropil. We demonstrate that mixture interactions of a natural blend are very rare and occur only at the AL output level resulting in a surprisingly linear blend representation. However, the information regarding single components is strongly modulated by the olfactory circuitry within the AL leading to a higher similarity between the representation of individual components and the banana blend. This observed modulation might tune the olfactory system in a way to distinctively categorize odor components and improve the detection of suitable food sources. Functional GC-I thus enables analysis of virtually any unknown natural odorant blend and its components in their relative occurring concentrations and allows characterization of neuronal responses of complete neural assemblies. This technique can be seen as a valuable complementary method to classical GC/electrophysiology techniques, and will be a highly useful tool in future investigations of insect-insect and insect-plant chemical interactions.},
  journal = {Frontiers in Physiology},
  pmcid = {PMC3929855},
  pmid = {24600405}
}

@article{Schultz_Neural_1997,
  title = {A {{Neural Substrate}} of {{Prediction}} and {{Reward}}},
  author = {Schultz, Wolfram and Dayan, Peter and Montague, P. Read},
  year = {1997},
  month = mar,
  volume = {275},
  pages = {1593--1599},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.275.5306.1593},
  abstract = {The capacity to predict future events permits a creature to detect, model, and manipulate the causal structure of its interactions with its environment. Behavioral experiments suggest that learning is driven by changes in the expectations about future salient events such as rewards and punishments. Physiological work has recently complemented these studies by identifying dopaminergic neurons in the primate whose fluctuating output apparently signals changes or errors in the predictions of future salient and rewarding events. Taken together, these findings can be understood through quantitative theories of adaptive optimizing control.},
  chapter = {Articles},
  copyright = {\textcopyright{} 1997 American Association for the Advancement of Science},
  journal = {Science},
  language = {en},
  number = {5306},
  pmid = {9054347}
}

@article{Schultz_Updating_2013,
  title = {Updating Dopamine Reward Signals},
  author = {Schultz, Wolfram},
  year = {2013},
  month = apr,
  volume = {23},
  pages = {229--238},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2012.11.012},
  abstract = {Recent work has advanced our knowledge of phasic dopamine reward prediction error signals. The error signal is bidirectional, reflects well the higher order prediction error described by temporal difference learning models, is compatible with model-free and model-based reinforcement learning, reports the subjective rather than physical reward value during temporal discounting and reflects subjective stimulus perception rather than physical stimulus aspects. Dopamine activations are primarily driven by reward, and to some extent risk, whereas punishment and salience have only limited activating effects when appropriate controls are respected. The signal is homogeneous in terms of time course but heterogeneous in many other aspects. It is essential for synaptic plasticity and a range of behavioural learning situations.},
  journal = {Current Opinion in Neurobiology},
  number = {2},
  series = {Macrocircuits}
}

@article{Schultz_Updating_2013a,
  title = {Updating Dopamine Reward Signals},
  author = {Schultz, Wolfram},
  year = {2013},
  month = apr,
  volume = {23},
  pages = {229--238},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2012.11.012},
  abstract = {Recent work has advanced our knowledge of phasic dopamine reward prediction error signals. The error signal is bidirectional, reflects well the higher order prediction error described by temporal difference learning models, is compatible with model-free and model-based reinforcement learning, reports the subjective rather than physical reward value during temporal discounting and reflects subjective stimulus perception rather than physical stimulus aspects. Dopamine activations are primarily driven by reward, and to some extent risk, whereas punishment and salience have only limited activating effects when appropriate controls are respected. The signal is homogeneous in terms of time course but heterogeneous in many other aspects. It is essential for synaptic plasticity and a range of behavioural learning situations.},
  journal = {Current Opinion in Neurobiology},
  number = {2},
  series = {Macrocircuits}
}

@article{Schwabe_Stress_2009,
  title = {Stress {{Prompts Habit Behavior}} in {{Humans}}},
  author = {Schwabe, Lars and Wolf, Oliver T.},
  year = {2009},
  month = jun,
  volume = {29},
  pages = {7191--7198},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.0979-09.2009},
  abstract = {Instrumental behavior can be controlled by goal-directed action\textendash outcome and habitual stimulus\textendash response processes that are supported by anatomically distinct brain systems. Based on previous findings showing that stress modulates the interaction of ``cognitive'' and ``habit'' memory systems, we asked in the presented study whether stress may coordinate goal-directed and habit processes in instrumental learning. For this purpose, participants were exposed to stress (socially evaluated cold pressor test) or a control condition before they were trained to perform two instrumental actions that were associated with two distinct food outcomes. After training, one of these food outcomes was selectively devalued as subjects were saturated with that food. Next, subjects were presented the two instrumental actions in extinction. Stress before training in the instrumental task rendered participants' behavior insensitive to the change in the value of the food outcomes, that is stress led to habit performance. Moreover, stress reduced subjects' explicit knowledge of the action\textendash outcome contingencies. These results demonstrate for the first time that stress promotes habits at the expense of goal-directed performance in humans.},
  copyright = {Copyright \textcopyright{} 2009 Society for Neuroscience 0270-6474/09/297191-08\$15.00/0},
  journal = {Journal of Neuroscience},
  language = {en},
  number = {22},
  pmid = {19494141}
}

@article{Schwartenbeck_Computational_2016,
  title = {Computational {{Phenotyping}} in {{Psychiatry}}: {{A Worked Example}}},
  shorttitle = {Computational {{Phenotyping}} in {{Psychiatry}}},
  author = {Schwartenbeck, Philipp and Friston, Karl},
  year = {2016},
  month = jul,
  volume = {3},
  pages = {ENEURO.0049-16.2016},
  issn = {2373-2822},
  doi = {10.1523/ENEURO.0049-16.2016},
  abstract = {Computational psychiatry is a rapidly emerging field that uses model-based quantities to infer the behavioral and neuronal abnormalities that underlie psychopathology. If successful, this approach promises key insights into (pathological) brain function as well as a more mechanistic and quantitative approach to psychiatric nosology\textemdash structuring therapeutic interventions and predicting response and relapse. The basic procedure in computational psychiatry is to build a computational model that formalizes a behavioral or neuronal process. Measured behavioral (or neuronal) responses are then used to infer the model parameters of a single subject or a group of subjects. Here, we provide an illustrative overview over this process, starting from the modeling of choice behavior in a specific task, simulating data, and then inverting that model to estimate group effects. Finally, we illustrate cross-validation to assess whether between-subject variables (e.g., diagnosis) can be recovered successfully. Our worked example uses a simple two-step maze task and a model of choice behavior based on (active) inference and Markov decision processes. The procedural steps and routines we illustrate are not restricted to a specific field of research or particular computational model but can, in principle, be applied in many domains of computational psychiatry.},
  copyright = {Copyright \textcopyright{} 2016 Schwartenbeck and Friston. This is an open-access article distributed under the terms of the Creative Commons Attribution 4.0 International, which permits unrestricted use, distribution and reproduction in any medium provided that the original work is properly attributed.},
  journal = {eneuro},
  language = {en},
  number = {4}
}

@article{Schwartenbeck_Dopaminergic_2015,
  title = {The {{Dopaminergic Midbrain Encodes}} the {{Expected Certainty}} about {{Desired Outcomes}}},
  author = {Schwartenbeck, Philipp and FitzGerald, Thomas H. B. and Mathys, Christoph and Dolan, Ray and Friston, Karl},
  year = {2015},
  month = oct,
  volume = {25},
  pages = {3434--3445},
  issn = {1047-3211},
  doi = {10.1093/cercor/bhu159},
  abstract = {Dopamine plays a key role in learning; however, its exact function in decision making and choice remains unclear. Recently, we proposed a generic model based on active (Bayesian) inference wherein dopamine encodes the precision of beliefs about optimal policies. Put simply, dopamine discharges reflect the confidence that a chosen policy will lead to desired outcomes. We designed a novel task to test this hypothesis, where subjects played a ``limited offer'' game in a functional magnetic resonance imaging experiment. Subjects had to decide how long to wait for a high offer before accepting a low offer, with the risk of losing everything if they waited too long. Bayesian model comparison showed that behavior strongly supported active inference, based on surprise minimization, over classical utility maximization schemes. Furthermore, midbrain activity, encompassing dopamine projection neurons, was accurately predicted by trial-by-trial variations in model-based estimates of precision. Our findings demonstrate that human subjects infer both optimal policies and the precision of those inferences, and thus support the notion that humans perform hierarchical probabilistic Bayesian inference. In other words, subjects have to infer both what they should do as well as how confident they are in their choices, where confidence may be encoded by dopaminergic firing.},
  journal = {Cerebral Cortex},
  number = {10}
}

@article{Schwartenbeck_Optimal_2015,
  title = {Optimal Inference with Suboptimal Models: {{Addiction}} and Active {{Bayesian}} Inference},
  shorttitle = {Optimal Inference with Suboptimal Models},
  author = {Schwartenbeck, Philipp and FitzGerald, Thomas H. B. and Mathys, Christoph and Dolan, Ray and Wurst, Friedrich and Kronbichler, Martin and Friston, Karl},
  year = {2015},
  month = feb,
  volume = {84},
  pages = {109--117},
  issn = {0306-9877},
  doi = {10.1016/j.mehy.2014.12.007},
  abstract = {When casting behaviour as active (Bayesian) inference, optimal inference is defined with respect to an agent's beliefs \textendash{} based on its generative model of the world. This contrasts with normative accounts of choice behaviour, in which optimal actions are considered in relation to the true structure of the environment \textendash{} as opposed to the agent's beliefs about worldly states (or the task). This distinction shifts an understanding of suboptimal or pathological behaviour away from aberrant inference as such, to understanding the prior beliefs of a subject that cause them to behave less `optimally' than our prior beliefs suggest they should behave. Put simply, suboptimal or pathological behaviour does not speak against understanding behaviour in terms of (Bayes optimal) inference, but rather calls for a more refined understanding of the subject's generative model upon which their (optimal) Bayesian inference is based. Here, we discuss this fundamental distinction and its implications for understanding optimality, bounded rationality and pathological (choice) behaviour. We illustrate our argument using addictive choice behaviour in a recently described `limited offer' task. Our simulations of pathological choices and addictive behaviour also generate some clear hypotheses, which we hope to pursue in ongoing empirical work.},
  journal = {Medical Hypotheses},
  number = {2}
}

@article{Schwarz_Estimating_1978,
  title = {Estimating the {{Dimension}} of a {{Model}}},
  author = {Schwarz, Gideon},
  year = {1978},
  month = mar,
  volume = {6},
  pages = {461--464},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/aos/1176344136},
  abstract = {The problem of selecting one of a number of models of different dimensions is treated by finding its Bayes solution, and evaluating the leading terms of its asymptotic expansion. These terms are a valid large-sample criterion beyond the Bayesian context, since they do not depend on the a priori distribution.},
  journal = {The Annals of Statistics},
  keywords = {Akaike information criterion,asymptotics,Dimension},
  language = {EN},
  mrnumber = {MR468014},
  number = {2},
  zmnumber = {0379.62005}
}

@article{Schweighofer_Humans_2006,
  title = {Humans {{Can Adopt Optimal Discounting Strategy}} under {{Real}}-{{Time Constraints}}},
  author = {Schweighofer, N. and Shishida, K. and Han, C. E. and Okamoto, Y. and Tanaka, S. C. and Yamawaki, S. and Doya, K.},
  year = {2006},
  month = nov,
  volume = {2},
  pages = {e152},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.0020152},
  abstract = {Critical to our many daily choices between larger delayed rewards, and smaller more immediate rewards, are the shape and the steepness of the function that discounts rewards with time. Although research in artificial intelligence favors exponential discounting in uncertain environments, studies with humans and animals have consistently shown hyperbolic discounting. We investigated how humans perform in a reward decision task with temporal constraints, in which each choice affects the time remaining for later trials, and in which the delays vary at each trial. We demonstrated that most of our subjects adopted exponential discounting in this experiment. Further, we confirmed analytically that exponential discounting, with a decay rate comparable to that used by our subjects, maximized the total reward gain in our task. Our results suggest that the particular shape and steepness of temporal discounting is determined by the task that the subject is facing, and question the notion of hyperbolic reward discounting as a universal principle.},
  journal = {PLOS Computational Biology},
  keywords = {Animal behavior,Artificial intelligence,Attitudes (psychology),Behavior,Decision Making,Optimization,serotonin,Tryptophan},
  number = {11}
}

@article{Schwobel_Balancing_2019,
  title = {Balancing Control: A {{Bayesian}} Interpretation of Habitual and Goal-Directed Behavior},
  shorttitle = {Balancing Control},
  author = {Schw{\"o}bel, Sarah and Markovic, Dimitrije and Smolka, Michael N. and Kiebel, Stefan J.},
  year = {2019},
  month = nov,
  pages = {836106},
  publisher = {{Cold Spring Harbor Laboratory}},
  doi = {10.1101/836106},
  abstract = {{$<$}h3{$>$}Abstract{$<$}/h3{$>$} {$<$}p{$>$}In everyday life, our behavior varies on a continuum from either automatic and habitual to deliberate and goal-directed. Recent evidence suggests that habit formation and relearning of habits operate in a context-dependent manner: Habit formation is promoted when actions are performed in a specific context, while breaking off habits is facilitated after a context change. It is an open question how one can computationally model the brain's balancing between context-specific habits and goal-directed actions. Here, we propose a hierarchical Bayesian approach for control of a partially observable Markov decision process that enables conjoint learning of habit and reward structure in a context-specific manner. In this model, habit learning corresponds to a value-free updating of priors over policies and interacts with the value-based learning of the reward structure. Importantly, the model is solely built on probabilistic inference, which effectively provides a simple explanation how the brain may balance contributions of habitual and goal-directed control. We illustrated the resulting behavior using agent-based simulated experiments, where we replicated several findings of devaluation and extinction experiments. In addition, we show how a single parameter, the so-called habitual tendency, can explain individual differences in habit learning and the balancing between habitual and goal-directed control. Finally, we discuss the relevance of the proposed model for understanding specific phenomena in substance use disorder and the potential computational role of activity in dorsolateral and dorsomedial striatum and infralimbic cortex, as reported in animal experiments.{$<$}/p{$>$}},
  chapter = {New Results},
  copyright = {\textcopyright{} 2019, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
  journal = {bioRxiv},
  language = {en}
}

@article{Secundo_perceptual_2014,
  title = {The Perceptual Logic of Smell},
  author = {Secundo, Lavi and Snitz, Kobi and Sobel, Noam},
  year = {2014},
  month = apr,
  volume = {25},
  pages = {107--115},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2013.12.010},
  abstract = {Mammals have {$\sim$}1000 different olfactory receptor subtypes, each responding to a number of different odorants, and each odorant activating a number of different receptor subtypes. These molecular and anatomical underpinnings of olfaction imply a perceptual structure of very high dimensionality that relies on combinatorial coding. In contrast to this expectation, the study of olfactory perception reveals a structure of much lower dimensionality. Moreover, a low-dimensionality approach to olfaction enabled derivation of perception-based structural metrics for smell. These metrics provided meaningful predictions of odorant-induced neural activity and perception from odorant structure alone. Based on this low functional dimensionality, we speculate that olfaction likely does not functionally rely on 1000 different receptor subtypes, and their persistence in evolution may imply that they have additional roles in non-olfactory functions such as in guidance of embryogenesis and development.},
  journal = {Current Opinion in Neurobiology},
  series = {Theoretical and Computational Neuroscience}
}

@article{Seli_Increasing_2019,
  title = {Increasing Participant Motivation Reduces Rates of Intentional and Unintentional Mind Wandering},
  author = {Seli, Paul and Schacter, Daniel L. and Risko, Evan F. and Smilek, Daniel},
  year = {2019},
  month = jul,
  volume = {83},
  pages = {1057--1069},
  issn = {1430-2772},
  doi = {10.1007/s00426-017-0914-2},
  abstract = {We explored the possibility that increasing participants' motivation to perform well on a focal task can reduce mind wandering. Participants completed a sustained-attention task either with standard instructions (normal motivation), or with instructions informing them that they could be excused from the experiment early if they achieved a certain level of performance (higher motivation). Throughout the task, we assessed rates of mind wandering (both intentional and unintentional types) via thought probes. Results showed that the motivation manipulation led to significant reductions in both intentional and unintentional mind wandering as well as improvements in task performance. Most critically, we found that our simple motivation manipulation led to a dramatic reduction in probe-caught mind-wandering rates (49\%) compared to a control condition (67\%), which suggests the utility of motivation-based methods to reduce people's propensity to mind-wander.},
  journal = {Psychological Research},
  keywords = {Attention,Female,Humans,Male,motivation,Motivation,Young Adult},
  language = {eng},
  number = {5},
  pmid = {28918525}
}

@article{Serban_Deep_2017,
  title = {A {{Deep Reinforcement Learning Chatbot}}},
  author = {Serban, Iulian V. and Sankar, Chinnadhurai and Germain, Mathieu and Zhang, Saizheng and Lin, Zhouhan and Subramanian, Sandeep and Kim, Taesup and Pieper, Michael and Chandar, Sarath and Ke, Nan Rosemary and Rajeshwar, Sai and {de Brebisson}, Alexandre and Sotelo, Jose M. R. and Suhubdy, Dendi and Michalski, Vincent and Nguyen, Alexandre and Pineau, Joelle and Bengio, Yoshua},
  year = {2017},
  month = nov,
  abstract = {We present MILABOT: a deep reinforcement learning chatbot developed by the Montreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prize competition. MILABOT is capable of conversing with humans on popular small talk topics through both speech and text. The system consists of an ensemble of natural language generation and retrieval models, including template-based models, bag-of-words models, sequence-to-sequence neural network and latent variable neural network models. By applying reinforcement learning to crowdsourced data and real-world user interactions, the system has been trained to select an appropriate response from the models in its ensemble. The system has been evaluated through A/B testing with real-world users, where it performed significantly better than many competing systems. Due to its machine learning architecture, the system is likely to improve with additional data.},
  archivePrefix = {arXiv},
  eprint = {1709.02349},
  eprinttype = {arxiv},
  journal = {arXiv:1709.02349 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,I.2.7,I.5.1,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{Sezener_Optimizing_2019,
  title = {Optimizing the Depth and the Direction of Prospective Planning Using Information Values},
  author = {Sezener, Can Eren and Dezfouli, Amir and Keramati, Mehdi},
  year = {2019},
  month = mar,
  volume = {15},
  pages = {e1006827},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1006827},
  abstract = {Evaluating the future consequences of actions is achievable by simulating a mental search tree into the future. Expanding deep trees, however, is computationally taxing. Therefore, machines and humans use a plan-until-habit scheme that simulates the environment up to a limited depth and then exploits habitual values as proxies for consequences that may arise in the future. Two outstanding questions in this scheme are ``in which directions the search tree should be expanded?'', and ``when should the expansion stop?''. Here we propose a principled solution to these questions based on a speed/accuracy tradeoff: deeper expansion in the appropriate directions leads to more accurate planning, but at the cost of slower decision-making. Our simulation results show how this algorithm expands the search tree effectively and efficiently in a grid-world environment. We further show that our algorithm can explain several behavioral patterns in animals and humans, namely the effect of time-pressure on the depth of planning, the effect of reward magnitudes on the direction of planning, and the gradual shift from goal-directed to habitual behavior over the course of training. The algorithm also provides several predictions testable in animal/human experiments.},
  journal = {PLOS Computational Biology},
  keywords = {Algorithms,Animal behavior,Behavior,Cognition,Decision making,Decision trees,Monte Carlo method,Working memory},
  language = {en},
  number = {3}
}

@article{Shadmehr_Adaptive_1994,
  title = {Adaptive Representation of Dynamics during Learning of a Motor Task},
  author = {Shadmehr, R. and {Mussa-Ivaldi}, F. A.},
  year = {1994},
  month = may,
  volume = {14},
  pages = {3208--3224},
  issn = {0270-6474},
  abstract = {We investigated how the CNS learns to control movements in different dynamical conditions, and how this learned behavior is represented. In particular, we considered the task of making reaching movements in the presence of externally imposed forces from a mechanical environment. This environment was a force field produced by a robot manipulandum, and the subjects made reaching movements while holding the end-effector of this manipulandum. Since the force field significantly changed the dynamics of the task, subjects' initial movements in the force field were grossly distorted compared to their movements in free space. However, with practice, hand trajectories in the force field converged to a path very similar to that observed in free space. This indicated that for reaching movements, there was a kinematic plan independent of dynamical conditions. The recovery of performance within the changed mechanical environment is motor adaptation. In order to investigate the mechanism underlying this adaptation, we considered the response to the sudden removal of the field after a training phase. The resulting trajectories, named aftereffects, were approximately mirror images of those that were observed when the subjects were initially exposed to the field. This suggested that the motor controller was gradually composing a model of the force field, a model that the nervous system used to predict and compensate for the forces imposed by the environment. In order to explore the structure of the model, we investigated whether adaptation to a force field, as presented in a small region, led to aftereffects in other regions of the workspace. We found that indeed there were aftereffects in workspace regions where no exposure to the field had taken place; that is, there was transfer beyond the boundary of the training data. This observation rules out the hypothesis that the subject's model of the force field was constructed as a narrow association between visited states and experienced forces; that is, adaptation was not via composition of a look-up table. In contrast, subjects modeled the force field by a combination of computational elements whose output was broadly tuned across the motor state space. These elements formed a model that extrapolated to outside the training region in a coordinate system similar to that of the joints and muscles rather than end-point forces. This geometric property suggests that the elements of the adaptive process represent dynamics of a motor task in terms of the intrinsic coordinate system of the sensors and actuators.},
  journal = {The Journal of Neuroscience: The Official Journal of the Society for Neuroscience},
  keywords = {Adaptation; Physiological,Adult,Arm,Humans,Learning,Models; Biological,Motor Activity},
  language = {eng},
  number = {5 Pt 2},
  pmcid = {PMC6577492},
  pmid = {8182467}
}

@article{Shamosh_Delay_2008,
  title = {Delay Discounting and Intelligence: {{A}} Meta-Analysis},
  shorttitle = {Delay Discounting and Intelligence},
  author = {Shamosh, Noah A. and Gray, Jeremy R.},
  year = {2008},
  month = jul,
  volume = {36},
  pages = {289--305},
  issn = {0160-2896},
  doi = {10.1016/j.intell.2007.09.004},
  abstract = {Delay discounting (DD), the tendency to prefer smaller, sooner rewards to larger, later ones, is an important indicator of self-control. Assessments of DD superficially require individuals to make choices based on motivational processes. However, several lines of evidence suggest that DD may be systematically related to cognitive ability. We sought to provide a definitive assessment of the relation between DD and intelligence via quantitative research synthesis. A comprehensive literature search in two electronic databases yielded 24 eligible studies with 26 effect sizes in total. Meta-analysis revealed that, across studies, higher intelligence was associated with lower DD (random effects model weighted mean r = - 0.23). Studies using reward schemes in which payoffs were subject to chance (i.e., involving either a chance of receiving one choice or random selection of one choice) showed weaker associations between DD and intelligence than did studies in which payoffs were all hypothetical or all real. Other moderator analyses revealed no influence of DD measure, DD choice paradigm, or intelligence type. There was no evidence of publication bias. Given clear evidence for a negative relation between DD and intelligence, investigating the processes that support or moderate this relation would be worthwhile.},
  journal = {Intelligence},
  keywords = {Cognitive ability,Delay discounting,Impulsiveness,Impulsivity,Intelligence,Inter-temporal choice,Self-control,Temporal discounting},
  number = {4}
}

@article{Shamosh_Delay_2008a,
  title = {Delay Discounting and Intelligence: {{A}} Meta-Analysis},
  shorttitle = {Delay Discounting and Intelligence},
  author = {Shamosh, Noah A. and Gray, Jeremy R.},
  year = {2008},
  month = jul,
  volume = {36},
  pages = {289--305},
  issn = {0160-2896},
  doi = {10.1016/j.intell.2007.09.004},
  abstract = {Delay discounting (DD), the tendency to prefer smaller, sooner rewards to larger, later ones, is an important indicator of self-control. Assessments of DD superficially require individuals to make choices based on motivational processes. However, several lines of evidence suggest that DD may be systematically related to cognitive ability. We sought to provide a definitive assessment of the relation between DD and intelligence via quantitative research synthesis. A comprehensive literature search in two electronic databases yielded 24 eligible studies with 26 effect sizes in total. Meta-analysis revealed that, across studies, higher intelligence was associated with lower DD (random effects model weighted mean r = - 0.23). Studies using reward schemes in which payoffs were subject to chance (i.e., involving either a chance of receiving one choice or random selection of one choice) showed weaker associations between DD and intelligence than did studies in which payoffs were all hypothetical or all real. Other moderator analyses revealed no influence of DD measure, DD choice paradigm, or intelligence type. There was no evidence of publication bias. Given clear evidence for a negative relation between DD and intelligence, investigating the processes that support or moderate this relation would be worthwhile.},
  journal = {Intelligence},
  keywords = {Cognitive ability,Delay discounting,Impulsiveness,Impulsivity,Intelligence,Inter-temporal choice,Printed,Self-control,Temporal discounting},
  number = {4}
}

@article{Shang_Excitatory_2007,
  title = {Excitatory {{Local Circuits}} and {{Their Implications}} for {{Olfactory Processing}} in the {{Fly Antennal Lobe}}},
  author = {Shang, Yuhua and {Claridge-Chang}, Adam and Sjulson, Lucas and Pypaert, Marc and Miesenb{\"o}ck, Gero},
  year = {2007},
  month = feb,
  volume = {128},
  pages = {601--612},
  issn = {0092-8674},
  doi = {10.1016/j.cell.2006.12.034},
  abstract = {Summary Conflicting views exist of how circuits of the antennal lobe, the insect equivalent of the olfactory bulb, translate input from olfactory receptor neurons (ORNs) into projection-neuron (PN) output. Synaptic connections between ORNs and PNs are one-to-one, yet PNs are more broadly tuned to odors than ORNs. The basis for this difference in receptive range remains unknown. Analyzing a Drosophila mutant lacking ORN input to one glomerulus, we show that some of the apparent complexity in the antennal lobe's output arises from lateral, interglomerular excitation of PNs. We describe~a previously unidentified population of cholinergic local neurons (LNs) with multiglomerular processes. These excitatory LNs respond broadly to odors but exhibit little glomerular specificity in their synaptic output, suggesting that PNs are driven by a combination of glomerulus-specific ORN afferents and diffuse LN excitation. Lateral excitation may boost PN signals and enhance their transmission to third-order neurons in a mechanism akin to stochastic resonance.},
  journal = {Cell},
  number = {3}
}

@article{Shead_PROBABILITY_2009,
  title = {{{PROBABILITY DISCOUNTING OF GAINS AND LOSSES}}: {{IMPLICATIONS FOR RISK}} 					{{ATTITUDES AND IMPULSIVITY}}},
  shorttitle = {{{PROBABILITY DISCOUNTING OF GAINS AND LOSSES}}},
  author = {Shead, N Will and Hodgins, David C},
  year = {2009},
  month = jul,
  volume = {92},
  pages = {1--16},
  issn = {0022-5002},
  doi = {10.1901/jeab.2009.92-1},
  abstract = {Sixty college students performed three discounting tasks: probability discounting 					of gains, probability discounting of losses, and delay discounting of gains. 					Each task used an adjusting-amount procedure, and participants' choices affected 					the amount and timing of their remuneration for participating. Both group and 					individual discounting functions from all three procedures were well fitted by 					hyperboloid discounting functions. A negative correlation between the 					probability discounting of gains and losses was observed, consistent with the 					idea that individuals' choices on probability discounting tasks reflect their 					general attitude towards risk, regardless of whether the outcomes are gains or 					losses. This finding further suggests that risk attitudes reflect the weighting 					an individual gives to the lowest-valued outcome (e.g., getting nothing when the 					probabilistic outcome is a gain or actually losing when the probabilistic 					outcome is a loss). According to this view, risk-aversion indicates a tendency 					to overweight the lowest-valued outcome, whereas risk-seeking indicates a 					tendency to underweight it. Neither probability discounting of gains nor 					probability discounting of losses were reliably correlated with discounting of 					delayed gains, a result that is inconsistent with the idea that probability 					discounting and delay discounting both reflect a general tendency towards 					impulsivity.},
  journal = {Journal of the Experimental Analysis of Behavior},
  number = {1},
  pmcid = {PMC2707142},
  pmid = {20119519}
}

@article{Shelton_Neural_2002,
  title = {Neural {{Correlates}} of {{Encoding Space}} from {{Route}} and {{Survey Perspectives}}},
  author = {Shelton, Amy L. and Gabrieli, John D. E.},
  year = {2002},
  month = apr,
  volume = {22},
  pages = {2711--2717},
  issn = {0270-6474, 1529-2401},
  abstract = {The neural mechanisms underlying ground-level spatial navigation have been investigated, but little is known about other kinds of spatial navigation. Functional magnetic resonance imaging was used to identify differences in brain activation for two types of spatial information, information from the ground-level perspective (route) and information from a global perspective (survey). Participants were scanned during the encoding of two different virtual reality environments, one from each perspective. Comparisons of brain activation during route and survey encoding suggested that both types of information recruited a common network of brain areas, but with important differences. Survey encoding recruited a subset of areas recruited by route encoding, but with greater activation in some areas, including inferior temporal cortex and posterior superior parietal cortex. Route encoding, in contrast, recruited regions that were not activated by survey encoding, including medial temporal lobe structures, anterior superior parietal cortex, and postcentral gyrus. These differences in brain activation are associated with differences in memory performance for the two types of spatial information and contribute to specification of brain components of spatial knowledge.},
  journal = {The Journal of Neuroscience},
  keywords = {functional MRI,medial temporal lobe,memory,navigation,parietal cortex,spatial representation},
  language = {en},
  number = {7},
  pmid = {11923436}
}

@article{Shen_Anterior_2015,
  title = {Anterior {{Cingulate Cortex Cells Identify Process}}-{{Specific Errors}} of {{Attentional Control Prior}} to {{Transient Prefrontal}}-{{Cingulate Inhibition}}},
  author = {Shen, Chen and Ardid, Salva and Kaping, Daniel and Westendorff, Stephanie and Everling, Stefan and Womelsdorf, Thilo},
  year = {2015},
  month = aug,
  volume = {25},
  pages = {2213--2228},
  issn = {1047-3211, 1460-2199},
  doi = {10.1093/cercor/bhu028},
  abstract = {Errors indicate the need to adjust attention for improved future performance. Detecting errors is thus a fundamental step to adjust and control attention. These functions have been associated with the dorsal anterior cingulate cortex (dACC), predicting that dACC cells should track the specific processing states giving rise to errors in order to identify which processing aspects need readjustment. Here, we tested this prediction by recording cells in the dACC and lateral prefrontal cortex (latPFC) of macaques performing an attention task that dissociated 3 processing stages. We found that, across prefrontal subareas, the dACC contained the largest cell populations encoding errors indicating (1) failures of inhibitory control of the attentional focus, (2) failures to prevent bottom-up distraction, and (3) lapses when implementing a choice. Error-locked firing in the dACC showed the earliest latencies across the PFC, emerged earlier than reward omission signals, and involved a significant proportion of putative inhibitory interneurons. Moreover, early onset error-locked response enhancement in the dACC was followed by transient prefrontal-cingulate inhibition, possibly reflecting active disengagement from task processing. These results suggest a functional specialization of the dACC to track and identify the actual processes that give rise to erroneous task outcomes, emphasizing its role to control attentional performance.},
  journal = {Cerebral Cortex},
  keywords = {Anterior cingulate cortex,Cognitive control,dorsolateral prefrontal cortex,error detection,inhibitory interneurons},
  language = {en},
  number = {8},
  pmid = {24591526}
}

@article{Shen_Encoding_2013,
  title = {Encoding of {{Mixtures}} in a {{Simple Olfactory System}}},
  author = {Shen, Kai and Tootoonian, Sina and Laurent, Gilles},
  year = {2013},
  month = dec,
  volume = {80},
  pages = {1246--1262},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2013.08.026},
  abstract = {Summary Natural odors are usually mixtures; yet, humans and animals can experience them as unitary percepts. Olfaction also enables stimulus categorization and generalization. We studied how these computations are performed with the responses of 168 locust antennal lobe projection neurons (PNs) to varying mixtures of two monomolecular odors, and of 174 PNs and 209 mushroom body Kenyon cells (KCs) to mixtures of up to eight monomolecular odors. Single-PN responses showed strong hypoadditivity and population trajectories clustered by odor concentration and mixture similarity. KC responses were much sparser on average than those of PNs and often signaled the presence of single components in mixtures. Linear classifiers could read out the responses of both populations in single time bins to perform odor identification, categorization, and generalization. Our results suggest that odor representations in the mushroom body may result from competing optimization constraints to facilitate memorization (sparseness) while enabling identification, classification, and generalization.},
  journal = {Neuron},
  number = {5}
}

@article{Shenhav_Anterior_2014,
  title = {Anterior Cingulate Engagement in a Foraging Context Reflects Choice Difficulty, Not Foraging Value},
  author = {Shenhav, Amitai and Straccia, Mark A. and Cohen, Jonathan D. and Botvinick, Matthew M.},
  year = {2014},
  month = sep,
  volume = {17},
  pages = {1249--1254},
  issn = {1097-6256},
  doi = {10.1038/nn.3771},
  abstract = {Previous theories predict that human dorsal anterior cingulate (dACC) should respond to decision difficulty. An alternative theory has been recently advanced that proposes that dACC evolved to represent the value of 'non-default', foraging behavior, calling into question its role in choice difficulty. However, this new theory does not take into account that choosing whether or not to pursue foraging-like behavior can also be more difficult than simply resorting to a default. The results of two neuroimaging experiments show that dACC is only associated with foraging value when foraging value is confounded with choice difficulty; when the two are dissociated, dACC engagement is only explained by choice difficulty, and not the value of foraging. In addition to refuting this new theory, our studies help to formalize a fundamental connection between choice difficulty and foraging-like decisions, while also prescribing a solution for a common pitfall in studies of reward-based decision making.},
  copyright = {\textcopyright{} 2014 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  journal = {Nature Neuroscience},
  language = {en},
  number = {9}
}

@article{Shenhav_Expected_2013,
  title = {The {{Expected Value}} of {{Control}}: {{An Integrative Theory}} of {{Anterior Cingulate Cortex Function}}},
  shorttitle = {The {{Expected Value}} of {{Control}}},
  author = {Shenhav, Amitai and Botvinick, Matthew M. and Cohen, Jonathan D.},
  year = {2013},
  month = jul,
  volume = {79},
  pages = {217--240},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2013.07.007},
  abstract = {The dorsal anterior cingulate cortex (dACC) has a near-ubiquitous presence in the neuroscience of cognitive control. It has been implicated in a diversity of functions, from reward processing and performance monitoring to the execution of control and action selection. Here, we propose that this diversity can be understood in terms of a single underlying function: allocation of control based on an evaluation of the expected value of control (EVC). We present a normative model of EVC that integrates three critical factors: the expected payoff from a controlled process, the amount of control that must be invested to achieve that payoff, and the cost in terms of cognitive effort. We propose that dACC integrates this information, using it to determine whether, where and how much control to allocate. We then consider how the EVC model can explain the diverse array of findings concerning dACC function.},
  journal = {Neuron},
  number = {2}
}

@article{Shenhav_Expected_2013a,
  title = {The {{Expected Value}} of {{Control}}: {{An Integrative Theory}} of {{Anterior Cingulate Cortex Function}}},
  shorttitle = {The {{Expected Value}} of {{Control}}},
  author = {Shenhav, Amitai and Botvinick, Matthew M. and Cohen, Jonathan D.},
  year = {2013},
  month = jul,
  volume = {79},
  pages = {217--240},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2013.07.007},
  abstract = {The dorsal anterior cingulate cortex (dACC) has a near-ubiquitous presence in the neuroscience of cognitive control. It has been implicated in a diversity of functions, from reward processing and performance monitoring to the execution of control and action selection. Here, we propose that this diversity can be understood in terms of a single underlying function: allocation of control based on an evaluation of the expected value of control (EVC). We present a normative model of EVC that integrates three critical factors: the expected payoff from a controlled process, the amount of control that must be invested to achieve that payoff, and the cost in terms of cognitive effort. We propose that dACC integrates this information, using it to determine whether, where and how much control to allocate. We then consider how the EVC model can explain the diverse array of findings concerning dACC function.},
  journal = {Neuron},
  number = {2}
}

@article{Shenhav_Rational_2017,
  title = {Toward a {{Rational}} and {{Mechanistic Account}} of {{Mental Effort}}},
  author = {Shenhav, Amitai and Musslick, Sebastian and Lieder, Falk and Kool, Wouter and Griffiths, Thomas L. and Cohen, Jonathan D. and Botvinick, Matthew M.},
  year = {2017},
  volume = {40},
  pages = {99--124},
  doi = {10.1146/annurev-neuro-072116-031526},
  abstract = {In spite of its familiar phenomenology, the mechanistic basis for mental effort remains poorly understood. Although most researchers agree that mental effort is aversive and stems from limitations in our capacity to exercise cognitive control, it is unclear what gives rise to those limitations and why they result in an experience of control as costly. The presence of these control costs also raises further questions regarding how best to allocate mental effort to minimize those costs and maximize the attendant benefits. This review explores recent advances in computational modeling and empirical research aimed at addressing these questions at the level of psychological process and neural mechanism, examining both the limitations to mental effort exertion and how we manage those limited cognitive resources. We conclude by identifying remaining challenges for theoretical accounts of mental effort as well as possible applications of the available findings to understanding the causes of and potential solutions for apparent failures to exert the mental effort required of us.},
  journal = {Annual Review of Neuroscience},
  number = {1},
  pmid = {28375769}
}

@article{Shenhav_Uncovering_2015,
  title = {Uncovering a {{Missing Link}} in {{Anterior Cingulate Research}}},
  author = {Shenhav, Amitai and Botvinick, Matthew},
  year = {2015},
  month = feb,
  volume = {85},
  pages = {455--457},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2015.01.020},
  abstract = {Research on human anterior cingulate cortex has long indicated a role in detecting conflict. However, efforts to find parallel effects in non-human primates were surprisingly unsuccessful. Here, Ebitz and Platt (2015) break the resulting impasse by uncovering what appear to be conflict-related signals in monkey cingulate cortex.},
  journal = {Neuron},
  number = {3}
}

@article{Shin_Neural_2015,
  title = {Neural Correlates of Cognitive Style and Flexible Cognitive Control},
  author = {Shin, Gyeonghee and Kim, Chobok},
  year = {2015},
  month = jun,
  volume = {113},
  pages = {78--85},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2015.03.046},
  abstract = {Human abilities of flexible cognitive control are associated with appropriately regulating the amount of cognitive control required in response to contextual demands. In the context of conflicting situations, for instance, the amount of cognitive control increases according to the level of previously experienced conflict, resulting in optimized performance. We explored whether the amount of cognitive control in conflict resolution was related to individual differences in cognitive style that were determined with the Object\textendash Spatial\textendash Verbal cognitive style questionnaire. In this functional magnetic resonance imaging (fMRI) study, a version of the color\textendash word Stroop task, which evokes conflict between color and verbal components, was employed to explore whether individual preferences for distracting information were related to the increases in neural conflict adaptation in cognitive control network regions. The behavioral data revealed that the more the verbal style was preferred, the greater the conflict adaptation effect was observed, especially when the current trial type was congruent. Consistent with the behavioral data, the imaging results demonstrated increased neural conflict adaptation effects in task-relevant network regions, including the left dorsolateral prefrontal cortex, left fusiform gyrus, and left precuneus, as the preference for verbal style increased. These results provide new evidence that flexible cognitive control is closely associated with individuals' preference of cognitive style.},
  journal = {NeuroImage},
  keywords = {Cognitive control,Cognitive style,Conflict adaptation,fMRI,Prefrontal cortex}
}

@article{Shlizerman_Datadriven_2014,
  title = {Data-Driven Inference of Network Connectivity for Modeling the Dynamics of Neural Codes in the Insect Antennal Lobe},
  author = {Shlizerman, Eli and Riffell, Jeffrey A. and Kutz, J. Nathan},
  year = {2014},
  volume = {8},
  pages = {70},
  doi = {10.3389/fncom.2014.00070},
  abstract = {The antennal lobe (AL), olfactory processing center in insects, is able to process stimuli into distinct neural activity patterns, called olfactory neural codes. To model their dynamics we perform multichannel recordings from the projection neurons in the AL driven by different odorants. We then derive a dynamic neuronal network from the electrophysiological data. The network consists of lateral-inhibitory neurons and excitatory neurons (modeled as firing-rate units), and is capable of producing unique olfactory neural codes for the tested odorants. To construct the network, we (1) design a projection, an odor space, for the neural recording from the AL, which discriminates between distinct odorants trajectories (2) characterize scent recognition, i.e., decision-making based on olfactory signals and (3) infer the wiring of the neural circuit, the connectome of the AL. We show that the constructed model is consistent with biological observations, such as contrast enhancement and robustness to noise. The study suggests a data-driven approach to answer a key biological question in identifying how lateral inhibitory neurons can be wired to excitatory neurons to permit robust activity patterns.},
  journal = {Frontiers in Computational Neuroscience},
  keywords = {contrast enhancement,data-driven modeling,insect olfaction,neuronal networks,odor discrimination,olfactory neural coding,reduced dynamics}
}

@article{Shmuelof_How_2012,
  title = {How Is a Motor Skill Learned? {{Change}} and Invariance at the Levels of Task Success and Trajectory Control},
  shorttitle = {How Is a Motor Skill Learned?},
  author = {Shmuelof, Lior and Krakauer, John W. and Mazzoni, Pietro},
  year = {2012},
  month = jul,
  volume = {108},
  pages = {578--594},
  issn = {1522-1598},
  doi = {10.1152/jn.00856.2011},
  abstract = {The public pays large sums of money to watch skilled motor performance. Notably, however, in recent decades motor skill learning (performance improvement beyond baseline levels) has received less experimental attention than motor adaptation (return to baseline performance in the setting of an external perturbation). Motor skill can be assessed at the levels of task success and movement quality, but the link between these levels remains poorly understood. We devised a motor skill task that required visually guided curved movements of the wrist without a perturbation, and we defined skill learning at the task level as a change in the speed-accuracy trade-off function (SAF). Practice in restricted speed ranges led to a global shift of the SAF. We asked how the SAF shift maps onto changes in trajectory kinematics, to establish a link between task-level performance and fine motor control. Although there were small changes in mean trajectory, improved performance largely consisted of reduction in trial-to-trial variability and increase in movement smoothness. We found evidence for improved feedback control, which could explain the reduction in variability but does not preclude other explanations such as an increased signal-to-noise ratio in cortical representations. Interestingly, submovement structure remained learning invariant. The global generalization of the SAF across a wide range of difficulty suggests that skill for this task is represented in a temporally scalable network. We propose that motor skill acquisition can be characterized as a slow reduction in movement variability, which is distinct from faster model-based learning that reduces systematic error in adaptation paradigms.},
  journal = {Journal of Neurophysiology},
  keywords = {Adolescent,Adult,Biofeedback; Psychology,Female,Humans,Learning,Male,Motor Skills,Movement,Task Performance and Analysis},
  language = {eng},
  number = {2},
  pmcid = {PMC3404800},
  pmid = {22514286}
}

@article{Siegler_Perils_1987,
  title = {The {{Perils}} of {{Averaging Data Over Strategies}} - an {{Example}} from {{Childrens Addition}}},
  author = {Siegler, Rs},
  year = {1987},
  month = sep,
  volume = {116},
  pages = {250--264},
  issn = {0096-3445},
  annotation = {WOS:A1987J657000004},
  journal = {Journal of Experimental Psychology-General},
  language = {English},
  number = {3}
}

@article{Silvanto_Statedependency_2008,
  title = {State-Dependency in Brain Stimulation Studies of Perception and Cognition},
  author = {Silvanto, Juha and Muggleton, Neil and Walsh, Vincent},
  year = {2008},
  month = dec,
  volume = {12},
  pages = {447--454},
  issn = {1364-6613},
  doi = {10.1016/j.tics.2008.09.004},
  abstract = {We address the importance of understanding initial states of neuronal populations and of state-dependent responses in cognitive neuroscience experiments with special emphasis on brain stimulation studies of perception and cognition. The approach we present is based on evidence that behavioural and perceptual effects of transcranial magnetic stimulation (TMS) are determined by initial neural activation state; by systematically manipulating neural activation states before application of TMS, one can selectively target specific, even spatially overlapping neural populations within the affected region. This approach is potentially of great benefit to cognitive neuroscience and remediation programmes as it combines high spatial and functional resolution with the ability to assess causality.},
  journal = {Trends in Cognitive Sciences},
  number = {12}
}

@article{Simon_Neural_2011,
  title = {Neural {{Correlates}} of {{Forward Planning}} in a {{Spatial Decision Task}} in {{Humans}}},
  author = {Simon, Dylan Alexander and Daw, Nathaniel D.},
  year = {2011},
  month = apr,
  volume = {31},
  pages = {5526--5539},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.4647-10.2011},
  abstract = {Although reinforcement learning (RL) theories have been influential in characterizing the mechanisms for reward-guided choice in the brain, the predominant temporal difference (TD) algorithm cannot explain many flexible or goal-directed actions that have been demonstrated behaviorally. We investigate such actions by contrasting an RL algorithm that is model based, in that it relies on learning a map or model of the task and planning within it, to traditional model-free TD learning. To distinguish these approaches in humans, we used functional magnetic resonance imaging in a continuous spatial navigation task, in which frequent changes to the layout of the maze forced subjects continually to relearn their favored routes, thereby exposing the RL mechanisms used. We sought evidence for the neural substrates of such mechanisms by comparing choice behavior and blood oxygen level-dependent (BOLD) signals to decision variables extracted from simulations of either algorithm. Both choices and value-related BOLD signals in striatum, although most often associated with TD learning, were better explained by the model-based theory. Furthermore, predecessor quantities for the model-based value computation were correlated with BOLD signals in the medial temporal lobe and frontal cortex. These results point to a significant extension of both the computational and anatomical substrates for RL in the brain.},
  copyright = {Copyright \textcopyright{} 2011 the authors 0270-6474/11/315526-14\$15.00/0},
  journal = {Journal of Neuroscience},
  language = {en},
  number = {14},
  pmid = {21471389}
}

@article{Sjoerds_Slips_2016,
  title = {Slips of {{Action}} and {{Sequential Decisions}}: {{A Cross}}-{{Validation Study}} of {{Tasks Assessing Habitual}} and {{Goal}}-{{Directed Action Control}}},
  shorttitle = {Slips of {{Action}} and {{Sequential Decisions}}},
  author = {Sjoerds, Zsuzsika and Dietrich, Anja and Deserno, Lorenz and {de Wit}, Sanne and Villringer, Arno and Heinze, Hans-Jochen and Schlagenhauf, Florian and Horstmann, Annette},
  year = {2016},
  month = dec,
  volume = {10},
  issn = {1662-5153},
  doi = {10.3389/fnbeh.2016.00234},
  abstract = {Instrumental learning and decision-making rely on two parallel systems: a goal-directed and a habitual system. In the past decade, several paradigms have been developed to study these systems in animals and humans by means of e.g., overtraining, devaluation procedures and sequential decision-making. These different paradigms are thought to measure the same constructs, but cross-validation has rarely been investigated. In this study we compared two widely used paradigms that assess aspects of goal-directed and habitual behavior. We correlated parameters from a two-step sequential decision-making task that assesses model-based (MB) and model-free (MF) learning with a slips-of-action paradigm that assesses the ability to suppress cue-triggered, learnt responses when the outcome has been devalued and is therefore no longer desirable. MB control during the two-step task showed a very moderately positive correlation with goal-directed devaluation sensitivity, whereas MF control did not show any associations. Interestingly, parameter estimates of MB and goal-directed behavior in the two tasks were positively correlated with higher-order cognitive measures (e.g., visual short-term memory). These cognitive measures seemed to (at least partly) mediate the association between MB control during sequential decision-making and goal-directed behavior after instructed devaluation. This study provides moderate support for a common framework to describe the propensity towards goal-directed behavior as measured with two frequently used tasks. However, we have to caution that the amount of shared variance between the goal-directed and MB system in both tasks was rather low, suggesting that each task does also pick up distinct aspects of goal-directed behavior. Further investigation of the commonalities and differences between the MF and habit systems as measured with these, and other, tasks is needed. Also, a follow-up cross-validation on the neural systems driving these constructs across different paradigms would promote the definition and operationalization of measures of instrumental learning and decision-making in humans.},
  journal = {Frontiers in Behavioral Neuroscience},
  pmcid = {PMC5167743},
  pmid = {28066200}
}

@article{Skvortsova_Learning_2014,
  title = {Learning {{To Minimize Efforts}} versus {{Maximizing Rewards}}: {{Computational Principles}} and {{Neural Correlates}}},
  shorttitle = {Learning {{To Minimize Efforts}} versus {{Maximizing Rewards}}},
  author = {Skvortsova, Vasilisa and Palminteri, Stefano and Pessiglione, Mathias},
  year = {2014},
  month = nov,
  volume = {34},
  pages = {15621--15630},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.1350-14.2014},
  abstract = {The mechanisms of reward maximization have been extensively studied at both the computational and neural levels. By contrast, little is known about how the brain learns to choose the options that minimize action cost. In principle, the brain could have evolved a general mechanism that applies the same learning rule to the different dimensions of choice options. To test this hypothesis, we scanned healthy human volunteers while they performed a probabilistic instrumental learning task that varied in both the physical effort and the monetary outcome associated with choice options. Behavioral data showed that the same computational rule, using prediction errors to update expectations, could account for both reward maximization and effort minimization. However, these learning-related variables were encoded in partially dissociable brain areas. In line with previous findings, the ventromedial prefrontal cortex was found to positively represent expected and actual rewards, regardless of effort. A separate network, encompassing the anterior insula, the dorsal anterior cingulate, and the posterior parietal cortex, correlated positively with expected and actual efforts. These findings suggest that the same computational rule is applied by distinct brain systems, depending on the choice dimension\textemdash cost or benefit\textemdash that has to be learned.},
  copyright = {Copyright \textcopyright{} 2014 the authors 0270-6474/14/3415621-10\$15.00/0},
  journal = {Journal of Neuroscience},
  keywords = {computational modeling,effort,reinforcement learning,reward,ventromedial prefrontal cortex},
  language = {en},
  number = {47},
  pmid = {25411490}
}

@article{Slaughter_Theory_2015,
  title = {Theory of {{Mind}} in {{Infants}} and {{Young Children}}: {{A Review}}},
  shorttitle = {Theory of {{Mind}} in {{Infants}} and {{Young Children}}},
  author = {Slaughter, Virginia},
  year = {2015},
  volume = {50},
  pages = {169--172},
  issn = {1742-9544},
  doi = {10.1111/ap.12080},
  abstract = {Theory of mind, or mindreading, refers to our uniquely human capacity to infer what is in other people's minds. Recent research suggests that ``implicit'' elements of this ability can be seen as early as the second year of life, in infants' spontaneous helping, communicative, and eye-gaze behaviours. More ``explicit'' verbally mediated mindreading skills emerge in the preschool period, and these are positively linked to social competence. Research with typically developing children as well as those with autism spectrum disorders suggests that exposure to conversation about mental states promotes theory of mind development.},
  annotation = {\_eprint: https://aps.onlinelibrary.wiley.com/doi/pdf/10.1111/ap.12080},
  copyright = {\textcopyright{} 2015 The Australian Psychological Society},
  journal = {Australian Psychologist},
  keywords = {childhood,infancy,mindreading,review,theory of mind},
  language = {en},
  number = {3}
}

@article{Slezak_entropic_2018,
  title = {An Entropic Barriers Diffusion Theory of Decision-Making in Multiple Alternative Tasks},
  author = {Slezak, Diego Fernandez and Sigman, Mariano and Cecchi, Guillermo A.},
  year = {2018},
  month = mar,
  volume = {14},
  pages = {e1005961},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1005961},
  abstract = {We present a theory of decision-making in the presence of multiple choices that departs from traditional approaches by explicitly incorporating entropic barriers in a stochastic search process. We analyze response time data from an on-line repository of 15 million blitz chess games, and show that our model fits not just the mean and variance, but the entire response time distribution (over several response-time orders of magnitude) at every stage of the game. We apply the model to show that (a) higher cognitive expertise corresponds to the exploration of more complex solution spaces, and (b) reaction times of users at an on-line buying website can be similarly explained. Our model can be seen as a synergy between diffusion models used to model simple two-choice decision-making and planning agents in complex problem solving.},
  journal = {PLOS Computational Biology},
  keywords = {Behavior,Cognition,Decision making,Decision theory,Decision trees,Games,Problem solving,Random walk},
  language = {en},
  number = {3}
}

@article{Smith_Interacting_2006,
  title = {Interacting {{Adaptive Processes}} with {{Different Timescales Underlie Short}}-{{Term Motor Learning}}},
  author = {Smith, Maurice A and Ghazizadeh, Ali and Shadmehr, Reza},
  year = {2006},
  month = jun,
  volume = {4},
  issn = {1544-9173},
  doi = {10.1371/journal.pbio.0040179},
  abstract = {Multiple processes may contribute to motor skill acquisition, but it is thought that many of these processes require sleep or the passage of long periods of time ranging from several hours to many days or weeks. Here we demonstrate that within a timescale of minutes, two distinct fast-acting processes drive motor adaptation. One process responds weakly to error but retains information well, whereas the other responds strongly but has poor retention. This two-state learning system makes the surprising prediction of spontaneous recovery (or adaptation rebound) if error feedback is clamped at zero following an adaptation-extinction training episode. We used a novel paradigm to experimentally confirm this prediction in human motor learning of reaching, and we show that the interaction between the learning processes in this simple two-state system provides a unifying explanation for several different, apparently unrelated, phenomena in motor adaptation including savings, anterograde interference, spontaneous recovery, and rapid unlearning. Our results suggest that motor adaptation depends on at least two distinct neural systems that have different sensitivity to error and retain information at different rates., This study presents evidence for two learning processes with distinct time courses that contribute to motor skill acquisition, and a computational model of the interactions between these processes that unifies much of the literature in motor adaptation.},
  journal = {PLoS Biology},
  number = {6},
  pmcid = {PMC1463025},
  pmid = {16700627}
}

@article{Smittenaar_Disruption_2013,
  title = {Disruption of {{Dorsolateral Prefrontal Cortex Decreases Model}}-{{Based}} in {{Favor}} of {{Model}}-Free {{Control}} in {{Humans}}},
  author = {Smittenaar, Peter and FitzGerald, Thomas H. B. and Romei, Vincenzo and Wright, Nicholas D. and Dolan, Raymond J.},
  year = {2013},
  month = nov,
  volume = {80},
  pages = {914--919},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2013.08.009},
  journal = {Neuron},
  language = {English},
  number = {4},
  pmid = {24206669}
}

@article{Solway_Goaldirected_2012,
  title = {Goal-Directed Decision Making as Probabilistic Inference: {{A}} Computational Framework and Potential Neural Correlates},
  shorttitle = {Goal-Directed Decision Making as Probabilistic Inference},
  author = {Solway, A. and Botvinick, M.},
  year = {2012},
  month = jan,
  volume = {119},
  pages = {120--154},
  issn = {0033-295X},
  doi = {10.1037/a0026435},
  abstract = {Recent work has given rise to the view that reward-based decision making is governed by two key controllers: a habit system, which stores stimulus-response associations shaped by past reward, and a goal-oriented system that selects actions based on their anticipated outcomes. The current literature provides a rich body of computational theory addressing habit formation, centering on temporal-difference learning mechanisms. Less progress has been made toward formalizing the processes involved in goal-directed decision making. We draw on recent work in cognitive neuroscience, animal conditioning, cognitive and developmental psychology and machine learning, to outline a new theory of goal-directed decision making. Our basic proposal is that the brain, within an identifiable network of cortical and subcortical structures, implements a probabilistic generative model of reward, and that goal-directed decision making is effected through Bayesian inversion of this model. We present a set of simulations implementing the account, which address benchmark behavioral and neuroscientific findings, and which give rise to a set of testable predictions. We also discuss the relationship between the proposed framework and other models of decision making, including recent models of perceptual choice, to which our theory bears a direct connection.},
  journal = {Psychological review},
  number = {1},
  pmcid = {PMC3767755},
  pmid = {22229491}
}

@article{Steel_Integrating_2006,
  title = {Integrating Theories of Motivation},
  author = {Steel, Piers and K{\"o}nig, Cornelius J.},
  year = {2006},
  volume = {31},
  pages = {889--913},
  issn = {1930-3807(Electronic),0363-7425(Print)},
  doi = {10.2307/20159257},
  abstract = {Progress toward understanding human behavior has been hindered by discipline-bound theories, dividing our efforts. Fortunately, these separate endeavors are converging and can be effectively integrated. Focusing on the fundamental features of picoeconomics, expectancy theory, cumulative prospect theory, and need theory, we construct a temporal motivational theory (TMT). TMT appears consistent with the major findings from many other investigations, including psychobiology and behaviorism. The potential implications of TMT are numerous, affecting our understanding on a wide range of topics, including group behavior, job design, stock market behavior, and goal setting. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  journal = {The Academy of Management Review},
  keywords = {Behavior,Motivation},
  number = {4}
}

@article{Steenbergen_Hedonic_2015,
  title = {Hedonic {{Hotspots Regulate Cingulate}}-Driven {{Adaptation}} to {{Cognitive Demands}}},
  author = {van Steenbergen, Henk and Band, Guido P. H. and Hommel, Bernhard and Rombouts, Serge A. R. B. and Nieuwenhuis, Sander},
  year = {2015},
  month = jul,
  volume = {25},
  pages = {1746--1756},
  issn = {1047-3211, 1460-2199},
  doi = {10.1093/cercor/bht416},
  abstract = {Positive hedonic states are known to attenuate the impact of demanding events on our body and brain, supporting adaptive behavior in response to changes in the environment. We used functional magnetic resonance imaging to examine the neural mechanism of this hedonic regulation. The effect of hedonic state (as induced by funny vs. neutral cartoons) on flexible behavioral and neural adaptation to cognitive demands was assessed in a flanker task in female volunteers. Behavioral results showed that humor reduced the compensatory adjustments to cognitive demands, as observed in sequential adaptations. This modulation was also reflected in midcingulate cortex (MCC; also known as the dorsal anterior cingulate cortex, ACC) activation. Furthermore, hedonic context increased activation in ventral striatum (VS) and ventral pallidum (VP). These hedonic hotspots attenuated the medial prefrontal cortex response to the cognitive demands in the ACC (also known as the rostral ACC). Activity in the ACC proved predictive of subsequent behavioral adaptation. Moreover, psychophysiological interaction analyses revealed that the MCC and the ACC were functionally connected with VS and VP, respectively. These observations reveal how MCC\textendash VS and VP\textendash ACC interactions are involved in the detection and hedonic modulation of behavioral adaptations to cognitive demands, which supports behavioral flexibility.},
  journal = {Cerebral Cortex},
  keywords = {Anterior cingulate cortex,basal ganglia,Cognitive control,Conflict adaptation,humor},
  language = {en},
  number = {7},
  pmid = {24451656}
}

@article{Stephan_Bayesian_2009,
  title = {Bayesian Model Selection for Group Studies},
  author = {Stephan, Klaas Enno and Penny, Will D. and Daunizeau, Jean and Moran, Rosalyn J. and Friston, Karl J.},
  year = {2009},
  month = jul,
  volume = {46},
  pages = {1004--1017},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2009.03.025},
  abstract = {Bayesian model selection (BMS) is a powerful method for determining the most likely among a set of competing hypotheses about the mechanisms that generated observed data. BMS has recently found widespread application in neuroimaging, particularly in the context of dynamic causal modelling (DCM). However, so far, combining BMS results from several subjects has relied on simple (fixed effects) metrics, e.g. the group Bayes factor (GBF), that do not account for group heterogeneity or outliers. In this paper, we compare the GBF with two random effects methods for BMS at the between-subject or group level. These methods provide inference on model-space using a classical and Bayesian perspective respectively. First, a classical (frequentist) approach uses the log model evidence as a subject-specific summary statistic. This enables one to use analysis of variance to test for differences in log-evidences over models, relative to inter-subject differences. We then consider the same problem in Bayesian terms and describe a novel hierarchical model, which is optimised to furnish a probability density on the models themselves. This new variational Bayes method rests on treating the model as a random variable and estimating the parameters of a Dirichlet distribution which describes the probabilities for all models considered. These probabilities then define a multinomial distribution over model space, allowing one to compute how likely it is that a specific model generated the data of a randomly chosen subject as well as the exceedance probability of one model being more likely than any other model. Using empirical and synthetic data, we show that optimising a conditional density of the model probabilities, given the log-evidences for each model over subjects, is more informative and appropriate than both the GBF and frequentist tests of the log-evidences. In particular, we found that the hierarchical Bayesian approach is considerably more robust than either of the other approaches in the presence of outliers. We expect that this new random effects method will prove useful for a wide range of group studies, not only in the context of DCM, but also for other modelling endeavours, e.g. comparing different source reconstruction methods for EEG/MEG or selecting among competing computational models of learning and decision-making.},
  journal = {NeuroImage},
  keywords = {Bayes factor,DCM,Dynamic causal modelling,EEG,fMRI,Hierarchical models,MEG,Model comparison,Model evidence,Random effects,Source reconstruction,Variational Bayes},
  number = {4}
}

@article{Stierle_Millisecond_2013,
  title = {Millisecond {{Stimulus Onset}}-{{Asynchrony Enhances Information}} about {{Components}} in an {{Odor Mixture}}},
  author = {Stierle, Jacob S. and Galizia, C. Giovanni and Szyszka, Paul},
  year = {2013},
  month = apr,
  volume = {33},
  pages = {6060--6069},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.5838-12.2013},
  abstract = {Airborne odorants rarely occur as pure, isolated stimuli. In a natural environment, odorants that intermingle from multiple sources create mixtures in which the onset and offset of odor components are asynchronous. Odor mixtures are known to elicit interactions in both behavioral and physiological responses, changing the perceptive quality of mixtures compared with the components. However, relevant odors need to be segregated from a distractive background. Honeybees (Apis mellifera) can use stimulus onset asynchrony of as little as 6 ms to segregate learned odor components within a mixture. Using in vivo calcium imaging of projection neurons in the honeybee, we studied neuronal mechanisms of odor-background segregation based on stimulus onset asynchrony in the antennal lobe. We found that asynchronous mixtures elicit response patterns that are different from their synchronous counterpart: the responses to asynchronous mixtures contain more information about the constituent components. With longer onset shifts, more features of the components were present in the mixture response patterns. Moreover, we found that the processing of asynchronous mixtures activated more inhibitory interactions than the processing of synchronous mixtures. This study provides evidence of neuronal mechanisms that underlie odor-object segregation on a timescale much faster than found for mammals.},
  journal = {The Journal of Neuroscience},
  language = {en},
  number = {14},
  pmid = {23554487}
}

@article{Stopfer_Impaired_1997,
  title = {Impaired Odour Discrimination on Desynchronization of Odour-Encoding Neural Assemblies},
  author = {Stopfer, Mark and Bhagavan, Seetha and Smith, Brian H. and Laurent, Gilles},
  year = {1997},
  month = nov,
  volume = {390},
  pages = {70--74},
  issn = {0028-0836},
  doi = {10.1038/36335},
  abstract = {Stimulus-evoked oscillatory synchronization of neural assemblies has been described in the olfactory and visual systems of several vertebrates and invertebrates. In locusts, information about odour identity is contained in the timing of action potentials in an oscillatory population response, suggesting that oscillations may reflect a common reference for messages encoded in time. Although the stimulus-evoked oscillatory phenomenon is reliable, its roles in sensation, perception, memory formation and pattern recognition remain to be demonstrated \textemdash{} a task requiring a behavioural paradigm. Using honeybees, we now demonstrate that odour encoding involves, as it does in locusts, the oscillatory synchronization of assemblies of projection neurons and that this synchronization is also selectively abolished by picrotoxin, an antagonist of the GABAA (-aminobutyric acid) receptor. By using a behavioural learning paradigm, we show that picrotoxin-induced desynchronization impairs the discrimination of molecularly similar odorants, but not that of dissimilar odorants. It appears, therefore, that oscillatory synchronization of neuronal assemblies is functionally relevant, and essential for fine sensory discrimination. This suggests that oscillatory synchronization and the kind of temporal encoding it affords provide an additional dimension by which the brain could segment spatially overlapping stimulus representations.},
  copyright = {\textcopyright{} 1997 Nature Publishing Group},
  journal = {Nature},
  language = {en},
  number = {6655}
}

@article{Stopfer_Impaired_1997a,
  title = {Impaired Odour Discrimination on Desynchronization of Odour-Encoding Neural Assemblies},
  author = {Stopfer, Mark and Bhagavan, Seetha and Smith, Brian H. and Laurent, Gilles},
  year = {1997},
  month = nov,
  volume = {390},
  pages = {70--74},
  issn = {0028-0836},
  doi = {10.1038/36335},
  abstract = {Stimulus-evoked oscillatory synchronization of neural assemblies has been described in the olfactory and visual systems of several vertebrates and invertebrates. In locusts, information about odour identity is contained in the timing of action potentials in an oscillatory population response, suggesting that oscillations may reflect a common reference for messages encoded in time. Although the stimulus-evoked oscillatory phenomenon is reliable, its roles in sensation, perception, memory formation and pattern recognition remain to be demonstrated \textemdash{} a task requiring a behavioural paradigm. Using honeybees, we now demonstrate that odour encoding involves, as it does in locusts, the oscillatory synchronization of assemblies of projection neurons and that this synchronization is also selectively abolished by picrotoxin, an antagonist of the GABAA (-aminobutyric acid) receptor. By using a behavioural learning paradigm, we show that picrotoxin-induced desynchronization impairs the discrimination of molecularly similar odorants, but not that of dissimilar odorants. It appears, therefore, that oscillatory synchronization of neuronal assemblies is functionally relevant, and essential for fine sensory discrimination. This suggests that oscillatory synchronization and the kind of temporal encoding it affords provide an additional dimension by which the brain could segment spatially overlapping stimulus representations.},
  copyright = {\textcopyright{} 1997 Nature Publishing Group},
  journal = {Nature},
  language = {en},
  number = {6655}
}

@article{Stopfer_Intensity_2003,
  title = {Intensity versus {{Identity Coding}} in an {{Olfactory System}}},
  author = {Stopfer, Mark and Jayaraman, Vivek and Laurent, Gilles},
  year = {2003},
  month = sep,
  volume = {39},
  pages = {991--1004},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2003.08.011},
  abstract = {We examined the encoding and decoding of odor identity and intensity by neurons in the antennal lobe and the mushroom body, first and second relays, respectively, of the locust olfactory system. Increased odor concentration led to changes in the firing patterns of individual antennal lobe projection neurons (PNs), similar to those caused by changes in odor identity, thus potentially confounding representations for identity and concentration. However, when these time-varying responses were examined across many PNs, concentration-specific patterns clustered by identity, resolving the apparent confound. This is because PN ensemble representations changed relatively continuously over a range of concentrations of each odorant. The PNs' targets in the mushroom body\textemdash Kenyon cells (KCs)\textemdash had sparse identity-specific responses with diverse degrees of concentration invariance. The tuning of KCs to identity and concentration and the patterning of their responses are consistent with piecewise decoding of their PN inputs over oscillation-cycle length epochs.},
  journal = {Neuron},
  number = {6}
}

@article{Stopfer_Shortterm_1999,
  title = {Short-Term Memory in Olfactory Network Dynamics},
  author = {Stopfer, Mark and Laurent, Gilles},
  year = {1999},
  month = dec,
  volume = {402},
  pages = {664--668},
  issn = {0028-0836},
  doi = {10.1038/45244},
  abstract = {Neural assemblies in a number of animal species display self-organized, synchronized oscillations in response to sensory stimuli in a variety of brain areas.. In the olfactory system of insects, odour-evoked oscillatory synchronization of antennal lobe projection neurons (PNs) is superimposed on slower and stimulus-specific temporal activity patterns. Hence, each odour activates a specific and dynamic projection neuron assembly whose evolution during a stimulus is locked to the oscillation clock. Here we examine, using locusts, the changes in population dynamics of projection-neuron assemblies over repeated odour stimulations, as would occur when an animal first encounters and then repeatedly samples an odour for identification or localization. We find that the responses of these assemblies rapidly decrease in intensity, while they show a marked increase in spike time precision and inter-neuronal oscillatory coherence. Once established, this enhanced precision in the representation endures for several minutes. This change is stimulus-specific, and depends on events within the antennal lobe circuits, independent of olfactory receptor adaptation: it may thus constitute a form of sensory memory. Our results suggest that this progressive change in olfactory network dynamics serves to converge, over repeated odour samplings, on a more precise and readily classifiable odour representation, using relational information contained across neural assemblies.},
  copyright = {\textcopyright{} 1999 Nature Publishing Group},
  journal = {Nature},
  language = {en},
  number = {6762}
}

@article{Strube-Bloss_Ensemble_2012,
  title = {Ensemble {{Response}} in {{Mushroom Body Output Neurons}} of the {{Honey Bee Outpaces Spatiotemporal Odor Processing Two Synapses Earlier}} in the {{Antennal Lobe}}},
  author = {{Strube-Bloss}, Martin F. and {Herrera-Valdez}, Marco A. and Smith, Brian H.},
  year = {2012},
  month = nov,
  volume = {7},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0050322},
  abstract = {Neural representations of odors are subject to computations that involve sequentially convergent and divergent anatomical connections across different areas of the brains in both mammals and insects. Furthermore, in both mammals and insects higher order brain areas are connected via feedback connections. In order to understand the transformations and interactions that this connectivity make possible, an ideal experiment would compare neural responses across different, sequential processing levels. Here we present results of recordings from a first order olfactory neuropile \textendash{} the antennal lobe (AL) \textendash{} and a higher order multimodal integration and learning center \textendash{} the mushroom body (MB) \textendash{} in the honey bee brain. We recorded projection neurons (PN) of the AL and extrinsic neurons (EN) of the MB, which provide the outputs from the two neuropils. Recordings at each level were made in different animals in some experiments and simultaneously in the same animal in others. We presented two odors and their mixture to compare odor response dynamics as well as classification speed and accuracy at each neural processing level. Surprisingly, the EN ensemble significantly starts separating odor stimuli rapidly and before the PN ensemble has reached significant separation. Furthermore the EN ensemble at the MB output reaches a maximum separation of odors between 84\textendash 120 ms after odor onset, which is 26 to 133 ms faster than the maximum separation at the AL output ensemble two synapses earlier in processing. It is likely that a subset of very fast PNs, which respond before the ENs, may initiate the rapid EN ensemble response. We suggest therefore that the timing of the EN ensemble activity would allow retroactive integration of its signal into the ongoing computation of the AL via centrifugal feedback.},
  journal = {PLoS ONE},
  number = {11},
  pmcid = {PMC3510213},
  pmid = {23209711}
}

@article{Strube-Bloss_Ensemble_2012a,
  title = {Ensemble {{Response}} in {{Mushroom Body Output Neurons}} of the {{Honey Bee Outpaces Spatiotemporal Odor Processing Two Synapses Earlier}} in the {{Antennal Lobe}}},
  author = {{Strube-Bloss}, Martin F. and {Herrera-Valdez}, Marco A. and Smith, Brian H.},
  year = {2012},
  month = nov,
  volume = {7},
  pages = {e50322},
  doi = {10.1371/journal.pone.0050322},
  abstract = {Neural representations of odors are subject to computations that involve sequentially convergent and divergent anatomical connections across different areas of the brains in both mammals and insects. Furthermore, in both mammals and insects higher order brain areas are connected via feedback connections. In order to understand the transformations and interactions that this connectivity make possible, an ideal experiment would compare neural responses across different, sequential processing levels. Here we present results of recordings from a first order olfactory neuropile \textendash{} the antennal lobe (AL) \textendash{} and a higher order multimodal integration and learning center \textendash{} the mushroom body (MB) \textendash{} in the honey bee brain. We recorded projection neurons (PN) of the AL and extrinsic neurons (EN) of the MB, which provide the outputs from the two neuropils. Recordings at each level were made in different animals in some experiments and simultaneously in the same animal in others. We presented two odors and their mixture to compare odor response dynamics as well as classification speed and accuracy at each neural processing level. Surprisingly, the EN ensemble significantly starts separating odor stimuli rapidly and before the PN ensemble has reached significant separation. Furthermore the EN ensemble at the MB output reaches a maximum separation of odors between 84\textendash 120 ms after odor onset, which is 26 to 133 ms faster than the maximum separation at the AL output ensemble two synapses earlier in processing. It is likely that a subset of very fast PNs, which respond before the ENs, may initiate the rapid EN ensemble response. We suggest therefore that the timing of the EN ensemble activity would allow retroactive integration of its signal into the ongoing computation of the AL via centrifugal feedback.},
  journal = {PLoS ONE},
  number = {11}
}

@article{Stuss_Multiple_2005,
  title = {Multiple Frontal Systems Controlling Response Speed},
  author = {Stuss, Donald T. and Alexander, Michael P. and Shallice, Tim and Picton, Terence W. and Binns, Malcolm A. and Macdonald, Ronald and Borowiec, Agnes and Katz, Douglas I.},
  year = {2005},
  volume = {43},
  pages = {396--417},
  issn = {0028-3932},
  doi = {10.1016/j.neuropsychologia.2004.06.010},
  abstract = {This study evaluated a model of attention that postulates several distinct component processes, each mediated by specific neural systems in the human frontal lobes. A series of reaction time (RT) tests (simple, choice, and prepare) examined the hypothesis that different attentional processes are related to distinct regions within the frontal lobes. These tests were given to 38 patients with frontal lesions and 38 age-matched control subjects. Lesions were localized both by general regions (superior medial, inferior medial, left and right lateral) and by individual architectonic areas. Lesions in the superior medial (SM) frontal lobes, particularly involving areas 24 and 32 on the right, were associated with slow RT in all tests and with failure to decrease RT after a warning signal. Lesions in the right lateral (RL) frontal lobe, centred in area 9/46v, prevented the decrease in RT with increasing foreperiod that was seen in normal subjects and in patients with lesions elsewhere in the frontal lobes. The ability to energize a response for rapid RT, either generally or specifically following a warning stimulus, is sensitive to lesions of the right SM. Monitoring of stimulus occurrence and response behaviour in order to enhance the speed of response to upcoming stimuli is sensitive to RL lesions.},
  journal = {Neuropsychologia},
  keywords = {Activation,frontal lobes,Monitoring,Preparatory signal,Reaction Time,Right frontal lateral},
  number = {3}
}

@article{Sutton_MDPs_1999,
  title = {Between {{MDPs}} and Semi-{{MDPs}}: {{A}} Framework for Temporal Abstraction in Reinforcement Learning},
  shorttitle = {Between {{MDPs}} and Semi-{{MDPs}}},
  author = {Sutton, Richard S. and Precup, Doina and Singh, Satinder},
  year = {1999},
  month = aug,
  volume = {112},
  pages = {181--211},
  issn = {0004-3702},
  doi = {10.1016/S0004-3702(99)00052-1},
  abstract = {Learning, planning, and representing knowledge at multiple levels of temporal abstraction are key, longstanding challenges for AI. In this paper we consider how these challenges can be addressed within the mathematical framework of reinforcement learning and Markov decision processes (MDPs). We extend the usual notion of action in this framework to include options\textemdash closed-loop policies for taking action over a period of time. Examples of options include picking up an object, going to lunch, and traveling to a distant city, as well as primitive actions such as muscle twitches and joint torques. Overall, we show that options enable temporally abstract knowledge and action to be included in the reinforcement learning framework in a natural and general way. In particular, we show that options may be used interchangeably with primitive actions in planning methods such as dynamic programming and in learning methods such as Q-learning. Formally, a set of options defined over an MDP constitutes a semi-Markov decision process (SMDP), and the theory of SMDPs provides the foundation for the theory of options. However, the most interesting issues concern the interplay between the underlying MDP and the SMDP and are thus beyond SMDP theory. We present results for three such cases: (1) we show that the results of planning with options can be used during execution to interrupt options and thereby perform even better than planned, (2) we introduce new intra-option methods that are able to learn about an option from fragments of its execution, and (3) we propose a notion of subgoal that can be used to improve the options themselves. All of these results have precursors in the existing literature; the contribution of this paper is to establish them in a simpler and more general setting with fewer changes to the existing reinforcement learning framework. In particular, we show that these results can be obtained without committing to (or ruling out) any particular approach to state abstraction, hierarchy, function approximation, or the macro-utility problem.},
  journal = {Artificial Intelligence},
  keywords = {Hierarchical planning,Intra-option learning,Macroactions,Macros,Markov decision processes,Options,Reinforcement learning,Semi-Markov decision processes,Subgoals,Temporal abstraction},
  number = {1\textendash 2}
}

@article{Sutton_modern_1981,
  title = {Toward a Modern Theory of Adaptive Networks: {{Expectation}} and Prediction},
  shorttitle = {Toward a Modern Theory of Adaptive Networks},
  author = {Sutton, Richard S. and Barto, Andrew G.},
  year = {1981},
  volume = {88},
  pages = {135--170},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1471(Electronic),0033-295X(Print)},
  doi = {10.1037/0033-295X.88.2.135},
  abstract = {Many adaptive neural network (AN) theories are based on neuronlike adaptive elements that can behave as single unit analogs of associative conditioning. This article describes a similar adaptive element, but one that is more closely in accord with the facts of animal learning theory than elements commonly studied in AN research. It is suggested that an essential feature of classical conditioning that has been largely overlooked by AN theorists is its predictive nature. The adaptive element learns to increase its response rate in anticipation of increased stimulation, producing a CR before the occurrence of the UCS. The element also is in strong agreement with the behavioral data regarding the effects of stimulus context, since it is a temporally refined extension of the model proposed by R. A. Rescorla and A. R. Wagner (1972). Computer simulation demonstrates that the element becomes sensitive to the most reliable, nonredundant, and earliest predictors of reinforcement. The model is discussed in light of recent advances in the physiology and biochemistry of synaptic mechanisms. (2{$\frac{1}{2}$} p ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  journal = {Psychological Review},
  keywords = {Classical Conditioning,Learning Theory,Literature Review,Reinforcement},
  number = {2}
}

@book{Sutton_Reinforcement_2018,
  title = {Reinforcement {{Learning}}: {{An Introduction}}},
  shorttitle = {Reinforcement {{Learning}}},
  author = {Sutton, Richard S. and Barto, Andrew G.},
  year = {2018},
  publisher = {{A Bradford Book}},
  address = {{Cambridge, MA, USA}},
  abstract = {The significantly expanded and updated new edition of a widely used text on reinforcement learning, one of the most active research areas in artificial intelligence. Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms. This second edition has been significantly expanded and updated, presenting new topics and updating coverage of other topics. Like the first edition, this second edition focuses on core online learning algorithms, with the more mathematical material set off in shaded boxes. Part I covers as much of reinforcement learning as possible without going beyond the tabular case for which exact solutions can be found. Many algorithms presented in this part are new to the second edition, including UCB, Expected Sarsa, and Double Learning. Part II extends these ideas to function approximation, with new sections on such topics as artificial neural networks and the Fourier basis, and offers expanded treatment of off-policy learning and policy-gradient methods. Part III has new chapters on reinforcement learning's relationships to psychology and neuroscience, as well as an updated case-studies chapter including AlphaGo and AlphaGo Zero, Atari game playing, and IBM Watson's wagering strategy. The final chapter discusses the future societal impacts of reinforcement learning.},
  isbn = {978-0-262-03924-6}
}

@article{Szyszka_Sparsening_2005,
  title = {{Sparsening and temporal sharpening of olfacoty representations in the honeybee mushroom bodies}},
  author = {Szyszka, Paul},
  year = {2005},
  journal = {Journal of Neurophysiology},
  language = {2005}
}

@article{Takeda_Explanation_2019,
  title = {Explanation of {{Fitts}}' Law in {{Reaching Movement}} Based on {{Human Arm Dynamics}}},
  author = {Takeda, Misaki and Sato, Takanori and Saito, Hisashi and Iwasaki, Hiroshi and Nambu, Isao and Wada, Yasuhiro},
  year = {2019},
  month = dec,
  volume = {9},
  issn = {2045-2322},
  doi = {10.1038/s41598-019-56016-7},
  abstract = {Why does Fitts' law fit various human behavioural data well even though it is not a model based on human physical dynamics? To clarify this, we derived the relationships among the factors applied in Fitts' law\textemdash movement duration and spatial endpoint error\textemdash based on a multi-joint forward- and inverse-dynamics models in the presence of signal-dependent noise. As a result, the relationship between them was modelled as an inverse proportion. To validate whether the endpoint error calculated by the model can represent the endpoint error of actual movements, we conducted a behavioural experiment in which centre-out reaching movements were performed under temporal constraints in four directions using the shoulder and elbow joints. The result showed that the distributions of model endpoint error closely expressed the observed endpoint error distributions. Furthermore, the model was found to be nearly consistent with Fitts' law. Further analysis revealed that the coefficients of Fitts' law could be expressed by arm dynamics and signal-dependent noise parameters. Consequently, our answer to the question above is: Fitts' law for reaching movements can be expressed based on human arm dynamics; thus, Fitts' law closely fits human's behavioural data under various conditions.},
  journal = {Scientific Reports},
  pmcid = {PMC6930222},
  pmid = {31874974}
}

@article{Talmi_How_2012,
  title = {How {{Costs Influence Decision Values}} for {{Mixed Outcomes}}},
  author = {Talmi, Deborah and Pine, Alex},
  year = {2012},
  month = oct,
  volume = {6},
  issn = {1662-4548},
  doi = {10.3389/fnins.2012.00146},
  abstract = {The things that we hold dearest often require a sacrifice, as epitomized in the maxim ``no pain, no gain.'' But how is the subjective value of outcomes established when they consist of mixtures of costs and benefits? We describe theoretical models for the integration of costs and benefits into a single value, drawing on both the economic and the empirical literatures, with the goal of rendering them accessible to the neuroscience community. We propose two key assays that go beyond goodness of fit for deciding between the dominant additive model and four varieties of interactive models. First, how they model decisions between costs when reward is not on offer; and second, whether they predict changes in reward sensitivity when costs are added to outcomes, and in what direction. We provide a selective review of relevant neurobiological work from a computational perspective, focusing on those studies that illuminate the underlying valuation mechanisms. Cognitive neuroscience has great potential to decide which of the theoretical models is actually employed by our brains, but empirical work has yet to fully embrace this challenge. We hope that future research improves our understanding of how our brain decides whether mixed outcomes are worthwhile.},
  journal = {Frontiers in Neuroscience},
  pmcid = {PMC3481112},
  pmid = {23112758}
}

@article{Tanaka_Neuronal_2008,
  title = {Neuronal Assemblies of the {{Drosophila}} Mushroom Body},
  author = {Tanaka, Nobuaki K. and Tanimoto, Hiromu and Ito, Kei},
  year = {2008},
  volume = {508},
  pages = {711--755},
  issn = {1096-9861},
  doi = {10.1002/cne.21692},
  abstract = {The mushroom body (MB) of the insect brain has important roles in odor learning and memory and in diverse other brain functions. To elucidate the anatomical basis underlying its function, we studied how the MB of Drosophila is organized by its intrinsic and extrinsic neurons. We screened for the GAL4 enhancer-trap strains that label specific subsets of these neurons and identified seven subtypes of Kenyon cells and three other intrinsic neuron types. Laminar organization of the Kenyon cell axons divides the pedunculus into at least five concentric strata. The {$\alpha{'}$}, {$\beta{'}$}, {$\alpha$}, and {$\beta$} lobes are each divided into three strata, whereas the {$\gamma$} lobe appears more homogeneous. The outermost stratum of the {$\alpha$}/{$\beta$} lobes is specifically connected with a small, protruded subregion of the calyx, the accessory calyx, which does not receive direct olfactory input. As for the MB extrinsic neurons (MBENs), we found three types of antennal lobe projection neurons, among which two are novel. In addition, we resolved 17 other types of MBENs that arborize in the calyx, lobes, and pedunculus. Lobe-associated MBENs arborize in only specific areas of the lobes, being restricted along their longitudinal axes, forming two to five segmented zones in each lobe. The laminar arrangement of the Kenyon cell axons and segmented organization of the MBENs together divide the lobes into smaller synaptic units, possibly facilitating characteristic interaction between intrinsic and extrinsic neurons in each unit for different functional activities along the longitudinal lobe axes and between lobes. Structural differences between lobes are also discussed. J. Comp. Neurol. 508:711\textendash 755, 2008. \textcopyright{} 2008 Wiley-Liss, Inc.},
  journal = {The Journal of Comparative Neurology},
  keywords = {extrinsic neuron,insect,intrinsic neuron,Kenyon cell,mushroom body,neural circuit,Olfaction},
  number = {5}
}

@article{Tangney_High_2004,
  title = {High {{Self}}-{{Control Predicts Good Adjustment}}, {{Less Pathology}}, {{Better Grades}}, and {{Interpersonal Success}}},
  author = {Tangney, June P. and Baumeister, Roy F. and Boone, Angie Luzio},
  year = {2004},
  volume = {72},
  pages = {271--324},
  issn = {1467-6494},
  doi = {10.1111/j.0022-3506.2004.00263.x},
  abstract = {What good is self-control? We incorporated a new measure of individual differences in self-control into two large investigations of a broad spectrum of behaviors. The new scale showed good internal consistency and retest reliability. Higher scores on self-control correlated with a higher grade point average, better adjustment (fewer reports of psychopathology, higher self-esteem), less binge eating and alcohol abuse, better relationships and interpersonal skills, secure attachment, and more optimal emotional responses. Tests for curvilinearity failed to indicate any drawbacks of so-called overcontrol, and the positive effects remained after controlling for social desirability. Low self-control is thus a significant risk factor for a broad range of personal and interpersonal problems.},
  journal = {Journal of Personality},
  language = {en},
  number = {2}
}

@article{Tartaglia_What_2017,
  title = {What to {{Choose Next}}? {{A Paradigm}} for {{Testing Human Sequential Decision Making}}},
  shorttitle = {What to {{Choose Next}}?},
  author = {Tartaglia, Elisa M. and Clarke, Aaron M. and Herzog, Michael H.},
  year = {2017},
  volume = {8},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2017.00312},
  abstract = {Many of the decisions we make in our everyday lives are sequential and entail sparse rewards. While sequential decision-making has been extensively investigated in theory (e.g., by reinforcement learning models) there is no systematic experimental paradigm to test it. Here, we developed such a paradigm and investigated key components of reinforcement learning models: the eligibility trace (i.e., the memory trace of previous decision steps), the external rewards, and the ability to exploit the statistics of the environment's structure (model-free versus model-based mechanisms). We show that the eligibility trace decays not with sheer time, but rather with the number of discrete decision steps made by the participants. We further show that, unexpectedly, neither monetary rewards nor the environment's spatial regularity significantly modulate behavioral performance. Finally, we found that model-free learning algorithms describe human performance better than model-based algorithms.},
  journal = {Frontiers in Psychology},
  keywords = {exploration,Q-learning,reinforcement learning,Sarsa(),Sequential decision making},
  language = {English}
}

@article{Tervo_Behavioral_2014,
  title = {Behavioral {{Variability}} through {{Stochastic Choice}} and {{Its Gating}} by {{Anterior Cingulate Cortex}}},
  author = {Tervo, Dougal G. R. and Proskurin, Mikhail and Manakov, Maxim and Kabra, Mayank and Vollmer, Alison and Branson, Kristin and Karpova, Alla Y.},
  year = {2014},
  month = sep,
  volume = {159},
  pages = {21--32},
  issn = {0092-8674},
  doi = {10.1016/j.cell.2014.08.037},
  abstract = {Summary Behavioral choices that ignore prior experience promote exploration and unpredictability but are seemingly at odds with the brain's tendency to use experience to optimize behavioral choice. Indeed, when faced with virtual competitors, primates resort to strategic counterprediction rather than to stochastic choice. Here, we show that rats also use history- and model-based strategies when faced with similar competitors but can switch to a ``stochastic'' mode when challenged with a competitor that they cannot defeat by counterprediction. In this mode, outcomes associated with an animal's actions are ignored, and normal engagement of anterior cingulate cortex (ACC) is suppressed. Using circuit perturbations in~transgenic rats, we demonstrate that switching between strategic and stochastic behavioral modes is controlled by locus coeruleus input into ACC. Our~findings suggest that, under conditions of uncertainty about environmental rules, changes in noradrenergic input alter ACC output and prevent erroneous beliefs from guiding decisions, thus enabling behavioral variation. PaperClip},
  journal = {Cell},
  number = {1}
}

@book{Thorndike_Animal_1898,
  title = {Animal Intelligence : An Experimental Study of the Associative Processes in Animals},
  shorttitle = {Animal Intelligence},
  author = {Thorndike, Edward L. (Edward Lee)},
  year = {1898},
  publisher = {{New York : Macmillan}},
  abstract = {24},
  collaborator = {{OISE - University of Toronto}},
  keywords = {Animal intelligence},
  language = {eng},
  lccn = {AXM-2305}
}

@article{Thrailkill_Contextual_2015,
  title = {Contextual Control of Instrumental Actions and Habits},
  author = {Thrailkill, Eric A. and Bouton, Mark E.},
  year = {2015},
  month = jan,
  volume = {41},
  pages = {69--80},
  issn = {2329-8456},
  doi = {10.1037/xan0000045},
  abstract = {After a relatively small amount of training, instrumental behavior is thought to be an action under the control of the motivational status of its goal or reinforcer. After more extended training, behavior can become habitual and insensitive to changes in reinforcer value. Recently, instrumental responding has been shown to weaken when tested outside of the training context. The present experiments compared the sensitivity of instrumental responding in rats to a context switch after training procedures that might differentially generate actions or habits. In Experiment 1, lever pressing was decremented in a new context after either short, medium, or long periods of training on either random-ratio or yoked random-interval reinforcement schedules. Experiment 2 found that more minimally-trained responding was also sensitive to a context switch. Moreover, Experiment 3 showed that when the goal-directed component of responding was removed by devaluing the reinforcer, the residual responding that remained was still sensitive to the change of context. Goal-directed responding, in contrast, transferred across contexts. Experiment 4 then found that after extensive training, a habit that was insensitive to reinforcer devaluation was still decremented by a context switch. Overall, the results suggest that a context switch primarily influences instrumental habit rather than action. In addition, even a response that has received relatively minimal training may have a habit component that is insensitive to reinforcer devaluation but sensitive to the effects of a context switch.},
  journal = {Journal of experimental psychology. Animal learning and cognition},
  keywords = {animal,rats,training},
  number = {1},
  pmcid = {PMC4339261},
  pmid = {25706547}
}

@article{Thut_aBand_2006,
  title = {{$\alpha$}-{{Band Electroencephalographic Activity}} over {{Occipital Cortex Indexes Visuospatial Attention Bias}} and {{Predicts Visual Target Detection}}},
  author = {Thut, Gregor and Nietzel, Annika and Brandt, Stephan A. and {Pascual-Leone}, Alvaro},
  year = {2006},
  month = sep,
  volume = {26},
  pages = {9494--9502},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.0875-06.2006},
  abstract = {Covertly directing visual attention toward a spatial location in the absence of visual stimulation enhances future visual processing at the attended position. The neuronal correlates of these attention shifts involve modulation of neuronal ``baseline'' activity in early visual areas, presumably through top-down control from higher-order attentional systems. We used electroencephalography to study the largely unknown relationship between these neuronal modulations and behavioral outcome in an attention orienting paradigm. Covert visuospatial attention shifts to either a left or right peripheral position in the absence of visual stimulation resulted in differential modulations of oscillatory {$\alpha$}-band (8\textendash 14 Hz) activity over left versus right posterior sites. These changes were driven by varying degrees of {$\alpha$}-decreases being maximal contralateral to the attended position. When expressed as a lateralization index, these {$\alpha$}-changes differed significantly between attention conditions, with negative values ({$\alpha\_$}right {$<$} {$\alpha\_$}left) indexing leftward and more positive values ({$\alpha\_$}left {$\leq$} {$\alpha\_$}right) indexing rightward attention. Moreover, this index appeared deterministic for processing of forthcoming visual targets. Collapsed over trials, there was an advantage for left target processing in accordance with an overall negative bias in {$\alpha$}-index values. Across trials, left targets were detected most rapidly when preceded by negative index values. Detection of right targets was fastest in trials with most positive values. Our data indicate that collateral modulations of posterior {$\alpha$}-activity, the momentary bias of visuospatial attention, and imminent visual processing are linked. They suggest that the momentary direction of attention, predicting spatial biases in imminent visual processing, can be estimated from a lateralization index of posterior {$\alpha$}-activity.},
  journal = {The Journal of Neuroscience},
  keywords = {alpha,cueing,lateralization index,oscillations,spatial attention,TSE},
  language = {en},
  number = {37},
  pmid = {16971533}
}

@article{Todorov_Optimal_2002,
  title = {Optimal Feedback Control as a Theory of Motor Coordination},
  author = {Todorov, Emanuel and Jordan, Michael I.},
  year = {2002},
  month = nov,
  volume = {5},
  pages = {1226--1235},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/nn963},
  abstract = {A central problem in motor control is understanding how the many biomechanical degrees of freedom are coordinated to achieve a common goal. An especially puzzling aspect of coordination is that behavioral goals are achieved reliably and repeatedly with movements rarely reproducible in their detail. Existing theoretical frameworks emphasize either goal achievement or the richness of motor variability, but fail to reconcile the two. Here we propose an alternative theory based on stochastic optimal feedback control. We show that the optimal strategy in the face of uncertainty is to allow variability in redundant (task-irrelevant) dimensions. This strategy does not enforce a desired trajectory, but uses feedback more intelligently, correcting only those deviations that interfere with task goals. From this framework, task-constrained variability, goal-directed corrections, motor synergies, controlled parameters, simplifying rules and discrete coordination modes emerge naturally. We present experimental results from a range of motor tasks to support this theory.},
  copyright = {2002 Nature Publishing Group},
  journal = {Nature Neuroscience},
  language = {en},
  number = {11}
}

@article{Todorov_Optimality_2004,
  title = {Optimality Principles in Sensorimotor Control},
  author = {Todorov, Emanuel},
  year = {2004},
  month = sep,
  volume = {7},
  pages = {907--915},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/nn1309},
  abstract = {The sensorimotor system is a product of evolution, development, learning and adaptation\textemdash which work on different time scales to improve behavioral performance. Consequently, many theories of motor function are based on 'optimal performance': they quantify task goals as cost functions, and apply the sophisticated tools of optimal control theory to obtain detailed behavioral predictions. The resulting models, although not without limitations, have explained more empirical phenomena than any other class. Traditional emphasis has been on optimizing desired movement trajectories while ignoring sensory feedback. Recent work has redefined optimality in terms of feedback control laws, and focused on the mechanisms that generate behavior online. This approach has allowed researchers to fit previously unrelated concepts and observations into what may become a unified theoretical framework for interpreting motor function. At the heart of the framework is the relationship between high-level goals, and the real-time sensorimotor control strategies most suitable for accomplishing those goals.},
  copyright = {2004 Nature Publishing Group},
  journal = {Nature Neuroscience},
  language = {en},
  number = {9}
}

@article{Tort_Cortical_2010,
  title = {Cortical {{Networks Produce Three Distinct}} 7-12 {{Hz Rhythms}} during {{Single Sensory Responses}} in the {{Awake Rat}}},
  author = {Tort, Adriano B. L. and Fontanini, Alfredo and Kramer, Mark A. and {Jones-Lush}, Lauren M. and Kopell, Nancy J. and Katz, Donald B.},
  year = {2010},
  month = mar,
  volume = {30},
  pages = {4315--4324},
  issn = {0270-6474},
  doi = {10.1523/JNEUROSCI.6051-09.2010},
  abstract = {Cortical rhythms in the alpha/mu frequency range (7-12 Hz) have been variously related to "idling," anticipation, seizure, and short-term or working memory. This overabundance of interpretations suggests that sensory cortex may be able to produce more than one (and even more than two) distinct alpha/mu rhythms. Here we describe simultaneous local field potential and single-neuron recordings made from primary sensory (gustatory) cortex of awake rats and reveal three distinct 7-12 Hz de novo network rhythms within single sessions: an " early," taste-induced similar to 11 Hz rhythm, the first peak of which was a short-latency gustatory evoked potential; a " late," significantly lower-frequency (similar to 7 Hz) rhythm that replaced this first rhythm at similar to 750-850 ms after stimulus onset (consistently timed with a previously described shift in taste temporal codes); and a "spontaneous" spike-and-wave rhythm of intermediate peak frequency (similar to 9 Hz) that appeared late in the session, as part of a oft-described reduction in arousal/attention. These rhythms proved dissociable on many grounds: in addition to having different peak frequencies, amplitudes, and shapes and appearing at different time points (although often within single 3 s snippets of activity), the early and late rhythms proved to have completely uncorrelated session-to-session variability, and the spontaneous rhythm affected the early rhythm only (having no impact on the late rhythm). Analysis of spike-to-wave coupling suggested that the early and late rhythms are a unified part of discriminative taste process: the identity of phase-coupled single-neuron ensembles differed from taste to taste, and coupling typically lasted across the change in frequency. These data reveal that even rhythms confined to a narrow frequency band may still have distinct properties.},
  annotation = {WOS:000275950100016},
  journal = {Journal of Neuroscience},
  keywords = {eeg alpha-activity,gamma   oscillations,gustatory cortex,mu rhythm,performance,reflects,synchronization,taste,theta-oscillations,visual-cortex},
  language = {English},
  number = {12}
}

@inproceedings{Toussaint_Probabilistic_2006,
  title = {Probabilistic Inference for Solving Discrete and Continuous State {{Markov Decision Processes}}},
  booktitle = {Proceedings of the 23rd International Conference on {{Machine}} Learning},
  author = {Toussaint, Marc and Storkey, Amos},
  year = {2006},
  month = jun,
  pages = {945--952},
  publisher = {{Association for Computing Machinery}},
  address = {{Pittsburgh, Pennsylvania, USA}},
  doi = {10.1145/1143844.1143963},
  abstract = {Inference in Markov Decision Processes has recently received interest as a means to infer goals of an observed action, policy recognition, and also as a tool to compute policies. A particularly interesting aspect of the approach is that any existing inference technique in DBNs now becomes available for answering behavioral question--including those on continuous, factorial, or hierarchical state representations. Here we present an Expectation Maximization algorithm for computing optimal policies. Unlike previous approaches we can show that this actually optimizes the discounted expected future return for arbitrary reward functions and without assuming an ad hoc finite total time. The algorithm is generic in that any inference technique can be utilized in the E-step. We demonstrate this for exact inference on a discrete maze and Gaussian belief state propagation in continuous stochastic optimal control problems.},
  isbn = {978-1-59593-383-6},
  series = {{{ICML}} '06}
}

@article{Tschantz_Control_2020,
  title = {Control as {{Hybrid Inference}}},
  author = {Tschantz, Alexander and Millidge, Beren and Seth, Anil K. and Buckley, Christopher L.},
  year = {2020},
  month = jul,
  abstract = {The field of reinforcement learning can be split into model-based and model-free methods. Here, we unify these approaches by casting model-free policy optimisation as amortised variational inference, and model-based planning as iterative variational inference, within a `control as hybrid inference' (CHI) framework. We present an implementation of CHI which naturally mediates the balance between iterative and amortised inference. Using a didactic experiment, we demonstrate that the proposed algorithm operates in a model-based manner at the onset of learning, before converging to a model-free algorithm once sufficient data have been collected. We verify the scalability of our algorithm on a continuous control benchmark, demonstrating that it outperforms strong model-free and model-based baselines. CHI thus provides a principled framework for harnessing the sample efficiency of model-based planning while retaining the asymptotic performance of model-free policy optimisation.},
  archivePrefix = {arXiv},
  eprint = {2007.05838},
  eprinttype = {arxiv},
  journal = {arXiv:2007.05838 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{Turner_Olfactory_2008,
  title = {Olfactory {{Representations}} by {{Drosophila Mushroom Body Neurons}}},
  author = {Turner, Glenn C. and Bazhenov, Maxim and Laurent, Gilles},
  year = {2008},
  month = feb,
  volume = {99},
  pages = {734--746},
  issn = {0022-3077, 1522-1598},
  doi = {10.1152/jn.01283.2007},
  abstract = {Learning and memory has been studied extensively in Drosophila using behavioral, molecular, and genetic approaches. These studies have identified the mushroom body as essential for the formation and retrieval of olfactory memories. We investigated odor responses of the principal neurons of the mushroom body, the Kenyon cells (KCs), in Drosophila using whole cell recordings in vivo. KC responses to odors were highly selective and, thus sparse, compared with those of their direct inputs, the antennal lobe projection neurons (PNs). We examined the mechanisms that might underlie this transformation and identified at least three contributing factors: excitatory synaptic potentials (from PNs) decay rapidly, curtailing temporal integration, PN convergence onto individual KCs is low ({$\sim$}10 PNs per KC on average), and KC firing thresholds are high. Sparse activity is thought to be useful in structures involved in memory in part because sparseness tends to reduce representation overlaps. By comparing activity patterns evoked by the same odors across olfactory receptor neurons and across KCs, we show that representations of different odors do indeed become less correlated as they progress through the olfactory system.},
  annotation = {Learning and memory has been studied extensively in Drosophila using behavioral, molecular, and genetic approaches. These studies have identified the mushroom body as essential for the formation and retrieval of olfactory memories. We investigated odor responses of the principal neurons of the mushroom body, the Kenyon cells (KCs), in Drosophila using whole cell recordings in vivo. KC responses to odors were highly selective and, thus sparse, compared with those of their direct inputs, the antennal lobe projection neurons (PNs). We examined the mechanisms that might underlie this transformation and identified at least three contributing factors: excitatory synaptic potentials (from PNs) decay rapidly, curtailing temporal integration, PN convergence onto individual KCs is low ({$\sim$}10 PNs per KC on average), and KC firing thresholds are high. Sparse activity is thought to be useful in structures involved in memory in part because sparseness tends to reduce representation overlaps. By comparing activity patterns evoked by the same odors across olfactory receptor neurons and across KCs, we show that representations of different odors do indeed become less correlated as they progress through the olfactory system.},
  copyright = {Copyright \textcopyright{} 2008 by the American Physiological Society},
  journal = {Journal of Neurophysiology},
  language = {en},
  number = {2},
  pmid = {18094099}
}

@article{Turner_Olfactory_2008a,
  title = {Olfactory {{Representations}} by {{Drosophila Mushroom Body Neurons}}},
  author = {Turner, Glenn C. and Bazhenov, Maxim and Laurent, Gilles},
  year = {2008},
  month = feb,
  volume = {99},
  pages = {734--746},
  issn = {0022-3077, 1522-1598},
  doi = {10.1152/jn.01283.2007},
  abstract = {Learning and memory has been studied extensively in Drosophila using behavioral, molecular, and genetic approaches. These studies have identified the mushroom body as essential for the formation and retrieval of olfactory memories. We investigated odor responses of the principal neurons of the mushroom body, the Kenyon cells (KCs), in Drosophila using whole cell recordings in vivo. KC responses to odors were highly selective and, thus sparse, compared with those of their direct inputs, the antennal lobe projection neurons (PNs). We examined the mechanisms that might underlie this transformation and identified at least three contributing factors: excitatory synaptic potentials (from PNs) decay rapidly, curtailing temporal integration, PN convergence onto individual KCs is low ({$\sim$}10 PNs per KC on average), and KC firing thresholds are high. Sparse activity is thought to be useful in structures involved in memory in part because sparseness tends to reduce representation overlaps. By comparing activity patterns evoked by the same odors across olfactory receptor neurons and across KCs, we show that representations of different odors do indeed become less correlated as they progress through the olfactory system.},
  annotation = {Learning and memory has been studied extensively in Drosophila using behavioral, molecular, and genetic approaches. These studies have identified the mushroom body as essential for the formation and retrieval of olfactory memories. We investigated odor responses of the principal neurons of the mushroom body, the Kenyon cells (KCs), in Drosophila using whole cell recordings in vivo. KC responses to odors were highly selective and, thus sparse, compared with those of their direct inputs, the antennal lobe projection neurons (PNs). We examined the mechanisms that might underlie this transformation and identified at least three contributing factors: excitatory synaptic potentials (from PNs) decay rapidly, curtailing temporal integration, PN convergence onto individual KCs is low ({$\sim$}10 PNs per KC on average), and KC firing thresholds are high. Sparse activity is thought to be useful in structures involved in memory in part because sparseness tends to reduce representation overlaps. By comparing activity patterns evoked by the same odors across olfactory receptor neurons and across KCs, we show that representations of different odors do indeed become less correlated as they progress through the olfactory system.},
  copyright = {Copyright \textcopyright{} 2008 by the American Physiological Society},
  journal = {Journal of Neurophysiology},
  language = {en},
  number = {2},
  pmid = {18094099}
}

@article{Tversky_Advances_1992,
  title = {Advances in Prospect Theory: {{Cumulative}} Representation of Uncertainty},
  shorttitle = {Advances in Prospect Theory},
  author = {Tversky, Amos and Kahneman, Daniel},
  year = {1992},
  month = oct,
  volume = {5},
  pages = {297--323},
  issn = {1573-0476},
  doi = {10.1007/BF00122574},
  abstract = {We develop a new version of prospect theory that employs cumulative rather than separable decision weights and extends the theory in several respects. This version, called cumulative prospect theory, applies to uncertain as well as to risky prospects with any number of outcomes, and it allows different weighting functions for gains and for losses. Two principles, diminishing sensitivity and loss aversion, are invoked to explain the characteristic curvature of the value function and the weighting functions. A review of the experimental evidence and the results of a new experiment confirm a distinctive fourfold pattern of risk attitudes: risk aversion for gains and risk seeking for losses of high probability; risk seeking for gains and risk aversion for losses of low probability.This article has benefited from discussions with Colin Camerer, Chew Soo-Hong, David Freedman, and David H. Krantz. We are especially grateful to Peter P. Wakker for his invaluable input and contribution to the axiomatic analysis. We are indebted to Richard Gonzalez and Amy Hayes for running the experiment and analyzing the data. This work was supported by Grants 89-0064 and 88-0206 from the Air Force Office of Scientific Research, by Grant SES-9109535 from the National Science Foundation, and by the Sloan Foundation.},
  journal = {Journal of Risk and Uncertainty},
  keywords = {cumulative prospect theory},
  language = {en},
  number = {4}
}

@article{Uchida_Speed_2003,
  title = {Speed and Accuracy of Olfactory Discrimination in the Rat},
  author = {Uchida, Naoshige and Mainen, Zachary F},
  year = {2003},
  month = nov,
  volume = {6},
  pages = {1224--1229},
  issn = {1097-6256},
  doi = {10.1038/nn1142},
  abstract = {The sense of smell is typically thought of as a 'slow' sense, but the true temporal constraints on the accuracy of olfactory perception are not known. It has been proposed that animals make finer odor discriminations at the expense of additional processing time. To test this idea, we measured the relationship between the speed and accuracy of olfactory discrimination in rats. We found that speed of discrimination was independent of odor similarity, as measured by overlap of glomerular activity patterns. Even when pushed to psychophysical limits using mixtures of two odors, rats needed to take only one sniff ({$<$}200 ms at theta frequency) to make a decision of maximum accuracy. These results show that, for the purpose of odor quality discrimination, a fully refined olfactory sensory representation can emerge within a single sensorimotor or theta cycle, suggesting that each sniff can be considered a snapshot of the olfactory world.},
  journal = {Nature neuroscience},
  keywords = {Animals,Behavior; Animal,Choice Behavior,Cluster Analysis,Discrimination (Psychology),Evoked Potentials,Inhalation,Male,Movement,Odors,Olfactory Bulb,Olfactory Pathways,Psychometrics,Rats,Rats; Long-Evans,Reaction Time,Respiration,Sensory Thresholds,Smell,Space Perception,Stimulation; Chemical,Time Factors},
  language = {eng},
  number = {11},
  pmid = {14566341}
}

@article{Uno_Formation_1989,
  title = {Formation and Control of Optimal Trajectory in Human Multijoint Arm Movement},
  author = {Uno, Y. and Kawato, M. and Suzuki, R.},
  year = {1989},
  month = jun,
  volume = {61},
  pages = {89--101},
  issn = {1432-0770},
  doi = {10.1007/BF00204593},
  abstract = {In this paper, we study trajectory planning and control in voluntary, human arm movements. When a hand is moved to a target, the central nervous system must select one specific trajectory among an infinite number of possible trajectories that lead to the target position. First, we discuss what criterion is adopted for trajectory determination. Several researchers measured the hand trajectories of skilled movements and found common invariant features. For example, when moving the hand between a pair of targets, subjects tended to generate roughly straight hand paths with bell-shaped speed profiles. On the basis of these observations and dynamic optimization theory, we propose a mathematical model which accounts for formation of hand trajectories. This model is formulated by defining an objective function, a measure of performance for any possible movement: square of the rate of change of torque integrated over the entire movement. That is, the objective function CT is defined as follows: \$\$C\_T  = \textbackslash frac\{1\}\{2\}\{\}\^t\textbackslash int\textbackslash limits\_0\^f \{\textbackslash sum\textbackslash limits\_\{i = 1\}\^n \{\textbackslash left( \{\textbackslash frac\{\{\{\textbackslash text\{d\}\}z\_i \}\}\{\{\{\textbackslash text\{d\}\}t\}\}\} \textbackslash right)\^2 \{\textbackslash text\{d\}\}t,\} \} \$\$where ziis the torque generated by the i-th actuator (muslce) out of n actuators, and tfis the movement time. Since this objective function critically depends on the complex nonlinear dynamics of the musculoskeletal system, it is very difficult to determine the unique trajectory which yields the best performance. We overcome this difficult by developing an iterative scheme, with which the optimal trajectory and the associated motor command are simultaneously computed. To evaluate our model, human hand trajectories were experimentally measured under various behavioral situations. These results supported the idea that the human hand trajectory is planned and controlled in accordance with the minimum torquechange criterion.},
  journal = {Biological Cybernetics},
  language = {en},
  number = {2}
}

@article{Vandierendonck_Working_2016,
  title = {A {{Working Memory System With Distributed Executive Control}}},
  author = {Vandierendonck, Andr{\'e}},
  year = {2016},
  month = jan,
  volume = {11},
  pages = {74--100},
  issn = {1745-6924},
  doi = {10.1177/1745691615596790},
  abstract = {Working memory consists of domain-specific storage facilities and domain-general executive control processes. In some working memory theories, these control processes are accounted for via a homunculus, the central executive. In the present article, the author defends a mechanistic view of executive control by adopting the position that executive control is situated in the context of goal-directed behavior to maintain and protect the goal and to select an action to attain the goal. On the basis of findings in task switching and dual tasking, he proposes an adapted multicomponent working memory model in which the central executive is replaced by three interacting components: an executive memory that maintains the task set, a collection of acquired procedural rules, and an engine that executes the procedural rules that match the ensemble of working memory contents. The strongest among the rules that match the ensemble of working memory contents is applied, resulting in changes of the working memory contents or in motor actions. According to this model, goals are attained when the route to the goals is known or can be searched when the route is unknown (problem solving). Empirical evidence for this proposal and new predictions are discussed.},
  journal = {Perspectives on Psychological Science: A Journal of the Association for Psychological Science},
  keywords = {executive control,Executive function,Task switching,working memory},
  language = {eng},
  number = {1},
  pmid = {26817727}
}

@article{vanNoordt_Watch_2015,
  title = {Watch out! {{Medial}} Frontal Cortex Is Activated by Cues Signaling Potential Changes in Response Demands},
  author = {{van Noordt}, Stefon J. R. and Desjardins, James A. and Segalowitz, Sidney J.},
  year = {2015},
  month = jul,
  volume = {114},
  pages = {356--370},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2015.04.021},
  abstract = {The human medial frontal cortex and especially the anterior cingulate cortex (ACC) have been implicated in several aspects of performance monitoring. We examined event-related EEG during a general process of controlling attention by using a novel paradigm to elicit a medial frontal negativity (MFN) to stimuli that indicate potential changes in future response demands. Independent components analysis revealed that the latent factors that accounted for MFN activity to such changes also accounted for activity associated with the error-related negativity and the NoGo inhibitory N2. Given that the medial frontal activation to these changes varied reliably across subjects simply as a function of potential need to alter responses in the absence of error commission and response inhibition, we propose that the underlying basis for medial frontal activation in situations demanding ongoing monitoring of performance involves an increase in attention control, a factor common to all MFN paradigms.},
  journal = {NeuroImage},
  keywords = {Anterior cingulate cortex,ERN,Independent components analysis,Performance monitoring,Robust estimation,Task switching}
}

@article{Vassena_Overlapping_2014,
  title = {Overlapping {{Neural Systems Represent Cognitive Effort}} and {{Reward Anticipation}}},
  author = {Vassena, Eliana and Silvetti, Massimo and Boehler, Carsten N. and Achten, Eric and Fias, Wim and Verguts, Tom},
  year = {2014},
  month = mar,
  volume = {9},
  pages = {e91008},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0091008},
  abstract = {Anticipating a potential benefit and how difficult it will be to obtain it are valuable skills in a constantly changing environment. In the human brain, the anticipation of reward is encoded by the Anterior Cingulate Cortex (ACC) and Striatum. Naturally, potential rewards have an incentive quality, resulting in a motivational effect improving performance. Recently it has been proposed that an upcoming task requiring effort induces a similar anticipation mechanism as reward, relying on the same cortico-limbic network. However, this overlapping anticipatory activity for reward and effort has only been investigated in a perceptual task. Whether this generalizes to high-level cognitive tasks remains to be investigated. To this end, an fMRI experiment was designed to investigate anticipation of reward and effort in cognitive tasks. A mental arithmetic task was implemented, manipulating effort (difficulty), reward, and delay in reward delivery to control for temporal confounds. The goal was to test for the motivational effect induced by the expectation of bigger reward and higher effort. The results showed that the activation elicited by an upcoming difficult task overlapped with higher reward prospect in the ACC and in the striatum, thus highlighting a pivotal role of this circuit in sustaining motivated behavior.},
  journal = {PLOS ONE},
  keywords = {Behavior,Brainstem,Cingulate cortex,Dopaminergics,Functional magnetic resonance imaging,Motivation,Neostriatum,Sensory cues},
  language = {en},
  number = {3}
}

@article{Vassena_Taskspecific_2019,
  title = {Task-Specific Prioritization of Reward and Effort Information: {{Novel}} Insights from Behavior and Computational Modeling},
  shorttitle = {Task-Specific Prioritization of Reward and Effort Information},
  author = {Vassena, Eliana and Deraeve, James and Alexander, William H.},
  year = {2019},
  month = jan,
  issn = {1531-135X},
  doi = {10.3758/s13415-018-00685-w},
  abstract = {Efficient integration of environmental information is critical in goal-directed behavior. Motivational information regarding potential rewards and costs (such as required effort) affects performance and decisions whether to engage in a task. While it is generally acknowledged that costs and benefits are integrated to determine the level of effort to be exerted, how this integration occurs remains an open question. Computational models of high-level cognition postulate serial processing of task-relevant features and demonstrate that prioritizing the processing of one feature over the other can affect performance. We investigated the hypothesis that motivationally relevant task features also may be processed serially, that people may prioritize either benefit or cost information, and that artificially controlling prioritization may be beneficial for performance (by improving task-accuracy) and decision-making (by boosting the willingness to engage in effortful trials). We manipulated prioritization by altering order of presentation of effort and reward cues in two experiments involving preparation for effortful performance and effort-based decision-making. We simulated the tasks with a recent model of prefrontal cortex (Alexander \& Brown in Neural Computation, 27(11), 2354\textendash 2410, 2015). Human behavior was in line with model predictions: prioritizing reward vs. effort differentially affected performance vs. decision. Prioritizing reward was beneficial for performance, showing striking increase in accuracy, especially when a large reward was offered for a difficult task. Counterintuitively (yet predicted by the model), prioritizing reward resulted in a blunted reward effect on decisions. Conversely, prioritizing effort increased reward impact on decision to engage. These results highlight the importance of controlling prioritization of motivational cues in neuroimaging studies.},
  journal = {Cognitive, Affective, \& Behavioral Neuroscience},
  keywords = {Computational modeling,Decision-making,Effort,Motivation,Prioritization,Reward,Task-performance},
  language = {en}
}

@article{Verguts_Adaptive_2015,
  title = {Adaptive Effort Investment in Cognitive and Physical Tasks: A Neurocomputational Model},
  shorttitle = {Adaptive Effort Investment in Cognitive and Physical Tasks},
  author = {Verguts, Tom and Vassena, Eliana and Silvetti, Massimo},
  year = {2015},
  volume = {9},
  issn = {1662-5153},
  doi = {10.3389/fnbeh.2015.00057},
  abstract = {Despite its importance in everyday life, the computational nature of effort investment remains poorly understood. We propose an effort model obtained from optimality considerations, and a neurocomputational approximation to the optimal model. Both are couched in the framework of reinforcement learning. It is shown that choosing when or when not to exert effort can be adaptively learned, depending on rewards, costs, and task difficulty. In the neurocomputational model, the limbic loop comprising anterior cingulate cortex and ventral striatum in the basal ganglia allocates effort to cortical stimulus-action pathways whenever this is valuable. We demonstrate that the model approximates optimality. Next, we consider two hallmark effects from the cognitive control literature, namely proportion congruency and sequential congruency effects. It is shown that the model exerts both proactive and reactive cognitive control. Then, we simulate two physical effort tasks. In line with empirical work, impairing the model's dopaminergic pathway leads to apathetic behavior. Thus, we conceptually unify the exertion of cognitive and physical effort, studied across a variety of literatures (e.g., motivation and cognitive control) and animal species.},
  journal = {Frontiers in Behavioral Neuroscience},
  keywords = {anterior cingulate cortex,cognitive control,computational modeling,Dopamine},
  language = {English}
}

@article{Volz_Cognitive_2012,
  title = {Cognitive Processes in Decisions under Risk Are Not the Same as in Decisions under Uncertainty},
  author = {Volz, Kirsten G. and Gigerenzer, Gerd},
  year = {2012},
  volume = {6},
  pages = {105},
  doi = {10.3389/fnins.2012.00105},
  abstract = {We deal with risk versus uncertainty, a distinction that is of fundamental importance for cognitive neuroscience yet largely neglected. In a world of risk (``small world''), all alternatives, consequences, and probabilities are known. In uncertain (``large'') worlds, some of this information is unknown or unknowable. Most of cognitive neuroscience studies exclusively study the neural correlates for decisions under risk (e.g., lotteries), with the tacit implication that understanding these would lead to an understanding of decision making in general. First, we show that normative strategies for decisions under risk do not generalize to uncertain worlds, where simple heuristics are often the more accurate strategies. Second, we argue that the cognitive processes for making decisions in a world of risk are not the same as those for dealing with uncertainty. Because situations with known risks are the exception rather than the rule in human evolution, it is unlikely that our brains are adapted to them. We therefore suggest a paradigm shift toward studying decision processes in uncertain worlds and provide first examples.},
  journal = {Decision Neuroscience},
  keywords = {as-if versus process models,heuristics,neuroscience of decision making,risk and uncertainty,small world versus large world problems}
}

@book{VonNeumann_Theory_1944,
  title = {Theory of Games and Economic Behavior},
  author = {Von Neumann, J. and Morgenstern, O.},
  year = {1944},
  pages = {xviii, 625},
  publisher = {{Princeton University Press}},
  address = {{Princeton, NJ, US}},
  abstract = {The authors analyze some fundamental questions of economic theory in terms of a mathematical theory of games. The common elements of economic behavior and such factors as strategy in games are presented, and the interrelated concepts are analyzed around the more or less central problem of utility. The book is divided into 12 chapters, the first being a formulation of the economic problem, presenting the objectives of the system used, the notion of utility, and a description of the structure of the authors' theory. The second chapter is a general formal description of games of strategy, and chapters 3-8 treat particular classifications of games. In chapter 9, the authors discuss the composition and decomposition of games. Chapter 10 is on simple games, and chapter 11 on general non-zero-sum games. (These are games in which the sum of all payments received by all players is not zero. Thus such games involve production or destruction of goods and are more closely analogous to general social and economic situations than zero-sum games.) The concluding chapter presents a generalization of the concept of utility and the discussion of an example. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  series = {Theory of Games and Economic Behavior}
}

@article{Vrieze_Model_2012,
  title = {Model Selection and Psychological Theory: {{A}} Discussion of the Differences between the {{Akaike Information Criterion}} ({{AIC}}) and the {{Bayesian Information Criterion}} ({{BIC}})},
  shorttitle = {Model Selection and Psychological Theory},
  author = {Vrieze, Scott I.},
  year = {2012},
  month = jun,
  volume = {17},
  pages = {228--243},
  issn = {1082-989X},
  doi = {10.1037/a0027127},
  abstract = {This article reviews the Akaike Information Criterion (AIC) and the Bayesian Information Criterion (BIC) in model selection and the appraisal of psychological theory. The focus is on latent variable models given their growing use in theory testing and construction. We discuss theoretical statistical results in regression and illustrate more important issues with novel simulations involving latent variable models including factor analysis, latent profile analysis, and factor mixture models. Asymptotically, the BIC is consistent, in that it will select the true model if, among other assumptions, the true model is among the candidate models considered. The AIC is not consistent under these circumstances. When the true model is not in the candidate model set the AIC is effcient, in that it will asymptotically choose whichever model minimizes the mean squared error of prediction/estimation. The BIC is not effcient under these circumstances. Unlike the BIC, the AIC also has a minimax property, in that it can minimize the maximum possible risk in finite sample sizes. In sum, the AIC and BIC have quite different properties that require different assumptions, and applied researchers and methodologists alike will benefit from improved understanding of the asymptotic and finite-sample behavior of these criteria. The ultimate decision to use AIC or BIC depends on many factors, including: the loss function employed, the study's methodological design, the substantive research question, and the notion of a true model and its applicability to the study at hand.},
  journal = {Psychological Methods},
  number = {2},
  pmcid = {PMC3366160},
  pmid = {22309957}
}

@article{Walasek_How_2015,
  title = {How to Make Loss Aversion Disappear and Reverse: {{Tests}} of the Decision by Sampling Origin of Loss Aversion},
  shorttitle = {How to Make Loss Aversion Disappear and Reverse},
  author = {Walasek, L. and Stewart, N.},
  year = {2015},
  volume = {144},
  pages = {7--11},
  doi = {10.1037/xge0000039},
  abstract = {One of the most robust empirical findings in the behavioral sciences is loss aversion-the finding that losses loom larger than gains. We offer a new psychological explanation of the origins of loss aversion in which loss aversion emerges from differences in the distribution of gains and losses people experience. In 4 experiments, we tested this proposition by manipulating the range of gains and losses that individuals saw during the process of eliciting their loss aversion. We were able to find loss aversion, loss neutrality, and even the reverse of loss aversion. \textcopyright{} 2014 The Author(s).},
  journal = {Journal of Experimental Psychology: General},
  keywords = {Context,Decision by sampling,loss aversion,Prospect theory},
  number = {1}
}

@article{Walker_SleepDependent_2004,
  title = {Sleep-{{Dependent Learning}} and {{Memory Consolidation}}},
  author = {Walker, Matthew P. and Stickgold, Robert},
  year = {2004},
  month = sep,
  volume = {44},
  pages = {121--133},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2004.08.031},
  abstract = {While the functions of sleep remain largely unknown, one of the most exciting and contentious hypotheses is that sleep contributes importantly to memory. A large number of studies offer a substantive body of evidence supporting this role of sleep in what is becoming known as sleep-dependent memory processing. This review will provide evidence of sleep-dependent memory consolidation and sleep-dependent brain plasticity and is divided into five sections: (1) an overview of sleep stages, memory categories, and the distinct stages of memory development; (2) a review of the specific relationships between sleep and memory, both in humans and animals; (3) a survey of evidence describing sleep-dependent brain plasticity, including human brain imaging studies as well as animal studies of cellular neurophysiology and molecular biology. We close (4) with a consideration of unanswered questions as well as existing arguments against the role of sleep in learning and memory and (5) a concluding summary.},
  journal = {Neuron},
  language = {en},
  number = {1}
}

@book{Walsh_Integrating_,
  title = {Integrating {{Sample}}-Based {{Planning}} and {{Model}}-Based {{Reinforcement Learning}}},
  author = {Walsh, Thomas J. and Goschin, Sergiu and Littman, Michael L.},
  abstract = {Recent advancements in model-based reinforcement learning have shown that the dynamics of many structured domains (e.g. DBNs) can be learned with tractable sample complexity, despite their exponentially large state spaces. Unfortunately, these algorithms all require access to a planner that computes a near optimal policy, and while many traditional MDP algorithms make this guarantee, their computation time grows with the number of states. We show how to replace these over-matched planners with a class of sample-based planners\textemdash whose computation time is independent of the number of states\textemdash without sacrificing the sampleefficiency guarantees of the overall learning algorithms. To do so, we define sufficient criteria for a sample-based planner to be used in such a learning system and analyze two popular sample-based approaches from the literature. We also introduce our own sample-based planner, which combines the strategies from these algorithms and still meets the criteria for integration into our learning system. In doing so, we define the first complete RL solution for compactly represented (exponentially sized) state spaces with efficiently learnable dynamics that is both sample efficient and whose computation time does not grow rapidly with the number of states.}
}

@article{Walton_Weighing_2006,
  title = {Weighing up the {{Benefits}} of {{Work}}: {{Behavioral}} and {{Neural Analyses}} of {{Effort}}-{{Related Decision Making}}},
  shorttitle = {Weighing up the {{Benefits}} of {{Work}}},
  author = {Walton, ME and Kennerley, SW and Bannerman, DM and Phillips, PEM and Rushworth, MFS},
  year = {2006},
  month = oct,
  volume = {19},
  pages = {1302--1314},
  issn = {0893-6080},
  doi = {10.1016/j.neunet.2006.03.005},
  abstract = {How we decide whether a course of action is worth undertaking is largely unknown. Recently, neuroscientists have been turning to ecological approaches to address this issue, examining how animals evaluate the costs and benefits of different options. We present here evidence from rodents and monkeys that demonstrate the degree to which they take into account work and energetic requirements when deciding what responses to make. These calculations appear to be critically mediated by the anterior cingulate cortex (ACC) and mesolimbic dopamine (DA) pathways, with damage to either causing a bias towards options that are easily obtain but yield relatively smaller reward rather than alternatives that required more work but result in greater reward. The evaluation of such decisions appears to be carried out in systems independent of those involved in delay-discounting. We suggest that top-down signals from ACC to nucleus accumbens (NAc) and/or midbrain DA cells may be vital for overcoming effort-related response costs.},
  journal = {Neural networks : the official journal of the International Neural Network Society},
  keywords = {unread},
  number = {8},
  pmcid = {PMC2519033},
  pmid = {16949252}
}

@incollection{Wan_Unscented_2001,
  title = {The {{Unscented Kalman Filter}}},
  booktitle = {Kalman {{Filtering}} and {{Neural Networks}}},
  author = {Wan, Eric A. and {van der Merwe}, Rudolph},
  year = {2001},
  publisher = {{John Wiley \& Sons, Inc.}}
}

@article{Wang_Effort_2017,
  title = {Effort Provides Its Own Reward: Endeavors Reinforce Subjective Expectation and Evaluation of Task Performance},
  shorttitle = {Effort Provides Its Own Reward},
  author = {Wang, Lei and Zheng, Jiehui and Meng, Liang},
  year = {2017},
  month = apr,
  volume = {235},
  pages = {1107--1118},
  issn = {0014-4819, 1432-1106},
  doi = {10.1007/s00221-017-4873-z},
  abstract = {Although many studies have investigated the relationship between the amount of effort invested in a certain task and one's attitude towards the subsequent reward, whether exerted effort would impact...},
  journal = {Experimental Brain Research},
  language = {en},
  number = {4}
}

@article{Wang_Probabilistic_2002,
  title = {Probabilistic Decision Making by Slow Reverberation in Cortical Circuits},
  author = {Wang, Xiao-Jing},
  year = {2002},
  month = dec,
  volume = {36},
  pages = {955--968},
  issn = {0896-6273},
  abstract = {Recent physiological studies of alert primates have revealed cortical neural correlates of key steps in a perceptual decision-making process. To elucidate synaptic mechanisms of decision making, I investigated a biophysically realistic cortical network model for a visual discrimination experiment. In the model, slow recurrent excitation and feedback inhibition produce attractor dynamics that amplify the difference between conflicting inputs and generates a binary choice. The model is shown to account for salient characteristics of the observed decision-correlated neural activity, as well as the animal's psychometric function and reaction times. These results suggest that recurrent excitation mediated by NMDA receptors provides a candidate cellular mechanism for the slow time integration of sensory stimuli and the formation of categorical choices in a decision-making neocortical network.},
  journal = {Neuron},
  keywords = {Animals,Cerebral Cortex,Decision Making,Mathematics,Models; Neurological,Neural Networks (Computer),Neurons,Reaction Time,Receptors; N-Methyl-D-Aspartate,Synapses},
  language = {eng},
  number = {5},
  pmid = {12467598}
}

@article{Warren_Rapid_2014,
  title = {Rapid and {{Slow Chemical Synaptic Interactions}} of {{Cholinergic Projection Neurons}} and {{GABAergic Local Interneurons}} in the {{Insect Antennal Lobe}}},
  author = {Warren, Ben and Kloppenburg, Peter},
  year = {2014},
  month = sep,
  volume = {34},
  pages = {13039--13046},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.0765-14.2014},
  abstract = {The antennal lobe (AL) of insects constitutes the first synaptic relay and processing center of olfactory information, received from olfactory sensory neurons located on the antennae. Complex synaptic connectivity between olfactory neurons of the AL ultimately determines the spatial and temporal tuning profile of (output) projection neurons to odors. Here we used paired whole-cell patch-clamp recordings in the cockroach Periplaneta americana to characterize synaptic interactions between cholinergic uniglomerular projection neurons (uPNs) and GABAergic local interneurons (LNs), both of which are key components of the insect olfactory system. We found rapid, strong excitatory synaptic connections between uPNs and LNs. This rapid excitatory transmission was blocked by the nicotinic acetylcholine receptor blocker mecamylamine. IPSPs, elicited by synaptic input from a presynaptic LN, were recorded in both uPNs and LNs. IPSPs were composed of both slow, sustained components and fast, transient components which were coincident with presynaptic action potentials. The fast IPSPs were blocked by the GABAA receptor chloride channel blocker picrotoxin, whereas the slow sustained IPSPs were blocked by the GABAB receptor blocker CGP-54626. This is the first study to directly show the predicted dual fast- and slow-inhibitory action of LNs, which was predicted to be key in shaping complex odor responses in the AL of insects. We also provide the first direct characterization of rapid postsynaptic potentials coincident with presynaptic spikes between olfactory processing neurons in the AL.},
  journal = {The Journal of Neuroscience},
  keywords = {acetylcholine,antennal lobe,GABA,local interneuron,olfaction,projection neuron},
  language = {en},
  number = {39},
  pmid = {25253851}
}

@article{Watkins_Qlearning_1992,
  title = {Q-Learning},
  author = {Watkins, Christopher J. C. H. and Dayan, Peter},
  year = {1992},
  month = may,
  volume = {8},
  pages = {279--292},
  issn = {1573-0565},
  doi = {10.1007/BF00992698},
  abstract = {Q-learning (Watkins, 1989) is a simple way for agents to learn how to act optimally in controlled Markovian domains. It amounts to an incremental method for dynamic programming which imposes limited computational demands. It works by successively improving its evaluations of the quality of particular actions at particular states.},
  journal = {Machine Learning},
  language = {en},
  number = {3}
}

@article{Weatherly_Probability_2014,
  title = {Probability {{Alters Delay Discounting}}, but {{Delay Does Not Alter Probability Discounting}}},
  author = {Weatherly, Jeffrey N. and Petros, Thomas V. and J{\'o}nsd{\'o}ttir, Harpa L. and Derenne, Adam and Miller, Joseph C.},
  year = {2014},
  month = nov,
  volume = {65},
  pages = {267--275},
  issn = {0033-2933, 2163-3452},
  doi = {10.1007/s40732-014-0102-3},
  abstract = {Delay and probability discounting occur when the subjective value of an outcome changes because its delivery is either delayed or uncertain, respectively. Although theorists have argued whether these processes are one in the same or distinct, few studies have investigated if and how they interact. Experiment 1 had 191 university students complete a discounting task in which both the delay to and the probability of the outcome were varied across questions about a hypothetical romantic relationship. Experiment 2 replicated this procedure with 153 participants completing a discounting task with a hypothetical monetary amount as the outcome. Experiment 3 had 181 participants complete the discounting task about a hypothetical romantic relationship and measured discounting over an increased number of delays or probabilities. Results across all three experiments showed that rates of delay discounting changed as a function of probability; greater impulsive responding was observed as the likelihood of obtaining the outcome decreased. Rates of probability discounting were largely unaltered by the delay to receiving the outcome. The present results support the idea that delay and probability discounting are at least somewhat distinct. Furthermore, they suggest that the processes may differentially interact with one another.},
  journal = {The Psychological Record},
  keywords = {Delay discounting,Printed,Probability discounting,Psychology; general,University students},
  language = {en},
  number = {2}
}

@article{Weisberg_Variations_2014,
  title = {Variations in Cognitive Maps: Understanding Individual Differences in Navigation},
  shorttitle = {Variations in Cognitive Maps},
  author = {Weisberg, Steven M. and Schinazi, Victor R. and Newcombe, Nora S. and Shipley, Thomas F. and Epstein, Russell A.},
  year = {2014},
  month = may,
  volume = {40},
  pages = {669--682},
  issn = {1939-1285},
  doi = {10.1037/a0035261},
  abstract = {There are marked individual differences in the formation of cognitive maps both in the real world and in virtual environments (VE; e.g., Blajenkova, Motes, \& Kozhevnikov, 2005; Chai \& Jacobs, 2010; Ishikawa \& Montello, 2006; Wen, Ishikawa, \& Sato, 2011). These differences, however, are poorly understood and can be difficult to assess except by self-report methods. VEs offer an opportunity to collect objective data in environments that can be controlled and standardized. In this study, we designed a VE consisting of buildings arrayed along 2 separated routes, allowing for differentiation of between-route and within-route representation. Performance on a pointing task and a model-building task correlated with self-reported navigation ability. However, for participants with lower levels of between-route pointing, the Santa Barbara Sense of Direction scale (Hegarty, Richardson, Montello, Lovelace, \& Subbiah, 2002) did not predict individual differences in accuracy when pointing to buildings within the same route. Thus, we confirm the existence of individual differences in the ability to construct a cognitive map of an environment, identify both the strengths and the potential weaknesses of self-report measures, and isolate a dimension that may help to characterize individual differences more completely. The VE designed for this study provides an objective behavioral measure of navigation ability that can be widely used as a research tool.},
  journal = {Journal of Experimental Psychology. Learning, Memory, and Cognition},
  keywords = {Adult,Female,Humans,Individuality,Male,Psychomotor Performance,Spatial Navigation,Spatial Processing,User-Computer Interface,Young Adult},
  language = {eng},
  number = {3},
  pmid = {24364725}
}

@article{Weissman_neural_2006,
  title = {The Neural Bases of Momentary Lapses in Attention},
  author = {Weissman, D. H. and Roberts, K. C. and Visscher, K. M. and Woldorff, M. G.},
  year = {2006},
  month = jul,
  volume = {9},
  pages = {971--978},
  issn = {1097-6256},
  doi = {10.1038/nn1727},
  abstract = {Momentary lapses in attention frequently impair goal-directed behavior, sometimes with serious consequences. Nevertheless, we lack an integrated view of the brain mechanisms underlying such lapses. By investigating trial-by-trial relationships between brain activity and response time in humans, we determined that attentional lapses begin with reduced prestimulus activity in anterior cingulate and right prefrontal regions involved in controlling attention. Less efficient stimulus processing during attentional lapses was also characterized by less deactivation of a 'default-mode' network, reduced stimulus-evoked sensory activity, and increased activity in widespread regions of frontal and parietal cortex. Finally, consistent with a mechanism for recovering from attentional lapses, increased stimulus-evoked activity in the right inferior frontal gyrus and the right temporal-parietal junction predicted better performance on the next trial. Our findings provide a new, system-wide understanding of the patterns of brain activity that are associated with brief attentional lapses, which informs both theoretical and clinical models of goal-directed behavior.},
  copyright = {\textcopyright{} 2006 Nature Publishing Group},
  journal = {Nature Neuroscience},
  language = {en},
  number = {7}
}

@article{Westbrook_What_2013,
  title = {What {{Is}} the {{Subjective Cost}} of {{Cognitive Effort}}? {{Load}}, {{Trait}}, and {{Aging Effects Revealed}} by {{Economic Preference}}},
  shorttitle = {What {{Is}} the {{Subjective Cost}} of {{Cognitive Effort}}?},
  author = {Westbrook, Andrew and Kester, Daria and Braver, Todd S.},
  year = {2013},
  month = jul,
  volume = {8},
  pages = {e68210},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0068210},
  abstract = {It has long been assumed that people treat cognitive effort as costly, but also that such effort costs may vary greatly across individuals. Individual differences in subjective effort could present a major and pervasive confound in behavioral and neuroscience assessments, by conflating cognitive ability with cognitive motivation. Self-report cognitive effort scales have been developed, but objective measures are lacking. In this study, we use the behavioral economic approach of revealed preferences to quantify subjective effort. Specifically, we adapted a well-established discounting paradigm to measure the extent to which cognitive effort causes participants to discount monetary rewards. The resulting metrics are sensitive to both within-individual factors, including objective load and reward amount, and between-individual factors, including age and trait cognitive engagement. We further validate cognitive effort discounting by benchmarking it against well-established measures of delay discounting. The results highlight the promise and utility of behavioral economic tools for assessing trait and state influences on cognitive motivation.},
  journal = {PLOS ONE},
  keywords = {Behavior,Cognition,Cognitive impairment,Cognitive neurology,Cognitive neuroscience,Cognitive psychology,Decision making,Elderly,nback},
  language = {en},
  number = {7}
}

@article{Wilson_Early_2006,
  title = {Early {{Events}} in {{Olfactory Processing}}},
  author = {Wilson, Rachel I. and Mainen, Zachary F.},
  year = {2006},
  volume = {29},
  pages = {163--201},
  doi = {10.1146/annurev.neuro.29.051605.112950},
  abstract = {AbstractOlfactory space has a higher dimensionality than does any other class of sensory stimuli, and the olfactory system receives input from an unusually large number of unique information channels. This suggests that aspects of olfactory processing may differ fundamentally from processing in other sensory modalities. This review summarizes current understanding of early events in olfactory processing. We focus on how odors are encoded by the activity of primary olfactory receptor neurons, how odor codes may be transformed in the olfactory bulb, and what relevance these codes may have for downstream neurons in higher brain centers. Recent findings in synaptic physiology, neural coding, and psychophysics are discussed, with reference to both vertebrate and insect model systems.},
  journal = {Annual Review of Neuroscience},
  keywords = {antennal lobe,chemotopy,concentration,Olfactory Bulb,segmentation,synchrony,temporal coding},
  number = {1},
  pmid = {16776583}
}

@incollection{Wilson_Neural_2009,
  title = {A {{Neural Implementation}} of the {{Kalman Filter}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 22},
  author = {Wilson, Robert and Finkel, Leif},
  editor = {Bengio, Y. and Schuurmans, D. and Lafferty, J. and Williams, C. K. I. and Culotta, A.},
  year = {2009},
  pages = {2062--2070},
  abstract = {Recent experimental evidence suggests that the brain is capable of approximating Bayesian inference in the face of noisy input stimuli. Despite this progress, the neural underpinnings of this computation are still poorly understood. In this paper we focus on the Bayesian filtering of stochastic time series and introduce a novel neural network, derived from a line attractor architecture, whose dynamics map directly onto those of the Kalman filter in the limit of small prediction error. When the prediction error is large we show that the network responds robustly to changepoints in a way that is qualitatively compatible with the optimal Bayesian model. The model suggests ways in which probability distributions are encoded in the brain and makes a number of testable experimental predictions.}
}

@article{Wilson_Orbitofrontal_2014,
  title = {Orbitofrontal {{Cortex}} as a {{Cognitive Map}} of {{Task Space}}},
  author = {Wilson, Robert C. and Takahashi, Yuji K. and Schoenbaum, Geoffrey and Niv, Yael},
  year = {2014},
  month = jan,
  volume = {81},
  pages = {267--279},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2013.11.005},
  abstract = {Orbitofrontal cortex (OFC) has long been known to play an important role in decision making. However, the exact nature of that role has remained elusive. Here, we propose a unifying theory of OFC function. We hypothesize that OFC provides an abstraction of currently available information in the form of a labeling of the current task state, which is used for reinforcement learning (RL) elsewhere in the brain. This~function is especially critical when task states include unobservable information, for instance, from working memory. We use this framework to explain classic findings in reversal learning, delayed alternation, extinction, and devaluation as well as more recent findings showing the effect of OFC lesions on the firing of dopaminergic neurons in ventral tegmental area (VTA) in rodents performing an RL task. In addition, we generate a number of testable experimental predictions that can distinguish our theory from other accounts of OFC function.},
  journal = {Neuron},
  language = {English},
  number = {2},
  pmid = {24462094, 24462094}
}

@article{Wimmer_Preference_2012,
  title = {Preference by {{Association}}: {{How Memory Mechanisms}} in the {{Hippocampus Bias Decisions}}},
  shorttitle = {Preference by {{Association}}},
  author = {Wimmer, G. Elliott and Shohamy, Daphna},
  year = {2012},
  month = oct,
  volume = {338},
  pages = {270--273},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1223252},
  abstract = {The Right Choice? So-called irrational decisions made by humans are popular fodder for ``believe it or not'' stories. But what's actually happening when we make choices that do not seem to be justifiable on purely economic or logical grounds? Presumably, we are not simply making errors; instead, our choices may reflect an internal bias that we are not aware of. Wimmer and Shohamy (p. 270) show how the hippocampus can instill an unconscious bias in valuations, whereby an object that is not highly valued on its own, increases in value when it becomes implicitly associated with a truly high-value object. As a consequence, we then end up preferring the associated object over a neutral object of equal objective value while not really knowing why. Every day people make new choices between alternatives that they have never directly experienced. Yet, such decisions are often made rapidly and confidently. Here, we show that the hippocampus, traditionally known for its role in building long-term declarative memories, enables the spread of value across memories, thereby guiding decisions between new choice options. Using functional brain imaging in humans, we discovered that giving people monetary rewards led to activation of a preestablished network of memories, spreading the positive value of reward to nonrewarded items stored in memory. Later, people were biased to choose these nonrewarded items. This decision bias was predicted by activity in the hippocampus, reactivation of associated memories, and connectivity between memory and reward regions in the brain. These findings explain how choices among new alternatives emerge automatically from the associative mechanisms by which the brain builds memories. Further, our findings demonstrate a previously unknown role for the hippocampus in value-based decisions. Remembered links between objects can result in the unintentional linking of their values and can affect choices. Remembered links between objects can result in the unintentional linking of their values and can affect choices.},
  chapter = {Report},
  copyright = {Copyright \textcopyright{} 2012, American Association for the Advancement of Science},
  journal = {Science},
  language = {en},
  number = {6104},
  pmid = {23066083}
}

@article{Winterhalder_Analyzing_2000,
  title = {Analyzing Adaptive Strategies: {{Human}} Behavioral Ecology at Twenty-Five},
  shorttitle = {Analyzing Adaptive Strategies},
  author = {Winterhalder, Bruce and Smith, Eric Alden},
  year = {2000},
  volume = {9},
  pages = {51--72},
  journal = {Evolutionary Anthropology: Issues, News, and Reviews},
  number = {2}
}

@article{Wolpert_Are_1995,
  title = {Are Arm Trajectories Planned in Kinematic or Dynamic Coordinates? {{An}} Adaptation Study},
  shorttitle = {Are Arm Trajectories Planned in Kinematic or Dynamic Coordinates?},
  author = {Wolpert, Daniel M. and Ghahramani, Zoubin and Jordan, Michael I.},
  year = {1995},
  month = nov,
  volume = {103},
  pages = {460--470},
  issn = {1432-1106},
  doi = {10.1007/BF00241505},
  abstract = {There are several invariant features of pointto-point human arm movements: trajectories tend to be straight, smooth, and have bell-shaped velocity profiles. One approach to accounting for these data is via optimization theory; a movement is specified implicitly as the optimum of a cost function, e.g., integrated jerk or torque change. Optimization models of trajectory planning, as well as models not phrased in the optimization framework, generally fall into two main groups-those specified in kinematic coordinates and those specified in dynamic coordinates. To distinguish between these two possibilities we have studied the effects of artificial visual feedback on planar two-joint arm movements. During self-paced point-to-point arm movements the visual feedback of hand position was altered so as to increase the perceived curvature of the movement. The perturbation was zero at both ends of the movement and reached a maximum at the midpoint of the movement. Cost functions specified by hand coordinate kinematics predict adaptation to increased curvature so as to reduce the visual curvature, while dynamically specified cost functions predict no adaptation in the underlying trajectory planner, provided the final goal of the movement can still be achieved. We also studied the effects of reducing the perceived curvature in transverse movements, which are normally slightly curved. Adaptation should be seen in this condition only if the desired trajectory is both specified in kinematic coordinates and actually curved. Increasing the perceived curvature of normally straight sagittal movements led to significant (P{$<$}0.001) corrective adaptation in the curvature of the actual hand movement; the hand movement became curved, thereby reducing the visually perceived curvature. Increasing the curvature of the normally curved transverse movements produced a significant (P{$<$}0.01) corrective adaptation; the hand movement became straighter, thereby again reducing the visually perceived curvature. When the curvature of naturally curved transverse movements was reduced, there was no significant adaptation (P{$>$}0.05). The results of the curvature-increasing study suggest that trajectories are planned in visually based kinematic coordinates. The results of the curvature-reducing study suggest that the desired trajectory is straight in visual space. These results are incompatible with purely dynamicbased models such as the minimum torque change model. We suggest that spatial perception-as mediated by vision-plays a fundamental role in trajectory planning.},
  journal = {Experimental Brain Research},
  language = {en},
  number = {3}
}

@article{Wolpert_Principles_2011,
  title = {Principles of Sensorimotor Learning},
  author = {Wolpert, Daniel M. and Diedrichsen, J{\"o}rn and Flanagan, J. Randall},
  year = {2011},
  month = dec,
  volume = {12},
  pages = {739--751},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0048},
  doi = {10.1038/nrn3112},
  abstract = {Learning movement skills involves a number of interacting components, such as information extraction, decision making, different classes of control, motor learning and its representations.Skilled performance requires the effective and efficient gathering and processing of sensory information that is relevant to an action.Decision-making processes involve determining what information to extract during the unfolding task and, based on this information, when to make the next movement and which movement to make.Classes of control used to optimize motor performance include predictive, reactive and biomechanical control. Processes of motor learning can be distinguished by the types of information that the motor system uses as a learning signal. These include error-based learning, reinforcement learning, observational learning and use-dependent learning.Representations in motor learning reflect the internal assumptions about the task structure and constrain the way in which learning occurs in response to errors. Such representations can be conceptualized in two ways, either as mechanistic or normative models.},
  copyright = {2011 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  journal = {Nature Reviews Neuroscience},
  language = {en},
  number = {12}
}

@article{Wood_Psychology_2016,
  title = {Psychology of {{Habit}}},
  author = {Wood, Wendy and R{\"u}nger, Dennis},
  year = {2016},
  volume = {67},
  pages = {289--314},
  doi = {10.1146/annurev-psych-122414-033417},
  abstract = {As the proverbial creatures of habit, people tend to repeat the same behaviors in recurring contexts. This review characterizes habits in terms of their cognitive, motivational, and neurobiological properties. In so doing, we identify three ways that habits interface with deliberate goal pursuit: First, habits form as people pursue goals by repeating the same responses in a given context. Second, as outlined in computational models, habits and deliberate goal pursuit guide actions synergistically, although habits are the efficient, default mode of response. Third, people tend to infer from the frequency of habit performance that the behavior must have been intended. We conclude by applying insights from habit research to understand stress and addiction as well as the design of effective interventions to change health and consumer behaviors.},
  annotation = {\_eprint: https://doi.org/10.1146/annurev-psych-122414-033417},
  journal = {Annual Review of Psychology},
  keywords = {habits,unread},
  number = {1},
  pmid = {26361052}
}

@article{Wright_honeybee_2009,
  title = {A Honeybee's Ability to Learn, Recognize, and Discriminate Odors Depends upon Odor Sampling Time and Concentration},
  author = {Wright, Geraldine A and Carlton, Michelle and Smith, Brian H},
  year = {2009},
  month = feb,
  volume = {123},
  pages = {36--43},
  issn = {0735-7044},
  doi = {10.1037/a0014040},
  abstract = {Animals sample sensory stimuli for longer periods when they must perform difficult discrimination tasks, implying that the brain's ability to represent stimuli improves as a function of time. Although it is true in other senses, few studies have examined whether increasing sampling time improves olfactory discrimination. In the experiments reported here, odor sampling time was controlled with the goal of testing whether odor concentration affected a honeybee's ability to learn, recognize, and discriminate odors. Increasing sampling time during conditioning and testing improved a honeybee's ability to learn, recognize, and differentiate low-concentration (0.0002 M) odors. For intermediate-concentration (0.02 M) odors, both acquisition and recognition improved when stimulus duration was longer, but discrimination was unaffected. Having longer to sample a high-concentration (2.0 M) stimulus also improved acquisition, but it did not affect the ability to recognize or differentiate odors. Differences in time to respond to the conditioned and novel odors during the test period depended on the difficulty of the discrimination task. The results suggest that the sensory coding of molecular identity takes longer for low-concentration odors.},
  journal = {Behavioral neuroscience},
  keywords = {Animals,Association Learning,Bees,Discrimination (Psychology),Dose-Response Relationship; Drug,Logistic Models,Odors,Reaction Time,Recognition (Psychology),Stimulation; Chemical,Time Factors},
  language = {eng},
  number = {1},
  pmcid = {PMC2632763},
  pmid = {19170428}
}

@article{Wright_honeybee_2009a,
  title = {A Honeybee's Ability to Learn, Recognize, and Discriminate Odors Depends upon Odor Sampling Time and Concentration},
  author = {Wright, Geraldine A. and Carlton, Michelle and Smith, Brian H.},
  year = {2009},
  month = feb,
  volume = {123},
  pages = {36--43},
  issn = {0735-7044},
  doi = {10.1037/a0014040},
  abstract = {Animals sample sensory stimuli for longer periods when they must perform difficult discrimination tasks, implying that the brain's ability to represent stimuli improves as a function of time. Though it is true in other senses, few studies have examined whether increasing sampling time improves olfactory discrimination. In the experiments reported here, we controlled odor sampling time with the goal of testing whether odor concentration affected a honeybee's ability to learn, recognize, and discriminate odors. We observed that increasing sampling time during conditioning and testing improved a honeybee's ability to learn, recognize, and differentiate low concentration (0.0002M) odors. For intermediate (0.02M) concentration odors, both acquisition and recognition improved when stimulus duration was longer, but discrimination was unaffected. Having longer to sample a high concentration (2.0M) stimulus also improved acquisition, but it did not affect the ability to recognize or differentiate odors. Differences in the time taken to respond to the conditioned and novel odors during the test period depended upon the difficulty of the discrimination task. Our results suggest that the sensory coding of molecular identity takes longer for low concentration odors.},
  journal = {Behavioral neuroscience},
  number = {1},
  pmcid = {PMC2632763},
  pmid = {19170428}
}

@article{Wunderlich_Dopamine_2012,
  title = {Dopamine {{Enhances Model}}-{{Based}} over {{Model}}-{{Free Choice Behavior}}},
  author = {Wunderlich, Klaus and Smittenaar, Peter and Dolan, Raymond J.},
  year = {2012},
  month = aug,
  volume = {75},
  pages = {418--424},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2012.03.042},
  journal = {Neuron},
  language = {English},
  number = {3},
  pmid = {22884326}
}

@article{Wypych_Roles_2018,
  title = {Roles of {{Impulsivity}}, {{Motivation}}, and {{Emotion Regulation}} in {{Procrastination}} \textendash{} {{Path Analysis}} and {{Comparison Between Students}} and {{Non}}-Students},
  author = {Wypych, Marek and Matuszewski, Jacek and Dragan, Wojciech {\L}},
  year = {2018},
  volume = {9},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2018.00891},
  abstract = {Procrastination \textendash{} an irrational delay of intended actions despite expecting to be worse off \textendash{} is a complex and non-homogenous phenomenon. Previous studies have found a number of correlates of procrastination, some of which seem to be particularly important. Impulsivity is closely connected to procrastination on behavioral, genetic, and neuronal levels. Difficulties in emotion regulation have also been shown to be strongly related to procrastination. Procrastination can also be considered as a motivation-based problem. To try to disentangle the connections of impulsivity, emotion regulation, and motivation to procrastination we collected data from over 600 subjects using multiple questionnaires (PPS \textendash{} Pure Procrastination Scale; UPPSP \textendash{} Impulsive Behavior Scale, ERQ \textendash{} Emotion Regulation Questionnaire and MDT \textendash{} Motivational Diagnostic Test). Structural equation modelling was performed to test several possible relationships between the measured variables. The effects of student status and age have also been investigated. The final path model was a directional model based on six explanatory variables and accounted for 70\% of the variance in procrastination. Path analysis revealed that the strongest contributions to procrastination came from lack of value, delay discounting, and lack of perseverance, suggesting the involvement of motivation and impulsivity. The model also revealed the moderating role of expressive suppression between several aspects of impulsivity and procrastination. Close inspection of the paths' weights suggests that there may be two partly competing strategies for dealing with impulsivity and negative emotions: either to suppress emotions and impulsive reactions or to react impulsively, discarding previous plans, and to procrastinate. Path invariance analysis showed the significant moderating roles of student status and age. Both in non-students and high-age groups, the path leading from suppression to procrastination was insignificant. This suggests that caution should be used in generalizing the results of studies carried out on students. These results support previous findings that procrastination may serve as a short-term mood regulation strategy. However, as the spectrum of the emotion regulation strategies included in the study was very limited, we conclude that future studies should seek more insight into the relationship between emotion regulation, self-control, and procrastination.},
  journal = {Frontiers in Psychology},
  keywords = {Emotion Regulation,impulsivity,Motivation,procrastination,students and non-students},
  language = {English}
}

@article{Xu_Differential_2018,
  title = {Differential Effects of Real versus Hypothetical Monetary Reward Magnitude on Risk-Taking Behavior and Brain Activity},
  author = {Xu, Sihua and Pan, Yu and Qu, Zhe and Fang, Zhuo and Yang, Zijing and Yang, Fan and Wang, Fenghua and Rao, Hengyi},
  year = {2018},
  month = feb,
  volume = {8},
  pages = {3712},
  issn = {2045-2322},
  doi = {10.1038/s41598-018-21820-0},
  abstract = {Human decisions are more easily affected by a larger amount of money than a smaller one. Although numerous studies have used hypothetical money as incentives to motivate human behavior, the validity of hypothetical versus real monetary rewards remains controversial. In the present study, we used event-related potential (ERP) with the balloon analogue risk task to investigate how magnitudes of real and hypothetical monetary rewards modulate risk-taking behavior and feedback-related negativity (FRN). Behavioral data showed that participants were more risk averse after negative feedback with increased magnitude of real monetary rewards, while no behavior differences were observed between large and small hypothetical monetary rewards. Similarly, ERP data showed a larger FRN in response to negative feedback during risk taking with large compared to small real monetary rewards, while no FRN differences were observed between large and small hypothetical monetary rewards. Moreover, FRN amplitude differences correlated with risk-taking behavior changes from small to large real monetary rewards, while such correlation was not observed for hypothetical monetary rewards. These findings suggest that the magnitudes of real and hypothetical monetary rewards have differential effects on risk-taking behavior and brain activity. Real and hypothetical money incentives may have different validity for modulating human decisions.},
  copyright = {2018 The Author(s)},
  journal = {Scientific Reports},
  language = {en},
  number = {1}
}

@article{Yaksi_Electrical_2010,
  title = {Electrical {{Coupling}} between {{Olfactory Glomeruli}}},
  author = {Yaksi, Emre and Wilson, Rachel I.},
  year = {2010},
  month = sep,
  volume = {67},
  pages = {1034--1047},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2010.08.041},
  abstract = {Summary In the Drosophila antennal lobe, excitation can spread between glomerular processing channels. In this study, we investigated the mechanism of lateral excitation. Dual recordings from excitatory local neurons (eLNs) and projection neurons (PNs)~showed that eLN-to-PN synapses transmit both hyperpolarization and depolarization, are not diminished by blocking chemical neurotransmission, and are abolished by a gap-junction mutation. This mutation eliminates odor-evoked lateral excitation in PNs and diminishes some PN odor responses. This implies that lateral excitation is mediated by electrical synapses from eLNs onto PNs. In addition, eLNs form synapses onto inhibitory LNs. Eliminating these synapses boosts some PN odor responses and reduces the disinhibitory effect of GABA receptor antagonists on PNs. Thus, eLNs have two opposing effects on PNs, driving both direct excitation and indirect inhibition. We propose that when stimuli are weak, lateral excitation promotes sensitivity, whereas when stimuli are strong, lateral excitation helps recruit inhibitory gain control.},
  journal = {Neuron},
  number = {6}
}

@article{Yeung_neural_2004,
  title = {The Neural Basis of Error Detection: Conflict Monitoring and the Error-Related Negativity},
  shorttitle = {The Neural Basis of Error Detection},
  author = {Yeung, Nick and Botvinick, Matthew M. and Cohen, Jonathan D.},
  year = {2004},
  month = oct,
  volume = {111},
  pages = {931--959},
  issn = {0033-295X},
  doi = {10.1037/0033-295X.111.4.939},
  abstract = {According to a recent theory, anterior cingulate cortex is sensitive to response conflict, the coactivation of mutually incompatible responses. The present research develops this theory to provide a new account of the error-related negativity (ERN), a scalp potential observed following errors. Connectionist simulations of response conflict in an attentional task demonstrated that the ERN--its timing and sensitivity to task parameters--can be explained in terms of the conflict theory. A new experiment confirmed predictions of this theory regarding the ERN and a second scalp potential, the N2, that is proposed to reflect conflict monitoring on correct response trials. Further analysis of the simulation data indicated that errors can be detected reliably on the basis of post-error conflict. It is concluded that the ERN can be explained in terms of response conflict and that monitoring for conflict may provide a simple mechanism for detecting errors.},
  journal = {Psychological Review},
  keywords = {Adolescent,Adult,Analysis of Variance,Brain Mapping,Computer Simulation,Conflict (Psychology),Electroencephalography,Evoked Potentials,Feedback; Psychological,Female,Humans,Male,Models; Psychological,Reaction Time,Scalp},
  language = {eng},
  number = {4},
  pmid = {15482068}
}

@article{Yeung_Switching_2003,
  title = {Switching between Tasks of Unequal Familiarity: The Role of Stimulus-Attribute and Response-Set Selection},
  shorttitle = {Switching between Tasks of Unequal Familiarity},
  author = {Yeung, Nick and Monsell, Stephen},
  year = {2003},
  month = apr,
  volume = {29},
  pages = {455--469},
  issn = {0096-1523},
  doi = {10.1037/0096-1523.29.2.455},
  abstract = {It has been reported that it is harder to switch to a strong, well-practiced task from a weaker, less-practiced task than vice versa. Three experiments replicated this surprising asymmetry and investigated how it is affected by a reduction in interference between tasks. Experiment 1 progressively delayed the onset of the stimulus attribute associated with the stronger task. Experiments 2 and 3 separated the response sets of the tasks. Both manipulations reduced, without eliminating, interference of the stronger with the weaker task but reversed the asymmetry of switch costs, resulting in a larger cost of switching to the weaker task. The results are interpreted in terms of a model of the interactions between control input, task strength, and task priming.},
  journal = {Journal of Experimental Psychology. Human Perception and Performance},
  keywords = {Adolescent,Adult,Attention,Choice Behavior,Color Perception,Cues,Female,Humans,Inhibition; Psychological,Male,Models; Psychological,Practice; Psychological,Problem Solving,Psychological Theory,Reaction Time,Reading,Set; Psychology,Time Factors,Verbal Behavior,Visual Perception},
  language = {eng},
  number = {2},
  pmid = {12760628}
}

@article{Yildiz_Birdsong_2013,
  title = {From {{Birdsong}} to {{Human Speech Recognition}}: {{Bayesian Inference}} on a {{Hierarchy}} of {{Nonlinear Dynamical Systems}}},
  shorttitle = {From {{Birdsong}} to {{Human Speech Recognition}}},
  author = {Yildiz, Izzet B. and {von Kriegstein}, Katharina and Kiebel, Stefan J.},
  year = {2013},
  month = sep,
  volume = {9},
  pages = {e1003219},
  doi = {10.1371/journal.pcbi.1003219},
  abstract = {Author SummaryNeuroscience still lacks a concrete explanation of how humans recognize speech. Even though neuroimaging techniques are helpful in determining the brain areas involved in speech recognition, there are rarely mechanistic explanations at a neuronal level. Here, we assume that songbirds and humans solve a very similar task: extracting information from sound wave modulations produced by a singing bird or a speaking human. Given strong evidence that both humans and songbirds, although genetically very distant, converged to a similar solution, we combined the vast amount of neurobiological findings for songbirds with nonlinear dynamical systems theory to develop a hierarchical, Bayesian model which explains fundamental functions in recognition of sound sequences. We found that the resulting model is good at learning and recognizing human speech. We suggest that this translated model can be used to qualitatively explain or predict experimental data, and the underlying mechanism can be used to construct improved automatic speech recognition algorithms.},
  journal = {PLoS Comput Biol},
  number = {9}
}

@article{Yildiz_Hierarchical_2011,
  title = {A {{Hierarchical Neuronal Model}} for {{Generation}} and {{Online Recognition}} of {{Birdsongs}}},
  author = {Yildiz, Izzet B. and Kiebel, Stefan J.},
  year = {2011},
  month = dec,
  volume = {7},
  pages = {e1002303},
  doi = {10.1371/journal.pcbi.1002303},
  abstract = {Author Summary How do birds communicate via their songs? Investigating this question may not only lead to a better understanding of communication via birdsong, but many believe that the answer will also give us hints about how humans decode speech from complex sound wave modulations. In birds, the output and neuronal responses of the song generation system can be measured precisely and this has resulted in a considerable body of experimental findings. We used these findings to assemble a complete model of birdsong generation and use it as the basis for constructing a potentially neurobiologically plausible, artificial recognition system based on state-of-the-art Bayesian inference techniques. Our artificial system resembles the real birdsong system when performing recognition tasks and may be used as a functional model to explain and predict experimental findings in song recognition.},
  journal = {PLoS Comput Biol},
  number = {12}
}

@article{York_Unified_2004,
  title = {Unified Equations for the Slope, Intercept, and Standard Errors of the Best Straight Line},
  author = {York, Derek and Evensen, Norman M. and Mart{\'{\i}}nez, Margarita L{\'o}pez and De Basabe Delgado, Jon{\'a}s},
  year = {2004},
  month = feb,
  volume = {72},
  pages = {367--375},
  issn = {0002-9505},
  doi = {10.1119/1.1632486},
  journal = {American Journal of Physics},
  number = {3}
}

@article{Zhang_SelfRegulatory_2017,
  title = {Self-{{Regulatory Capacities Are Depleted}} in a {{Domain}}-{{Specific Manner}}},
  author = {Zhang, Rui and Stock, Ann-Kathrin and Rzepus, Anneka and Beste, Christian},
  year = {2017},
  volume = {11},
  issn = {1662-5137},
  doi = {10.3389/fnsys.2017.00070},
  abstract = {Performing an act of self-regulation such as making decisions has been suggested to deplete a common limited resource, which impairs all subsequent self-regulatory actions (ego depletion theory). It has however remained unclear whether self-referred decisions truly impair behavioral control even in seemingly unrelated cognitive domains, and which neurophysiological mechanisms are affected by these potential depletion effects. In the current study, we therefore used an inter-individual design to compare two kinds of depletion, namely a self-referred choice-based depletion and a categorization-based switching depletion, to a non-depleted control group. We used a backward inhibition paradigm to assess the effects of depletion on task switching and associated inhibition processes. It was combined with EEG and source localization techniques to assess both behavioral and neurophysiological depletion effects. The results challenge the ego depletion theory in its current form: Opposing the theory's prediction of a general limited resource, which should have yielded comparable effects in both depletion groups, or maybe even a larger depletion in the self-referred choice group, there were stronger performance impairments following a task domain-specific depletion (i.e. the switching-based depletion) than following a depletion based on self-referred choices. This suggests at least partly separate and independent resources for various cognitive control processes rather than just one joint resource for all self-regulation activities. The implications are crucial to consider for people making frequent far-reaching decisions e.g. in law or economy.},
  journal = {Frontiers in Systems Neuroscience},
  keywords = {backward inhibition,EEG,Ego Depletion,Neurophysiology,task switching},
  language = {English}
}


