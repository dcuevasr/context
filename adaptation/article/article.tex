\documentclass[a4paper,doc,floatsintext,natbib]{apa6}%article}
% \documentclass{article}
\usepackage[font=small]{caption}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage[utf8]{inputenc}
\usepackage{nameref}
\usepackage{todonotes}
\usepackage{authblk}
% \usepackage[nomarkers,figuresonly]{endfloat}

% Remember to start reftex-mode

\setlength{\parskip}{1em}
\def \fref #1{Figure \ref{#1}}     % Reference figures
\def \tref #1{Table \ref{#1}}      % Reference tables
\def \eref #1{Equation \ref{#1}}   % Reference equations
\def \sref #1{Section '\nameref{#1}'}    % Reference sections

\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}

% For revision
\DeclareRobustCommand{\newcontent}[1]{#1}

\title{The effects of uncertain context inference on motor adaptation}
\shorttitle{Context-inference-dependent motor adaptation}
\author[1,2]{Cuevas Rivera, Darío}
\author[1,2]{Kiebel, Stefan J.}
\affil[1]{Chair of Neuroimaging, Faculty of Psychology, Technische Universität Dresden, 01062 Dresden, Germany.}
\affil[2]{Centre for Tactile Internet with Human-in-the-Loop (CeTI)}
% \author[1]{Author list}
% \affil[1]{Affiliation list}
\affiliation{~}

\begin{document}

\maketitle

\abstract{Abstract}
Humans have been shown to adapt their movements when a sudden change to the dynamics of the environment is introduced, a phenomenon called motor adaptation. If the change is reverted, the adaptation is also quickly reverted. Human are also able to adapt to multiple changes in dynamics presented separately, and to be able to switch between adapted movements on the fly. Such switching relies on contextual information which is often noisy or misleading, which affects the switch between adaptations. In this work, we introduce a computational model to explain the behavioral phenomena effected by uncertain contextual information. Specifically, we present a hierarchical model for motor adaptation based on exact Bayesian inference. This model explicitly takes into account contextual information and how the dynamics of context inference affect adaptation and action selection. We show how the proposed model provides a unifying explanation for four different experimentally-established phenomena: (i) effects of sensory cues and proprioceptive information on switching between tasks, (ii) the effects of previously-learned adaptations on switching between tasks, (iii) the effects of training history on behavior in new contexts, in addition to (iv) the well-studied savings, de-adaptation and spontaneous recovery.


\section{Introduction}
It has been shown that humans can adapt motor commands to counteract changes in the dynamics of the environment and their own bodies, such as performing reaching movements with a weight attached to the wrist. This is known as motor adaptation. Moreover, human participants have been shown to adapt to different, even opposing, such changes during the course of a single experiment \citep{Gandolfo_Motor_1996,Shadmehr_Functional_1997}. Additionally, humans have been shown to dynamically switch between different learned adaptations \citep{Davidson_Scaling_2004,Ethier_Spontaneous_2008,Lee_Dual_2009}.

By introducing blocks of trials in which body dynamics are altered (e.g. a mechanical arm exerts a force on the participant's hand), experimenters are able to observe motor adaptation through the lens of motor error. Across many different motor adaptation experiments \citep[e.g.][]{Gandolfo_Motor_1996,Shadmehr_Adaptive_1994,Davidson_Scaling_2004}, well-established phenomena have been observed: (i) the ability to recall previously-learned skills, called savings; (ii) the ability to return to unmodified dynamics, termed de-adaptation; (iii) the interference in motor learning between opposing manipulations in dynamics, called anterograde interference; (iv) spontaneous display of behavior consistent with a previously-learned adaptation, during trials where errors are forced to be zero, called spontaneous recovery.

To explain these phenomena, a number of computational models have been introduced, which adapt their motor commands after observing motor errors. The most studied are linear learners \citep{Smith_Interacting_2006,Forano_Timescales_2020,Scheidt_Learning_2001}, but Bayesian accounts have also been presented, providing an alternative explanation for savings and quick de-adaptation in the form of switching between forward models \citep{Kording_Bayesian_2004,Oh_Minimizing_2019}.

While these general models of adaptation explain the most common phenomena observed in experiments, other known phenomena remain outside of their scope. For example, it is known that adaptation rate is reduced in situations where the environment is unstable and unpredictable \citep{Herzfeld_memory_2014}, or situations in which errors are small \citep{Marko_Sensitivity_2012} or adaptations slowly introduced \citep{Huang_Persistence_2009}. Action selection has also been found to depend on the history of adaptations learned \citep{Vaswani_Decay_2013,Davidson_Scaling_2004}.

In this work, we show that these unexplained phenomena can be explained in terms context inference, an idea that has recently been gaining traction in motor adaptation \citep{Heald_Contextual_2021}, as well as in other fields \cite[e.g.][]{Sanders_Hippocampal_2020,Hunter_Contextsensitive_2021}. We build on models such as MOSAIC \citep{Wolpert_Multiple_1998} and Bayesian switching models \citep{Kording_Bayesian_2004,Oh_Minimizing_2019} by expanding the concept of context and introducing an explicit mechanism for inferring the context based on Bayesian inference. In the proposed model, the context encompasses all the information relevant to making decisions, both environmental and internal to the agent making these decisions. To infer the current context, our model integrates several sources of information, including the predictions made by its internal forward models, an estimate of the reliability of these predictions, direct sensory information (such as visual contextual cues), proprioceptive information, and feedback provided by the environment.

This work expands on the work by \cite{Heald_Contextual_2021}, who showed that context inference modulates learning rate in cases of unstable contexts. To do this, we focused on the effects of uncertain contextual information on switching behavior, especially during so-called error-clamp trials, in which errors are forced to zero by experimenters.

We show that the dynamics of context inference provide a principled mechanistic explanation for the experimental phenomena outlined above, providing a single account for motor adaptation under changing contexts, while relying on known mechanisms for adaptation.

\section{Results}
We present a motor adaptation model in which an existing model of the environment is updated based on error signals produced by the need of adaptation. We expanded on existing models \citep{Wolpert_Multiple_1998,Kording_Bayesian_2004,Oh_Minimizing_2019} by adding an explicit component of context inference. As we will show, context inference guides the selection of the adequate forward model, its updating and the sampling of actions.

We simulated representative experiments from a number of experimental studies on motor adaptation to illustrate how our model explains these experimental findings using the dynamics of context inference. We will present these simulations alongside the experimental results from the representative studies and discuss in detail how context inference explains the experimental phenomena.

Before presenting our simulations, we will briefly go through the fundamentals of the model we present. We leave the mathematical details of the implementation to the Methods section.

\subsection{Modeling context-dependent adaptation}
The model we present has three main components: (1) context inference, (2) motor adaptation and (3) action selection. The processes defined by these component occur in this order, and each component informs the ones that follow.

Central to the model is the concept of context, defined in terms of the task to be performed, the variables of the environment that are relevant to perform the task, the forward models used by the decision-making agent to perform the task, and the update mechanisms necessary to adapt these forward models to the changing environment. Together, these elements allow the agent to make predictions on future observations when this context is active, and these predictions are used to infer the context. For example, when lifting an object of unknown weight, an agent might have learned one context for heavy objects and one for light objects. When observing an object to be lifted, the agent can use its size and texture to estimate the weight of the object, which in turn allows the agent to infer the appropriate context and, with it, decide how to lift the object.

We now briefly describe the three components of the model separately. For clarity, we start with the second component (i.e. motor adaptation), in order to introduce the terminology that we use throughout this work. For an overview, we show in \fref{fig:model} how these three components affect each other. The full mathematical description of the model can be found in the Methods.

\begin{figure}
\centering
\includegraphics[]{./figures/figure_1.png}
\caption{Schematic representation of the model. $\zeta$ represents the identity of the context as a categorical variable, $\vartheta$ are observations, $c_t$ are motor commands at trial $t$, $\phi$ are the parameters of the forward model and $s$ are the hidden states of the environment (e.g. the position of the hand). The arrows show flow of information, i.e. the dependencies in the update equations, as well as the flow of a single trial. Trial $t$ starts at the top when an observation $\vartheta_t$ is received, from which the current context is inferred ($q(\zeta)$), which informs motor adaptation ($q(\phi)$), which informs action selection ($p(c)$). The update equations can be found in the Methods section. After an action is selected, a new observation $\vartheta_{t+1}$ is received and the process is repeated. The posteriors over $\zeta$ and $\phi$ are used as priors at the next trial.}
\label{fig:model}
\end{figure}

\subsubsection{Motor adaptation}
It is widely accepted that in order to adapt motor commands to a novel environment, we create and update internal forward models of the outcomes of control signals \citep{Wolpert_Multiple_1998}. We used this principle and chose to make use of an exact Bayesian learner. To adapt to altered dynamics (e.g. a mechanical arm exerting a force on a participant's hand), our model updates the parameters $\phi$ (see Methods) of a context-specific forward model. These updates are done according to \eref{eqn:motor-adaptation}, using the difference between predictions made with the current parameters of the forward model, and the current observation. With this, a posterior estimate on $\phi$, $q(\phi)$ in \fref{fig:model}, is calculated after each trial.

\subsubsection{Context inference}
To infer the adequate forward model to deploy, most previous models \cite[e.g.][]{Wolpert_Multiple_1998,Imamizu_Neural_2008,Oh_Minimizing_2019} have focused on the elements of the context which are directly related to the forward models: the model that best predicts the current observation given the past is deemed to be the ``correct'' model, i.e. the model that best represents the current context. \cite{Imamizu_Explicit_2007} expanded on this idea by showing the effects of visual cues on model switching.

Following these ideas, our model performs context inference that integrates several sources of information, including those typical for experimental studies such as visual cues \citep{Lee_Dual_2009,Kim_Neural_2015}, the place where the task must be carried out \citep{Forano_Timescales_2020,Shadmehr_Adaptive_1994} or the start of a new block of trials \citep{Ethier_Spontaneous_2008}, in addition to proprioceptive information, outcome prediction errors and reward prediction errors. As with motor adaptation, the context is inferred as a probability distribution $q(\zeta)$ with exact Bayesian inference, with the updates given by \eref{eqn:estimated-context}.

\subsubsection{Action selection}
Action selection is affected by the current context via the context-dependent forward model that is used. In our model, action selection is made by building a distribution over available actions which is a weighted sum of the distributions given by the existing forward models, where the weights are obtained by the context inference component of the model.

In other words, a distribution $p(c_t)$ over all possible motor commands is created following \eref{eqn:dist-comm}, from which the next action (motor command $c_t$) can be sampled and carried out.

\subsection{Experimental results}
In this section, we present experimentally-observed phenomena in three sections, and show that the dynamics of context inference provide a unifying explanation for all of them. In the first section, we discuss switches between contexts, and how slow context inference affects these switches. In the second section, we focus on the effects of volatility in the environment on motor adaptation. Finally, in the third section we discuss context inference during so-called error-clamp trials, and its effect on behavior. For each of the three sections, we selected one or two studies which are representative of the phenomenon being discussed.

For clarity, we first introduce necessary terminology that is typically used in experimental studies. As an example, we will use a typical motor adaptation task in which participants have to make reaching movements while holding the handle of a mechanical arm that exerts a curl force on the participant's hand. Depending on the trial, the mechanical arm might exert a curl force in a clockwise or counter-clockwise direction, or no force at all. Let us define the baseline context O as that in which the mechanical arm exerts no force. Contexts A and B can be defined as those with clockwise or counter-clockwise, respectively. Abusing notation, a usual statement is that $B = (-A)$, as the forces have the same magnitude but point in opposite directions. Similarly, one can define context A/2, with the same direction of adaptation as A, but half the magnitude. Finally, many experiments include a block of error-clamp trials at the end of the experiment, in which the mechanical arm forces the participant to make straight-line movements; we represent these with the letter E.

With this terminology, a typical experiment \cite[e.g.][]{Ethier_Spontaneous_2008} would have a block structure of O-A-B-E, or O-A-(-A)-E, which means that the participant goes through a block of trials with no external force applied (O), a number of trials with a clockwise curl force (A), a block with counter-clockwise forces (B), and finally a block with error-clamp trials (E). With repeated contexts \citep[e.g.][]{Oh_Minimizing_2019}, an experiment can be described as $O_1$-$A_1$-$O_2$-\ldots .

\subsubsection{Savings and slow/fast switching}
The term 'savings' refer to the ability to remember a previously-learned adaptation and apply it without having to re-learn it. Savings is almost universally observed in humans \citep{Brashers-Krug_Consolidation_1996,Shadmehr_Functional_1997,Medina_Mechanism_2001,Smith_Interacting_2006,Zarahn_Explaining_2008}. In an O-A-O-A experiment, for example, savings would express themselves in the second A block in the form of a much higher adaptation rate higher than that observed during the first A block. The related concept of quick de-adaptation occurs in A-O transitions, where participants switch back to baseline without having to re-learn it.

In this section, we discuss savings and de-adaptation in terms of switching between forward models. This has been modeled before \citep[e.g.][]{Wolpert_Multiple_1998,Oh_Minimizing_2019,Imamizu_Explicit_2007}. Here we show in addition that expanding forward model switching into context inference explains facets of savings that these previous studies did not, namely that savings are not immediate, but a relatively fast process that reflects context inference.

To show this, we examined multiple experimental studies in which savings are observed. We categorized these studies based on the amount of contextual information made available to participants: In some experiments \citep[e.g.][]{Kim_Neural_2015,Lee_Dual_2009}, the context is clearly revealed to the participant. We call these cued-context experiments. In other experiments, partial information is available to participants \citep[e.g.][]{Davidson_Scaling_2004,Zarahn_Explaining_2008} in the form of large prediction errors, partial contextual information or reward prediction errors; we refer to these as partially-cued experiments.

We selected three representative experiments from two studies \citep{Kim_Neural_2015,Oh_Minimizing_2019} which differ in the amount of contextual information available to participants. \cite{Kim_Neural_2015} performed a cued-context visuomotor rotation experiment with three contexts with different rotation: no rotation, 40 degrees and -40 degrees. Participants performed shooting movements in blocks of trials with the same rotation. Importantly, a colored light identified the current context, making this a cued-context experiment. Consistent with our model, the authors found that switching was immediate and accurate. In \fref{fig:oh-2019}A we show the results of simulations with our model using the parameters of the task, as well as the experimental results from \cite{Kim_Neural_2015}. The correspondence between simulations and experimental results can be seen in the switches between contexts, i.e. when the solid black line (representing the true context) switches between 40, 0 and -40; in both panels (left and right), the blue line, representing the agent's adaptation, quickly follows the switches.

\begin{figure}
\centering
\includegraphics{./figures/figure_2.png}
\caption{Savings and de-adaptation. Data from our simulations (left column) compared to data adapted from figure 2A by \cite{Kim_Neural_2015} and figure 4A from \cite{Oh_Minimizing_2019} (right column). Experimental data was, in all three experiments, averaged across all participants; in our simulations, a single simulation is shown. In all panels, the blue line represents the adaptation displayed by the agent as a function of trial number. The black lines represent the optimal adaptation, i.e. the size of the true visuomotor rotation during the task. (A) Experiment by \cite{Kim_Neural_2015} with two visuomotor rotations (-40 and 40 degrees), in addition to baseline, with all possible transitions between A, (-A) and O. Participants must adapt to the rotations during shooting movements, and the blue line can be understood as the rotation of the participants' shooting movements to compensate for the task's rotation. When black and blue lines match, the participant perfectly counteracted the visuomotor rotation and reached the target. (B) An experiment by \cite{Oh_Minimizing_2019} similar to A, but the contexts were not cued and only one context, with an adaptation of 20 degrees, is introduced. O-A and A-O transitions (i.e. adaptation and de-adaptation) can be observed. Blue and black lines are as in A. Different blocks with the same adaptation are differentiated by the subscript (e.g. $A_1$ and $A_2$ have the same 20 degree visuomotor rotation). (C) Same experiment as (B) but with a 10 degree adaptation.} \label{fig:oh-2019}
\end{figure}

Critically, in \fref{fig:oh-2019}A it can be seen for the first four context switches (until about trial 250) that participants had not yet completely adapted to the rotation, as evidenced by the blue line not reaching as low or high as the black line during the first blocks. Switching between opposite adaptations was nevertheless immediate in simulations and experimental data. After around 500 trials, participants had adapted completely, as seen by the blue line reaching the heights of the black line, and switches continued to be immediate. These results are similar to those shown by \cite{Imamizu_Explicit_2007}, where sensory cues of varying reliability effected immediate or slow contextual switches. To expand on these results, we now turn to performance feedback and its effects on switching behavior.

\cite{Oh_Minimizing_2019} performed two partially-cued experiments with a visual rotation of 20 and 10 degrees, respectively. The results of their experiments can be seen in \fref{fig:oh-2019}B and \ref{fig:oh-2019}C, alongside simulations with our model. Participants in the first experiment (\fref{fig:oh-2019}B) first learned the adaptation in $A_1$. From the $A_1 - O_2$ transition onward, participants showed immediate switching (with a one-trial lag) between A and O (both ways), which can be seen in terms of the blue line (adaptation) closely following the switches in the black line (true rotation). In the second experiment (\fref{fig:oh-2019}C), switching happens more slowly, with adaptation lagging behind the switches in the real context, and slowly catching up. As can be seen in the left panels in \fref{fig:oh-2019}B and \ref{fig:oh-2019}C, the same model parametrization produces fast, accurate switches when the adaptation is large (B), and slow, noisy switches when it is low (C). This difference is explained by our model in terms of the size of the adaptation: as the adaptation is smaller (10 degrees), it becomes more difficult to distinguish errors made by incorrectly inferring the context from the noise due to trial-to-trial variation in motor output. Because of this, the model requires more evidence (i.e. more trials) to infer a switch in contexts.

Note that the results from our simulations, from \cite{Oh_Minimizing_2019} and from \cite{Kim_Neural_2015} include both savings (O-A transitions) and de-adaptation (A-O transitions), both of which display the same characteristics and are explained by the same mechanism.

\subsubsection{Uncertainty over contexts affects action selection}
As with learning, our model selects actions (motor commands) based on context inference. If the identity of the current context is known, the forward model for this context is used to select the current action. However, if uncertainty over the context exists, the selected action is influenced by all the possible contexts, with a weight directly related to how likely each one of those contexts is (see \eref{eqn:dist-comm}).

Experimental evidence supporting this view can be found in experiments with context switching. For example, \cite{Davidson_Scaling_2004} reported a curl-force experiment in which participants had to switch from 3A to A in one group, with a block sequence A-3A-A-3A, and from -A to A in another group, with a block sequence A-(-A)-A-(-A). After A and 3A (or -A in the other group) had been learned in the first two blocks, the authors found that the switch from 3A to A was faster than that from -A to A. The authors interpreted this as evidence that switching between adaptations happens more quickly if it is in the same direction as the current adaptation (e.g. both counter-clockwise), and more slowly if they are in the opposite direction (e.g. clockwise to counter-clockwise).

In our context-inference account, the asymmetry is caused by the baseline context, which have a non-zero probability $p(\zeta_O | s_t ...)$. When a new block of trials starts (e.g. in the transition from 3A to A), a switch is inferred by the model (given feedback after the first trial) and $\zeta_O$ becomes more likely (given that $\zeta_{3A}$ has been ruled out). Therefore, in these first trials, action selection has a component guided by the baseline model, in which no extra compensatory force is applied, effectively ``pulling'' adaptation towards zero (no compensatory force). In the first group, this initial pull towards zero accelerates the transition towards A because $3A > A > 0$, but in the second group, it slows down the switch because $A > 0 > -A$.

We simulated data with our model fitting the experimental structure in \cite{Davidson_Scaling_2004}. We show the results in \fref{fig:davidson-2004}, alongside the experimental results from \cite{Davidson_Scaling_2004}. It can be seen that the agent exposed to the -A context shifts back to A more slowly than the one exposed to 3A, qualitatively reproducing the data from \cite{Davidson_Scaling_2004}. Note that in our simulations, the difference between the groups, as well as the variability within each group, is smaller than in the experimental data. However, the effect can be reproduced with any number of simulated runs (each one representing one participant), pointing towards a reliable effect.

\begin{figure}
\centering
\includegraphics{./figures/figure_3.png}
\caption{Motor error when switching back to a previously learned adaptation. Following the block structure from \cite{Davidson_Scaling_2004}, the first 40 trials of the switch from 3A (yellow) or -A (blue) to A is shown(A) Simulations from our model, with the task parameters from \cite{Davidson_Scaling_2004}, running eight simulations per group, each simulation representing one participant. On the y axis, the error is shown in arbitrary units, related to centimeters through a monotonically increasing transformation with the same origin. The shaded area is the SEM across simulated runs (participants). (B) Data adapted from figure 4 by \cite{Davidson_Scaling_2004}, showing the error in the same trials as (A).}
\label{fig:davidson-2004}
\end{figure}

\subsubsection{Action selection in error-clamp blocks}
During error-clamp blocks at the end of block sequences, participants' behavior can be divided in two phases: (1) Spontaneous recovery, during which participants' behavior is consistent with a previously-encountered context (e.g. in an O-A-E experiment, consistent with A); this phase, when present, is seen during the early trials of the E block. (2) A slow return to baseline, which can last as long as hundreds of trials \citep{Brennan_Decay_2015}. However, the direction of the spontaneous recovery, its duration, the delay before it is observed, the speed of the return to baseline and the final asymptote of the adaptation vary greatly depending on the experiment \citep{Brennan_Decay_2015,Vaswani_Decay_2013,Smith_Interacting_2006,Shmuelof_Overcoming_2012}.

Because context inference integrates information from different sources, many experiments in which no intentional, overt contextual cues are available indeed contain contextual information that the participant can use to infer the context. For example, proprioceptive signals  provide contextual information \citep{Dizio_Motor_1995,Shadmehr_Adaptive_1994}. The sudden appearance of motor errors can itself be a cue for contextual change \citep{Herzfeld_memory_2014} and even a pause between two trials could suggest a change in context \cite{Ethier_Spontaneous_2008}.

In this section, we show how context inference can explain these different parameters of behavior by changing the way contextual cues mislead participants' context inference, which in turn influences action selection.

\cite{Vaswani_Decay_2013} studied in detail human behavior during an error-clamp block in a shooting movement paradigm with a mechanical arm. The authors found that during an E block at the end of each experiment, there was a lag of a few trials (depending on participant) before their motor behavior changed from that of the previous block. After that, the exerted force slowly dropped towards zero throughout tens of trials, but never reaching values around zero. Participants were divided into four groups, each of which going through a different block sequence: (1) A-E, (2) O-A-E, (3) (-A/2)-A-E, and (4) (-A)-E. No pauses were made during the experiment nor were there any contextual cues, so transitions between blocks were not signaled to participants.

In \fref{fig:vaswani-2013}A, we show data simulated with our model, following the parameters of the experiment by \cite{Vaswani_Decay_2013}, and in \fref{fig:vaswani-2013}B we show the experimental plots adapted from \cite{Vaswani_Decay_2013}. The displayed adaptation is shown during the E trials for the three experimental groups in the experiment. It can be seen that group 1.3 (i.e. the participants who had learned in the -A/2 context in addition to A) more quickly recognized a change in context and lowers the force applied on the mechanical handle, as can be seen in the experimental data.

\begin{figure}
\centering
\includegraphics[width=\textwidth]{./figures/figure_4.png}
\caption{Adaptation during error clamp trials. (A) Simulated adaptation during the error-clamp trials for the three groups of participants in \cite{Vaswani_Decay_2013}, using the same colors. The groups differ in the sequence of adaptations: 1.1 performed an A-E sequence; 1.2, O-A-E; 1.3, (-A/2)-A-E; and 1.4, (-A)-E. Following \cite{Vaswani_Decay_2013}, group 1.4 is not shown in A and B, as their behavior is identical to group 1.1. The solid line is the average across 10 runs (i.e. a group of 10 simulated participants) and the shaded area represents the standard deviation. The vertical dashed line is the start of the error-clamp trials. (B) Corresponding experimental data adapted from figure 2C by \cite{Vaswani_Decay_2013}. (C) Simulations: Inference over the current context, where contexts are color coded: black for baseline, orange for the counter-clockwise force, purple for the clockwise force and brown for counter-clockwise force with half strength. The lines represent the posterior probability of each context in every trial, while the background color represents the true context. An olive-colored background represents error-clamp trials. As in (A), solid lines represent the average across all runs and shaded areas represent the standard deviation. (D) Simulations: Visualization of the lag before a change in context is detected by the agent during the E trials. Each line represents one run (10 runs per group).}
\label{fig:vaswani-2013}
\end{figure}

In \fref{fig:vaswani-2013}C, the inference over context is shown for each group separately. Context inference works reliably until the error-clamp trials start, which do not correspond to any of the known contexts. This causes the agent to infer the combination of some of the known contexts that best fits the observations. Depending on the contexts previously learned by the agent: groups 1.1 and 1.4 display the same behavior, where the previous context (A and -A, respectively) slowly dwindles. These agents will slowly lower the force applied. In contrast, group 1.3 has learned the additional -A/2 context, which has a non-zero posterior probability during E trials, pushing the agent's adaptation force more quickly towards zero. Group 1.2 behaves similarly to 1.1, with the exception that the baseline context, which was recently seen, plays a bigger role during E trials, making the agent reduce its force during E trials slightly more quickly than groups 1.1 and 1.4.

Context inference also explains the variability in the lag before adaptation starts to drop to zero after the E block starts. In the model, this lag is due to a period in which context inference has not ``caught on'' to the change of context; during this period, behavior remains consistent with that of the previously-observed block, as can be seen in the experimental data as well. To show this, we show in \fref{fig:vaswani-2013}D the drop in the inferred probability of the previous context for each simulated run (one line per run, 10 runs per group, all groups). The start and speed of the drop depend on the run (i.e. the participant), reproducing the different lags observed in experimental data.

\section{Discussion}
We presented a hierarchical model for motor adaptation based on Bayesian inference, which not only learns to adapt its motor outputs by observing errors, but also infers the context in which these errors were committed and updates the forward model associated with that context.

We generalized the inference over the best-fitting internal models to the concept of context inference, which includes all sensory information, in addition to feedback provided by the experimenters or the task. With this, we showed how this seemingly-simple generalization provides a parsimonious explanation for several experimental phenomena across many experiments in motor adaptation that, up to now, had assumed the existence of multiple mechanisms.

We selected representative experimental studies that show the well-established effects of savings, quick de-adaptation, spontaneous recovery and the effects of sensory cues. Using our model, we showed how each of these effects can be explained by the specifics of context inference, which integrates all the available information (e.g. sensory cues, workspace location, reward and endpoint feedback), in some cases throughout many trials.

Our choice of an exact Bayesian learner greatly simplified our simulations, but we expect the results we presented here to hold using alternative models for motor adaptation, such as Kalman filter-based learners \cite[e.g.][]{Oh_Minimizing_2019,Baddeley_System_2003} and other Bayesian implementations \cite[e.g.][]{Wolpert_Multiple_1998,Kording_Bayesian_2004}, as well as the recently-introduced COIN model \citep{Heald_Contextual_2021}. An exception is linear learners \cite[e.g.][]{Smith_Interacting_2006,Forano_Timescales_2020,Lee_Dual_2009}, as these models do not incorporate uncertainty in the estimate of the parameters of the forward models.

\subsection{Further experimental evidence}
In many cases, the context is not directly observable and context inference takes the form of an evidence-accumulating process that can take any amount of time to be sure of the context. It is in these cases where the effects of context inference are most noticeable. While many experiments exist that give probabilistic contextual information \cite[e.g.][]{Scholz_uncontrolled_1999,Behrens_Learning_2007,Nassar_Dissociable_2019}, evidence accumulation is not limited to these explicit cases. Indeed, as we noted in the Results section, many experiments inadvertently include partial contextual information used by participants.

The most direct secondary contextual information comes in the form of reward and endpoint feedback. Participants are told whether they obtained the desired reward at the end of a trial and are shown the end point of their movement. When a participants observe an unexpectedly large error, they can infer that the inferred context might be incorrect. This is the case of the experiments by \cite{Oh_Minimizing_2019} shown in \fref{fig:oh-2019}B-C: if the adaptation is high, changes in context produce errors much larger than those of motor variability, and a context switch is easily and immediately identified; if adaptation is low, the errors produced by context switching are closer in magnitude to motor variability and evidence accumulation is necessary.

The same rationale explains the results by \cite{Herzfeld_memory_2014}: motor learning, which in our model is modulated by context inference, is minimal for errors close to 2 and -2 (see their figure 2E). This is because an error of 2 or -2 signals that the participant incorrectly identified the context (as adaptation has a magnitude of 1). Additionally, as was shown by \cite{Heald_Contextual_2021}, context inference explains the modulation of learning rate by the volatility of the environment observed by \cite{Herzfeld_memory_2014}.

A subtler source of information can be found in long pauses between blocks of adaptation trials, after which an unprompted partial return to baseline has been observed \cite{Ethier_Spontaneous_2008}. This can be explained by context inference, as a long pause could prompt participants to infer that a switch had occurred, prompting participants to rely on their belief of the underlying probability of observing any of the known contexts, which is dominated by the previously observed context A, but now includes a component of the baseline O, as it is the most common one in everyday life.

Error-clamp (E) trials present another insight. If error is kept at zero, one could assume that participants would continue doing what they were doing before, as there is no reason (no observed error) to infer a change in context. However, this is almost never the case \cite[e.g.][]{Smith_Interacting_2006,Ethier_Spontaneous_2008,Forano_Timescales_2020,Vaswani_Decay_2013,Scheidt_Persistence_2000,Pekny_Protection_2011}. Instead, participants slowly reduce their adaptation, often displaying spontaneous recovery \cite[e.g.][]{Smith_Interacting_2006}. Our model provides a principled account of this behavior: the natural variability in participants' behavior lead them to expect errors, which clashes with the observed zero error. This prompts participants to re-evaluate their inferred context, which can partially activate a previously-observed context, as we showed in \fref{fig:vaswani-2013}. \cite{Pekny_Protection_2011} found similar results, demonstrating that the duration of the previously-observed adaptation block also affects behavior in the E block. Additionally, \cite{Criscimagna-Hemminger_Consolidation_2008} showed that introducing long periods before the E block begins lowers the initial force that participants exerted on the mechanical arm during the E block; longer periods of time make context inference revert to the prior expectation that a new baseline block begins, because participants are free to move their arm about during the pause.

In our account, if all information indicating a change in context is removed from the experiment, participants would continue to behave as they were in the previous block. Evidence for this can be seen in experiments 2 and 3 by \cite{Vaswani_Decay_2013}, where participants were shown random errors during E trials, with a variance matching that of previously observed motor commands. The authors showed that by matching the errors expected by participants, they eliminated the slow tapering off observed in most E blocks.



\subsection{Model predictions and future work}
The basic principle behind the results we presented is that context inference is a process that develops over time and that carries with it uncertainty. This uncertainty affects learning and behavior during motor adaptation, effecting phenomena that are directly observable during behavioral experiments.

\subsubsection{Error-clamp as a known context}
The inclusion of reliable sensory contextual cues (e.g. lights whose color uniquely identify a context) makes switching immediate, as in the experiments by \cite{Kim_Neural_2015}. We expect that the same effect would be observed in error-clamp trials. If the E block is learned by participants during training, it might still be difficult for them to infer that an E block has started, which would create delays similar to those in \fref{fig:vaswani-2013}. However, the model predicts that if a visual cue is introduced that identifies the E block, participants would immediately switch to their baseline behavior, no longer displaying spontaneous recovery, lag, nor the slow return to baseline. This immediate switch in the presence of contextual cues would persist even if endpoint feedback is manipulated as \cite{Vaswani_Decay_2013} did.

\subsubsection{Reducing the effect of volatility on learning}
Experiments \citep{Herzfeld_memory_2014} have shown an effect of the volatility of the environment (i.e. unpredictable switching between contexts) on measured learning rate. Our model predicts that this effect would be greatly reduced if reliable contextual cues were introduced: if a participant can infer the context of the current trial before any decision or observation has occurred, the learning rate would not be affected by the volatility of the environment.

If this prediction is confirmed, our model would additionally suggest that human participants do not revisit the learned adaptation of the previous trial when a new observation comes in. To see this, consider the following scenario from the experiments by \cite{Herzfeld_memory_2014}: at trial $t$, the true context was B but the participant inferred context A, issued a motor command consistent with context A and then observed the outcome at $t + 1$. When the outcome is observed, it becomes clear to the participant that the context was B. Does the participant update the internal model of A or of B? According to our model, participants incorrectly update A and, upon learning of their mistake at trial $t+1$, do not revert this update. If this were not the case, the volatility of the environment would have no effect even without contextual cues, as the context at trial $t$ can almost always be identified at trial $t+1$.

\subsubsection{Multi-source integration}
The model also predicts an effect reminiscent of multisensory integration \citep{Ernst_Humans_2002}: in order to integrate contextual information from conflicting sources (e.g. probabilistic visual cues and noisy endpoint feedback), the weight placed on a source increases with its reliability. Such integration would manifest itself in experiments in which observations are noisy, as in the experiments by \cite{Kording_Bayesian_2004}, in which the position of the finger was obscured and instead participants are shown a blurry cursor which was some times shifted from its real position. If the added observation noise gives evidence for a particular context (the true underlying context or another one) and a visual cue gave partial information for another context, the participants' behavior would be more consistent with the most reliable source of contextual information.

\subsection{Conclusions}
The results we presented in this work show that many behavioral phenomena observed across different experiments can be explained by the uncertainty in context inference and its effects on learning and action selection. Together with the results by \cite{Heald_Contextual_2021}, these results suggest new venues of investigation for future works in motor adaptation and context-dependent behavior.


\section{Methods}
\subsection{Model description}
\label{subsection:model-description}
We first describe the general principle behind the model, followed, in the next
subsection, by the full mathematical description of each one of its components.

Before proceeding with the model description, let us introduce nomenclature:
\begin{itemize}
\item $t$: Discrete time at the moment an observation is made, before inference is done. 
Here taken as the trial number.
\item $\vartheta_t$: Observation. Note that this is assumed to be a noisy
observation of the generalized state (see below)
\item $s_t$: Hidden state, e.g. the position of the hand in reaching
experiments. It does not depend on the context.
\item $c_t$: Motor command (action) taken after observing $\vartheta_t$ and inferring the context.
\item $\zeta_t$: Categorical variable representing the context inferred after observing $\vartheta_t$.
\item $\omega_t$: Contextual information. This term includes, e.g. visual cues,
proprioceptive feedback, performance feedback.
\item $z_t$: Generalized state, $z_t = \{s_t, \zeta_t\}$. Observed noisily
as $\vartheta_t$.
\item $m_i$: Forward model for context $\zeta_i$.
\item $\phi_i$: Parametrization of the forward model $m_i$. In adaptation experiments, this
can be interpreted as the inferred size of the adaptation.
\end{itemize}

Context inference can work through context-specific (possibly unreliable) sensory cues,
or through the dynamics of the system (e.g. expected outputs of motor
commands), using prediction error as the force behind inference. In this case,
the generative model can be written as follows:
\[
p(z_t, \vartheta_t | z_{t-1}, c_{t-1}) = p(\vartheta_t | z_t)p(z_t|z_{t-1}, c_{t-1})
\]
and inferring the current (hidden) generalized state is done with Bayes' theorem:
\[
  q(z_t | \vartheta_t, \vartheta_{t-1}, c_{t-1}) \propto p(\vartheta_t | z_t)p(z_t|\vartheta_{t-1}, c_{t-1})
\]
  
Additionally, after having inferred the current state, motor adaptation is given by
\begin{equation}
q(\phi | z_t, z_{t-1}, c_{t-1}) \propto p(z_t | z_{t-1}, c_{t-1}, \phi)q(z_{t-1}|\ldots)p(\phi) \label{eqn:motor-adaptation}
\end{equation}
where $\phi$ are the parameters of the internal model for the dynamics, also called the forward model,
i.e. the function $f: (z_t, c_t) \rightarrow z_{t+1}$, which determines the beliefs of
the agent regarding how the system evolves after having taken action $c_t$. $q(z_{t-1}|\ldots)$ is the
posterior probability calculated in the previous trial.

Having inferred the generalized state (including context), a motor command is
sampled from a distribution:
\begin{equation}
p(c_t | s_t, \zeta_t) = \displaystyle\sum_{i}q(\zeta_i)p(c_t | s_t, \zeta_i)
\end{equation}
where $i$ runs over all contexts and $p(a_t | ... m)$ is the probability distribution over actions
prescribed by the forward model $m_i$ for context $\zeta_i$.

In the following sections, we present a specific mathematical implementation
of the principles outlined above. This is the implementation used throughout the
simulations in the Results section.

\subsubsection{Mathematical implementation}
The generalized state is given by:
\begin{equation}
z_t = \{s_t, \zeta_t\}
\end{equation}
where $s_t$ is, e.g. in a reaching task, the current position of the hand in
Cartesian coordinates, where the origin is the starting point. We assume that
motor commands are issued every $\Delta t$ for simplicity. At the beginning of
each time interval, the context is inferred combining the contextual
information and the prediction error of the outcome of the previous motor
command. This yields:
\begin{align}
  \begin{split}
  q(\zeta_t) &= q(\zeta_t | \omega_t)q(\zeta_t | s_t, s_{t-1}, c_{t-1}) \\ \label{eqn:estimated-context}
  q(\zeta_t | \omega_t) &\propto p(\omega_t | \zeta_t)p(\zeta_t) \\
  q(\zeta_t | s_t, s_{t-1}, c_{t-1}) &\propto p(s_t | \zeta_t, s_{t-1}, c_{t-1})p(\zeta_t)
  \end{split}
\end{align}
The terms $p(\zeta_t)$ refer to the prior probability of the context at the
beginning of the trial: at the first trial, this refers to prior beliefs over
which contexts are more common/likely, which we call $p_0(\zeta_t)$. At each
subsequent trial, it incorporates the belief that has so far been accumulated,
given previous trials. Note that certain events, such as the start of a new
block of trials (see main text) can return an agent to a state in which
$p_0(\zeta_t)$ becomes relevant.

We do not directly model hand movements or eye position. Instead, we model
systems in the motor error space: the position $s_t = 0$ represents a trial in
which no motor error occurred. We make use of the fact that in most
experiments, motor adaptation needs to happen in one of two directions
(e.g. clockwise vs. counter-clockwise) to keep the error space
one-dimensional. With this, $s_t > 0$ represents motor error in one direction
(e.g. clockwise) and $s_t < 0$, error in the other direction. We made this
choice because in this work we modeled different experiments with
different state spaces, but with the commonality of (at most)
two-dimensional error spaces. In order to model a specific experiment in its
own physical space (e.g. hand positions in a reaching task), only the dynamical
system  $p(s_t | \zeta_t, s_{t-1}, c_{t-1})$ would need to be adapted.

We assume that the decision-making agent has a baseline internal forward model $m_O$ that
maps motor commands to outcomes:
\begin{equation}
p(s_{t+1} | s_t, c_t, m=m_O) = f_O(s_t, c_t)
\end{equation}
where $c_t$ are motor commands (actions). We further assume that participants
have learned $f_O$ throughout their lives and use it to decide which motor
command to issue under normal circumstances (i.e. no adaptation). When a
perturbation is introduced, to which the participant must adapt, we assume they
learn a new forward model $f_m^{\phi}$, where $\phi$ represents the parameters
of the function that participants must learn. For example, in a saccade task,
$\phi$ represents the new gain. Note that $\phi$ depends on the context and
participants may need to use and update multiple forward adapted models
$f_m^{\phi}$ throughout one experiment.

Given a forward model $f_m$ (or $f_m^\phi$), action selection is done by
building a probability distribution over possible actions $c_t$ based on how
likely they are to produce zero motor error. For example, in saccade
experiments, motor commands are issued based on how likely they are to move the
fovea to the target. These motor commands are issued to counteract intrinsic
sources of error, such as muscle variability and exhaustion, and extrinsic
sources of error, such as the experimental manipulations on saccade gain. Thus,
the expected observed error can be written as:
\begin{equation}
p(\epsilon | c_t) \propto p(\epsilon_{\text{intrinsic}} | c_t) + p(\epsilon_{\text{extrinsic}} | c_t)
\end{equation}
and a motor command can be chosen to maximize the chance of observing zero error:
\begin{equation}
p(c_t) = argmin_{c_t} p(\epsilon | c_t)
\end{equation}

For simplicity, we assume that motor errors are Gaussian, such that:
\begin{equation}
p(\epsilon | c_t) = N(\mu_{\text{extrinsic}}, \sigma_\epsilon)
\end{equation}
where $\sigma_\epsilon$ incorporates both intrinsic and extrinsic sources of
error and is a free parameter of the model. The mean of the error is assumed to
have no intrinsic component.

With this, a forward model will produce a motor command with outcomes centered
at $-\mu_{\text{extrinsic}}$, which counteracts the externally-induced errors.

To complete the action-selection picture, we return to context inference. As
discussed above, action selection is made via a weighted sum of the motor commands
produced by each forward model:
\begin{equation}
p(c_t | ...) \propto \displaystyle \sum_{i} q(\zeta_i)p(c_t | \zeta_i, ...) \label{eqn:dist-comm}
\end{equation}
From this distribution, an action is sampled at each trial.

To update the agent's estimates on the parameters of the forward models, we
make use of Bayes' theorem with conjugate priors. This approach has the
advantage of not only greatly simplifying computational calculations, but also
presenting update equations with intuitive appeal.

In the following equations, we drop the dependence on the context and
observations for notational simplicity:
\begin{equation}
q(\phi | s_{1:t}) \propto p(s_{1:t} | \phi)p(\phi)
\end{equation}
where $s_{1:t}$ are the observed states up until time $t$. The likelihood is a
Gaussian:
\begin{align}
  p(s_t | \phi) &= N(\mu_s, \sigma_s)  \\
  \mu_s &= \phi + s_t \\
  \sigma_s &= \xi_0 1
\end{align}
This likelihood is the probability of observing $s$ given the previous estimate
of the parameters of the forward model, $\phi_{t-1}$, and given the dynamics of
the system (see below).

To update $\phi$, we assumed that for each context, the agent's belief over
the magnitude of the adaptation is given by a normal distribution:
\begin{equation}
p(\phi) = N(\mu_\phi, \sigma_\phi) \label{eqn:data-dist}
\end{equation}
where $\mu_\phi$ and $\sigma_\phi$ are parameters to be estimated at each
trial. Before the experiment begins, the agent will have a prior distribution
over these parameters. A standard Bayesian approach is to choose NormalGamma
priors:
\begin{equation}
p(\mu_\phi, \sigma_\phi) = NG(\mu_0, \nu_0, \alpha_0, \beta_0)
\end{equation}
where $\mu_{\phi}^0, \nu_{\phi}^0, \alpha_{\phi}^0$ and $\beta_{\phi}^0$ are free
hyperparameters of the model.

The update equations for the magnitude parameters are given by:
\begin{equation}
q(\mu_\phi, \sigma_\phi | s_t, s_{t-1}, c_{t-1}) \propto p(s_t |
s_{t-1}, c_{t-1}, \zeta_t)p(\mu_\phi, \sigma_\phi) \label{eqn:context-from-x}
\end{equation}
where $p(s_t | s_{t-1}, c_{t-1}, \zeta_t)$ is a Gaussian distribution centered
around $\mu_c$ with standard deviation $\sigma_c$, which is a free parameter of
the model. It is assumed that the standard deviation over outcomes ($\sigma_c$)
is related to that of the parameter $\mu_\phi$ as follows:
\begin{equation}
\sigma_\phi = \sigma_c / \nu_\phi
\end{equation}
which makes $\nu_\phi$ a parameter to estimate. Each one of the forward models can
be updated at every trial, depending on context inference (see main text). The
updated parameters for any one forward model $i$ are given by:
\begin{align}
  \begin{split}
  \mu_\phi^{(t)} &= \frac{\nu_\phi^{(t-1)} \mu_\phi^{(t-1)} + q(\zeta_i)s_t}{\nu_\phi^{(t-1)} + q(\zeta_i)} \\
  \nu_\phi^{(t)} &= \nu_\phi^{(t-1)} + q(\zeta_i) \\
  \alpha_\phi^{(t)} &= \alpha_\phi^{(t-1)} + q(\zeta_i) / 2 \\
  \beta_\phi^{(t)} &= \beta_\phi^{(t-1)} + \frac{q(\zeta_i)\nu_\phi^{(t-1)}}{\nu_\phi^{(t-1)} +
    q(\zeta_i)}\frac{\left(s_t - \mu_\phi^{(t-1)}\right)^2}{2}  \label{eqn:update-full}
  \end{split}
\end{align}
where $q(\zeta_i)$ is the posterior probability of context $\zeta_i$ from
\eref{eqn:estimated-context}. Note that when $q(\zeta_i) = 0$, the model $i$ is not
updated.

\subsubsection{Interpreting the hyperparameters}
\label{sec:interpreting-hyperparameters}
$\mu$ determines the initial estimate of the adaptation, in the same units as
the necessary adaptation. $\nu$ encodes how stable this hyperprior is: higher
values (e.g. 10,000) all but guarantee that the hypermean will not change its
value after observations; In principle, enough evidence should still modify it,
but that would not happen during an experiment. Smaller values (i.e. $\sim 1$)
make the hypermean follow evidence more freely. Note that as more observations
are accumulated, $\nu$ becomes bigger and bigger, stabilizing the value of the
hypermean.

The hyperparameters $\alpha$ and $\beta$ have a more complex effect. Note that
the mean of a gamma distribution is $1 / (\alpha \nu)$; this mean is being used
as the standard deviation of a Gaussian by the rest of the agent, which makes it
an important measure of uncertainty. While setting the default hyperparameters,
the values used are $\alpha = 0.5 / \sigma_0$ and $\beta = 0.5$, where
$\sigma_0$ is the \textit{a priori} estimate of the standard deviation of the
force exerted by the environment, which controls the initial learning rate. This
makes the initial standard deviation equal $\sigma_0$, which makes it consistent
with the fixed-force model. The 0.5 values ensure that uncertainty is large at
the beginning and is greatly reduced during the experiment, but never to a point
where it is so small that it makes trial-to-trial variation in the environment
surprising. Changing this 0.5 would make the standard deviation change more
quickly, making the model more or less precise in its predictions, independently
of the volatility of the mean of the adaptation (via the hypermean).

The baseline model defaults to different values that make it a lot more
stable. The hyper-standard deviation of the mean is set to 10,000, which makes
the mean entirely stable during the duration of the experiment. The values of
$\alpha$ and $\beta$ are fixed regardless of $\sigma_0$ such that the standard
deviation is 0.001 (compared that to the size of the adaptations in mechanical
arm experiments, around 0.0125), and the hyperparameters of the standard
deviation are stable during the experiment.


\section{Acknowledgment}
Funded by the German Research Foundation (DFG, Deutsche Forschungsgemeinschaft) as part of Germany’s Excellence Strategy – EXC 2050/1 – Project ID 390696704 – Cluster of Excellence “Centre for Tactile Internet with Human-in-the-Loop” (CeTI) of Technische Universität Dresden.

\bibliography{MyLibrary}



\end{document}
