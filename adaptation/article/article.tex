\documentclass[a4paper,doc,floatsintext,natbib]{apa6}
% \documentclass{article, a4paper}
\usepackage[font=small]{caption}
\usepackage{lscape}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{authblk}
\usepackage[utf8]{inputenc}
\usepackage{nameref}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{soul}
\usepackage{todonotes}

% Remember to start reftex-mode

\hypersetup{
  colorlinks=true,
  linkcolor=black,
  citecolor=black,
  urlcolor=black
  }

\setlength{\parskip}{1em}
\def \fref #1{Figure \ref{#1}}     % Reference figures
\def \tref #1{Table \ref{#1}}      % Reference tables
\def \eref #1{Equation \ref{#1}}   % Reference equations
\def \sref #1{Section '\nameref{#1}'}    % Reference sections

\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}

% For revision
\DeclareRobustCommand{\newcontent}[1]{#1}

\title{The effects of context inference on motor learning: savings, de-adaptation and spontaneous recovery}
\shorttitle{Context-inference-dependent motor learning}
\author[1,2]{Cuevas Rivera, Darío}
\author[1,2]{Kiebel, Stefan J.}
\affil[1]{Chair of Neuroimaging, Faculty of Psychology. Technische Universität Dresden, 01062 Dresden, Germany.}
\affil[2]{Centre for Tactile Internet with Human-in-the-Loop (CeTI)}
\affiliation{~}

\begin{document}

\maketitle

\abstract{Abstract}
Humans have been shown to adapt their movements when a sudden change to the dynamics of the environment is introduced, a phenomenon called motor adaptation. If the change is reverted, the adaptation is also quickly reverted. Human are also able to adapt to multiple changes in dynamics presented separately, and to be able to switch between adapted movements on the fly. Such switching relies on contextual information which is often noisy or misleading, which affects the switch between adaptations. In this work, we use a model to explain the behavioral phenomena effected by imperfect contextual information. Specifically, we present a hierarchical computational model for motor adaptation based on exact Bayesian inference. This model explicitly takes into account contextual information and how the dynamics of context inference affect adaptation and action selection. We show how the proposed model provides a unifying explanation for four different experimentally established phenomena: (i) effects of sensory cues and proprioceptive information on switching between tasks, (ii) the effects of previously-learned adaptations on switching between tasks, in addition to  (iii) the well-studied savings, de-adaptation and spontaneous recovery.


\section{Introduction}
Humans are able to adapt their movements to changing dynamics of the environment and of the body itself. We adapt to slow changes in our body dynamics, e.g. because of muscle exhaustion throughout the day, but we can also adapt to sudden changes in the environment. For example, when picking up a heavy object, we must adapt our motor commands to be able to move the extra weight safely. Even before picking it up, the size and material of an object provide us with contextual information which we can use to prepare the correct posture for moving the object. However, contextual information cannot always be relied on, e.g. a large parcel with unknown content.

It has been shown that humans can learn multiple tasks during the course of a single experiment, as well as learn to adapt to often-opposing modifications to the dynamics of movements \citep{Gandolfo_Motor_1996,Shadmehr_Functional_1997}, although interference between tasks can slow down learning \citep{Brashers-Krug_Consolidation_1996,Sing_Reduction_2010}. Additionally, humans have been shown to dynamically switch between different learned adaptation \citep{Davidson_Scaling_2004,Ethier_Spontaneous_2008,Lee_Dual_2009}. The mechanisms behind these switches, the specifics of how these switches manifest in behavior, and the ways in which switching can be impeded or improved, are an ongoing, active topic of research.

In order to study motor adaptation, motor error is defined in experiments as the deviation between the observed movements of a participant and a baseline movement. For example, in experiments with a mechanical arm \citep[e.g.][]{Gandolfo_Motor_1996}, a correlation coefficient can be defined between the movements when the mechanical arm exerts a force and the movements when it does not; the higher the correlation coefficient, the lower the error. Other examples include measuring the force profile in error-clamp trials \citep{Smith_Interacting_2006}, endpoint errors in visuomotor rotations \citep{Kim_Neural_2015} and saccade adaptation \citep{Catz_Cerebellardependent_2008}.

By introducing blocks of trials in which a manipulation is present (e.g. a mechanical arm exerts a force), experimenters are able to observe the dynamics of adaptation through the lens of motor error. Across many different motor adaptation experiments, now well-established phenomena have been observed, for example: (i) savings (the ability to recall previously-learned skills), (ii) quick de-adaptation (the ability to return to unmodified dynamics), (iii) anterograde interference (the interference in motor learning between opposing manipulations in dynamics) and (iv) spontaneous recovery (during trials where errors are forced to be zero, the display of behavior consistent with the previously-learned dynamics) \citep[e.g.][]{Davidson_Scaling_2004}.

To explain these phenomena, a number of computational models have been introduced. The least complex of these models are linear learners \citep{Smith_Interacting_2006,Forano_Timescales_2020,Scheidt_Learning_2001}, in which a single one-dimensional variable is used to describe the adaptation of motor commands given the observed motor errors. By having multiple time scales, each with a learning rate and a forgetting rate, these models have been fitted to experimental data, partially explaining these distinct experimental phenomena.

Bayesian accounts of motor adaptation have also been presented, providing an alternative explanation for savings and quick de-adaptation in the form of switching between internal models of adaptation via predictions generated by these internal models \citep{Kording_Bayesian_2004,Oh_Minimizing_2019}. These models replace the idea of explicit multiple time scales with an estimation of their own uncertainty: as the the same task is practiced, the uncertainty on an estimate of the underlying modification is reduced, which lowers variability in responses and increases the stability of the estimate.

While these general models of adaptation explain the most common phenomena observed in experiments, other known phenomena remain outside of their scope. For example, it is known that adaptation rate is reduced in situations where the environment is unstable and unpredictable \citep{Herzfeld_memory_2014}, or situations in which errors are small \citep{Marko_Sensitivity_2012} and slowly introduced \citep{Huang_Persistence_2009}. Action selection has also been found to depend on the history of adaptations learned \citep{Vaswani_Decay_2013,Davidson_Scaling_2004}.

In this work, we show that these unexplained phenomena, alongside savings, de-adaptation, anterograde interference and spontaneous recovery, can be explained in terms of the concept of context, an idea that has recently been gaining traction in different fields \cite[e.g.][]{Sanders_Hippocampal_2020,Hunter_Contextsensitive_2021}. Intuitively, in mechanical arm experiments, one can think of one context in which the arm exerts no force and one in which it does. By inferring the current context, a participant can know how to counteract the mechanical arm and succeed in a reaching movement. In some experiments, the context is clearly inferable via sensory cues \cite[e.g.][]{Gandolfo_Motor_1996,Shadmehr_Adaptive_1994,Ethier_Spontaneous_2008}. In many other experiments, the context is not directly observable, and context inference is probabilistic and takes the form of an evidence-accumulating process across multiple trials. In this work, we propose that the behavioral consequences of this slow process of evidence accumulation can be observed in behavior and can be used to explain the phenomena outlined above.

To this end, we present a computational model for motor adaptation inspired by models such as MOSAIC \citep{Wolpert_Multiple_1998} and Bayesian switching models \citep{Kording_Bayesian_2004,Oh_Minimizing_2019}. We build on these models by expanding the concept of context and introducing an explicit mechanism for inferring the context based on Bayesian inference. In our model, the context encompasses all the information relevant to making decisions, both environmental and internal to the agent making these decisions. To infer the current context, our model integrates several sources of information, including the predictions made by its internal forward models, an estimate of the reliability of these predictions, direct sensory information (such as visual contextual cues), proprioceptive information, and feedback provided by the environment (e.g. whether the task was successfully completed). Having inferred the context, the model can choose the best-fitting internal model with which to make decisions.

We show that the dynamics of context inference provide a principled mechanistic explanation for the experimental phenomena outlined above, providing a single account for motor adaptation under changing contexts, while relying on known mechanisms for adaptation.

\section{Results}
In this work, we present a motor adaptation model in which the agent (e.g. a human learning a motor task) updates an existing model of the environment based on error signals produced by the need of adaptation. Several models exist for such error-based motor adaptation \cite[e.g.][]{Wolpert_Multiple_1998,Kording_Bayesian_2004,Oh_Minimizing_2019}. We expand on these existing models by adding an explicit component of context inference. As we will show, this context inference guides the selection of the adequate internal model, its updating and the sampling of actions.

In what follows, we show that the proposed model explains several experimental phenomena found in previous studies. We simulated representative experiments from these studies to illustrate how our model explains these experimental findings using the dynamics of context inference. We will present these simulations alongside the experimental results from the representative studies and discuss in detail how context inference explains the experimental phenomena.

Before presenting our simulations, we will briefly go through the fundamentals of the model we present. We leave the mathematical details of the implementation to the Methods section.

\subsection{Modeling context-dependent adaptation}
The model we present has three main components: (1) context inference, (2) motor adaptation and (3) action selection. The processes defined by these component happen in this order, and each component informs the ones that follow: motor adaptation is informed by context inference, and action selection is informed directly by both motor adaptation and by context inference.

Central to the model is the concept of context. In our model, contexts are defined in terms of the task to be performed (see \fref{fig:model}A), the variables of the environment that are relevant to perform the task, the forward models used by the decision-making agent to perform the task, and the update mechanisms necessary to adapt these forward models to the variables of the environment. Together, these elements allow the agent to make predictions on future observations when this context is active, and these predictions are used to infer the context. For example, when lifting an object of unknown weight, an agent might have learned one context for heavy objects and one for light objects. When observing an object to be lifted, the agent can use its size and texture to estimate the weight of the object, which in turn allows the agent to infer the appropriate context and, with it, decide how to lift the object. These contextual cues (size and texture) do not necessarily identify the context with certainty (e.g. it could be a movie prop that looks like a rock) and integration over time might be necessary. All the variables of the model are fully described in the Methods section.

\begin{figure}
\centering
\includegraphics[]{./figures/figure_1.png}
\caption{Description of the model. (A) Definition of a context in terms of its components. (B) Update equations for context inference, motor adaptation and action selection. $\zeta$ represents the identity of the context as a categorical variable, $\vartheta$ are observations, $c_t$ are motor commands at trial $t$, $\phi$ are the parameters of the forward model and $s$ are the hidden states of the environment (e.g. the position of the hand). (C) Schematic representation of the model. The arrows show flow of information, i.e. the dependencies in the update equations, as well as the flow of a single trial. The elements (e.g. $q(\zeta)$) are those shown in B. Trial $t$ starts at the top when an observation $\vartheta_t$ is received, from which the current context is inferred ($q(\zeta)$), which informs motor adaptation ($q(\phi)$), which informs action selection ($p(c)$). After an action is selected, a new observation $\vartheta_{t+1}$ is received and the process is repeated. The posteriors over $\zeta$ and $\phi$ are used as priors at the next trial.}
\label{fig:model}
\end{figure}

We now briefly describe the three components of the model separately. For clarity, we start with the second component (i.e. motor adaptation), in order to introduce the terminology that we use throughout this work. For an overview, we show in \fref{fig:model}B and C how these three components affect each other.

\subsubsection{Motor adaptation}
Motor adaptation refers to the ability of humans and other animals to adapt their motor commands based on performance errors. For example, we can learn to perform a reaching movement even when underwater, where the relatively high viscosity of water means that the motor commands we have learned all our lives no longer produce the desired effect.

It is widely accepted that in order to adapt motor commands to a novel environment, we create and update internal forward models of the outcomes of control signals \citep{Wolpert_Multiple_1998}. Here, we use this principle and chose to make use of an exact Bayesian learner. As has been discussed before \citep{Oh_Minimizing_2019}, a Bayesian learner has the advantage of not only fitting experimental data on motor adaptation, but also eliminating the need for explicit multiple time scales of learning as the learner can deal with adaptation after any number of trials. As we will show below this feature will be useful to explain specific key phenomena parsimoniously.

To describe this component of the model, we make use of the example of reaching movements. We define a forward model as follows:
\begin{equation}
p(\vartheta | s, c; \phi) = f(s, c; \phi) \label{eqn:forward-model}
\end{equation}
where $\vartheta$ are the predicted outcomes of an action (e.g. the final position of the hand in a reaching movement), $s$ is the current state (the current position of the hand), $c$ is a motor command and $\phi$ are the parameters of the forward model $f(\cdot)$. We assume that during learning the parameters $\phi$ have been fine tuned to produce an accurate forward model $f$ to guide our movements and it is these parameters which are updated during motor adaptation.

When an observed outcome does not match the predictions produced by $f$, the prediction error is used to update the parameters $\phi$ of the forward model. To describe this adaptation process, our model makes uses of Bayesian inference, such that
\begin{equation}
q(\phi | \vartheta, s, c) \propto p(\vartheta | s, c, \phi)p(\phi) \label{eqn:update-mini}
\end{equation}
where $q(\phi | ...)$ represents the new estimated probability distribution over the possible values of $\phi$ after having observed the outcome $\vartheta$ of the previous motor command $c$. The likelihood $p(\vartheta | s, c, \phi)$ is the probability of observing the outcome $\vartheta$ as predicted by the forward model $f$, and $p(\phi)$ is the previous estimate of $\phi$.

\subsubsection{Context inference}
In our model, the idea of context is quite general (see \fref{fig:model}A). The context comprises the relevant elements of the environment (e.g. the strength and direction of the wind when walking), of the task at hand (e.g. immediate and long-term goals and reward structure) and task-related information internal to the decision-making agent (e.g. forward model, decision-making algorithms, motor adaptation equations, expected observations). Most previous models \cite[e.g.][]{Wolpert_Multiple_1998,Imamizu_Neural_2008,Oh_Minimizing_2019} have focused on the elements of the context which are directly related to the internal models: given a past action, the different internal models (e.g. two forward models $f_B$ and $f_H$) make different predictions for the outcome of that action; the model that best predicts that action is deemed to be the ``correct'' model, i.e. the model that best represents the context. In addition, \cite{Imamizu_Explicit_2007} expanded on this idea by showing the effects of visual cues on model switching.

Following these ideas, our model performs context inference that integrates several sources of information, including sensory cues, proprioceptive information, outcome prediction errors and reward prediction errors.

In the model, context is a categorical variable $\zeta$ which is inferred using Bayes' theorem:
\begin{equation}
q(\zeta | \vartheta_t, \vartheta_{t-1}, c_{t-1}) \propto p(\vartheta_t | \vartheta_{t-1}, c_{t-1})p(\zeta)
\label{eqn:context-inference-mini}
\end{equation}
where the prior distribution over contexts $p(\zeta)$ includes information from two sources: (1) an expectation of continuity, encoding the expectation that the context does not change from trial to trial, and (2) an overall expectation of observing any one context, if the context did change. Below, we discuss how these two sources of information effect different experimentally observed phenomena.

In the previous section, we used the variable $\vartheta$ to refer to the outcomes of actions. In this section, we expand the definition of an observation $\vartheta$ to include any information given to the decision-making agent by the environment. This includes, as before, the outcomes of actions (e.g. the new position of the hand), but also any other sensory information that might be indirectly related to actions, or even completely independent from them, as is the case for visual cues in experiments \cite[e.g.][]{Addou_Colored_2011}. For this section, the most important component of $\vartheta$ is contextual sensory information, i.e. information that might directly help infer the identity of the current context.

In experimental settings, the contextual sensory information can take the form of a visual cue \citep[e.g.][]{Lee_Dual_2009,Kim_Neural_2015}, the place where the task must be carried out \citep[e.g.][]{Forano_Timescales_2020,Shadmehr_Adaptive_1994} or even the start of a new block of trials \citep{Ethier_Spontaneous_2008}. All these sources of information, alongside the outcomes of previous actions and the priors $p(\vartheta)$ form part of $p(\vartheta_t | \vartheta_{t-1}, c_{t-1})$ and are integrated together to infer the identity of a context.


\subsubsection{Action selection}
Action selection is affected by the current context via the context-dependent forward model that is used. In our model, action selection is made by building a distribution over available actions which is a weighted sum of the distributions given by the existing forward models, where the weights are obtained by the context inference component of the model. In other words, a distribution is created as follows:
\begin{equation}
p(c_t) \propto \displaystyle\sum_{\zeta \in \Phi}q(\zeta | \vartheta_t, \vartheta_{t-1}, c_{t-1}) p(c_t | \zeta) \label{eq:action-selection}
\end{equation}
where $p(c_t | \zeta)$ corresponds to \eref{eqn:forward-model}. From this distribution, the current action (motor command $c_t$) can be sampled and carried out.


\subsubsection{From observation to action selection}
Each trial starts with a new observation $\vartheta_t$, which comprises contextual sensory information (when available), as well as the outcome of the previously-selected action.

The first step in the model is to perform context inference using the current observation $\vartheta_t$ according to \eref{eqn:context-inference-mini} and \eref{eqn:estimated-context}. Once a probability distribution over contexts has been created, all models are updated according to \eref{eqn:update-mini} and \eref{eqn:update-full}, based on the distribution over contexts. Finally, action selection is performed using the distribution over contexts as well as the updated forward models, following \eref{eq:action-selection}.


\subsection{Experimental results}
In this section, we present experimentally-observed phenomena in four sections, and show that context inference, as done in our model, provides a unifying explanation for all of them. In the first section, we discuss switches between contexts, and how slow context inference affects these switches. In the second section, we focus on the effects of volatility in the environment on motor adaptation. In the third section, we discuss the effects of slow context inference on action selection. Finally, in the fourth section we discuss context inference during so-called error-clamp trials, and its effect on behavior. For each of the four sections, we selected one or two studies which are representative of the phenomenon being discussed; a more extensive review of the literature can be found in the Discussion.

For clarity, we first introduce necessary terminology that is typically used in experimental studies and will be useful for linking experimental to computational observations. As an example, we will use a typical motor adaptation task in which participants have to make reaching movements while holding the handle of a mechanical arm that exerts a curl force (i.e. a force that pushes the participant's hand in the direction perpendicular to movement). Depending on the trial, the mechanical arm might exert a curl force in a clockwise or counter-clockwise direction, or no force at all. Let us define the baseline context O as that in which the mechanical arm exerts no force. Context A can be defined as that in which the arm exerts the clockwise curl force and context B counter-clockwise. Additionally, abusing notation, the usual statement is that $B = (-A)$, as the forces have the same magnitude but point in opposite directions. Studies often talk of contexts such as A and A/2, which means that both have the same direction of the adaptation (e.g. clockwise), but the second one has half the magnitude. Finally, many experiments include a block of error-clamp trials at the end of the experiment, in which the mechanical arm forces the participant to make straight-line movements; we represent these with the letter E.

With this terminology, a typical experiment \cite[e.g.][]{Ethier_Spontaneous_2008} would have a block structure of O-A-B-E, or O-A-(-A)-E, which means that the participant goes through a block of trials with no external force applied (O), a number of trials with a clockwise curl force (A), a block with counter-clockwise forces (B), and finally a block with error-clamp trials (E).

In some experiments, adaptation blocks are repeated throughout the experiments. For example, \cite{Oh_Minimizing_2019} used an O-A-O-A-O-A-O-A sequence. To differentiate the repeating blocks, the authors named them $O_i$ and $A_i$, where $i = 1, 2, ...$. Their experiment can be described as $O_1$-$A_1$-$O_2$-.... We adopt this naming convention.

We use the term "learned adaptation" and similar to refer to motor outputs (e.g. reaching movements) that have already been adapted by the participant to a change in the dynamics of the environment. For example, the learned adaptation during a task with a curl force refers to the movements of the participant that already counteract the force exerted by the mechanical arm.

<<<<<<< HEAD
\subsection{Savings and slow/fast switching}
=======
\subsubsection{Savings and slow/fast switching}
>>>>>>> 37accfed1cde9e6d4f82c4b8657e73f46d32ce8d
The term 'savings' refer to the ability of humans and other animals to remember a previously-learned adaptation and apply it without having to re-learn it. Savings is almost universally observed in human participants \citep{Brashers-Krug_Consolidation_1996,Shadmehr_Functional_1997,Medina_Mechanism_2001,Smith_Interacting_2006,Zarahn_Explaining_2008}. In an O-A-O-A experiment, for example, savings would express themselves in the second A block in the form of a much higher adaptation rate higher than that observed during the first A block.

In this section, we discuss savings, and the related phenomenon of de-adaptation, in terms of switching between forward models. This has been modeled before \citep[e.g.][]{Wolpert_Multiple_1998,Oh_Minimizing_2019,Imamizu_Explicit_2007} where we show in addition that expanding forward model switching into context inference explains facets of savings that these previous models do not.

To show this, we examined multiple experimental studies in which savings are observed. We categorized these studies based on the amount of contextual information made available to participants into cued-context and partially-cued experiments: In some experiments \citep[e.g.][]{Kim_Neural_2015,Lee_Dual_2009}, the context is clearly revealed to the participant. We call these cued-context experiments. In other experiments, partial information is available to participants \citep[e.g.][]{Davidson_Scaling_2004,Zarahn_Explaining_2008} in the form of large prediction errors, partial contextual information or reward prediction errors; we refer to these as partially-cued experiments.

Because context inference integrates information from different sources, many experiments in which no intentional, overt contextual cues are available indeed contain contextual information that the participant can use to infer the context. For example, in curl-force-field experiments with mechanical arms, the force feedback provided by the mechanical arm always gives participants a sense for the current context, although error-clamp trials are difficult to distinguish from adaptation trials based on force feedback alone. In fact, the mere act of holding the handle informs participants that something is different from baseline. Proprioceptive signals can also provide contextual information \cite{Dizio_Motor_1995,Shadmehr_Adaptive_1994}. The sudden appearance of motor errors can itself be a cue for contextual change, as long as the motor error is perceivably higher than the expected trial-by-trial variation in performance, and even an unusually long pause between two trials could indicate to participants that a new block with a potentially different context could have started \cite{Ethier_Spontaneous_2008}.

To our knowledge, there are no experiments in which no contextual information is available. However, many experiments \citep[e.g.][]{Huang_Persistence_2009,Brennan_Decay_2015,Smith_Interacting_2006} contain blocks of error-clamp trials in which participants are not provided with contextual information. These blocks could be considered uncued, however, as we discuss in the following sections, contextual information is nevertheless available to participants. In this section, we focus on cued and partially-cued experiments and leave error-clamp trials to the following sections.

To show how adaptation changes depending on the amount of contextual information, we selected three representative experiments from two studies: \cite{Kim_Neural_2015} and \cite{Oh_Minimizing_2019} which differ in the amount of contextual information. \cite{Kim_Neural_2015} performed a cued-context visuomotor rotation experiment with three contexts with different rotation: no rotation, 40 degrees and -40 degrees. Participants performed shooting movements in blocks of trials with the same rotation. Importantly, the identity of the current context was displayed as a visual cue (colored light), making this a cued-context experiment. Consistent with our model, the authors found that switching was immediate and accurate. In \fref{fig:oh-2019}A we show the results of simulations with our model using the parameters of the task, as well as the experimental results from \cite{Kim_Neural_2015}. The correspondence between simulations and experimental results can be seen in the switches between contexts, i.e. when the solid black line (representing the true context) switches between 40, 0 and -40; in both panels (left and right), the blue line, representing the agent's adaptation, quickly follows the switches.

\begin{figure}
\centering
\includegraphics{./figures/figure_2.png}
\caption{Savings and de-adaptation. Data from our simulations (left column) compared to data adapted from figure 2A by \cite{Kim_Neural_2015} and figure 4A from \cite{Oh_Minimizing_2019} (right column). Experimental data was, in all three experiments, averaged across all participants; in our simulations, a single simulation is shown. In all panels, the blue line represents the adaptation displayed by the agent as a function of trial number. The black lines represent the optimal adaptation, i.e. the size of the true visuomotor rotation during the task. (A) Experiment by \cite{Kim_Neural_2015} with two visuomotor rotations (-40 and 40 degrees), in addition to baseline, with all possible transitions between A, (-A) and O. Participants must adapt to the rotations during shooting movements, and the blue line can be understood as the rotation of the participants' shooting movements to compensate for the task's rotation. When black and blue lines match, the participant perfectly counteracted the visuomotor rotation and reached the target. (B) An experiment by \cite{Oh_Minimizing_2019} similar to A, but the contexts were not cued and only one context, with an adaptation of 20 degrees, is introduced. O-A and A-O transitions (i.e. adaptation and de-adaptation) can be observed. Blue and black lines are as in A. Different blocks with the same adaptation are differentiated by the subscript (e.g. $A_1$ and $A_2$ have the same 20 degree visuomotor rotation). (C) Same experiment as (B) but with a 10 degree adaptation.} \label{fig:oh-2019}
\end{figure}

Critically, in \fref{fig:oh-2019}A it can be seen until trial 250 and especially for the first four context switches,  that participants did not completely adapt to the rotation, as evidenced by the blue line not reaching as low or high as the black line during the first blocks. Switching between opposite adaptations was nevertheless immediate in simulations and experimental data. After around 500 trials, participants had adapted completely, as seen by the blue line reaching the heights of the black line, and switches continued to be immediate.

These results are similar to those shown by \cite{Imamizu_Explicit_2007}, where sensory cues of varying reliability effected immediate or slow contextual switches. To expand on these results, we now turn to performance feedback and its effects on switching behavior.

\cite{Oh_Minimizing_2019} performed partially-cued experiments similar to \cite{Kim_Neural_2015}. The authors performed two experiments that differed in the size of the adaptation: in the first experiment, the angle of rotation was 20 degrees, while in the second experiment it was only 10 degrees. The results of their experiments can be seen in \fref{fig:oh-2019}B and \ref{fig:oh-2019}C, respectively, alongside simulations with our model. Participants in the first experiment (\fref{fig:oh-2019}B) first learned the adaptation in $A_1$. From the $A_1 - O_2$ transition onward, participants showed immediate switching (with a one-trial lag) between A and O (both ways), which can be seen in terms of the blue line (adaptation) closely following the switches in the black line (true rotation). In the second experiment (\fref{fig:oh-2019}C), switching happens more slowly, with adaptation (blue line) lagging behind the switches in the real context (black line), and slowly catching up. As can be seen in the left panels in \fref{fig:oh-2019}B and \ref{fig:oh-2019}C, the same model parametrization produces fast, accurate switches when the adaptation is large (B), and slow, noisy switches when it is low (C). This difference is explained by our model in terms of the size of the adaptation: as the adaptation is smaller (10 degrees), it becomes more difficult to distinguish errors made by incorrectly inferring the context from the noise due to trial-to-trial variation in motor output. Because of this, the model requires more evidence (i.e. more trials) to infer a switch in contexts.

Note that the results from our simulations, from \cite{Oh_Minimizing_2019} and from \cite{Kim_Neural_2015} include both savings (O-A transitions) and de-adaptation (A-O transitions), both of which display the same characteristics and are explained by the same mechanism in our model.



\subsubsection{Uncertainty over contexts affects action selection}
As with learning, our model selects actions (motor commands) based on context inference. If the identity of the current context is known, the forward model for this context is used to select the current action. However, if uncertainty over the context exists, the selected action is influenced by all the possible contexts, with a weight directly related to how likely each one of those contexts is (see \eref{eq:action-selection}).

Experimental evidence supporting this view can be found in experiments with context switching. For example, \cite{Davidson_Scaling_2004} reported an curl-force experiment in which participants had to switch from 3A to A in one group, with a block sequence A-3A-A-3A, and from -A to A in another group, with a block sequence A-(-A)-A-(-A). After A and 3A (or -A in the other group) had been learned in the first two blocks, the authors found that the switch from 3A to A was faster than that from -A to A. The authors interpreted this as evidence that switching between adaptations happens more quickly if it is in the same direction as the current adaptation (e.g. both counter-clockwise), and more slowly if they are in the opposite direction (e.g. clockwise to counter-clockwise).

Our model offers a different explanation of the observed results, based on context inference: the asymmetry is due to the existence of the baseline context. As discussed above, action selection in our model is done via a weighted average (see \eref{eq:action-selection}). In experiments without cued contexts, the baseline context O and its associated forward model $m_O$, have a non-zero probability $p(\zeta | s_t ...)$. When a new block of trials starts (e.g. in the transition from 3A to A), a switch is inferred by the model (given feedback after the first trial) and $m_O$ becomes more likely (given that $m_{3A}$ has been ruled out). Therefore, in these first trials, action selection has a component guided by the baseline model, in which no extra compensatory force is applied, effectively ``pulling'' adaptation towards zero (no compensatory force). In the first group, this initial pull towards zero accelerates the transition towards A because $3A > A > 0$, but in the second group, it slows down the switch because $A > 0 > -A$.

We simulated data with our model fitting the experimental structure in \cite{Davidson_Scaling_2004}. We show the results in \fref{fig:davidson-2004}, alongside the experimental results from \cite{Davidson_Scaling_2004}. It can be seen that the agent exposed to the -A context shifts back to A more slowly than the one exposed to 3A, qualitatively reproducing the data from \cite{Davidson_Scaling_2004}, shown in \fref{fig:davidson-2004}B. Note that in our simulations, the difference between the groups, as well as the variability within each group, is smaller than in the experimental data. However, the effect can be reproduced with any number of simulated runs (each one representing one participant), pointing towards a reliable effect. While we focused here on a specific, well-known experiment, we discuss experiments similar to that by \cite{Davidson_Scaling_2004} in the Discussion.

\begin{figure}
\centering
\includegraphics{./figures/figure_3.png}
\caption{Motor error when switching back to a previously learned adaptation. Following the block structure from \cite{Davidson_Scaling_2004}, the first 40 trials of the switch from 3A (yellow) or -A (blue) to A is shown(A) Simulations from our model, with the task parameters from \cite{Davidson_Scaling_2004}, running eight simulations per group, each simulation representing one participant. On the y axis, the error is shown in arbitrary units, related to centimeters through a monotonically increasing transformation with the same origin. The shaded area is the SEM across simulated runs (participants). (B) Data adapted from figure 4 by \cite{Davidson_Scaling_2004}, showing the error in the same trials as (A).}
\label{fig:davidson-2004}
\end{figure}

Further evidence for this effect of uncertainty about contexts can be found during error-clamp blocks in several experiments. We discuss these experiments in the following section. Additionally, we discuss experiments similar to that by \cite{Davidson_Scaling_2004} in the Discussion.


\subsubsection{Action selection in error-clamp blocks}
During error-clamp blocks at the end of block sequences, participants' behavior can be divided in two phases: (1) Spontaneous recovery, during which participants' behavior is consistent with a previously-encountered context (e.g. in an O-A-E experiment, consistent with A); this phase, when present, is seen during the early trials of the E block. (2) A slow return to baseline (i.e. no observable adaptation, consistent with the baseline context), which can last as long as hundreds of trials \citep{Brennan_Decay_2015}. However, the direction of the spontaneous recovery, its duration, the delay before it is observed, the speed of the return to baseline and the final asymptote of the adaptation seem to vary greatly depending on the experiment \citep{Brennan_Decay_2015,Vaswani_Decay_2013,Smith_Interacting_2006,Shmuelof_Overcoming_2012}.

In this section, we show how our model can explain these different parameters of behavior by changing the way contextual cues mislead participants' context inference, which in turn influences action selection.

\cite{Vaswani_Decay_2013} studied in detail human behavior during an error-clamp block in a shooting movement paradigm with a mechanical arm. The authors found that during an E block at the end of each experiment, there was a lag of a few trials (depending on participant) before their motor behavior changed from that of the previous block. After that, the exerted force slowly dropped towards zero throughout tens of trials, but never reaching values around zero. Participants were divided into four groups, each of which going through a different block sequence: (1) A-E, (2) O-A-E, (3) (-A/2)-A-E, and (4) (-A)-E. No pauses were made during the experiment nor were there any contextual cues, so transitions between blocks were not signaled to participants.

In \fref{fig:vaswani-2013}A, we show data simulated with our model, following the parameters of the experiment by \cite{Vaswani_Decay_2013}, and in \fref{fig:vaswani-2013}B we show the experimental plots adapted from \cite{Vaswani_Decay_2013}. The displayed adaptation is shown during the E trials for the three experimental groups in the experiment. It can be seen that group 1.3 (i.e. the participants who had learned in the -A/2 context in addition to A) more quickly recognizes a change in context and lowers the force applied on the mechanical handle, as can be seen in the experimental data.

\begin{figure}
\centering
\includegraphics[width=\textwidth]{./figures/figure_4.png}
\caption{Adaptation during error clamp trials. (A) Simulated adaptation during the error-clamp trials for the three groups of participants in \cite{Vaswani_Decay_2013}, using the same colors. The groups differ in the sequence of adaptations: 1.1 performed an A-E sequence; 1.2, O-A-E; 1.3, (-A/2)-A-E; and 1.4, (-A)-E. Following \cite{Vaswani_Decay_2013}, group 1.4 is not shown in A and B, as their behavior is identical to group 1.1. The solid line is the average across 10 runs (i.e. a group of 10 simulated participants) and the shaded area represents the standard deviation. The vertical dashed line is the start of the error-clamp trials. (B) Corresponding experimental data adapted from figure 2C by \cite{Vaswani_Decay_2013}. (C) Simulations: Inference over the current context, where contexts are color coded: black for baseline, orange for the counter-clockwise force, purple for the clockwise force and brown for counter-clockwise force with half strength. The lines represent the posterior probability of each context in every trial, while the background color represents the true context. An olive-colored background represents error-clamp trials. As in (A), solid lines represent the average across all runs and shaded areas represent the standard deviation. (D) Simulations: Visualization of the lag before a change in context is detected by the agent during the E trials. Each line represents one run (10 runs per group).}
\label{fig:vaswani-2013}
\end{figure}

This effect is explained in our model in terms of context inference. In \fref{fig:vaswani-2013}C, the inference over context is shown for each group separately. Context inference works reliably until the error-clamp trials start, which do not correspond to any of the known contexts. This causes the agent to infer the combination of some of the known contexts that best fits the observations. Depending on the contexts previously learned by the agent (which change from group to group), inference during E trials will vary: groups 1.1 and 1.4 have exactly the same behavior, where the previous context (A and -A, respectively) slowly dwindles. These agents will slowly lower the force applied until eventually reaching zero (after hundreds of trials; not shown). In contrast, group 1.3 has learned the additional -A/2 context (represented by brown in \fref{fig:vaswani-2013}C), which has a non-zero posterior probability during E trials, pushing the agent's adaptation force more quickly towards zero. Group 1.2 behaves similarly to 1.1, with the exception that the baseline context, which was recently seen, plays a bigger role during E trials, making the agent reduce its force during E trials slightly more slowly than groups 1.1 and 1.4.

Our model also reproduces the variability in the lag before adaptation starts to drop to zero after the E block starts. In the model, this lag is due to a period in which context inference has not ``caught on'' to the change of context; during this period, behavior remains consistent with that of the previously-observed block, as can be seen in the experimental data as well. To show this, we show in \fref{fig:vaswani-2013}D the drop in the inferred probability of the previous context for each simulated run (one line per run, 10 runs per group, all groups). The start and speed of the drop depend on the run (i.e. the participant), reproducing the different lags observed in experimental data. This can also be seen directly in context inference, displayed as the shaded areas in \fref{fig:vaswani-2013}C.


\section{Discussion}
We presented a hierarchical model for motor adaptation based on Bayesian inference, which not only learns to adapt its motor outputs by observing errors, but also infers the context in which these errors were committed and updates the forward model associated with that context.

Similar models have been presented before \cite[e.g.][]{Wolpert_Multiple_1998,Baddeley_System_2003,Imamizu_Explicit_2007}, which infer the internal models (forward and backward) that best explain the observations and use them to issue motor command. We built on these studies in two important ways: (1) we generalized the inference over the best-fitting internal models to the concept of context inference, which includes all sensory information, in addition to feedback provided by the experimenters or the task; (2) we showed how this seemingly small generalization provides a parsimonious explanation for several experimental phenomena across many experiments in motor adaptation that, up to now, had required multiple \textit{ad hoc} mechanisms.

We selected representative experimental studies that show savings, quick de-adaptation, spontaneous recovery and the effects of sensory cues. Using our model, we showed how each of these effects can be explained by the specifics of context inference, which integrates all the available information (e.g. sensory cues, workspace location, reward and endpoint feedback), in some cases throughout many trials.

It is important to note that the most essential part of the model we presented is the concept of the context and the inclusion of a Bayesian inference scheme over the context, which integrates all the information that is available to the participant during the experiment. Most notably, we chose to make use of exact Bayesian inference for motor adaptation, with conjugate priors to derive exact update equations. This choice greatly simplified our simulations and provides intuitive interpretations of experimental results. However, we expect the results we presented here to hold using alternative models for motor adaptation, such as Kalman filter-based learners \cite[e.g.][]{Oh_Minimizing_2019,Baddeley_System_2003} and other Bayesian implementations \cite[e.g.][]{Wolpert_Multiple_1998,Kording_Bayesian_2004}. A well established family of models for motor adaptation is linear learners \cite[e.g.][]{Smith_Interacting_2006,Forano_Timescales_2020,Lee_Dual_2009}, however, these models do not incorporate uncertainty in the estimate of the parameters of the internal models, which would limit their implementation in our hierarchical model.

In what follows, we review the experimental literature to highlight the importance of contextual information and its effects on observed behavior during motor learning tasks, as shown by our model. In addition, we discuss several predictions that our model makes, which could be verified experimentally in future studies.

\subsection{Alternative explanations}
For each of the representative studies presented in the Results section, the authors put forward explanations for the phenomena they observed in their data. While our model provides a single explanation for all these phenomena, it is not necessarily at odds with those presented by the respective authors and might instead act on top of the explanations the authors presented.

\cite{Oh_Minimizing_2019} posited that the difference between their two groups (~\fref{fig:oh-2019}B and C) can be explained by considering that the smaller visual rotation of 10 degrees caused participants to update their baseline forward model instead of creating a new forward model for the context. If such an account were true, it would predict that when participants walk away from the experiment they would have trouble adapting to the no-rotation reality, having to re-learn it. Our model instead would suggest that participants would immediately switch back to their baseline movements the moment they walk away from the computer screen, as that is a clear indication that the context has switched back to baseline. More generally, our model predicts that the observed difference between the two groups would disappear if clear sensory contextual cues were added to the experiment.

The paradigm by \cite{Herzfeld_memory_2014} was designed to test the hypothesis that a memory of errors affected the speed with which participants adapted to curl forces. While it has been shown that sensitivity to error can be modulated \citep{Marko_Sensitivity_2012}, and indeed in our model it depends on the amount of experience (see \sref{sec:interpreting-hyperparameters}), to our knowledge there are no other experiments suggesting that it depends on the history of errors. As before, the introduction of clear sensory contextual cues would allow us to gauge the importance of context inference and of previous errors in the observed data. The same applies to the experiments by \cite{Davidson_Scaling_2004}.

\subsection{Further experimental evidence}
Context is often directly observable, either via environmental cues or via feedback observed after actions. In many behavioral experiments, for example, the context of the current block of trials is easily identifiable by the color of a cue light \citep[e.g.][]{Ethier_Spontaneous_2008}, the posture of the hand \citep[e.g.][]{Gandolfo_Motor_1996}, the target of the movement \citep[e.g.][]{Lee_Dual_2009} or by the workspace in which the task is being performed \citep[e.g.][]{Shadmehr_Adaptive_1994}. The context can also be selected by the agent itself. For example, a person can decide the level of care devoted to moving an egg or a lead ball around, which determines the way in which the person would move their hands. In these cases, the context is clearly determined and known to the agent and switches between different adaptations are immediate.

In other cases, however, the context might not be directly observable, and context inference takes the form of an evidence-accumulating process that can take any amount of time to be sure of the context. It is in these cases where the effects of context inference are most noticeable. While many experiments exist that give probabilistic contextual information \cite[e.g.][]{Scholz_uncontrolled_1999,Behrens_Learning_2007,Nassar_Dissociable_2019}, evidence accumulation is not limited to these explicit cases. Indeed, as we noted in the Results section, many experiments inadvertently include partial contextual information used by participants.

The most direct secondary contextual information comes in the form of reward and endpoint feedback. Participants are told whether they obtained the desired reward at the end of a trial and are shown the end point of their movement. When a participant observes an error that is too large to explain with the expected motor variability, this information can be used to infer that the inferred context might be incorrect. This is the case of the experiments by \cite{Oh_Minimizing_2019} shown in \fref{fig:oh-2019}B-C: if the adaptation is high, changes in context produce errors much larger than those of motor variability, and a context switch is easily and immediately identified; if adaptation is low, the errors produced by context switching are closer in magnitude to motor variability and evidence accumulation is necessary.

The same rationale explains the results by \cite{Davidson_Scaling_2004}: motor learning, which in our model is modulated by context inference, is minimal for errors close to 2 and -2 (see their figure 2E). This is because an error of 2 or -2 signals that the participant incorrectly identified the context (as adaptation has a magnitude of 1).

A subtler source of information can be found in long pauses between blocks of adaptation trials. \cite{Ethier_Spontaneous_2008} performed an experiment where the adaptation blocks were divided into sub-blocks of 60 trials each, with a long 30s pause between sub-blocks. The authors observed that at the beginning of each sub-block, participants showed an average dip in their learned adaptation, suggesting that they were partially returning to baseline (O) after each pause. This can be explained by context inference, as a long pause could prompt participants to infer that a switch had occurred. Because this was inferred without any information that points at the identity of the new context, prior beliefs take over. This means that participants rely on their belief of the underlying probability of observing any of the known contexts, which is dominated by the previously observed context A, but now includes a component of the baseline O, as it is the most common one in everyday life.

Error-clamp (E) trials present another insight. During E trials, error is artificially kept at zero. This takes different forms, depending on the type of experiment. If error is kept at zero, one could assume that participants would continue doing what they were doing before, as there is no reason (no observed error) to infer a change in context. However, this is almost never the case \cite[e.g.][]{Smith_Interacting_2006,Ethier_Spontaneous_2008,Forano_Timescales_2020,Vaswani_Decay_2013,Scheidt_Persistence_2000,Pekny_Protection_2011}. Instead, participants slowly reduce their adaptation, often displaying spontaneous recovery \cite[e.g.][]{Smith_Interacting_2006}, i.e. an initial response in the direction of one of the learned adaptations. Our model provides a principled account of this behavior: while the observed error (i.e. the cursor on the screen) is kept at zero, participants still receive proprioceptive feedback which tells them that something has changed. The natural variability in a participant's behavior will lead her to expect observing errors, which clashes with the observed zero error. This prompts the participant to re-evaluate their inferred context, which can partially activate a previously-learned adaptation, as we showed in \fref{fig:vaswani-2013}. \cite{Pekny_Protection_2011} found similar results, demonstrating that the duration of the previously-observed adaptation block also affects behavior in the E block. Additionally, \cite{Criscimagna-Hemminger_Consolidation_2008} showed that introducing long periods before the E block begins lowers the initial force that participants exerted on the mechanical arm during the E block; longer periods of time make context inference revert to the prior expectation that a new baseline block begins, because participants are free to move their arm about during the pause.

In our account, if all information indicating a change in context is removed from the experiment, participants would continue to behave as they were in the previous block. Evidence for this can be seen in experiments 2 and 3 by \cite{Vaswani_Decay_2013}, where participants were shown random errors during E trials, with a variance matching that of previously observed motor commands. The authors showed that by matching the errors expected by participants, they eliminated the slow tapering off observed in most E blocks. As we showed in \fref{fig:vaswani-2013}D, this effect need not be all or none: in some experimental sessions, participants might fail to notice that a change has occurred due to the stochasticity of their own actions. This would lead to an observed delay before a participant changes her behavior after the E block has started.


\subsection{Model predictions and future work}
The basic principle behind the results we presented is that context inference is a process that develops over time and that carries with it uncertainty. This uncertainty affects learning and behavior during motor adaptation, effecting phenomena that are directly observable during behavioral experiments.

In addition to providing a unifying explanation for phenomena such as switching, savings, spontaneous recovery and slow return to baseline, our model makes unique predictions that could be tested in future experiments.

\subsubsection{Error-clamp as a context}
The inclusion of reliable sensory contextual cues (e.g. lights whose color uniquely identify a context) makes switching immediate, as in the experiments by \cite{Kim_Neural_2015}. We expect that the same effect would be observed in error-clamp trials. If the E block is learned by participants during training, it might still be difficult for them to infer that an E block has started, which would create delays similar to those in \fref{fig:vaswani-2013}. However, the model predicts that if a visual cue is introduced that identifies the E block, participants would immediately switch to their baseline behavior, no longer displaying spontaneous recovery, lag, nor the slow return to baseline. This immediate switch in the presence of contextual cues would persist even if endpoint feedback is manipulated as \cite{Vaswani_Decay_2013} did.

\subsubsection{Volatility has no effect on learning}
Experiments \citep{Herzfeld_memory_2014} have shown an effect of the volatility of the environment (i.e. unpredictable switching between contexts) on measured learning rate. Our model predicts that this effect would be greatly reduced if reliable contextual cues were introduced: if a participant can infer the context of the current trial before any decision or observation has occurred, the learning rate would not be affected by the volatility of the environment. In the experiments by \cite{Herzfeld_memory_2014}, participants had to adapt to two contexts, and the context could change from trial to trial, with a fix probability. This probability was different for two groups of participants. Our model predicts that no discernible differences would be observed between the participants that performed the task in a highly volatile environment, and those that performed in a very stable environment.

If this prediction is confirmed, our model would additionally suggest that human participants do not revisit the learned adaptation of the last trial when a new observation comes in. To see this, consider the following scenario from the experiments by \cite{Herzfeld_memory_2014}: at trial $t$, the true context was B but the participant inferred context A, issued a motor command consistent with context A and then observed the outcome at $t + 1$. When the outcome is observed, it becomes clear to the participant that the context was B. Does the participant update the internal model of A or of B? According to our model, the participant incorrectly updates A and, upon learning of her mistake at trial $t+1$, does not revert this update. If this were not the case, the volatility of the environment would have no effect, as the context at trial $t$ can almost always be identified at trial $t+1$.

\subsubsection{Multi-source integration}
The model also predicts an effect reminiscent of multisensory integration \citep[e.g.][]{Ernst_Humans_2002}: in order to integrate contextual information from conflicting sources (e.g. probabilistic visual cues and noisy endpoint feedback), the weight placed on a source increases with its reliability (e.g. the inverse of its variance). Such integration would manifest itself in experiments in which observations are noisy, as in the experiments by \cite{Kording_Bayesian_2004}, in which the position of the finger was obscured and instead participants are shown a blurry cursor which was some times shifted from its real position. If the added observation noise gives evidence for a particular context (the true underlying context or another one) and a visual cue gave partial information for another context, the participants' behavior would be more consistent with the most reliable source of contextual information.

\subsubsection{Adaptation history affects lag in E blocks}
As \cite{Vaswani_Decay_2013} discussed, participants had different delays before their behavior is modified after entering the E block. Our model presents the same run-dependent delay, as can be seen in \fref{fig:vaswani-2013}D. In addition, the model predicts that this delay depends on the history of adaptation, as evidenced by the red group having very small delays (one or two trials) compared to the other groups. Importantly, \cite{Vaswani_Decay_2013} found no significant difference between groups in their fitted parameter for delay, contrary to our results. This discrepancy could be due to the models used by \cite{Vaswani_Decay_2013} to determine the lag, but could also point to an explicit component of inertia that is missing from our model. Future experimental and modelling work is needed to understand this.

\section{Methods}
\subsection{Model description}
\label{subsection:model-description}
We first describe the general principle behind the model, followed, in the next
subsection, by the full mathematical description of each one of its components.

Before proceeding with the model description, let us introduce nomenclature:
\begin{itemize}
\item $t$: Discrete time at the moment an observation is made, before inference is done. 
Here taken as the trial number.
\item $\vartheta_t$: Observation. Note that this is assumed to be a noisy
observation of the generalized state (see below)
\item $s_t$: Hidden state, e.g. the position of the hand in reaching
experiments. It does not depend on the context.
\item $c_t$: Motor command (action) taken after observing $\vartheta_t$ and inferring the context.
\item $\zeta_t$: Categorical variable representing the context inferred after observing $\vartheta_t$.
\item $\omega_t$: Contextual information. This term includes, e.g. visual cues,
proprioceptive feedback, performance feedback.
\item $z_t$: Generalized state, $z_t = \{s_t, \zeta_t\}$. Observed noisily
as $\vartheta_t$.
\item $m_i$: Forward model for context $\zeta_i$.
\item $\phi_i$: Parametrization of the forward model $m_i$. In adaptation experiments, this
can be interpreted as the inferred size of the adaptation.
\end{itemize}

Context inference can work through context-specific (possibly unreliable) sensory cues,
or through the dynamics of the system (e.g. expected outputs of motor
commands), using prediction error as the force behind inference. In this case,
the generative model can be written as follows:
\[
p(z_t, \vartheta_t | z_{t-1}, c_{t-1}) = p(\vartheta_t | z_t)p(z_t|\z_{t-1}, c_{t-1})
\]
and inferring the current (hidden) generalized state is done with Bayes' theorem:
\[
  q(z_t | \vartheta_t, \vartheta_{t-1}, c_{t-1}) \propto p(\vartheta_t | z_t)p(z_t|\vartheta_{t-1}, c_{t-1})
\]
  
Additionally, after having inferred the current state, motor adaptation is given by
\[
q(\phi | z_t, z_{t-1}, c_{t-1}) \propto p(z_t | z_{t-1}, c_{t-1}, \phi)q(z_{t-1}|\ldots)p(\phi)
\]
where $\phi$ are the parameters of the internal model for the dynamics, also called the forward model,
i.e. the function $f: (z_t, c_t) \rightarrow z_{t+1}$, which determines the beliefs of
the agent regarding how the system evolves after having taken action $c_t$. $q(z_{t-1}|\ldots)$ is the
posterior probability calculated in the previous trial.

Having inferred the generalized state (including context), a motor command is
sampled from a distribution:
\begin{equation}
p(c_t | s_t, \zeta_t) = \displaystyle\sum_{i}q(\zeta_i)p(c_t | s_t, \zeta_i)
\end{equation}
where $i$ runs over all contexts and $p(a_t | ... m)$ is the probability distribution over actions
prescribed by the forward model $m_i$ for context $\zeta_i$.

In the following sections, we present a specific mathematical implementation
of the principles outlined above. This is the implementation used throughout the
simulations in the Results section.

\subsubsection{Mathematical implementation}
The generalized state is given by:
\begin{equation}
z_t = \{s_t, \zeta_t\}
\end{equation}
where $s_t$ is, e.g. in a reaching task, the current position of the hand in
Cartesian coordinates, where the origin is the starting point. We assume that
motor commands are issued every $\Delta t$ for simplicity. At the beginning of
each time interval, the context is inferred combining the contextual
information and the prediction error of the outcome of the previous motor
command. This yields:
\begin{align}
  \begin{split}
  q(\zeta_t) &= q(\zeta_t | \omega_t)q(\zeta_t | s_t, s_{t-1}, c_{t-1}) \\ \label{eqn:estimated-context}
  q(\zeta_t | \omega_t) &\propto p(\omega_t | \zeta_t)p(\zeta_t) \\
  q(\zeta_t | s_t, s_{t-1}, c_{t-1}) &\propto p(s_t | \zeta_t, s_{t-1}, c_{t-1})p(\zeta_t)
  \end{split}
\end{align}
The terms $p(\zeta_t)$ refer to the prior probability of the context at the
beginning of the trial: at the first trial, this refers to prior beliefs over
which contexts are more common/likely, which we call $p_0(\zeta_t)$. At each
subsequent trial, it incorporates the belief that has so far been accumulated,
given previous trials. Note that certain events, such as the start of a new
block of trials (see main text) can return an agent to a state in which
$p_0(\zeta_t)$ becomes relevant.

We do not directly model hand movements or eye position. Instead, we model
systems in the motor error space: the position $s_t = 0$ represents a trial in
which no motor error occurred. We make use of the fact that in most
experiments, motor adaptation needs to happen in one of two directions
(e.g. clockwise vs. counter-clockwise) to keep the error space
one-dimensional. With this, $s_t > 0$ represents motor error in one direction
(e.g. clockwise) and $s_t < 0$, error in the other direction. We made this
choice because in this work we modeled different experiments with
different state spaces, but with the commonality of (at most)
two-dimensional error spaces. In order to model a specific experiment in its
own physical space (e.g. hand positions in a reaching task), only the dynamical
system  $p(s_t | \zeta_t, s_{t-1}, c_{t-1})$ would need to be adapted.

We assume that the decision-making agent has a baseline internal forward model $m_O$ that
maps motor commands to outcomes:
\begin{equation}
p(s_{t+1} | s_t, c_t, m=m_O) = f_O(s_t, c_t)
\end{equation}
where $c_t$ are motor commands (actions). We further assume that participants
have learned $f_O$ throughout their lives and use it to decide which motor
command to issue under normal circumstances (i.e. no adaptation). When a
perturbation is introduced, to which the participant must adapt, we assume they
learn a new forward model $f_m^{\phi}$, where $\phi$ represents the parameters
of the function that participants must learn. For example, in a saccade task,
$\phi$ represents the new gain. Note that $\phi$ depends on the context and
participants may need to use and update multiple forward adapted models
$f_m^{\phi}$ throughout one experiment.

Given a forward model $f_m$ (or $f_m^\phi$), action selection is done by
building a probability distribution over possible actions $c_t$ based on how
likely they are to produce zero motor error. For example, in saccade
experiments, motor commands are issued based on how likely they are to move the
fovea to the target. These motor commands are issued to counteract intrinsic
sources of error, such as muscle variability and exhaustion, and extrinsic
sources of error, such as the experimental manipulations on saccade gain. Thus,
the expected observed error can be written as:
\begin{equation}
p(\epsilon | c_t) \propto p(\epsilon_{\text{intrinsic}} | c_t) + p(\epsilon_{\text{extrinsic}} | c_t)
\end{equation}
and a motor command can be chosen to maximize the chance of observing zero error:
\begin{equation}
p(c_t) = argmin_{c_t} p(\epsilon | c_t)
\end{equation}

For simplicity, we assume that motor errors are Gaussian, such that:
\begin{equation}
p(\epsilon | c_t) = N(\mu_{\text{extrinsic}}, \sigma_\epsilon)
\end{equation}
where $\sigma_\epsilon$ incorporates both intrinsic and extrinsic sources of
error and is a free parameter of the model. The mean of the error is assumed to
have no intrinsic component.

With this, a forward model will produce a motor command with outcomes centered
at $-\mu_{\text{extrinsic}}$, which counteracts the externally-induced errors.

To complete the action-selection picture, we return to context inference. As
discussed above, action selection is made via a weighted sum of the motor commands
produced by each forward model:
\begin{equation}
p(c_t | ...) \propto \displaystyle \sum_{i} q(\zeta_i)p(c_t | \zeta_i, ...)
\end{equation}
From this distribution, an action is sampled at each trial.

To update the agent's estimates on the parameters of the forward models, we
make use of Bayes' theorem with conjugate priors. This approach has the
advantage of not only greatly simplifying computational calculations, but also
presenting update equations with intuitive appeal.

In the following equations, we drop the dependence on the context and
observations for notational simplicity:
\begin{equation}
q(\phi | s_{1:t}) \propto p(s_{1:t} | \phi)p(\phi)
\end{equation}
where $s_{1:t}$ are the observed states up until time $t$. The likelihood is a
Gaussian:
\begin{align}
  p(s_t | \phi) &= N(\mu_s, \sigma_s)  \\
  \mu_s &= \phi + s_t \\
  \sigma_s &= \xi_0 1
\end{align}
This likelihood is the probability of observing $s$ given the previous estimate
of the parameters of the forward model, $\phi_{t-1}$, and given the dynamics of
the system (see below).

To update $\phi$, we assumed that for each context, the agent's belief over
the magnitude of the adaptation is given by a normal distribution:
\begin{equation}
p(\phi) = N(\mu_\phi, \sigma_\phi) \label{eqn:data-dist}
\end{equation}
where $\mu_\phi$ and $\sigma_\phi$ are parameters to be estimated at each
trial. Before the experiment begins, the agent will have a prior distribution
over these parameters. A standard Bayesian approach is to choose NormalGamma
priors:
\begin{equation}
p(\mu_\phi, \sigma_\phi) = NG(\mu_0, \nu_0, \alpha_0, \beta_0)
\end{equation}
where $\mu_{\phi}^0, \nu_{\phi}^0, \alpha_{\phi}^0$ and $\beta_{\phi}^0$ are free
hyperparameters of the model.

The update equations for the magnitude parameters are given by:
\begin{equation}
q(\mu_\phi, \sigma_\phi | s_t, s_{t-1}, c_{t-1}) \propto p(s_t |
s_{t-1}, c_{t-1}, \zeta_t)p(\mu_\phi, \sigma_\phi) \label{eqn:context-from-x}
\end{equation}
where $p(s_t | s_{t-1}, c_{t-1}, \zeta_t)$ is a Gaussian distribution centered
around $\mu_c$ with standard deviation $\sigma_c$, which is a free parameter of
the model. It is assumed that the standard deviation over outcomes ($\sigma_c$)
is related to that of the parameter $\mu_\phi$ as follows:
\begin{equation}
\sigma_\phi = \sigma_c / \nu_\phi
\end{equation}
which makes $\nu_\phi$ a parameter to estimate. Each one of the forward models can
be updated at every trial, depending on context inference (see main text). The
updated parameters for any one forward model $i$ are given by:
\begin{align}
  \begin{split}
  \mu_\phi^{(t)} &= \frac{\nu_\phi^{(t-1)} \mu_\phi^{(t-1)} + q(\zeta_i)s_t}{\nu_\phi^{(t-1)} + q(\zeta_i)} \\
  \nu_\phi^{(t)} &= \nu_\phi^{(t-1)} + q(\zeta_i) \\
  \alpha_\phi^{(t)} &= \alpha_\phi^{(t-1)} + q(\zeta_i) / 2 \\
  \beta_\phi^{(t)} &= \beta_\phi^{(t-1)} + \frac{q(\zeta_i)\nu_\phi^{(t-1)}}{\nu_\phi^{(t-1)} +
    q(\zeta_i)}\frac{\left(s_t - \mu_\phi^{(t-1)}\right)^2}{2}  \label{eqn:update-full}
  \end{split}
\end{align}
where $q(\zeta_i)$ is the posterior probability of context $\zeta_i$ from
\eref{eqn:estimated-context}. Note that when $q(\zeta_i) = 0$, the model $i$ is not
updated.

\subsubsection{Interpreting the hyperparameters}
\label{sec:interpreting-hyperparameters}
$\mu$ determines the initial estimate of the adaptation, in the same units as
the necessary adaptation. $\nu$ encodes how stable this hyperprior is: higher
values (e.g. 10,000) all but guarantee that the hypermean will not change its
value after observations; In principle, enough evidence should still modify it,
but that would not happen during an experiment. Smaller values (i.e. $\sim 1$)
make the hypermean follow evidence more freely. Note that as more observations
are accumulated, $\nu$ becomes bigger and bigger, stabilizing the value of the
hypermean.

The hyperparameters $\alpha$ and $\beta$ have a more complex effect. Note that
the mean of a gamma distribution is $1 / (\alpha \nu)$; this mean is being used
as the standard deviation of a Gaussian by the rest of the agent, which makes it
an important measure of uncertainty. While setting the default hyperparameters,
the values used are $\alpha = 0.5 / \sigma_0$ and $\beta = 0.5$, where
$\sigma_0$ is the \textit{a priori} estimate of the standard deviation of the
force exerted by the environment, which controls the initial learning rate. This
makes the initial standard deviation equal $\sigma_0$, which makes it consistent
with the fixed-force model. The 0.5 values ensure that uncertainty is large at
the beginning and is greatly reduced during the experiment, but never to a point
where it is so small that it makes trial-to-trial variation in the environment
surprising. Changing this 0.5 would make the standard deviation change more
quickly, making the model more or less precise in its predictions, independently
of the volatility of the mean of the adaptation (via the hypermean).

The baseline model defaults to different values that make it a lot more
stable. The hyper-standard deviation of the mean is set to 10,000, which makes
the mean entirely stable during the duration of the experiment. The values of
$\alpha$ and $\beta$ are fixed regardless of $\sigma_0$ such that the standard
deviation is 0.001 (compared that to the size of the adaptations in mechanical
arm experiments, around 0.0125), and the hyperparameters of the standard
deviation are stable during the experiment.


\section{Acknowledgment}
Funded by the German Research Foundation (DFG, Deutsche Forschungsgemeinschaft) as part of Germany’s Excellence Strategy – EXC 2050/1 – Project ID 390696704 – Cluster of Excellence “Centre for Tactile Internet with Human-in-the-Loop” (CeTI) of Technische Universität Dresden.

\bibliography{MyLibrary}



\end{document}
